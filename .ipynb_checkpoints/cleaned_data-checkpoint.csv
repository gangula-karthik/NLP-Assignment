,Text,Author,length,preprocessed_text
0,Scoring in PROC DISCRIM is as easy as validation. Specify a valid data set name in the TESTOUT= option to save scored (classified) observations to an output data set. Testing Discriminant Functions on a New Data Set,AM,215,"['scoring', 'proc', 'discrim', 'easy', 'validation', 'specify', 'valid', 'data_set', 'name', 'testout', 'option', 'save', 'scored', 'classified', 'observation', 'output', 'data_set', 'testing', 'discriminant_function', 'new', 'data_set']"
1,"In the GLM procedure, you may have used LSMEANS and MEANS statements to generate pairwise tests of group differences for a model. However, there are many times when pairwise differences are not the tests of interest in an analysis. Particularly in multivariate analyses, testing every possible pair of groups on several dependent variables can be very inefficient. For example, you may only be interested in the difference between a control group and one of the treatments on one of your dependent measures. Or you may want to compare the average of a few different control groups to a treatment group. The CONTRAST statement enables you to test any linear combination of cell means. The ESTIMATE statement enables you to estimate any linear combination as well as conduct the test.",AM,782,"['glm', 'procedure', 'may', 'used', 'lsmeans', 'mean', 'statement', 'generate', 'pairwise', 'test', 'group', 'difference', 'model', 'however', 'many', 'time', 'pairwise', 'difference', 'test', 'interest', 'analysis', 'particularly', 'multivariate', 'analysis', 'testing', 'every', 'possible', 'pair', 'group', 'several', 'dependent', 'variable', 'inefficient', 'example', 'may', 'interested', 'difference', 'control', 'group', 'one', 'treatment', 'one', 'dependent', 'measure', 'may', 'want', 'compare', 'average', 'different', 'control', 'group', 'treatment', 'group', 'contrast', 'statement', 'enables', 'test', 'linear', 'combination', 'cell', 'mean', 'estimate', 'statement', 'enables', 'estimate', 'linear', 'combination', 'well', 'conduct', 'test']"
2,"The first problem, accuracy of the data file, is a problem for essentially any statistical analysis. Investigate summary reports using the MEANS procedure and frequency tables using the FREQ procedure. Look for observations that are outside of the reasonable range for the variables. Drop duplicated observations in the data using the SORT procedure with the NODUPKEY option. You can also use PROC FORMAT to specify a formatted value for any values of your variable that are not in a specified range or on a specified list. This enables you to quickly and easily identify many of your incorrect data values. If you find problems, document them and try to learn what caused the problem. Correct any mis- keyed values, filter out duplicated observations, and so on. !	If you are interested in learning more about screening data files for accuracy, Cody?s Data Cleaning Techniques Using SAS Software by Ron Cody or the instructor-based course Data Cleaning Techniques are strongly recommended.",AM,990,"['first', 'problem', 'accuracy', 'data', 'file', 'problem', 'essentially', 'statistical', 'analysis', 'investigate', 'summary', 'report', 'using', 'mean', 'procedure', 'frequency', 'table', 'using', 'freq', 'procedure', 'look', 'observation', 'outside', 'reasonable', 'range', 'variable', 'drop', 'duplicated', 'observation', 'data', 'using', 'sort', 'procedure', 'nodupkey', 'option', 'also', 'use', 'proc', 'format', 'specify', 'formatted', 'value', 'value', 'variable', 'specified', 'range', 'specified', 'list', 'enables', 'quickly', 'easily', 'identify', 'many', 'incorrect', 'data', 'value', 'find', 'problem', 'document', 'try', 'learn', 'caused', 'problem', 'correct', 'mi', 'keyed', 'value', 'filter', 'duplicated', 'observation', '\tif', 'interested', 'learning', 'screening', 'data', 'file', 'accuracy', 'cody', 'data', 'cleaning', 'technique', 'using', 'sa', 'software', 'ron', 'cody', 'instructorbased', 'course', 'data', 'cleaning', 'technique', 'strongly', 'recommended']"
3,"If the homogeneity of covariance matrices assumption is violated, it is possible to perform the discriminant analysis using information about each of the groups separately. In this case, a third term is added to the generalized squared distance formula: the natural log of the determinant of the covariance matrix for each group. This is known as quadratic discriminant analysis. If the determinant of a covariance matrix for a group is large, this suggests large within-group variability. Using g1(t) results in the generalized squared distance from observations to group centroids being larger for that group than for groups with smaller within-group variability. Recall in the example you saw in the first section that the control group had the widest variability on the CDA plot. The Steady group had the smallest variability. It is possible that in this example, the assumption of homogeneity of covariance matrices was violated.",AM,934,"['homogeneity', 'covariance', 'matrix', 'assumption', 'violated', 'possible', 'perform', 'discriminant_analysis', 'using', 'information', 'group', 'separately', 'case', 'third', 'term', 'added', 'generalized', 'squared', 'distance', 'formula', 'natural', 'log', 'determinant', 'covariance', 'matrix', 'group', 'known', 'quadratic', 'discriminant_analysis', 'determinant', 'covariance', 'matrix', 'group', 'large', 'suggests', 'large', 'withingroup', 'variability', 'using', 'g1t', 'result', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'larger', 'group', 'group', 'smaller', 'withingroup', 'variability', 'recall', 'example', 'saw', 'first', 'section', 'control', 'group', 'widest', 'variability', 'cda', 'plot', 'steady', 'group', 'smallest', 'variability', 'possible', 'example', 'assumption', 'homogeneity', 'covariance', 'matrix', 'wa', 'violated']"
4,"With a CONTRAST statement, you specify L, in this case, a vector of coefficients for the effect to be tested. M is a transformation matrix that in this case is an identity matrix. For this reason, M is sometimes dropped from the null hypothesis specification. CONTRAST	enables you to perform custom hypothesis tests by specifying an L vector or matrix for testing the univariate hypothesis . There is no limit to the number of CONTRAST statements you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE	enables you to estimate linear functions of the parameters by multiplying the vector L by the parameter estimate vector b resulting in Lb. There is no limit to the number of ESTIMATE statements that you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE statements only perform 1-df univariate tests. In the CONTRAST and ESTIMATE statements, label	applies a label to the contrast (or estimate) on the output. A label is required for every contrast (or estimate) specified. Labels must be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement, or the INTERCEPT effect. The INTERCEPT effect can be used when an intercept is fitted in the model. You do not need to include all effects that are in the MODEL statement. values	are constants that are elements of the L vector associated with the effect. You do not need to include trailing zeros in the L vector.",AM,1490,"['contrast', 'statement', 'specify', 'l', 'case', 'vector', 'coefficient', 'effect', 'tested', 'transformation', 'matrix', 'case', 'identity', 'matrix', 'reason', 'sometimes', 'dropped', 'null', 'hypothesis', 'specification', 'contrast\tenables', 'perform', 'custom', 'hypothesis', 'test', 'specifying', 'l', 'vector', 'matrix', 'testing', 'univariate', 'hypothesis', '', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate\tenables', 'estimate', 'linear', 'function', 'parameter', 'multiplying', 'vector', 'l', 'parameter_estimate', 'vector', 'b', 'resulting', 'lb', 'limit', 'number', 'estimate', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate', 'statement', 'perform', '1df', 'univariate', 'test', 'contrast', 'estimate', 'statement', 'label\tapplies', 'label', 'contrast', 'estimate', 'output', 'label', 'required', 'every', 'contrast', 'estimate', 'specified', 'label', 'must', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'intercept', 'effect', 'intercept', 'effect', 'used', 'intercept', 'fitted', 'model', 'need', 'include', 'effect', 'model_statement', 'values\tare', 'constant', 'element', 'l', 'vector', 'associated', 'effect', 'need', 'include', 'trailing', 'zero', 'l', 'vector']"
5,"There are many ways to specify a contrast. Perhaps the easiest method is by using the cell means model. Writing contrasts with the cell means model enables you to specify any contrast you are interested in. However, it is very important to understand that this model specification method is used for simplifying the contrasts, and it does not generally produce an overall test of model fit that researchers are interested in. In specifying coefficients for a CONTRAST or ESTIMATE statement, ordering of the terms is determined by the order in which variables appear in the CLASS statement. The levels of each factor are expressed in alphanumeric order. ?	If you are uncertain about the order of the terms in your model, specify the SOLUTION option in the MODEL statement in PROC GLM. This will display a table of parameter estimates, and you will see the order in which the contrast terms should be specified.",AM,909,"['many', 'way', 'specify', 'contrast', 'perhaps', 'easiest', 'method', 'using', 'cell', 'mean', 'model', 'writing', 'contrast', 'cell', 'mean', 'model', 'enables', 'specify', 'contrast', 'interested', 'however', 'important', 'understand', 'model', 'specification', 'method', 'used', 'simplifying', 'contrast', 'doe', 'generally', 'produce', 'overall', 'test', 'model', 'fit', 'researcher', 'interested', 'specifying', 'coefficient', 'contrast', 'estimate', 'statement', 'ordering', 'term', 'determined', 'order', 'variable', 'appear', 'class', 'statement', 'level', 'factor', 'expressed', 'alphanumeric', 'order', '\tif', 'uncertain', 'order', 'term', 'model', 'specify', 'solution', 'option', 'model_statement', 'proc', 'glm', 'display', 'table', 'parameter_estimate', 'see', 'order', 'contrast', 'term', 'specified']"
6,"Consider an agricultural example. Suppose you were interested in predicting crop type (corn, cotton, and soybeans) based on a series of remote sensing measures. You could perform canonical correlation analysis for this data set by recoding the groups with values of 0,1 creating dummy codes, or indicator variables. You would have two indicator variables for three crops. You could treat these variables as one group, V, and the set of predictors (the remote sensing measures) as a second set of variables, W. The plot above shows the two canonical variates. Canonical correlation analysis on the data would help you find the first linear combination of each set of variables that maximizes the correlation between them, then find the second combination, uncorrelated with the first, that maximizes the correlation among the second pair of variates, and so on. Canonical correlation analysis with a set of indicator variables is the same as canonical discriminant analysis.",AM,973,"['consider', 'agricultural', 'example', 'suppose', 'interested', 'predicting', 'crop', 'type', 'corn', 'cotton', 'soybean', 'based', 'series', 'remote', 'sensing', 'measure', 'could', 'perform', 'canonical', 'correlation', 'analysis', 'data_set', 'recoding', 'group', 'value', '01', 'creating', 'dummy', 'code', 'indicator', 'variable', 'would', 'two', 'indicator', 'variable', 'three', 'crop', 'could', 'treat', 'variable', 'one', 'group', 'v', 'set', 'predictor', 'remote', 'sensing', 'measure', 'second', 'set', 'variable', 'w', 'plot', 'show', 'two', 'canonical', 'variate', 'canonical', 'correlation', 'analysis', 'data', 'would', 'help', 'find', 'first', 'linear', 'combination', 'set', 'variable', 'maximizes', 'correlation', 'find', 'second', 'combination', 'uncorrelated', 'first', 'maximizes', 'correlation', 'among', 'second', 'pair', 'variate', 'canonical', 'correlation', 'analysis', 'set', 'indicator', 'variable', 'canonical', 'discriminant_analysis']"
7,"With a CONTRAST statement, you specify L, in this case, a vector of coefficients for the effect to be tested. M is a transformation matrix that in this case is an identity matrix. For this reason, M is sometimes dropped from the null hypothesis specification. CONTRAST	enables you to perform custom hypothesis tests by specifying an L vector or matrix for testing the univariate hypothesis . There is no limit to the number of CONTRAST statements you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE	enables you to estimate linear functions of the parameters by multiplying the vector L by the parameter estimate vector b resulting in Lb. There is no limit to the number of ESTIMATE statements that you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE statements only perform 1-df univariate tests. In the CONTRAST and ESTIMATE statements, label	applies a label to the contrast (or estimate) on the output. A label is required for every contrast (or estimate) specified. Labels must be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement, or the INTERCEPT effect. The INTERCEPT effect can be used when an intercept is fitted in the model. You do not need to include all effects that are in the MODEL statement. values	are constants that are elements of the L vector associated with the effect. You do not need to include trailing zeros in the L vector.",AM,1490,"['contrast', 'statement', 'specify', 'l', 'case', 'vector', 'coefficient', 'effect', 'tested', 'transformation', 'matrix', 'case', 'identity', 'matrix', 'reason', 'sometimes', 'dropped', 'null', 'hypothesis', 'specification', 'contrast\tenables', 'perform', 'custom', 'hypothesis', 'test', 'specifying', 'l', 'vector', 'matrix', 'testing', 'univariate', 'hypothesis', '', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate\tenables', 'estimate', 'linear', 'function', 'parameter', 'multiplying', 'vector', 'l', 'parameter_estimate', 'vector', 'b', 'resulting', 'lb', 'limit', 'number', 'estimate', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate', 'statement', 'perform', '1df', 'univariate', 'test', 'contrast', 'estimate', 'statement', 'label\tapplies', 'label', 'contrast', 'estimate', 'output', 'label', 'required', 'every', 'contrast', 'estimate', 'specified', 'label', 'must', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'intercept', 'effect', 'intercept', 'effect', 'used', 'intercept', 'fitted', 'model', 'need', 'include', 'effect', 'model_statement', 'values\tare', 'constant', 'element', 'l', 'vector', 'associated', 'effect', 'need', 'include', 'trailing', 'zero', 'l', 'vector']"
8,"Univariate ANOVA as a method of interpreting multivariate effects often fails to produce the useful interpretation needed for data analysis. In this chapter, you will see ANOVA as a method of evaluating multivariate effects. Later you will learn to use canonical discriminant analysis to interpret multivariate group differences in a way that retains the multidimensional associations in the data. Multivariate Analysis of Variance",AM,431,"['univariate', 'anova', 'method', 'interpreting', 'multivariate', 'effect', 'often', 'fails', 'produce', 'useful', 'interpretation', 'needed', 'data', 'analysis', 'chapter', 'see', 'anova', 'method', 'evaluating', 'multivariate', 'effect', 'later', 'learn', 'use', 'canonical', 'discriminant_analysis', 'interpret', 'multivariate', 'group', 'difference', 'way', 'retains', 'multidimensional', 'association', 'data', 'multivariate', 'analysis', 'variance']"
9,"Where ANOVA tests for differences among group means, MANOVA tests for differences among the multivariate centroids of groups. In MANOVA, correlations among dependent variables can have dramatic effects on the inference based on the resulting linear model.",AM,255,"['anova', 'test', 'difference', 'among', 'group', 'mean', 'manova', 'test', 'difference', 'among', 'multivariate', 'centroid', 'group', 'manova', 'correlation', 'among', 'dependent', 'variable', 'dramatic', 'effect', 'inference', 'based', 'resulting', 'linear', 'model']"
10,"Many of the important issues in this chapter such as data accuracy and missing data apply to all statistical analyses, including univariate statistics, inferential statistics, and descriptive statistics. Some issues are unique to multivariate statistics, and some topics are unique to inferential statistics.",AM,308,"['many', 'important', 'issue', 'chapter', 'data', 'accuracy', 'missing', 'data', 'apply', 'statistical', 'analysis', 'including', 'univariate', 'statistic', 'inferential', 'statistic', 'descriptive', 'statistic', 'issue', 'unique', 'multivariate', 'statistic', 'topic', 'unique', 'inferential', 'statistic']"
11,"There are many ways to specify a contrast. Perhaps the easiest method is by using the cell means model. Writing contrasts with the cell means model enables you to specify any contrast you are interested in. However, it is very important to understand that this model specification method is used for simplifying the contrasts, and it does not generally produce an overall test of model fit that researchers are interested in. In specifying coefficients for a CONTRAST or ESTIMATE statement, ordering of the terms is determined by the order in which variables appear in the CLASS statement. The levels of each factor are expressed in alphanumeric order. ?	If you are uncertain about the order of the terms in your model, specify the SOLUTION option in the MODEL statement in PROC GLM. This will display a table of parameter estimates, and you will see the order in which the contrast terms should be specified.",AM,909,"['many', 'way', 'specify', 'contrast', 'perhaps', 'easiest', 'method', 'using', 'cell', 'mean', 'model', 'writing', 'contrast', 'cell', 'mean', 'model', 'enables', 'specify', 'contrast', 'interested', 'however', 'important', 'understand', 'model', 'specification', 'method', 'used', 'simplifying', 'contrast', 'doe', 'generally', 'produce', 'overall', 'test', 'model', 'fit', 'researcher', 'interested', 'specifying', 'coefficient', 'contrast', 'estimate', 'statement', 'ordering', 'term', 'determined', 'order', 'variable', 'appear', 'class', 'statement', 'level', 'factor', 'expressed', 'alphanumeric', 'order', '\tif', 'uncertain', 'order', 'term', 'model', 'specify', 'solution', 'option', 'model_statement', 'proc', 'glm', 'display', 'table', 'parameter_estimate', 'see', 'order', 'contrast', 'term', 'specified']"
12,"It is useful to examine the means of the subgroups on each of the canonical discriminant functions. The space defined by the canonical discriminant functions is the space that maximally separates the group centroids (multivariate mean vectors). In this case, you see that the first canonical discriminant function seems to be mostly separating the Binge and the Steady gamblers, and the second canonical discriminant function appears to be separating the Control group from the Steady gamblers. If your data set is very large, it is often useful to plot the group centroids in the space defined by the canonical discriminant functions to get an idea of how well the group centroids are separated. In this case, the data set is sufficiently small that you can plot the individual observations in the space defined by the discriminant functions. ?	Although it is not shown here, you could use ODS to save the centroids from the Class Means on Canonical Variables table and plot them using the GPLOT procedure. An example program, CDA plot with centroids.sas, is included with the course data.",AM,1090,"['useful', 'examine', 'mean', 'subgroup', 'canonical', 'discriminant_function', 'space', 'defined', 'canonical', 'discriminant_function', 'space', 'maximally', 'separate', 'group', 'centroid', 'multivariate', 'mean', 'vector', 'case', 'see', 'first', 'canonical', 'discriminant_function', 'seems', 'mostly', 'separating', 'binge', 'steady', 'gambler', 'second', 'canonical', 'discriminant_function', 'appears', 'separating', 'control', 'group', 'steady', 'gambler', 'data_set', 'large', 'often', 'useful', 'plot', 'group', 'centroid', 'space', 'defined', 'canonical', 'discriminant_function', 'get', 'idea', 'well', 'group', 'centroid', 'separated', 'case', 'data_set', 'sufficiently', 'small', 'plot', 'individual', 'observation', 'space', 'defined', 'discriminant_function', '\talthough', 'shown', 'could', 'use', 'od', 'save', 'centroid', 'class', 'mean', 'canonical', 'variable', 'table', 'plot', 'using', 'gplot', 'procedure', 'example', 'program', 'cda', 'plot', 'centroidssas', 'included', 'course', 'data']"
13,"To understand exactly how canonical discriminant analysis is performed, consider the model for one-way MANOVA. The goal for MANOVA is to test for equality of the mean vector across class levels. In canonical discriminant analyses, you find linear combinations of the quantitative variables that provide maximal separation between the groups. This is done by deriving canonical variates.",AM,386,"['understand', 'exactly', 'canonical', 'discriminant_analysis', 'performed', 'consider', 'model', 'oneway', 'manova', 'goal', 'manova', 'test', 'equality', 'mean', 'vector', 'across', 'class', 'level', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'quantitative', 'variable', 'provide', 'maximal', 'separation', 'group', 'done', 'deriving', 'canonical', 'variate']"
14,"The first problem, accuracy of the data file, is a problem for essentially any statistical analysis. Investigate summary reports using the MEANS procedure and frequency tables using the FREQ procedure. Look for observations that are outside of the reasonable range for the variables. Drop duplicated observations in the data using the SORT procedure with the NODUPKEY option. You can also use PROC FORMAT to specify a formatted value for any values of your variable that are not in a specified range or on a specified list. This enables you to quickly and easily identify many of your incorrect data values. If you find problems, document them and try to learn what caused the problem. Correct any mis- keyed values, filter out duplicated observations, and so on. !	If you are interested in learning more about screening data files for accuracy, Cody?s Data Cleaning Techniques Using SAS Software by Ron Cody or the instructor-based course Data Cleaning Techniques are strongly recommended.",AM,990,"['first', 'problem', 'accuracy', 'data', 'file', 'problem', 'essentially', 'statistical', 'analysis', 'investigate', 'summary', 'report', 'using', 'mean', 'procedure', 'frequency', 'table', 'using', 'freq', 'procedure', 'look', 'observation', 'outside', 'reasonable', 'range', 'variable', 'drop', 'duplicated', 'observation', 'data', 'using', 'sort', 'procedure', 'nodupkey', 'option', 'also', 'use', 'proc', 'format', 'specify', 'formatted', 'value', 'value', 'variable', 'specified', 'range', 'specified', 'list', 'enables', 'quickly', 'easily', 'identify', 'many', 'incorrect', 'data', 'value', 'find', 'problem', 'document', 'try', 'learn', 'caused', 'problem', 'correct', 'mi', 'keyed', 'value', 'filter', 'duplicated', 'observation', '\tif', 'interested', 'learning', 'screening', 'data', 'file', 'accuracy', 'cody', 'data', 'cleaning', 'technique', 'using', 'sa', 'software', 'ron', 'cody', 'instructorbased', 'course', 'data', 'cleaning', 'technique', 'strongly', 'recommended']"
15,"To understand exactly how canonical discriminant analysis is performed, consider the model for one-way MANOVA. The goal for MANOVA is to test for equality of the mean vector across class levels. In canonical discriminant analyses, you find linear combinations of the quantitative variables that provide maximal separation between the groups. This is done by deriving canonical variates.",AM,386,"['understand', 'exactly', 'canonical', 'discriminant_analysis', 'performed', 'consider', 'model', 'oneway', 'manova', 'goal', 'manova', 'test', 'equality', 'mean', 'vector', 'across', 'class', 'level', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'quantitative', 'variable', 'provide', 'maximal', 'separation', 'group', 'done', 'deriving', 'canonical', 'variate']"
16,"Sometimes you have a significant multivariate effect and no significant univariate effects. Sometime just the opposite occurs?nonsignificant multivariate effects and significant univariate effects. There are several reasons that this may occur, among them type-I error, type-II error, multivariate outliers, and collinearity among the responses. You can use univariate ANOVA to try to interpret your MV effects. By default, the univariate ANOVA for each response is shown. You can suppress the default univariate ANOVA output with the NOUNI option in the MODEL statement. You can obtain an abbreviated summary of the univariate ANOVAs by including the SUMMARY option in MANOVA statement. Later, you will learn to use discriminant analysis, which allows you a multivariate method for interpreting group differences that is often preferable to univariate ANOVA.",AM,859,"['sometimes', 'significant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'sometime', 'opposite', 'occursnonsignificant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'several', 'reason', 'may', 'occur', 'among', 'typei', 'error', 'typeii', 'error', 'multivariate', 'outlier', 'collinearity', 'among', 'response', 'use', 'univariate', 'anova', 'try', 'interpret', 'mv', 'effect', 'default', 'univariate', 'anova', 'response', 'shown', 'suppress', 'default', 'univariate', 'anova', 'output', 'nouni', 'option', 'model_statement', 'obtain', 'abbreviated', 'summary', 'univariate', 'anova', 'including', 'summary', 'option', 'manova', 'statement', 'later', 'learn', 'use', 'discriminant_analysis', 'allows', 'multivariate', 'method', 'interpreting', 'group', 'difference', 'often', 'preferable', 'univariate', 'anova']"
17,"Create a table of the cell means in your model. The ordering of the variables is determined by the order of the variables in the CLASS statement. The first independent variable represents the rows. The second represents the columns. Specify the contrast hypothesis in terms of the cell means, as shown below:",AM,308,"['create', 'table', 'cell', 'mean', 'model', 'ordering', 'variable', 'determined', 'order', 'variable', 'class', 'statement', 'first', 'independent', 'variable', 'represents', 'row', 'second', 'represents', 'column', 'specify', 'contrast', 'hypothesis', 'term', 'cell', 'mean', 'shown']"
18,"Sometimes values fall within the possible range on a variable but far from the other values in the data. Sometimes, as in the picture above, an observation may fall within the normal ranges on several variables, but the pattern of several variables reveals a multivariate outlier. Outliers can be problematic for a variety of reasons. Many analyses that assume normality are sensitive to outliers. Linear statistical models such as ANOVA and regression are sensitive to the effects of outliers.",AM,494,"['sometimes', 'value', 'fall', 'within', 'possible', 'range', 'variable', 'far', 'value', 'data', 'sometimes', 'picture', 'observation', 'may', 'fall', 'within', 'normal', 'range', 'several', 'variable', 'pattern', 'several', 'variable', 'reveals', 'multivariate', 'outlier', 'outlier', 'problematic', 'variety', 'reason', 'many', 'analysis', 'assume', 'normality', 'sensitive', 'outlier', 'linear', 'statistical', 'model', 'anova', 'regression', 'sensitive', 'effect', 'outlier']"
19,"You express the coefficients as integers by multiplying them by a constant. There are situations when you want to use the CONTRAST statement and the ESTIMATE statement together, such as when you are performing comparisons with more than one degree of freedom and you want the estimates from the tests. If you were only interested in the significance test from the contrast and not in the estimates, then you would use the CONTRAST statement only. The ESTIMATE statement for this contrast would be the same as the CONTRAST statement, except you would also include the DIVISOR= option to tell SAS to divide each estimate by 3 (so you can get the mean of the cell, instead of 3 ? the mean of the cell): In the following example, you will see both the CONTRAST and the ESTIMATE statements used. Using Contrasts for Custom Hypothesis Tests",AM,834,"['express', 'coefficient', 'integer', 'multiplying', 'constant', 'situation', 'want', 'use', 'contrast', 'statement', 'estimate', 'statement', 'together', 'performing', 'comparison', 'one', 'degree', 'freedom', 'want', 'estimate', 'test', 'interested', 'significance', 'test', 'contrast', 'estimate', 'would', 'use', 'contrast', 'statement', 'estimate', 'statement', 'contrast', 'would', 'contrast', 'statement', 'except', 'would', 'also', 'include', 'divisor', 'option', 'tell', 'sa', 'divide', 'estimate', '3', 'get', 'mean', 'cell', 'instead', '3', '', 'mean', 'cell', 'following', 'example', 'see', 'contrast', 'estimate', 'statement', 'used', 'using', 'contrast', 'custom', 'hypothesis', 'test']"
20,"Consider the example you just saw. Because the same data that are being classified are also used to create the discriminant functions, the analysis capitalizes on chance. You saw a predicted error rate of 4% in the population. However, that assumes that the population is exactly like the sample you observed and has exactly the priors that you specified. Both of these conditions are unlikely to be met, and the first one is certainly unreasonable. It is very important to empirically validate the results of a discriminant analysis on new data before using the results of a discriminant analysis to predict group membership. To do this, use the first data set as the calibration data set, and use the second data set as the validation data set. ?	If a new data set is not available, you can perform crossvalidation of the data by using a one-observation holdout method that computes the discriminant function for each data point from all the remaining data with that observation left out.",AM,990,"['consider', 'example', 'saw', 'data', 'classified', 'also', 'used', 'create', 'discriminant_function', 'analysis', 'capitalizes', 'chance', 'saw', 'predicted', 'error', 'rate', '4', 'population', 'however', 'assumes', 'population', 'exactly', 'like', 'sample', 'observed', 'ha', 'exactly', 'prior', 'specified', 'condition', 'unlikely', 'met', 'first', 'one', 'certainly', 'unreasonable', 'important', 'empirically', 'validate', 'result', 'discriminant_analysis', 'new', 'data', 'using', 'result', 'discriminant_analysis', 'predict', 'group', 'membership', 'use', 'first', 'data_set', 'calibration', 'data_set', 'use', 'second', 'data_set', 'validation', 'data_set', '\tif', 'new', 'data_set', 'available', 'perform', 'crossvalidation', 'data', 'using', 'oneobservation', 'holdout', 'method', 'computes', 'discriminant_function', 'data', 'point', 'remaining', 'data', 'observation', 'left']"
21,"When there are multiple dependent measures for a factorial design, multivariate analysis of variance (MANOVA) can be a very useful tool in determining whether groups differ on a set of measures. Sometimes you are interested in specific comparisons between pairs of groups, between one group and a combination of groups, or perhaps other comparisons. Contrasts in the GLM procedure enable you to test custom hypotheses about your population. After you learn to fit multivariate models using SAS, you learn to apply other multivariate methods using SAS such as factor analysis, structural equation models, and discriminant function analysis.",AM,639,"['multiple', 'dependent', 'measure', 'factorial', 'design', 'multivariate', 'analysis', 'variance', 'manova', 'useful', 'tool', 'determining', 'whether', 'group', 'differ', 'set', 'measure', 'sometimes', 'interested', 'specific', 'comparison', 'pair', 'group', 'one', 'group', 'combination', 'group', 'perhaps', 'comparison', 'contrast', 'glm', 'procedure', 'enable', 'test', 'custom', 'hypothesis', 'population', 'learn', 'fit', 'multivariate', 'model', 'using', 'sa', 'learn', 'apply', 'multivariate', 'method', 'using', 'sa', 'factor', 'analysis', 'structural', 'equation', 'model', 'discriminant_function', 'analysis']"
22,"In the DISCRIM procedure, the POOL= option controls whether linear or quadratic discriminant analysis is performed. Is you specify POOL=YES (the default), DISCRIM performs linear discriminant analysis. POOL=NO requests quadratic discriminant analysis. You can also request a chi-square test of homogeneity of covariance matrices with the option POOL=TEST. The test for homogeneity of covariance matrices uses a chi-square statistic that assumes that the data are multivariate normal. The null hypothesis of the test is that the within-group covariance matrices are equal to the pooled covariance matrix. If you specify POOL=TEST, the default alpha for the test is 0.05. You can change this using the SLPOOL= option. If you reject the null hypothesis for this test, PROC DISCRIM automatically performs quadratic discriminant analysis. If the null hypothesis is not rejected, PROC DISCRIM performs linear discriminant analysis.",AM,925,"['discrim', 'procedure', 'pool', 'option', 'control', 'whether', 'linear', 'quadratic', 'discriminant_analysis', 'performed', 'specify', 'poolyes', 'default', 'discrim', 'performs', 'linear', 'discriminant_analysis', 'poolno', 'request', 'quadratic', 'discriminant_analysis', 'also', 'request', 'chisquare', 'test', 'homogeneity', 'covariance', 'matrix', 'option', 'pooltest', 'test', 'homogeneity', 'covariance', 'matrix', 'us', 'chisquare', 'statistic', 'assumes', 'data', 'multivariate', 'normal', 'null', 'hypothesis', 'test', 'withingroup', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'specify', 'pooltest', 'default', 'alpha', 'test', '005', 'change', 'using', 'slpool', 'option', 'reject', 'null', 'hypothesis', 'test', 'proc', 'discrim', 'automatically', 'performs', 'quadratic', 'discriminant_analysis', 'null', 'hypothesis', 'rejected', 'proc', 'discrim', 'performs', 'linear', 'discriminant_analysis']"
23,"Related to the problem of restricted range is the problem of zero or near-zero group sizes. Many kinds of statistical estimates are unstable at small samples. Furthermore, dramatically unequal group sizes pose a problem for models such as MANOVA, which assume equal variances and covariances across groups.",AM,306,"['related', 'problem', 'restricted', 'range', 'problem', 'zero', 'nearzero', 'group', 'size', 'many', 'kind', 'statistical', 'estimate', 'unstable', 'small', 'sample', 'furthermore', 'dramatically', 'unequal', 'group', 'size', 'pose', 'problem', 'model', 'manova', 'assume', 'equal', 'variance', 'covariance', 'across', 'group']"
24,"Many of the recommendations for restricted ranges apply to unequal group sizes. Careful planning is key to avoiding the problem of unequal group sizes. If you have enough small groups that are reasonably similar, you may be able to combine smaller groups and compare them to the larger group(s).",AM,295,"['many', 'recommendation', 'restricted', 'range', 'apply', 'unequal', 'group', 'size', 'careful', 'planning', 'key', 'avoiding', 'problem', 'unequal', 'group', 'size', 'enough', 'small', 'group', 'reasonably', 'similar', 'may', 'able', 'combine', 'smaller', 'group', 'compare', 'larger', 'group']"
25,Scoring in PROC DISCRIM is as easy as validation. Specify a valid data set name in the TESTOUT= option to save scored (classified) observations to an output data set. Testing Discriminant Functions on a New Data Set,AM,215,"['scoring', 'proc', 'discrim', 'easy', 'validation', 'specify', 'valid', 'data_set', 'name', 'testout', 'option', 'save', 'scored', 'classified', 'observation', 'output', 'data_set', 'testing', 'discriminant_function', 'new', 'data_set']"
26,"It is useful to examine the means of the subgroups on each of the canonical discriminant functions. The space defined by the canonical discriminant functions is the space that maximally separates the group centroids (multivariate mean vectors). In this case, you see that the first canonical discriminant function seems to be mostly separating the Binge and the Steady gamblers, and the second canonical discriminant function appears to be separating the Control group from the Steady gamblers. If your data set is very large, it is often useful to plot the group centroids in the space defined by the canonical discriminant functions to get an idea of how well the group centroids are separated. In this case, the data set is sufficiently small that you can plot the individual observations in the space defined by the discriminant functions. ?	Although it is not shown here, you could use ODS to save the centroids from the Class Means on Canonical Variables table and plot them using the GPLOT procedure. An example program, CDA plot with centroids.sas, is included with the course data.",AM,1090,"['useful', 'examine', 'mean', 'subgroup', 'canonical', 'discriminant_function', 'space', 'defined', 'canonical', 'discriminant_function', 'space', 'maximally', 'separate', 'group', 'centroid', 'multivariate', 'mean', 'vector', 'case', 'see', 'first', 'canonical', 'discriminant_function', 'seems', 'mostly', 'separating', 'binge', 'steady', 'gambler', 'second', 'canonical', 'discriminant_function', 'appears', 'separating', 'control', 'group', 'steady', 'gambler', 'data_set', 'large', 'often', 'useful', 'plot', 'group', 'centroid', 'space', 'defined', 'canonical', 'discriminant_function', 'get', 'idea', 'well', 'group', 'centroid', 'separated', 'case', 'data_set', 'sufficiently', 'small', 'plot', 'individual', 'observation', 'space', 'defined', 'discriminant_function', '\talthough', 'shown', 'could', 'use', 'od', 'save', 'centroid', 'class', 'mean', 'canonical', 'variable', 'table', 'plot', 'using', 'gplot', 'procedure', 'example', 'program', 'cda', 'plot', 'centroidssas', 'included', 'course', 'data']"
27,"Repeat this to create plots of Carb*Calories, Carb*TFat and Carb* Protein. Select outliers on each plot and find the corresponding observations on the other plots.",AM,163,"['repeat', 'create', 'plot', 'carbcalories', 'carbtfat', 'carb', 'protein', 'select', 'outlier', 'plot', 'find', 'corresponding', 'observation', 'plot']"
28,"There are two procedures in SAS that can be used to perform canonical discriminant analysis: the DISCRIM procedure and the CANDISC procedure. PROC DISCRIM is more general than PROC CANDISC and can be used to perform both steps of discriminant analysis shown above. PROC CANDISC performs the first step only. However, PROC CANDISC produces output that is generally more familiar to users and may be easier to interpret. If you are simply trying to find the combinations of variables that predict group membership, it is simpler to use PROC CANDISC. ?	You will learn to use PROC DISCRIM later in the chapter.",AM,606,"['two', 'procedure', 'sa', 'used', 'perform', 'canonical', 'discriminant_analysis', 'discrim', 'procedure', 'candisc', 'procedure', 'proc', 'discrim', 'general', 'proc', 'candisc', 'used', 'perform', 'step', 'discriminant_analysis', 'shown', 'proc', 'candisc', 'performs', 'first', 'step', 'however', 'proc', 'candisc', 'produce', 'output', 'generally', 'familiar', 'user', 'may', 'easier', 'interpret', 'simply', 'trying', 'find', 'combination', 'variable', 'predict', 'group', 'membership', 'simpler', 'use', 'proc', 'candisc', '\tyou', 'learn', 'use', 'proc', 'discrim', 'later', 'chapter']"
29,"Presume you are investigating variables that are related to career success among university faculty (number of publications, years experience, type of university, salary, job satisfaction). For the most part, higher salaries are associated with a higher number of publications. However, a few participants in your study have relatively low salaries and a somewhat large number of publications. These participants, although not necessarily outliers on any one variable, are outliers on the combination of these two variables. When you are interested specifically in multivariate outliers, there are myriad options. Two methods that are emphasized here are scatter plots and principal components analysis. Scatter plots of two or three variables at a time can reveal multivariate outliers that you might have missed using univariate plots only. Three-way rotatable plots enable you to look at the relationships among three variables at a time. Sometimes, however, even three-way plots can fail to reveal multivariate outliers in greater than three-dimensional space. Sometimes it is simply inefficient to create so many two-and three-way plots. In such situations, principal components analysis can be valuable. Recall that principal components are linear combinations of variables that account for the most variance with the first component, the second most with the second component, and so on. By consolidating most of the variance into one or two variables and looking over histograms of the components, you can easily spot multivariate outliers in your data.",AM,1561,"['presume', 'investigating', 'variable', 'related', 'career', 'success', 'among', 'university', 'faculty', 'number', 'publication', 'year', 'experience', 'type', 'university', 'salary', 'job', 'satisfaction', 'part', 'higher', 'salary', 'associated', 'higher', 'number', 'publication', 'however', 'participant', 'study', 'relatively', 'low', 'salary', 'somewhat', 'large', 'number', 'publication', 'participant', 'although', 'necessarily', 'outlier', 'one', 'variable', 'outlier', 'combination', 'two', 'variable', 'interested', 'specifically', 'multivariate', 'outlier', 'myriad', 'option', 'two', 'method', 'emphasized', 'scatter', 'plot', 'principal', 'component', 'analysis', 'scatter', 'plot', 'two', 'three', 'variable', 'time', 'reveal', 'multivariate', 'outlier', 'might', 'missed', 'using', 'univariate', 'plot', 'threeway', 'rotatable', 'plot', 'enable', 'look', 'relationship', 'among', 'three', 'variable', 'time', 'sometimes', 'however', 'even', 'threeway', 'plot', 'fail', 'reveal', 'multivariate', 'outlier', 'greater', 'threedimensional', 'space', 'sometimes', 'simply', 'inefficient', 'create', 'many', 'twoand', 'threeway', 'plot', 'situation', 'principal', 'component', 'analysis', 'valuable', 'recall', 'principal', 'component', 'linear', 'combination', 'variable', 'account', 'variance', 'first', 'component', 'second', 'second', 'component', 'consolidating', 'variance', 'one', 'two', 'variable', 'looking', 'histogram', 'component', 'easily', 'spot', 'multivariate', 'outlier', 'data']"
30,"Many types of studies exhibit problems with restricted range on variables. If a variable demonstrates restricted range, it does not have enough variability to be useful as a continuous variable in your analyses. An example of restricted range is shown above. In your study of university professors, you suspect that more years of education would be associated with greater career success. However, the vast majority of university professors have many years of education. There are very few who have less than a doctoral or perhaps a master?s degree. The restriction of range demonstrated here is sometimes known as a ceiling effect because the restriction is at the high end (the ceiling) of the data. The opposite of the ceiling effect is known as a floor effect. For example, if you were interested in reducing the risk of heart attacks among women between 20-30 years of age, you would likely run into a floor effect because very few women between 20 and 30 years of age have heart attacks, and it would be difficult to reduce this amount further with an intervention.",AM,1071,"['many', 'type', 'study', 'exhibit', 'problem', 'restricted', 'range', 'variable', 'variable', 'demonstrates', 'restricted', 'range', 'doe', 'enough', 'variability', 'useful', 'continuous', 'variable', 'analysis', 'example', 'restricted', 'range', 'shown', 'study', 'university', 'professor', 'suspect', 'year', 'education', 'would', 'associated', 'greater', 'career', 'success', 'however', 'vast', 'majority', 'university', 'professor', 'many', 'year', 'education', 'le', 'doctoral', 'perhaps', 'master', 'degree', 'restriction', 'range', 'demonstrated', 'sometimes', 'known', 'ceiling', 'effect', 'restriction', 'high', 'end', 'ceiling', 'data', 'opposite', 'ceiling', 'effect', 'known', 'floor', 'effect', 'example', 'interested', 'reducing', 'risk', 'heart', 'attack', 'among', 'woman', '2030', 'year', 'age', 'would', 'likely', 'run', 'floor', 'effect', 'woman', '20', '30', 'year', 'age', 'heart', 'attack', 'would', 'difficult', 'reduce', 'amount', 'intervention']"
31,"The contrast coefficients for all the terms in the linear model are shown above. However, coefficients must be expressed as integers or decimal values. Expressing 1/3 as a decimal value can be problematic, so the values must be multiplied by a constant.",AM,253,"['contrast', 'coefficient', 'term', 'linear', 'model', 'shown', 'however', 'coefficient', 'must', 'expressed', 'integer', 'decimal', 'value', 'expressing', '13', 'decimal', 'value', 'problematic', 'value', 'must', 'multiplied', 'constant']"
32,"In addition to canonical discriminant analysis, there are many other methods for performing discriminant analysis. One that is commonly used is Fisher linear discriminant analysis (FLDA). Although the two approaches are conceptually similar, FLDA provides additional information beyond canonical discriminant analysis. With FLDA, the scores obtained from the analysis can be interpreted as the probability of membership in each group, for each observation. This enables you to assess the error rate in the initial data, as well as get predictions of group membership when group information is not available.",AM,607,"['addition', 'canonical', 'discriminant_analysis', 'many', 'method', 'performing', 'discriminant_analysis', 'one', 'commonly', 'used', 'fisher', 'linear', 'discriminant_analysis', 'flda', 'although', 'two', 'approach', 'conceptually', 'similar', 'flda', 'provides', 'additional', 'information', 'beyond', 'canonical', 'discriminant_analysis', 'flda', 'score', 'obtained', 'analysis', 'interpreted', 'probability', 'membership', 'group', 'observation', 'enables', 'ass', 'error', 'rate', 'initial', 'data', 'well', 'get', 'prediction', 'group', 'membership', 'group', 'information', 'available']"
33,"Sometimes you have a significant multivariate effect and no significant univariate effects. Sometime just the opposite occurs?nonsignificant multivariate effects and significant univariate effects. There are several reasons that this may occur, among them type-I error, type-II error, multivariate outliers, and collinearity among the responses. You can use univariate ANOVA to try to interpret your MV effects. By default, the univariate ANOVA for each response is shown. You can suppress the default univariate ANOVA output with the NOUNI option in the MODEL statement. You can obtain an abbreviated summary of the univariate ANOVAs by including the SUMMARY option in MANOVA statement. Later, you will learn to use discriminant analysis, which allows you a multivariate method for interpreting group differences that is often preferable to univariate ANOVA.",AM,859,"['sometimes', 'significant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'sometime', 'opposite', 'occursnonsignificant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'several', 'reason', 'may', 'occur', 'among', 'typei', 'error', 'typeii', 'error', 'multivariate', 'outlier', 'collinearity', 'among', 'response', 'use', 'univariate', 'anova', 'try', 'interpret', 'mv', 'effect', 'default', 'univariate', 'anova', 'response', 'shown', 'suppress', 'default', 'univariate', 'anova', 'output', 'nouni', 'option', 'model_statement', 'obtain', 'abbreviated', 'summary', 'univariate', 'anova', 'including', 'summary', 'option', 'manova', 'statement', 'later', 'learn', 'use', 'discriminant_analysis', 'allows', 'multivariate', 'method', 'interpreting', 'group', 'difference', 'often', 'preferable', 'univariate', 'anova']"
34,"If the homogeneity of covariance matrices assumption is violated, it is possible to perform the discriminant analysis using information about each of the groups separately. In this case, a third term is added to the generalized squared distance formula: the natural log of the determinant of the covariance matrix for each group. This is known as quadratic discriminant analysis. If the determinant of a covariance matrix for a group is large, this suggests large within-group variability. Using g1(t) results in the generalized squared distance from observations to group centroids being larger for that group than for groups with smaller within-group variability. Recall in the example you saw in the first section that the control group had the widest variability on the CDA plot. The Steady group had the smallest variability. It is possible that in this example, the assumption of homogeneity of covariance matrices was violated.",AM,934,"['homogeneity', 'covariance', 'matrix', 'assumption', 'violated', 'possible', 'perform', 'discriminant_analysis', 'using', 'information', 'group', 'separately', 'case', 'third', 'term', 'added', 'generalized', 'squared', 'distance', 'formula', 'natural', 'log', 'determinant', 'covariance', 'matrix', 'group', 'known', 'quadratic', 'discriminant_analysis', 'determinant', 'covariance', 'matrix', 'group', 'large', 'suggests', 'large', 'withingroup', 'variability', 'using', 'g1t', 'result', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'larger', 'group', 'group', 'smaller', 'withingroup', 'variability', 'recall', 'example', 'saw', 'first', 'section', 'control', 'group', 'widest', 'variability', 'cda', 'plot', 'steady', 'group', 'smallest', 'variability', 'possible', 'example', 'assumption', 'homogeneity', 'covariance', 'matrix', 'wa', 'violated']"
35,"The PROC DISCRIM statement has options that make validation on a test data set or crossvalidation within the same data easy: TESTDATA=	specifies a SAS data set to be used in validation. TESTLIST	lists the observations in the TESTDATA= data set, along with predicted group membership based on the prediction equations developed using the data specified with the DATA= option. TESTOUT=	specifies a SAS data set where the TESTDATA= data are scored. Scores include the original data, classification, and posterior probabilities for each observation. CROSSLIST	lists the observations in the DATA= data set, along with predicted group membership, by classifying each observation in the DATA= data set using a discriminant function computed from the other observations in the DATA= data set, excluding the observation being classified. CROSSVALIDATE	 specifies that crossvalidation of the input data set be performed. This is used when you do not have a second sample upon which to calibrate/test. TESTCLASS	this statement names the CLASS variable from the TESTDATA= data set to be used in the analysis. It is not required if the CLASS variable name in the TESTDATA= data set matches the CLASS variable name in the DATA= data set.",AM,1223,"['proc', 'discrim', 'statement', 'ha', 'option', 'make', 'validation', 'test', 'data_set', 'crossvalidation', 'within', 'data', 'easy', 'testdata\tspecifies', 'sa', 'data_set', 'used', 'validation', 'testlist\tlists', 'observation', 'testdata', 'data_set', 'along', 'predicted', 'group', 'membership', 'based', 'prediction', 'equation', 'developed', 'using', 'data', 'specified', 'data', 'option', 'testout\tspecifies', 'sa', 'data_set', 'testdata', 'data', 'scored', 'score', 'include', 'original', 'data', 'classification', 'posterior', 'probability', 'observation', 'crosslist\tlists', 'observation', 'data', 'data_set', 'along', 'predicted', 'group', 'membership', 'classifying', 'observation', 'data', 'data_set', 'using', 'discriminant_function', 'computed', 'observation', 'data', 'data_set', 'excluding', 'observation', 'classified', 'crossvalidate\t', 'specifies', 'crossvalidation', 'input', 'data_set', 'performed', 'used', 'second', 'sample', 'upon', 'calibratetest', 'testclass\tthis', 'statement', 'name', 'class', 'variable', 'testdata', 'data_set', 'used', 'analysis', 'required', 'class', 'variable', 'name', 'testdata', 'data_set', 'match', 'class', 'variable', 'name', 'data', 'data_set']"
36,"Related to the problem of restricted range is the problem of zero or near-zero group sizes. Many kinds of statistical estimates are unstable at small samples. Furthermore, dramatically unequal group sizes pose a problem for models such as MANOVA, which assume equal variances and covariances across groups.",AM,306,"['related', 'problem', 'restricted', 'range', 'problem', 'zero', 'nearzero', 'group', 'size', 'many', 'kind', 'statistical', 'estimate', 'unstable', 'small', 'sample', 'furthermore', 'dramatically', 'unequal', 'group', 'size', 'pose', 'problem', 'model', 'manova', 'assume', 'equal', 'variance', 'covariance', 'across', 'group']"
37,"Recall that just as ANOVA assumes that groups have equal variances, MANOVA and linear discriminant analysis both assume that groups have homogeneous covariance matrices. Violating this assumption can result in incorrect inference about group differences in MANOVA and canonical discriminant analysis. In Fisher linear discriminant analysis, it can result in incorrect prediction of group membership. Consider the generalized squared distance between observations and group centroids, above. In this formula, a single (pooled) estimate of the covariance matrix is used and therefore the formula does not reflect group differences in variances and covariances.",AM,658,"['recall', 'anova', 'assumes', 'group', 'equal', 'variance', 'manova', 'linear', 'discriminant_analysis', 'assume', 'group', 'homogeneous', 'covariance', 'matrix', 'violating', 'assumption', 'result', 'incorrect', 'inference', 'group', 'difference', 'manova', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'result', 'incorrect', 'prediction', 'group', 'membership', 'consider', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'formula', 'single', 'pooled', 'estimate', 'covariance', 'matrix', 'used', 'therefore', 'formula', 'doe', 'reflect', 'group', 'difference', 'variance', 'covariance']"
38,"The research questions above share a common thread ? prediction of groups. These questions are conceptually similar to logistic regression, which models the odds of membership in one group versus another group based on values of predictors. Discriminant function analysis can be thought of as a multivariate generalization of logistic regression, although as you will see, the computation for discriminant analysis is more similar to MANOVA or canonical correlation analysis than to logistic regression.",AM,503,"['research', 'question', 'share', 'common', 'thread', '', 'prediction', 'group', 'question', 'conceptually', 'similar', 'logistic_regression_model', 'odds', 'membership', 'one', 'group', 'versus', 'another', 'group', 'based', 'value', 'predictor', 'discriminant_function', 'analysis', 'thought', 'multivariate', 'generalization', 'logistic_regression', 'although', 'see', 'computation', 'discriminant_analysis', 'similar', 'manova', 'canonical', 'correlation', 'analysis', 'logistic_regression']"
39,"The research questions above share a common thread ? prediction of groups. These questions are conceptually similar to logistic regression, which models the odds of membership in one group versus another group based on values of predictors. Discriminant function analysis can be thought of as a multivariate generalization of logistic regression, although as you will see, the computation for discriminant analysis is more similar to MANOVA or canonical correlation analysis than to logistic regression.",AM,503,"['research', 'question', 'share', 'common', 'thread', '', 'prediction', 'group', 'question', 'conceptually', 'similar', 'logistic_regression_model', 'odds', 'membership', 'one', 'group', 'versus', 'another', 'group', 'based', 'value', 'predictor', 'discriminant_function', 'analysis', 'thought', 'multivariate', 'generalization', 'logistic_regression', 'although', 'see', 'computation', 'discriminant_analysis', 'similar', 'manova', 'canonical', 'correlation', 'analysis', 'logistic_regression']"
40,"*	examining group differences on predictor variables *	forming linear discriminant functions useful for predicting groups *	assessing error rates in predictions *	saving out statistics to apply the functions to a new set of data *	assessing how well the functions discriminate on new data *	performing quadratic discriminant analysis *	performing nearest-neighbor type and nonparametric analyses similar to discriminant analysis. Details For parametric discriminant analysis (including canonical discriminant analysis, Fisher linear discriminant analysis and quadratic discriminant analysis), the DISCRIM procedure develops a classification criterion using a method of generalized squared distance. Accounting for prior probabilities, each observation is classified in the group to which it has the smallest generalized squared distance. The generalized squared distance from an observation x to a group t is",AM,908,"['\texamining', 'group', 'difference', 'predictor_variable', '\tforming', 'linear', 'discriminant_function', 'useful', 'predicting', 'group', '\tassessing', 'error', 'rate', 'prediction', '\tsaving', 'statistic', 'apply', 'function', 'new', 'set', 'data', '\tassessing', 'well', 'function', 'discriminate', 'new', 'data', '\tperforming', 'quadratic', 'discriminant_analysis', '\tperforming', 'nearestneighbor', 'type', 'nonparametric', 'analysis', 'similar', 'discriminant_analysis', 'detail', 'parametric', 'discriminant_analysis', 'including', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'quadratic', 'discriminant_analysis', 'discrim', 'procedure', 'develops', 'classification', 'criterion', 'using', 'method', 'generalized', 'squared', 'distance', 'accounting', 'prior', 'probability', 'observation', 'classified', 'group', 'ha', 'smallest', 'generalized', 'squared', 'distance', 'generalized', 'squared', 'distance', 'observation', 'x', 'group']"
41,"When there are multiple dependent measures for a factorial design, multivariate analysis of variance (MANOVA) can be a very useful tool in determining whether groups differ on a set of measures. Sometimes you are interested in specific comparisons between pairs of groups, between one group and a combination of groups, or perhaps other comparisons. Contrasts in the GLM procedure enable you to test custom hypotheses about your population. After you learn to fit multivariate models using SAS, you learn to apply other multivariate methods using SAS such as factor analysis, structural equation models, and discriminant function analysis.",AM,639,"['multiple', 'dependent', 'measure', 'factorial', 'design', 'multivariate', 'analysis', 'variance', 'manova', 'useful', 'tool', 'determining', 'whether', 'group', 'differ', 'set', 'measure', 'sometimes', 'interested', 'specific', 'comparison', 'pair', 'group', 'one', 'group', 'combination', 'group', 'perhaps', 'comparison', 'contrast', 'glm', 'procedure', 'enable', 'test', 'custom', 'hypothesis', 'population', 'learn', 'fit', 'multivariate', 'model', 'using', 'sa', 'learn', 'apply', 'multivariate', 'method', 'using', 'sa', 'factor', 'analysis', 'structural', 'equation', 'model', 'discriminant_function', 'analysis']"
42,?	You can also rotate without using the Graph Toolbar by holding down the Alt key on your keyboard and the left mouse button. Move the cursor over the picture to rotate it while holding these two buttons.,AM,204,"['\tyou', 'also', 'rotate', 'without', 'using', 'graph', 'toolbar', 'holding', 'alt', 'key', 'keyboard', 'left', 'mouse', 'button', 'move', 'cursor', 'picture', 'rotate', 'holding', 'two', 'button']"
43,"where Vt = St if using within-group covariance matrices, or Vt = Sp if using pooled covariance matrices, and mt is the mean vector of group t. ?	The default in PROC DISCRIM is to use pooled covariances in calculating the generalized squared distances. If you prefer to use within-class covariances, specify POOL = NO in the DISCRIM statement. You will learn to use this option later in the course for quadratic discriminant analysis.",AM,433,"['vt', '', 'st', 'using', 'withingroup', 'covariance', 'matrix', 'vt', '', 'sp', 'using', 'pooled', 'covariance', 'matrix', 'mt', 'mean', 'vector', 'group', '\tthe', 'default', 'proc', 'discrim', 'use', 'pooled', 'covariance', 'calculating', 'generalized', 'squared', 'distance', 'prefer', 'use', 'withinclass', 'covariance', 'specify', 'pool', '', 'discrim', 'statement', 'learn', 'use', 'option', 'later', 'course', 'quadratic', 'discriminant_analysis']"
44,"*	examining group differences on predictor variables *	forming linear discriminant functions useful for predicting groups *	assessing error rates in predictions *	saving out statistics to apply the functions to a new set of data *	assessing how well the functions discriminate on new data *	performing quadratic discriminant analysis *	performing nearest-neighbor type and nonparametric analyses similar to discriminant analysis. Details For parametric discriminant analysis (including canonical discriminant analysis, Fisher linear discriminant analysis and quadratic discriminant analysis), the DISCRIM procedure develops a classification criterion using a method of generalized squared distance. Accounting for prior probabilities, each observation is classified in the group to which it has the smallest generalized squared distance. The generalized squared distance from an observation x to a group t is",AM,908,"['\texamining', 'group', 'difference', 'predictor_variable', '\tforming', 'linear', 'discriminant_function', 'useful', 'predicting', 'group', '\tassessing', 'error', 'rate', 'prediction', '\tsaving', 'statistic', 'apply', 'function', 'new', 'set', 'data', '\tassessing', 'well', 'function', 'discriminate', 'new', 'data', '\tperforming', 'quadratic', 'discriminant_analysis', '\tperforming', 'nearestneighbor', 'type', 'nonparametric', 'analysis', 'similar', 'discriminant_analysis', 'detail', 'parametric', 'discriminant_analysis', 'including', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'quadratic', 'discriminant_analysis', 'discrim', 'procedure', 'develops', 'classification', 'criterion', 'using', 'method', 'generalized', 'squared', 'distance', 'accounting', 'prior', 'probability', 'observation', 'classified', 'group', 'ha', 'smallest', 'generalized', 'squared', 'distance', 'generalized', 'squared', 'distance', 'observation', 'x', 'group']"
45,"In addition to canonical discriminant analysis, there are many other methods for performing discriminant analysis. One that is commonly used is Fisher linear discriminant analysis (FLDA). Although the two approaches are conceptually similar, FLDA provides additional information beyond canonical discriminant analysis. With FLDA, the scores obtained from the analysis can be interpreted as the probability of membership in each group, for each observation. This enables you to assess the error rate in the initial data, as well as get predictions of group membership when group information is not available.",AM,607,"['addition', 'canonical', 'discriminant_analysis', 'many', 'method', 'performing', 'discriminant_analysis', 'one', 'commonly', 'used', 'fisher', 'linear', 'discriminant_analysis', 'flda', 'although', 'two', 'approach', 'conceptually', 'similar', 'flda', 'provides', 'additional', 'information', 'beyond', 'canonical', 'discriminant_analysis', 'flda', 'score', 'obtained', 'analysis', 'interpreted', 'probability', 'membership', 'group', 'observation', 'enables', 'ass', 'error', 'rate', 'initial', 'data', 'well', 'get', 'prediction', 'group', 'membership', 'group', 'information', 'available']"
46,"Many types of studies exhibit problems with restricted range on variables. If a variable demonstrates restricted range, it does not have enough variability to be useful as a continuous variable in your analyses. An example of restricted range is shown above. In your study of university professors, you suspect that more years of education would be associated with greater career success. However, the vast majority of university professors have many years of education. There are very few who have less than a doctoral or perhaps a master?s degree. The restriction of range demonstrated here is sometimes known as a ceiling effect because the restriction is at the high end (the ceiling) of the data. The opposite of the ceiling effect is known as a floor effect. For example, if you were interested in reducing the risk of heart attacks among women between 20-30 years of age, you would likely run into a floor effect because very few women between 20 and 30 years of age have heart attacks, and it would be difficult to reduce this amount further with an intervention.",AM,1071,"['many', 'type', 'study', 'exhibit', 'problem', 'restricted', 'range', 'variable', 'variable', 'demonstrates', 'restricted', 'range', 'doe', 'enough', 'variability', 'useful', 'continuous', 'variable', 'analysis', 'example', 'restricted', 'range', 'shown', 'study', 'university', 'professor', 'suspect', 'year', 'education', 'would', 'associated', 'greater', 'career', 'success', 'however', 'vast', 'majority', 'university', 'professor', 'many', 'year', 'education', 'le', 'doctoral', 'perhaps', 'master', 'degree', 'restriction', 'range', 'demonstrated', 'sometimes', 'known', 'ceiling', 'effect', 'restriction', 'high', 'end', 'ceiling', 'data', 'opposite', 'ceiling', 'effect', 'known', 'floor', 'effect', 'example', 'interested', 'reducing', 'risk', 'heart', 'attack', 'among', 'woman', '2030', 'year', 'age', 'would', 'likely', 'run', 'floor', 'effect', 'woman', '20', '30', 'year', 'age', 'heart', 'attack', 'would', 'difficult', 'reduce', 'amount', 'intervention']"
47,"Canonical discriminant analysis is a classification technique closely tied to canonical correlation analysis. Given a classification variable and several quantitative variables, you can derive canonical variates that summarize between-class variation. As with canonical correlation analysis, the number of discriminant functions is to the smaller of the number of predictors or the number of groups minus one in the analysis. The canonical discriminant functions maximize the distances between the group centroids.",AM,514,"['canonical', 'discriminant_analysis', 'classification', 'technique', 'closely', 'tied', 'canonical', 'correlation', 'analysis', 'given', 'classification', 'variable', 'several', 'quantitative', 'variable', 'derive', 'canonical', 'variate', 'summarize', 'betweenclass', 'variation', 'canonical', 'correlation', 'analysis', 'number', 'discriminant_function', 'smaller', 'number', 'predictor', 'number', 'group', 'minus', 'one', 'analysis', 'canonical', 'discriminant_function', 'maximize', 'distance', 'group', 'centroid']"
48,Only the first 20 out of 100 observations are shown here. PROC DISCRIM flags misclassified observations with an asterisk. You can see that observations 12 and 13 were misclassified. Classification Summary for Calibration Data: AMUL.GAMBLEGRP Resubstitution Summary using Linear Discriminant Function,AM,299,"['first', '20', '100', 'observation', 'shown', 'proc', 'discrim', 'flag', 'misclassified', 'observation', 'asterisk', 'see', 'observation', '12', '13', 'misclassified', 'classification', 'summary', 'calibration', 'data', 'amulgamblegrp', 'resubstitution', 'summary', 'using', 'linear', 'discriminant_function']"
49,"*	examining group differences on predictor variables *	forming linear discriminant functions useful for predicting groups *	assessing error rates in predictions *	saving out statistics to apply the functions to a new set of data *	assessing how well the functions discriminate on new data *	performing quadratic discriminant analysis *	performing nearest-neighbor type and nonparametric analyses similar to discriminant analysis. Details For parametric discriminant analysis (including canonical discriminant analysis, Fisher linear discriminant analysis and quadratic discriminant analysis), the DISCRIM procedure develops a classification criterion using a method of generalized squared distance. Accounting for prior probabilities, each observation is classified in the group to which it has the smallest generalized squared distance. The generalized squared distance from an observation x to a group t is",AM,908,"['\texamining', 'group', 'difference', 'predictor_variable', '\tforming', 'linear', 'discriminant_function', 'useful', 'predicting', 'group', '\tassessing', 'error', 'rate', 'prediction', '\tsaving', 'statistic', 'apply', 'function', 'new', 'set', 'data', '\tassessing', 'well', 'function', 'discriminate', 'new', 'data', '\tperforming', 'quadratic', 'discriminant_analysis', '\tperforming', 'nearestneighbor', 'type', 'nonparametric', 'analysis', 'similar', 'discriminant_analysis', 'detail', 'parametric', 'discriminant_analysis', 'including', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'quadratic', 'discriminant_analysis', 'discrim', 'procedure', 'develops', 'classification', 'criterion', 'using', 'method', 'generalized', 'squared', 'distance', 'accounting', 'prior', 'probability', 'observation', 'classified', 'group', 'ha', 'smallest', 'generalized', 'squared', 'distance', 'generalized', 'squared', 'distance', 'observation', 'x', 'group']"
50,"In order for the test statistics in MANOVA to follow the theorized distribution, certain assumptions should be met: *	Observations are randomly sampled from the population. *	Observations are independent of one another; in other words, one observation does not provide information about other observations. *	The set of dependent variables follows a multivariate normal distribution conditional on the independent variables. This implies univariate conditional normality for each DV separately, but univariate normality alone is not sufficient for the assumption of multivariate normality to be met. *	The within-group covariance matrices are equal across groups. This implies equal variances across groups for each DV, and it also implies that all pairwise correlations between the DVs are equal across groups. As with ANOVA, MANOVA test statistics are robust to violations of some, but not all, of these assumptions. The robustness of each test statistic varies (Bray and Maxwell 1985). As a result, there is not a single test statistic that is uniformly preferred in all situations.",AM,1085,"['order', 'test', 'statistic', 'manova', 'follow', 'theorized', 'distribution', 'certain', 'assumption', 'met', '\tobservations', 'randomly', 'sampled', 'population', '\tobservations', 'independent', 'one', 'another', 'word', 'one', 'observation', 'doe', 'provide', 'information', 'observation', '\tthe', 'set', 'dependent', 'variable', 'follows', 'multivariate', 'normal', 'distribution', 'conditional', 'independent', 'variable', 'implies', 'univariate', 'conditional', 'normality', 'dv', 'separately', 'univariate', 'normality', 'alone', 'sufficient', 'assumption', 'multivariate', 'normality', 'met', '\tthe', 'withingroup', 'covariance', 'matrix', 'equal', 'across', 'group', 'implies', 'equal', 'variance', 'across', 'group', 'dv', 'also', 'implies', 'pairwise', 'correlation', 'dvs', 'equal', 'across', 'group', 'anova', 'manova', 'test', 'statistic', 'robust', 'violation', 'assumption', 'robustness', 'test', 'statistic', 'varies', 'bray', 'maxwell', '1985', 'result', 'single', 'test', 'statistic', 'uniformly', 'preferred', 'situation']"
51,"The PROC DISCRIM statement has options that make validation on a test data set or crossvalidation within the same data easy: TESTDATA=	specifies a SAS data set to be used in validation. TESTLIST	lists the observations in the TESTDATA= data set, along with predicted group membership based on the prediction equations developed using the data specified with the DATA= option. TESTOUT=	specifies a SAS data set where the TESTDATA= data are scored. Scores include the original data, classification, and posterior probabilities for each observation. CROSSLIST	lists the observations in the DATA= data set, along with predicted group membership, by classifying each observation in the DATA= data set using a discriminant function computed from the other observations in the DATA= data set, excluding the observation being classified. CROSSVALIDATE	 specifies that crossvalidation of the input data set be performed. This is used when you do not have a second sample upon which to calibrate/test. TESTCLASS	this statement names the CLASS variable from the TESTDATA= data set to be used in the analysis. It is not required if the CLASS variable name in the TESTDATA= data set matches the CLASS variable name in the DATA= data set.",AM,1223,"['proc', 'discrim', 'statement', 'ha', 'option', 'make', 'validation', 'test', 'data_set', 'crossvalidation', 'within', 'data', 'easy', 'testdata\tspecifies', 'sa', 'data_set', 'used', 'validation', 'testlist\tlists', 'observation', 'testdata', 'data_set', 'along', 'predicted', 'group', 'membership', 'based', 'prediction', 'equation', 'developed', 'using', 'data', 'specified', 'data', 'option', 'testout\tspecifies', 'sa', 'data_set', 'testdata', 'data', 'scored', 'score', 'include', 'original', 'data', 'classification', 'posterior', 'probability', 'observation', 'crosslist\tlists', 'observation', 'data', 'data_set', 'along', 'predicted', 'group', 'membership', 'classifying', 'observation', 'data', 'data_set', 'using', 'discriminant_function', 'computed', 'observation', 'data', 'data_set', 'excluding', 'observation', 'classified', 'crossvalidate\t', 'specifies', 'crossvalidation', 'input', 'data_set', 'performed', 'used', 'second', 'sample', 'upon', 'calibratetest', 'testclass\tthis', 'statement', 'name', 'class', 'variable', 'testdata', 'data_set', 'used', 'analysis', 'required', 'class', 'variable', 'name', 'testdata', 'data_set', 'match', 'class', 'variable', 'name', 'data', 'data_set']"
52,"To understand exactly how canonical discriminant analysis is performed, consider the model for one-way MANOVA. The goal for MANOVA is to test for equality of the mean vector across class levels. In canonical discriminant analyses, you find linear combinations of the quantitative variables that provide maximal separation between the groups. This is done by deriving canonical variates.",AM,386,"['understand', 'exactly', 'canonical', 'discriminant_analysis', 'performed', 'consider', 'model', 'oneway', 'manova', 'goal', 'manova', 'test', 'equality', 'mean', 'vector', 'across', 'class', 'level', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'quantitative', 'variable', 'provide', 'maximal', 'separation', 'group', 'done', 'deriving', 'canonical', 'variate']"
53,"Throughout this course, you have learned to use SAS to perform a variety of multivariate statistical analyses. It is important to understand how the analyses work, what the assumptions are, and how to interpret the results of the analyses. It is equally important to know how to evaluate the assumptions of the analyses and determine whether your data are appropriate for the kind of analysis you plan to perform. Real data is almost never as simple and straightforward as classroom data, so this chapter is devoted to helping you prepare your data for multivariate analysis.",AM,575,"['throughout', 'course', 'learned', 'use', 'sa', 'perform', 'variety', 'multivariate', 'statistical', 'analysis', 'important', 'understand', 'analysis', 'work', 'assumption', 'interpret', 'result', 'analysis', 'equally', 'important', 'know', 'evaluate', 'assumption', 'analysis', 'determine', 'whether', 'data', 'appropriate', 'kind', 'analysis', 'plan', 'perform', 'real', 'data', 'almost', 'never', 'simple', 'straightforward', 'classroom', 'data', 'chapter', 'devoted', 'helping', 'prepare', 'data', 'multivariate', 'analysis']"
54,"You used PROC CANDISC to assess the extent to which the variables discriminate between the groups. If this is your primary research goal, then you are advised to use PROC CANDISC. However, if your primary goal is to assess and apply the discriminant functions to future data in the interest of predicting group membership, then you are advised to use the DISCRIM procedure. PROC DISCRIM can be used for canonical discriminant analysis as well as other applications. Although PROC DISCRIM is capable of a wider range of analyses, the output from PROC CANDISC is generally simpler than output from PROC DISCRIM.",AM,609,"['used', 'proc', 'candisc', 'ass', 'extent', 'variable', 'discriminate', 'group', 'primary', 'research', 'goal', 'advised', 'use', 'proc', 'candisc', 'however', 'primary', 'goal', 'ass', 'apply', 'discriminant_function', 'future', 'data', 'interest', 'predicting', 'group', 'membership', 'advised', 'use', 'discrim', 'procedure', 'proc', 'discrim', 'used', 'canonical', 'discriminant_analysis', 'well', 'application', 'although', 'proc', 'discrim', 'capable', 'wider', 'range', 'analysis', 'output', 'proc', 'candisc', 'generally', 'simpler', 'output', 'proc', 'discrim']"
55,"Recall that just as ANOVA assumes that groups have equal variances, MANOVA and linear discriminant analysis both assume that groups have homogeneous covariance matrices. Violating this assumption can result in incorrect inference about group differences in MANOVA and canonical discriminant analysis. In Fisher linear discriminant analysis, it can result in incorrect prediction of group membership. Consider the generalized squared distance between observations and group centroids, above. In this formula, a single (pooled) estimate of the covariance matrix is used and therefore the formula does not reflect group differences in variances and covariances.",AM,658,"['recall', 'anova', 'assumes', 'group', 'equal', 'variance', 'manova', 'linear', 'discriminant_analysis', 'assume', 'group', 'homogeneous', 'covariance', 'matrix', 'violating', 'assumption', 'result', 'incorrect', 'inference', 'group', 'difference', 'manova', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'result', 'incorrect', 'prediction', 'group', 'membership', 'consider', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'formula', 'single', 'pooled', 'estimate', 'covariance', 'matrix', 'used', 'therefore', 'formula', 'doe', 'reflect', 'group', 'difference', 'variance', 'covariance']"
56,"The PROC DISCRIM statement has options that make validation on a test data set or crossvalidation within the same data easy: TESTDATA=	specifies a SAS data set to be used in validation. TESTLIST	lists the observations in the TESTDATA= data set, along with predicted group membership based on the prediction equations developed using the data specified with the DATA= option. TESTOUT=	specifies a SAS data set where the TESTDATA= data are scored. Scores include the original data, classification, and posterior probabilities for each observation. CROSSLIST	lists the observations in the DATA= data set, along with predicted group membership, by classifying each observation in the DATA= data set using a discriminant function computed from the other observations in the DATA= data set, excluding the observation being classified. CROSSVALIDATE	 specifies that crossvalidation of the input data set be performed. This is used when you do not have a second sample upon which to calibrate/test. TESTCLASS	this statement names the CLASS variable from the TESTDATA= data set to be used in the analysis. It is not required if the CLASS variable name in the TESTDATA= data set matches the CLASS variable name in the DATA= data set.",AM,1223,"['proc', 'discrim', 'statement', 'ha', 'option', 'make', 'validation', 'test', 'data_set', 'crossvalidation', 'within', 'data', 'easy', 'testdata\tspecifies', 'sa', 'data_set', 'used', 'validation', 'testlist\tlists', 'observation', 'testdata', 'data_set', 'along', 'predicted', 'group', 'membership', 'based', 'prediction', 'equation', 'developed', 'using', 'data', 'specified', 'data', 'option', 'testout\tspecifies', 'sa', 'data_set', 'testdata', 'data', 'scored', 'score', 'include', 'original', 'data', 'classification', 'posterior', 'probability', 'observation', 'crosslist\tlists', 'observation', 'data', 'data_set', 'along', 'predicted', 'group', 'membership', 'classifying', 'observation', 'data', 'data_set', 'using', 'discriminant_function', 'computed', 'observation', 'data', 'data_set', 'excluding', 'observation', 'classified', 'crossvalidate\t', 'specifies', 'crossvalidation', 'input', 'data_set', 'performed', 'used', 'second', 'sample', 'upon', 'calibratetest', 'testclass\tthis', 'statement', 'name', 'class', 'variable', 'testdata', 'data_set', 'used', 'analysis', 'required', 'class', 'variable', 'name', 'testdata', 'data_set', 'match', 'class', 'variable', 'name', 'data', 'data_set']"
57,"Since the Chi-Square value is significant at the 0.05 level, the within covariance matrices will be used in the discriminant function. Reference: Morrison, D.F. (1976) Multivariate Statistical Methods p252. Documentation for the test of equality of covariance matrices is provided in the DISCRIM output. Recall that the null hypothesis is that the covariance matrices are homogeneous, or that the covariance matrices are equal to the pooled covariance matrix. You reject this hypothesis. Quadratic discriminant analysis is more appropriate than linear discriminant analysis in this example, and a note in the output tells you that within covariance matrices are used in the discriminant function. Pairwise Generalized Squared Distances Between Groups",AM,750,"['since', 'chisquare', 'value', 'significant', '005', 'level', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'reference', 'morrison', 'df', '1976', 'multivariate', 'statistical', 'method', 'p252', 'documentation', 'test', 'equality', 'covariance', 'matrix', 'provided', 'discrim', 'output', 'recall', 'null', 'hypothesis', 'covariance', 'matrix', 'homogeneous', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'reject', 'hypothesis', 'quadratic', 'discriminant_analysis', 'appropriate', 'linear', 'discriminant_analysis', 'example', 'note', 'output', 'tell', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
58,"To understand exactly how canonical discriminant analysis is performed, consider the model for one-way MANOVA. The goal for MANOVA is to test for equality of the mean vector across class levels. In canonical discriminant analyses, you find linear combinations of the quantitative variables that provide maximal separation between the groups. This is done by deriving canonical variates.",AM,386,"['understand', 'exactly', 'canonical', 'discriminant_analysis', 'performed', 'consider', 'model', 'oneway', 'manova', 'goal', 'manova', 'test', 'equality', 'mean', 'vector', 'across', 'class', 'level', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'quantitative', 'variable', 'provide', 'maximal', 'separation', 'group', 'done', 'deriving', 'canonical', 'variate']"
59,"NOTE: F Statistic for Roy's Greatest Root is an upper bound. NOTE: F Statistic for Wilks' Lambda is exact. The multivariate statistics test the null hypothesis that all the canonical correlations are simultaneously zero, which is the same as the hypothesis that there is no linear prediction of group membership from the predictor variables. You reject this null hypothesis. Adjusted Approximate Squared Canonical Canonical Standard Canonical Correlation Correlation Error Correlation",AM,484,"['note', 'f', 'statistic', 'roys', 'greatest', 'root', 'upper', 'bound', 'note', 'f', 'statistic', 'wilks', 'lambda', 'exact', 'multivariate', 'statistic', 'test', 'null', 'hypothesis', 'canonical', 'correlation', 'simultaneously', 'zero', 'hypothesis', 'linear', 'prediction', 'group', 'membership', 'predictor_variable', 'reject', 'null', 'hypothesis', 'adjusted', 'approximate', 'squared', 'canonical', 'canonical', 'standard', 'canonical', 'correlation', 'correlation', 'error', 'correlation']"
60,"Univariate ANOVA as a method of interpreting multivariate effects often fails to produce the useful interpretation needed for data analysis. In this chapter, you will see ANOVA as a method of evaluating multivariate effects. Later you will learn to use canonical discriminant analysis to interpret multivariate group differences in a way that retains the multidimensional associations in the data. Multivariate Analysis of Variance",AM,431,"['univariate', 'anova', 'method', 'interpreting', 'multivariate', 'effect', 'often', 'fails', 'produce', 'useful', 'interpretation', 'needed', 'data', 'analysis', 'chapter', 'see', 'anova', 'method', 'evaluating', 'multivariate', 'effect', 'later', 'learn', 'use', 'canonical', 'discriminant_analysis', 'interpret', 'multivariate', 'group', 'difference', 'way', 'retains', 'multidimensional', 'association', 'data', 'multivariate', 'analysis', 'variance']"
61,"There are potential problems in any kind of data. Computers crash, researchers enter erroneous factor settings, data entry coders make typographical errors, and research participants fall asleep. Human error, technical difficulties in automated systems, collinear variables, duplicated records, outlying observations, and a host of other problems can plague your data. The more time you invest in validating, cleaning, preparing and checking your data, the more you will be able to reap the rewards of your statistical analyses. In addition to making the data ready for your analyses, often preparing and evaluating the data provide you with insight that you may not have gained otherwise.",AM,689,"['potential', 'problem', 'kind', 'data', 'computer', 'crash', 'researcher', 'enter', 'erroneous', 'factor', 'setting', 'data', 'entry', 'coder', 'make', 'typographical', 'error', 'research', 'participant', 'fall', 'asleep', 'human', 'error', 'technical', 'difficulty', 'automated', 'system', 'collinear', 'variable', 'duplicated', 'record', 'outlying', 'observation', 'host', 'problem', 'plague', 'data', 'time', 'invest', 'validating', 'cleaning', 'preparing', 'checking', 'data', 'able', 'reap', 'reward', 'statistical', 'analysis', 'addition', 'making', 'data', 'ready', 'analysis', 'often', 'preparing', 'evaluating', 'data', 'provide', 'insight', 'may', 'gained', 'otherwise']"
62,"There are two procedures in SAS that can be used to perform canonical discriminant analysis: the DISCRIM procedure and the CANDISC procedure. PROC DISCRIM is more general than PROC CANDISC and can be used to perform both steps of discriminant analysis shown above. PROC CANDISC performs the first step only. However, PROC CANDISC produces output that is generally more familiar to users and may be easier to interpret. If you are simply trying to find the combinations of variables that predict group membership, it is simpler to use PROC CANDISC. ?	You will learn to use PROC DISCRIM later in the chapter.",AM,606,"['two', 'procedure', 'sa', 'used', 'perform', 'canonical', 'discriminant_analysis', 'discrim', 'procedure', 'candisc', 'procedure', 'proc', 'discrim', 'general', 'proc', 'candisc', 'used', 'perform', 'step', 'discriminant_analysis', 'shown', 'proc', 'candisc', 'performs', 'first', 'step', 'however', 'proc', 'candisc', 'produce', 'output', 'generally', 'familiar', 'user', 'may', 'easier', 'interpret', 'simply', 'trying', 'find', 'combination', 'variable', 'predict', 'group', 'membership', 'simpler', 'use', 'proc', 'candisc', '\tyou', 'learn', 'use', 'proc', 'discrim', 'later', 'chapter']"
63,"A natural extension of the MANOVA research question ?How do my continuous responses differ as a function of group levels?? is the discriminant analysis research question ?How do my continuous variables predict membership in groups? With discriminant analysis, you can use parametric or nonparametric methods to *	find linear combinations of continuous variables (discriminant functions) that predict group membership *	estimate the expected misclassification rate based on the discriminant functions *	test the discriminant functions on a new sample to determine the extent to which the functions correctly and incorrectly classify observations Canonical discriminant analysis has the advantage of conceptual and computational simplicity, while Fisher linear discriminant analysis is powerful enough to allow you to find the discriminant functions and test or crossvalidate your results using one simple procedure. You learned to use two procedures in SAS to perform discriminant analysis: PROC CANDISC performs canonical discriminant analysis to find linear combinations of variables that best discriminate among groups. PROC DISCRIM performs linear and quadratic discriminant analysis and produces a prediction function to help classify observations in to groups based on a set of predictors. Remember that discriminant analysis and other predictive modeling techniques capitalize on chance associations among the predictors in your data to find the discriminant functions. For this reason it is important always to perform empirical validation on a new sample of data, or at least use crossvalidation before using the discriminant functions for prediction and scoring.",AM,1671,"['natural', 'extension', 'manova', 'research', 'question', 'continuous', 'response', 'differ', 'function', 'group', 'level', 'discriminant_analysis', 'research', 'question', 'continuous', 'variable', 'predict', 'membership', 'group', 'discriminant_analysis', 'use', 'parametric', 'nonparametric', 'method', '\tfind', 'linear', 'combination', 'continuous', 'variable', 'discriminant_function', 'predict', 'group', 'membership', '\testimate', 'expected', 'misclassification', 'rate', 'based', 'discriminant_function', '\ttest', 'discriminant_function', 'new', 'sample', 'determine', 'extent', 'function', 'correctly', 'incorrectly', 'classify', 'observation', 'canonical', 'discriminant_analysis', 'ha', 'advantage', 'conceptual', 'computational', 'simplicity', 'fisher', 'linear', 'discriminant_analysis', 'powerful', 'enough', 'allow', 'find', 'discriminant_function', 'test', 'crossvalidate', 'result', 'using', 'one', 'simple', 'procedure', 'learned', 'use', 'two', 'procedure', 'sa', 'perform', 'discriminant_analysis', 'proc', 'candisc', 'performs', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'variable', 'best', 'discriminate', 'among', 'group', 'proc', 'discrim', 'performs', 'linear', 'quadratic', 'discriminant_analysis', 'produce', 'prediction', 'function', 'help', 'classify', 'observation', 'group', 'based', 'set', 'predictor', 'remember', 'discriminant_analysis', 'predictive', 'modeling', 'technique', 'capitalize', 'chance', 'association', 'among', 'predictor', 'data', 'find', 'discriminant_function', 'reason', 'important', 'always', 'perform', 'empirical', 'validation', 'new', 'sample', 'data', 'least', 'use', 'crossvalidation', 'using', 'discriminant_function', 'prediction', 'scoring']"
64,"In the GLM procedure, you may have used LSMEANS and MEANS statements to generate pairwise tests of group differences for a model. However, there are many times when pairwise differences are not the tests of interest in an analysis. Particularly in multivariate analyses, testing every possible pair of groups on several dependent variables can be very inefficient. For example, you may only be interested in the difference between a control group and one of the treatments on one of your dependent measures. Or you may want to compare the average of a few different control groups to a treatment group. The CONTRAST statement enables you to test any linear combination of cell means. The ESTIMATE statement enables you to estimate any linear combination as well as conduct the test.",AM,782,"['glm', 'procedure', 'may', 'used', 'lsmeans', 'mean', 'statement', 'generate', 'pairwise', 'test', 'group', 'difference', 'model', 'however', 'many', 'time', 'pairwise', 'difference', 'test', 'interest', 'analysis', 'particularly', 'multivariate', 'analysis', 'testing', 'every', 'possible', 'pair', 'group', 'several', 'dependent', 'variable', 'inefficient', 'example', 'may', 'interested', 'difference', 'control', 'group', 'one', 'treatment', 'one', 'dependent', 'measure', 'may', 'want', 'compare', 'average', 'different', 'control', 'group', 'treatment', 'group', 'contrast', 'statement', 'enables', 'test', 'linear', 'combination', 'cell', 'mean', 'estimate', 'statement', 'enables', 'estimate', 'linear', 'combination', 'well', 'conduct', 'test']"
65,"Multivariate analysis of variance (MANOVA) is an extension of the concepts and techniques of ANOVA to situations with multiple dependent variables. One-way MANOVA can be used to test for group differences on several dependent variables simultaneously. Factorial MANOVA can be used to identify main effects and interactions among factors on a set of dependent variables. Unlike ANOVA, MANOVA takes into account relationships among the dependent variables as well as the relationship between independent and dependent variables.",AM,526,"['multivariate', 'analysis', 'variance', 'manova', 'extension', 'concept', 'technique', 'anova', 'situation', 'multiple', 'dependent', 'variable', 'oneway', 'manova', 'used', 'test', 'group', 'difference', 'several', 'dependent', 'variable', 'simultaneously', 'factorial', 'manova', 'used', 'identify', 'main_effect', 'interaction', 'among', 'factor', 'set', 'dependent', 'variable', 'unlike', 'anova', 'manova', 'take', 'account', 'relationship', 'among', 'dependent', 'variable', 'well', 'relationship', 'independent', 'dependent', 'variable']"
66,"In addition to canonical discriminant analysis, there are many other methods for performing discriminant analysis. One that is commonly used is Fisher linear discriminant analysis (FLDA). Although the two approaches are conceptually similar, FLDA provides additional information beyond canonical discriminant analysis. With FLDA, the scores obtained from the analysis can be interpreted as the probability of membership in each group, for each observation. This enables you to assess the error rate in the initial data, as well as get predictions of group membership when group information is not available.",AM,607,"['addition', 'canonical', 'discriminant_analysis', 'many', 'method', 'performing', 'discriminant_analysis', 'one', 'commonly', 'used', 'fisher', 'linear', 'discriminant_analysis', 'flda', 'although', 'two', 'approach', 'conceptually', 'similar', 'flda', 'provides', 'additional', 'information', 'beyond', 'canonical', 'discriminant_analysis', 'flda', 'score', 'obtained', 'analysis', 'interpreted', 'probability', 'membership', 'group', 'observation', 'enables', 'ass', 'error', 'rate', 'initial', 'data', 'well', 'get', 'prediction', 'group', 'membership', 'group', 'information', 'available']"
67,"Consider an agricultural example. Suppose you were interested in predicting crop type (corn, cotton, and soybeans) based on a series of remote sensing measures. You could perform canonical correlation analysis for this data set by recoding the groups with values of 0,1 creating dummy codes, or indicator variables. You would have two indicator variables for three crops. You could treat these variables as one group, V, and the set of predictors (the remote sensing measures) as a second set of variables, W. The plot above shows the two canonical variates. Canonical correlation analysis on the data would help you find the first linear combination of each set of variables that maximizes the correlation between them, then find the second combination, uncorrelated with the first, that maximizes the correlation among the second pair of variates, and so on. Canonical correlation analysis with a set of indicator variables is the same as canonical discriminant analysis.",AM,973,"['consider', 'agricultural', 'example', 'suppose', 'interested', 'predicting', 'crop', 'type', 'corn', 'cotton', 'soybean', 'based', 'series', 'remote', 'sensing', 'measure', 'could', 'perform', 'canonical', 'correlation', 'analysis', 'data_set', 'recoding', 'group', 'value', '01', 'creating', 'dummy', 'code', 'indicator', 'variable', 'would', 'two', 'indicator', 'variable', 'three', 'crop', 'could', 'treat', 'variable', 'one', 'group', 'v', 'set', 'predictor', 'remote', 'sensing', 'measure', 'second', 'set', 'variable', 'w', 'plot', 'show', 'two', 'canonical', 'variate', 'canonical', 'correlation', 'analysis', 'data', 'would', 'help', 'find', 'first', 'linear', 'combination', 'set', 'variable', 'maximizes', 'correlation', 'find', 'second', 'combination', 'uncorrelated', 'first', 'maximizes', 'correlation', 'among', 'second', 'pair', 'variate', 'canonical', 'correlation', 'analysis', 'set', 'indicator', 'variable', 'canonical', 'discriminant_analysis']"
68,"Repeat this to create plots of Carb*Calories, Carb*TFat and Carb* Protein. Select outliers on each plot and find the corresponding observations on the other plots.",AM,163,"['repeat', 'create', 'plot', 'carbcalories', 'carbtfat', 'carb', 'protein', 'select', 'outlier', 'plot', 'find', 'corresponding', 'observation', 'plot']"
69,"Specifying contrasts using your full model, with intercept, drug, dose, drug*dose, can be difficult. This is especially true for large, complex models. In order to simplify the process of writing contrasts, you can re-specify the model as a cell means model. This is a model that estimates only one parameter for each group and sets the y-intercept to 0. If there is more than one independent variable, this model does not test main effects separately from interactions. Instead, interactions are pooled with all lower-order terms.",AM,531,"['specifying', 'contrast', 'using', 'full', 'model', 'intercept', 'drug', 'dose', 'drugdose', 'difficult', 'especially', 'true', 'large', 'complex', 'model', 'order', 'simplify', 'process', 'writing', 'contrast', 'respecify', 'model', 'cell', 'mean', 'model', 'model', 'estimate', 'one', 'parameter', 'group', 'set', 'yintercept', '0', 'one', 'independent', 'variable', 'model', 'doe', 'test', 'main_effect', 'separately', 'interaction', 'instead', 'interaction', 'pooled', 'lowerorder', 'term']"
70,"Throughout this course, you have learned to use SAS to perform a variety of multivariate statistical analyses. It is important to understand how the analyses work, what the assumptions are, and how to interpret the results of the analyses. It is equally important to know how to evaluate the assumptions of the analyses and determine whether your data are appropriate for the kind of analysis you plan to perform. Real data is almost never as simple and straightforward as classroom data, so this chapter is devoted to helping you prepare your data for multivariate analysis.",AM,575,"['throughout', 'course', 'learned', 'use', 'sa', 'perform', 'variety', 'multivariate', 'statistical', 'analysis', 'important', 'understand', 'analysis', 'work', 'assumption', 'interpret', 'result', 'analysis', 'equally', 'important', 'know', 'evaluate', 'assumption', 'analysis', 'determine', 'whether', 'data', 'appropriate', 'kind', 'analysis', 'plan', 'perform', 'real', 'data', 'almost', 'never', 'simple', 'straightforward', 'classroom', 'data', 'chapter', 'devoted', 'helping', 'prepare', 'data', 'multivariate', 'analysis']"
71,"The research questions above share a common thread ? prediction of groups. These questions are conceptually similar to logistic regression, which models the odds of membership in one group versus another group based on values of predictors. Discriminant function analysis can be thought of as a multivariate generalization of logistic regression, although as you will see, the computation for discriminant analysis is more similar to MANOVA or canonical correlation analysis than to logistic regression.",AM,503,"['research', 'question', 'share', 'common', 'thread', '', 'prediction', 'group', 'question', 'conceptually', 'similar', 'logistic_regression_model', 'odds', 'membership', 'one', 'group', 'versus', 'another', 'group', 'based', 'value', 'predictor', 'discriminant_function', 'analysis', 'thought', 'multivariate', 'generalization', 'logistic_regression', 'although', 'see', 'computation', 'discriminant_analysis', 'similar', 'manova', 'canonical', 'correlation', 'analysis', 'logistic_regression']"
72,"In addition to canonical discriminant analysis, there are many other methods for performing discriminant analysis. One that is commonly used is Fisher linear discriminant analysis (FLDA). Although the two approaches are conceptually similar, FLDA provides additional information beyond canonical discriminant analysis. With FLDA, the scores obtained from the analysis can be interpreted as the probability of membership in each group, for each observation. This enables you to assess the error rate in the initial data, as well as get predictions of group membership when group information is not available.",AM,607,"['addition', 'canonical', 'discriminant_analysis', 'many', 'method', 'performing', 'discriminant_analysis', 'one', 'commonly', 'used', 'fisher', 'linear', 'discriminant_analysis', 'flda', 'although', 'two', 'approach', 'conceptually', 'similar', 'flda', 'provides', 'additional', 'information', 'beyond', 'canonical', 'discriminant_analysis', 'flda', 'score', 'obtained', 'analysis', 'interpreted', 'probability', 'membership', 'group', 'observation', 'enables', 'ass', 'error', 'rate', 'initial', 'data', 'well', 'get', 'prediction', 'group', 'membership', 'group', 'information', 'available']"
73,"CLASS	names the classification variables to be used in the model. If you specify a CLASS statement, it must appear before the MODEL statement. MODEL	names the dependent variables and independent effects. Variable names are separated by a space. Crossed independent effects are indicated with asterisks (*). The bar operator (|) can be used to simplify effect specification for large factorial models. In PROC GLM, you can specify only one MODEL statement. MANOVA	performs multivariate analysis of variance when multiple dependent variables are listed in the MODEL statement. When the MANOVA statement is specified before the first RUN statement, GLM uses a multivariate method of handling missing values. This means that if a case is missing any values for a variable specified in the model, the entire case is deleted from the analysis. Selected test option for the MANOVA statement: H = effects | INTERCEPT | _ALL_ specifies the effects in the model to use as hypothesis (H) matrices. The H= option displays the eigenvalues and eigenvectors associated with E-1H and the four multivariate test statistics. To use all the effects in the model, specify the _ALL_ option. Selected detail options for the MANOVA statement: MSTAT = EXACT|FAPPROX specifies the method of evaluating the multivariate test statistics. The default is MSTAT=FAPPROX, which specifies that the multivariate tests are evaluated using the usual approximations based on the F distribution. MSTAT=EXACT computes exact p-values for three of the four tests (Wilks' Lambda, the Hotelling-Lawley Trace, and Roy's Greatest Root) and an improved F-approximation for the fourth (Pillai's Trace). PRINTE	displays the error SSCP matrix, E. Also produces a table of partial correlations of the dependent variables given the independent variables when the residual matrix from the analysis is the E matrix. PRINTH	displays the hypothesis SSCP matrix H associated with each effect in the H= specification. Selected option for the MODEL statement: NOUNI	suppresses univariate ANOVA output.",AM,2044,"['class\tnames', 'classification', 'variable', 'used', 'model', 'specify', 'class', 'statement', 'must', 'appear', 'model_statement', 'model\tnames', 'dependent', 'variable', 'independent', 'effect', 'variable', 'name', 'separated', 'space', 'crossed', 'independent', 'effect', 'indicated', 'asterisk', '', 'bar', 'operator', '', 'used', 'simplify', 'effect', 'specification', 'large', 'factorial', 'model', 'proc', 'glm', 'specify', 'one', 'model_statement', 'manova\tperforms', 'multivariate', 'analysis', 'variance', 'multiple', 'dependent', 'variable', 'listed', 'model_statement', 'manova', 'statement', 'specified', 'first', 'run', 'statement', 'glm', 'us', 'multivariate', 'method', 'handling', 'missing', 'value', 'mean', 'case', 'missing', 'value', 'variable', 'specified', 'model', 'entire', 'case', 'deleted', 'analysis', 'selected', 'test', 'option', 'manova', 'statement', 'h', '', 'effect', '', 'intercept', '', 'specifies', 'effect', 'model', 'use', 'hypothesis', 'h', 'matrix', 'h', 'option', 'display', 'eigenvalue', 'eigenvectors', 'associated', 'e1h', 'four', 'multivariate', 'test', 'statistic', 'use', 'effect', 'model', 'specify', 'option', 'selected', 'detail', 'option', 'manova', 'statement', 'mstat', '', 'exactfapprox', 'specifies', 'method', 'evaluating', 'multivariate', 'test', 'statistic', 'default', 'mstatfapprox', 'specifies', 'multivariate', 'test', 'evaluated', 'using', 'usual', 'approximation', 'based', 'f', 'distribution', 'mstatexact', 'computes', 'exact', 'pvalues', 'three', 'four', 'test', 'wilks', 'lambda', 'hotellinglawley', 'trace', 'roys', 'greatest', 'root', 'improved', 'fapproximation', 'fourth', 'pillais', 'trace', 'printe\tdisplays', 'error', 'sscp', 'matrix', 'e', 'also', 'produce', 'table', 'partial', 'correlation', 'dependent', 'variable', 'given', 'independent', 'variable', 'residual', 'matrix', 'analysis', 'e', 'matrix', 'printh\tdisplays', 'hypothesis', 'sscp', 'matrix', 'h', 'associated', 'effect', 'h', 'specification', 'selected', 'option', 'model_statement', 'nouni\tsuppresses', 'univariate', 'anova', 'output']"
74,"Some of the bivariate outliers you saw earlier are also outliers on the PRIN variables. !	For more than two PCs at a time, you could create a three-way rotating scatter plot of several principal component variables. Feel free to try this plot on your own! After looking over the output for outlier analysis, you decide that you have four observations that are outliers. You choose to continue with your screening and data preparation with the complete set of data. Restricted Range and Group Size Use the data set sandwiches to investigate variables for restricted range and unequal group sizes. You selected Weight because you are concerned that there is not enough variation in the weight of sandwiches. You selected Category because you were concerned that there may be types of sandwiches that are underrepresented in the data. 1.	Select the sandwiches data set from the Window menu. 2.	Create a histogram for the Weight variable by selecting Plots => Create Histogram => Weight => Set X. The histogram for Weight is displayed below:",AM,1037,"['bivariate', 'outlier', 'saw', 'earlier', 'also', 'outlier', 'prin', 'variable', '\tfor', 'two', 'pc', 'time', 'could', 'create', 'threeway', 'rotating', 'scatter', 'plot', 'several', 'principal', 'component', 'variable', 'feel', 'free', 'try', 'plot', 'looking', 'output', 'outlier', 'analysis', 'decide', 'four', 'observation', 'outlier', 'choose', 'continue', 'screening', 'data', 'preparation', 'complete', 'set', 'data', 'restricted', 'range', 'group', 'size', 'use', 'data_set', 'sandwich', 'investigate', 'variable', 'restricted', 'range', 'unequal', 'group', 'size', 'selected', 'weight', 'concerned', 'enough', 'variation', 'weight', 'sandwich', 'selected', 'category', 'concerned', 'may', 'type', 'sandwich', 'underrepresented', 'data', '1\tselect', 'sandwich', 'data_set', 'window', 'menu', '2\tcreate', 'histogram', 'weight', 'variable', 'selecting', 'plot', '', 'create', 'histogram', '', 'weight', '', 'set', 'x', 'histogram', 'weight', 'displayed']"
75,"Some of the bivariate outliers you saw earlier are also outliers on the PRIN variables. !	For more than two PCs at a time, you could create a three-way rotating scatter plot of several principal component variables. Feel free to try this plot on your own! After looking over the output for outlier analysis, you decide that you have four observations that are outliers. You choose to continue with your screening and data preparation with the complete set of data. Restricted Range and Group Size Use the data set sandwiches to investigate variables for restricted range and unequal group sizes. You selected Weight because you are concerned that there is not enough variation in the weight of sandwiches. You selected Category because you were concerned that there may be types of sandwiches that are underrepresented in the data. 1.	Select the sandwiches data set from the Window menu. 2.	Create a histogram for the Weight variable by selecting Plots => Create Histogram => Weight => Set X. The histogram for Weight is displayed below:",AM,1037,"['bivariate', 'outlier', 'saw', 'earlier', 'also', 'outlier', 'prin', 'variable', '\tfor', 'two', 'pc', 'time', 'could', 'create', 'threeway', 'rotating', 'scatter', 'plot', 'several', 'principal', 'component', 'variable', 'feel', 'free', 'try', 'plot', 'looking', 'output', 'outlier', 'analysis', 'decide', 'four', 'observation', 'outlier', 'choose', 'continue', 'screening', 'data', 'preparation', 'complete', 'set', 'data', 'restricted', 'range', 'group', 'size', 'use', 'data_set', 'sandwich', 'investigate', 'variable', 'restricted', 'range', 'unequal', 'group', 'size', 'selected', 'weight', 'concerned', 'enough', 'variation', 'weight', 'sandwich', 'selected', 'category', 'concerned', 'may', 'type', 'sandwich', 'underrepresented', 'data', '1\tselect', 'sandwich', 'data_set', 'window', 'menu', '2\tcreate', 'histogram', 'weight', 'variable', 'selecting', 'plot', '', 'create', 'histogram', '', 'weight', '', 'set', 'x', 'histogram', 'weight', 'displayed']"
76,"The pooled covariance matrix, Sp, was used. Information about Sp is displayed above. There were 12 (noncollinear) predictors; the covariance matrix Sp is rank 12. Pairwise Generalized Squared Distances Between Groups",AM,216,"['pooled', 'covariance', 'matrix', 'sp', 'wa', 'used', 'information', 'sp', 'displayed', '12', 'noncollinear', 'predictor', 'covariance', 'matrix', 'sp', 'rank', '12', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
77,"The pooled covariance matrix, Sp, was used. Information about Sp is displayed above. There were 12 (noncollinear) predictors; the covariance matrix Sp is rank 12. Pairwise Generalized Squared Distances Between Groups",AM,216,"['pooled', 'covariance', 'matrix', 'sp', 'wa', 'used', 'information', 'sp', 'displayed', '12', 'noncollinear', 'predictor', 'covariance', 'matrix', 'sp', 'rank', '12', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
78,"When there are multiple dependent measures for a factorial design, multivariate analysis of variance (MANOVA) can be a very useful tool in determining whether groups differ on a set of measures. Sometimes you are interested in specific comparisons between pairs of groups, between one group and a combination of groups, or perhaps other comparisons. Contrasts in the GLM procedure enable you to test custom hypotheses about your population. After you learn to fit multivariate models using SAS, you learn to apply other multivariate methods using SAS such as factor analysis, structural equation models, and discriminant function analysis.",AM,639,"['multiple', 'dependent', 'measure', 'factorial', 'design', 'multivariate', 'analysis', 'variance', 'manova', 'useful', 'tool', 'determining', 'whether', 'group', 'differ', 'set', 'measure', 'sometimes', 'interested', 'specific', 'comparison', 'pair', 'group', 'one', 'group', 'combination', 'group', 'perhaps', 'comparison', 'contrast', 'glm', 'procedure', 'enable', 'test', 'custom', 'hypothesis', 'population', 'learn', 'fit', 'multivariate', 'model', 'using', 'sa', 'learn', 'apply', 'multivariate', 'method', 'using', 'sa', 'factor', 'analysis', 'structural', 'equation', 'model', 'discriminant_function', 'analysis']"
79,"The CLASS and VAR statements serve the same purpose as they do in PROC CANDISC. Selection options for the PROC DISCRIM statement: LIST	classifies observations into groups based on the discriminant functions. ANOVA	performs univariate ANOVAs to see whether the groups differ significantly on each predictor variable. It can be useful in eliminating irrelevant variables from the analysis. CAN	specifies that canonical discriminant analysis be performed. To achieve the same analysis as the one you saw in PROC CANDISC, specify proportional priors in the PRIORS statement. ?	See Appendix C for an example of how to perform canonical discriminant analysis using PROC DISCRIM. The PRIORS statement is discussed on the next page.",AM,724,"['class', 'var', 'statement', 'serve', 'purpose', 'proc', 'candisc', 'selection', 'option', 'proc', 'discrim', 'statement', 'list\tclassifies', 'observation', 'group', 'based', 'discriminant_function', 'anova\tperforms', 'univariate', 'anova', 'see', 'whether', 'group', 'differ', 'significantly', 'predictor_variable', 'useful', 'eliminating', 'irrelevant', 'variable', 'analysis', 'can\tspecifies', 'canonical', 'discriminant_analysis', 'performed', 'achieve', 'analysis', 'one', 'saw', 'proc', 'candisc', 'specify', 'proportional', 'prior', 'prior', 'statement', '\tsee', 'appendix', 'c', 'example', 'perform', 'canonical', 'discriminant_analysis', 'using', 'proc', 'discrim', 'prior', 'statement', 'discussed', 'next', 'page']"
80,"Many of the important issues in this chapter such as data accuracy and missing data apply to all statistical analyses, including univariate statistics, inferential statistics, and descriptive statistics. Some issues are unique to multivariate statistics, and some topics are unique to inferential statistics.",AM,308,"['many', 'important', 'issue', 'chapter', 'data', 'accuracy', 'missing', 'data', 'apply', 'statistical', 'analysis', 'including', 'univariate', 'statistic', 'inferential', 'statistic', 'descriptive', 'statistic', 'issue', 'unique', 'multivariate', 'statistic', 'topic', 'unique', 'inferential', 'statistic']"
81,"One way to handle outliers without deleting the observation from the analysis completely is to replace the value or values with something less extreme. For example, with univariate outliers, winsorized means are measures of central tendency in which the extreme values have been replaced with less extreme values. Trimmed means are measures of central tendency whose most extreme (upper and lower) values have been removed from calculations. You can obtain winsorized and trimmed means with the UNIVARIATE procedure. Outliers can pose real problems for your analyses. Regardless of how you choose to handle outliers, it is always important to document your actions carefully so that others know what you did.",AM,708,"['one', 'way', 'handle', 'outlier', 'without', 'deleting', 'observation', 'analysis', 'completely', 'replace', 'value', 'value', 'something', 'le', 'extreme', 'example', 'univariate', 'outlier', 'winsorized', 'mean', 'measure', 'central', 'tendency', 'extreme', 'value', 'replaced', 'le', 'extreme', 'value', 'trimmed', 'mean', 'measure', 'central', 'tendency', 'whose', 'extreme', 'upper', 'lower', 'value', 'removed', 'calculation', 'obtain', 'winsorized', 'trimmed', 'mean', 'univariate', 'procedure', 'outlier', 'pose', 'real', 'problem', 'analysis', 'regardless', 'choose', 'handle', 'outlier', 'always', 'important', 'document', 'action', 'carefully', 'others', 'know']"
82,"The sandwiches data set includes nutritional information about several brands and types of sandwiches sold at fast-food restaurants and in grocery store freezer sections. The data are simulated but based on real nutritional information about sandwiches. The variables for the sandwiches data set are described below: Calories	The number of calories in the sandwich from testing TFat		Grams of fat Protein	Grams of protein Carb		Grams of carbohydrate Fiber		Grams of fiber	 Sodium	Milligrams of sodium Brand		Brand name of the sandwich (A, B, ?, I) (Character variable) Name		Name of the sandwich (Character variable) Category	Type of sandwich (Tuna, Chicken, Ham,?) (Character variable) Weight	Weight in ounces FatCal	Number of calories from fat CarbCal	Number of calories from carbohydrate ProCal	Number of calories from protein CalSum	Sum of FatCal, CarbCal, and ProCal ? to evaluate accuracy of the Calories measurement. You will perform analyses on some but not necessarily all of the variables in the data set. You may want to explore further with the data on your own to practice the methods demonstrated in this course. Outlier Analysis and Data Screening Using SAS/IML Workshop 2.1 You can use the SAS/IML Workshop to perform interactive graphical analysis of your data. In addition to graphical capabilities, you can use IML (Interactive Matrix Language) for customized analyses, and you can run SAS programs and view SAS output within the code editor in the SAS/IML Workshop. 1.	Open SAS/IML Workshop by selecting Start => Programs => IML Workshop 2.1. You see the SAS/IML workspace:",AM,1593,"['sandwich', 'data_set', 'includes', 'nutritional', 'information', 'several', 'brand', 'type', 'sandwich', 'sold', 'fastfood', 'restaurant', 'grocery', 'store', 'freezer', 'section', 'data', 'simulated', 'based', 'real', 'nutritional', 'information', 'sandwich', 'variable', 'sandwich', 'data_set', 'described', 'calories\tthe', 'number', 'calorie', 'sandwich', 'testing', 'tfat\t\tgrams', 'fat', 'protein\tgrams', 'protein', 'carb\t\tgrams', 'carbohydrate', 'fiber\t\tgrams', 'fiber\t', 'sodium\tmilligrams', 'sodium', 'brand\t\tbrand', 'name', 'sandwich', 'b', '', 'character', 'variable', 'name\t\tname', 'sandwich', 'character', 'variable', 'category\ttype', 'sandwich', 'tuna', 'chicken', 'ham', 'character', 'variable', 'weight\tweight', 'ounce', 'fatcal\tnumber', 'calorie', 'fat', 'carbcal\tnumber', 'calorie', 'carbohydrate', 'procal\tnumber', 'calorie', 'protein', 'calsum\tsum', 'fatcal', 'carbcal', 'procal', '', 'evaluate', 'accuracy', 'calorie', 'measurement', 'perform', 'analysis', 'necessarily', 'variable', 'data_set', 'may', 'want', 'explore', 'data', 'practice', 'method', 'demonstrated', 'course', 'outlier', 'analysis', 'data', 'screening', 'using', 'sasiml', 'workshop', '21', 'use', 'sasiml', 'workshop', 'perform', 'interactive', 'graphical', 'analysis', 'data', 'addition', 'graphical', 'capability', 'use', 'iml', 'interactive', 'matrix', 'language', 'customized', 'analysis', 'run', 'sa', 'program', 'view', 'sa', 'output', 'within', 'code', 'editor', 'sasiml', 'workshop', '1\topen', 'sasiml', 'workshop', 'selecting', 'start', '', 'program', '', 'iml', 'workshop', '21', 'see', 'sasiml', 'workspace']"
83,"When planning a study, give special consideration to the problem of restricted range. For example, you may be interested in studying the effects of an intervention on behavioral and attitudinal symptoms of depression. If you only study depressed patients, then at the start of your study, you may have restricted range (ceiling effects) on your baseline symptom measures. It may be helpful to specifically recruit participants who are not depressed for your study and increase the variation in baseline depression in the overall group. Another possible solution for restricted range would be to classify participants based on the small amount of variation you have in the data. For example, you might compare the career success of university faculty with less than a doctoral degree, one doctoral degree, and more than one doctoral degree (for example, Ph.D. and J.D.). Of course, in this situation, you may encounter problems with unequal group sizes.",AM,952,"['planning', 'study', 'give', 'special', 'consideration', 'problem', 'restricted', 'range', 'example', 'may', 'interested', 'studying', 'effect', 'intervention', 'behavioral', 'attitudinal', 'symptom', 'depression', 'study', 'depressed', 'patient', 'start', 'study', 'may', 'restricted', 'range', 'ceiling', 'effect', 'baseline', 'symptom', 'measure', 'may', 'helpful', 'specifically', 'recruit', 'participant', 'depressed', 'study', 'increase', 'variation', 'baseline', 'depression', 'overall', 'group', 'another', 'possible', 'solution', 'restricted', 'range', 'would', 'classify', 'participant', 'based', 'small', 'amount', 'variation', 'data', 'example', 'might', 'compare', 'career', 'success', 'university', 'faculty', 'le', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'example', 'phd', 'jd', 'course', 'situation', 'may', 'encounter', 'problem', 'unequal', 'group', 'size']"
84,"The Pooled Within Canonical Structure table shows the correlations between the predictors and the discriminant functions after adjusting for group differences. In other words, the pooled within canonical structure shows the correlations among the canonical variates and the predictors within the groups. Examining the variables that correlate highly with the first discriminant function (dsm4, dsm8, dsm10, and dsm12) suggests that these variables are all consequences of gambling. Thus, it appears that variables that pertain to consequences of gambling are responsible for an important portion of the discrimination among the three groups. Examining the variables that correlate highly with the second discriminant function (dsm1, dsm2, dsm3, and dsm9) suggests that these variables involve thoughts about gambling. Thus, it appears that variables pertaining to thoughts about gambling are responsible for an important portion of the discrimination among the groups. Additionally, PROC CANDISC displays several tables of canonical coefficients. These coefficients are influenced by correlations among the variables and, in some cases, by the scale of the variables. For these reasons, the coefficients are problematic to interpret, and are thus not shown here. Class Means on Canonical Variables",AM,1297,"['pooled', 'within', 'canonical', 'structure', 'table', 'show', 'correlation', 'predictor', 'discriminant_function', 'adjusting', 'group', 'difference', 'word', 'pooled', 'within', 'canonical', 'structure', 'show', 'correlation', 'among', 'canonical', 'variate', 'predictor', 'within', 'group', 'examining', 'variable', 'correlate', 'highly', 'first', 'discriminant_function', 'dsm4', 'dsm8', 'dsm10', 'dsm12', 'suggests', 'variable', 'consequence', 'gambling', 'thus', 'appears', 'variable', 'pertain', 'consequence', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'three', 'group', 'examining', 'variable', 'correlate', 'highly', 'second', 'discriminant_function', 'dsm1', 'dsm2', 'dsm3', 'dsm9', 'suggests', 'variable', 'involve', 'thought', 'gambling', 'thus', 'appears', 'variable', 'pertaining', 'thought', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'group', 'additionally', 'proc', 'candisc', 'display', 'several', 'table', 'canonical', 'coefficient', 'coefficient', 'influenced', 'correlation', 'among', 'variable', 'case', 'scale', 'variable', 'reason', 'coefficient', 'problematic', 'interpret', 'thus', 'shown', 'class', 'mean', 'canonical', 'variable']"
85,"The Tofu Veg Delite does not appear to fit with the general pattern of the rest of the data. You also notice that the Frozen sandwiches are close to one another near the low end of Calories and Sodium. Principal Components and Outliers: SAS Code within the SAS/IML Workshop For more than three-dimensional space, the easiest way to spot outliers can be with a histogram of principal component scores. The program App_OutliersIML.iml is displayed below: libname amul 'C:\workshop\winsas\amul\data\';",AM,498,"['tofu', 'veg', 'delite', 'doe', 'appear', 'fit', 'general', 'pattern', 'rest', 'data', 'also', 'notice', 'frozen', 'sandwich', 'close', 'one', 'another', 'near', 'low', 'end', 'calorie', 'sodium', 'principal', 'component', 'outlier', 'sa', 'code', 'within', 'sasiml', 'workshop', 'threedimensional', 'space', 'easiest', 'way', 'spot', 'outlier', 'histogram', 'principal', 'component', 'score', 'program', 'appoutliersimliml', 'displayed', 'libname', 'amul', 'cworkshopwinsasamuldata']"
86,"In addition to canonical discriminant analysis, there are many other methods for performing discriminant analysis. One that is commonly used is Fisher linear discriminant analysis (FLDA). Although the two approaches are conceptually similar, FLDA provides additional information beyond canonical discriminant analysis. With FLDA, the scores obtained from the analysis can be interpreted as the probability of membership in each group, for each observation. This enables you to assess the error rate in the initial data, as well as get predictions of group membership when group information is not available.",AM,607,"['addition', 'canonical', 'discriminant_analysis', 'many', 'method', 'performing', 'discriminant_analysis', 'one', 'commonly', 'used', 'fisher', 'linear', 'discriminant_analysis', 'flda', 'although', 'two', 'approach', 'conceptually', 'similar', 'flda', 'provides', 'additional', 'information', 'beyond', 'canonical', 'discriminant_analysis', 'flda', 'score', 'obtained', 'analysis', 'interpreted', 'probability', 'membership', 'group', 'observation', 'enables', 'ass', 'error', 'rate', 'initial', 'data', 'well', 'get', 'prediction', 'group', 'membership', 'group', 'information', 'available']"
87,"You express the coefficients as integers by multiplying them by a constant. There are situations when you want to use the CONTRAST statement and the ESTIMATE statement together, such as when you are performing comparisons with more than one degree of freedom and you want the estimates from the tests. If you were only interested in the significance test from the contrast and not in the estimates, then you would use the CONTRAST statement only. The ESTIMATE statement for this contrast would be the same as the CONTRAST statement, except you would also include the DIVISOR= option to tell SAS to divide each estimate by 3 (so you can get the mean of the cell, instead of 3 ? the mean of the cell): In the following example, you will see both the CONTRAST and the ESTIMATE statements used. Using Contrasts for Custom Hypothesis Tests",AM,834,"['express', 'coefficient', 'integer', 'multiplying', 'constant', 'situation', 'want', 'use', 'contrast', 'statement', 'estimate', 'statement', 'together', 'performing', 'comparison', 'one', 'degree', 'freedom', 'want', 'estimate', 'test', 'interested', 'significance', 'test', 'contrast', 'estimate', 'would', 'use', 'contrast', 'statement', 'estimate', 'statement', 'contrast', 'would', 'contrast', 'statement', 'except', 'would', 'also', 'include', 'divisor', 'option', 'tell', 'sa', 'divide', 'estimate', '3', 'get', 'mean', 'cell', 'instead', '3', '', 'mean', 'cell', 'following', 'example', 'see', 'contrast', 'estimate', 'statement', 'used', 'using', 'contrast', 'custom', 'hypothesis', 'test']"
88,"In the DISCRIM procedure, the POOL= option controls whether linear or quadratic discriminant analysis is performed. Is you specify POOL=YES (the default), DISCRIM performs linear discriminant analysis. POOL=NO requests quadratic discriminant analysis. You can also request a chi-square test of homogeneity of covariance matrices with the option POOL=TEST. The test for homogeneity of covariance matrices uses a chi-square statistic that assumes that the data are multivariate normal. The null hypothesis of the test is that the within-group covariance matrices are equal to the pooled covariance matrix. If you specify POOL=TEST, the default alpha for the test is 0.05. You can change this using the SLPOOL= option. If you reject the null hypothesis for this test, PROC DISCRIM automatically performs quadratic discriminant analysis. If the null hypothesis is not rejected, PROC DISCRIM performs linear discriminant analysis.",AM,925,"['discrim', 'procedure', 'pool', 'option', 'control', 'whether', 'linear', 'quadratic', 'discriminant_analysis', 'performed', 'specify', 'poolyes', 'default', 'discrim', 'performs', 'linear', 'discriminant_analysis', 'poolno', 'request', 'quadratic', 'discriminant_analysis', 'also', 'request', 'chisquare', 'test', 'homogeneity', 'covariance', 'matrix', 'option', 'pooltest', 'test', 'homogeneity', 'covariance', 'matrix', 'us', 'chisquare', 'statistic', 'assumes', 'data', 'multivariate', 'normal', 'null', 'hypothesis', 'test', 'withingroup', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'specify', 'pooltest', 'default', 'alpha', 'test', '005', 'change', 'using', 'slpool', 'option', 'reject', 'null', 'hypothesis', 'test', 'proc', 'discrim', 'automatically', 'performs', 'quadratic', 'discriminant_analysis', 'null', 'hypothesis', 'rejected', 'proc', 'discrim', 'performs', 'linear', 'discriminant_analysis']"
89,"In the DISCRIM procedure, the POOL= option controls whether linear or quadratic discriminant analysis is performed. Is you specify POOL=YES (the default), DISCRIM performs linear discriminant analysis. POOL=NO requests quadratic discriminant analysis. You can also request a chi-square test of homogeneity of covariance matrices with the option POOL=TEST. The test for homogeneity of covariance matrices uses a chi-square statistic that assumes that the data are multivariate normal. The null hypothesis of the test is that the within-group covariance matrices are equal to the pooled covariance matrix. If you specify POOL=TEST, the default alpha for the test is 0.05. You can change this using the SLPOOL= option. If you reject the null hypothesis for this test, PROC DISCRIM automatically performs quadratic discriminant analysis. If the null hypothesis is not rejected, PROC DISCRIM performs linear discriminant analysis.",AM,925,"['discrim', 'procedure', 'pool', 'option', 'control', 'whether', 'linear', 'quadratic', 'discriminant_analysis', 'performed', 'specify', 'poolyes', 'default', 'discrim', 'performs', 'linear', 'discriminant_analysis', 'poolno', 'request', 'quadratic', 'discriminant_analysis', 'also', 'request', 'chisquare', 'test', 'homogeneity', 'covariance', 'matrix', 'option', 'pooltest', 'test', 'homogeneity', 'covariance', 'matrix', 'us', 'chisquare', 'statistic', 'assumes', 'data', 'multivariate', 'normal', 'null', 'hypothesis', 'test', 'withingroup', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'specify', 'pooltest', 'default', 'alpha', 'test', '005', 'change', 'using', 'slpool', 'option', 'reject', 'null', 'hypothesis', 'test', 'proc', 'discrim', 'automatically', 'performs', 'quadratic', 'discriminant_analysis', 'null', 'hypothesis', 'rejected', 'proc', 'discrim', 'performs', 'linear', 'discriminant_analysis']"
90,"Because of the unequal group sizes, you may want to consider combining similar groups together, and/or testing for equality of covariance matrices before performing any multivariate analyses with this variable.",AM,210,"['unequal', 'group', 'size', 'may', 'want', 'consider', 'combining', 'similar', 'group', 'together', 'andor', 'testing', 'equality', 'covariance', 'matrix', 'performing', 'multivariate', 'analysis', 'variable']"
91,"Many types of studies exhibit problems with restricted range on variables. If a variable demonstrates restricted range, it does not have enough variability to be useful as a continuous variable in your analyses. An example of restricted range is shown above. In your study of university professors, you suspect that more years of education would be associated with greater career success. However, the vast majority of university professors have many years of education. There are very few who have less than a doctoral or perhaps a master?s degree. The restriction of range demonstrated here is sometimes known as a ceiling effect because the restriction is at the high end (the ceiling) of the data. The opposite of the ceiling effect is known as a floor effect. For example, if you were interested in reducing the risk of heart attacks among women between 20-30 years of age, you would likely run into a floor effect because very few women between 20 and 30 years of age have heart attacks, and it would be difficult to reduce this amount further with an intervention.",AM,1071,"['many', 'type', 'study', 'exhibit', 'problem', 'restricted', 'range', 'variable', 'variable', 'demonstrates', 'restricted', 'range', 'doe', 'enough', 'variability', 'useful', 'continuous', 'variable', 'analysis', 'example', 'restricted', 'range', 'shown', 'study', 'university', 'professor', 'suspect', 'year', 'education', 'would', 'associated', 'greater', 'career', 'success', 'however', 'vast', 'majority', 'university', 'professor', 'many', 'year', 'education', 'le', 'doctoral', 'perhaps', 'master', 'degree', 'restriction', 'range', 'demonstrated', 'sometimes', 'known', 'ceiling', 'effect', 'restriction', 'high', 'end', 'ceiling', 'data', 'opposite', 'ceiling', 'effect', 'known', 'floor', 'effect', 'example', 'interested', 'reducing', 'risk', 'heart', 'attack', 'among', 'woman', '2030', 'year', 'age', 'would', 'likely', 'run', 'floor', 'effect', 'woman', '20', '30', 'year', 'age', 'heart', 'attack', 'would', 'difficult', 'reduce', 'amount', 'intervention']"
92,"Throughout this course, you have learned to use SAS to perform a variety of multivariate statistical analyses. It is important to understand how the analyses work, what the assumptions are, and how to interpret the results of the analyses. It is equally important to know how to evaluate the assumptions of the analyses and determine whether your data are appropriate for the kind of analysis you plan to perform. Real data is almost never as simple and straightforward as classroom data, so this chapter is devoted to helping you prepare your data for multivariate analysis.",AM,575,"['throughout', 'course', 'learned', 'use', 'sa', 'perform', 'variety', 'multivariate', 'statistical', 'analysis', 'important', 'understand', 'analysis', 'work', 'assumption', 'interpret', 'result', 'analysis', 'equally', 'important', 'know', 'evaluate', 'assumption', 'analysis', 'determine', 'whether', 'data', 'appropriate', 'kind', 'analysis', 'plan', 'perform', 'real', 'data', 'almost', 'never', 'simple', 'straightforward', 'classroom', 'data', 'chapter', 'devoted', 'helping', 'prepare', 'data', 'multivariate', 'analysis']"
93,"One way to handle outliers without deleting the observation from the analysis completely is to replace the value or values with something less extreme. For example, with univariate outliers, winsorized means are measures of central tendency in which the extreme values have been replaced with less extreme values. Trimmed means are measures of central tendency whose most extreme (upper and lower) values have been removed from calculations. You can obtain winsorized and trimmed means with the UNIVARIATE procedure. Outliers can pose real problems for your analyses. Regardless of how you choose to handle outliers, it is always important to document your actions carefully so that others know what you did.",AM,708,"['one', 'way', 'handle', 'outlier', 'without', 'deleting', 'observation', 'analysis', 'completely', 'replace', 'value', 'value', 'something', 'le', 'extreme', 'example', 'univariate', 'outlier', 'winsorized', 'mean', 'measure', 'central', 'tendency', 'extreme', 'value', 'replaced', 'le', 'extreme', 'value', 'trimmed', 'mean', 'measure', 'central', 'tendency', 'whose', 'extreme', 'upper', 'lower', 'value', 'removed', 'calculation', 'obtain', 'winsorized', 'trimmed', 'mean', 'univariate', 'procedure', 'outlier', 'pose', 'real', 'problem', 'analysis', 'regardless', 'choose', 'handle', 'outlier', 'always', 'important', 'document', 'action', 'carefully', 'others', 'know']"
94,"Some of the bivariate outliers you saw earlier are also outliers on the PRIN variables. !	For more than two PCs at a time, you could create a three-way rotating scatter plot of several principal component variables. Feel free to try this plot on your own! After looking over the output for outlier analysis, you decide that you have four observations that are outliers. You choose to continue with your screening and data preparation with the complete set of data. Restricted Range and Group Size Use the data set sandwiches to investigate variables for restricted range and unequal group sizes. You selected Weight because you are concerned that there is not enough variation in the weight of sandwiches. You selected Category because you were concerned that there may be types of sandwiches that are underrepresented in the data. 1.	Select the sandwiches data set from the Window menu. 2.	Create a histogram for the Weight variable by selecting Plots => Create Histogram => Weight => Set X. The histogram for Weight is displayed below:",AM,1037,"['bivariate', 'outlier', 'saw', 'earlier', 'also', 'outlier', 'prin', 'variable', '\tfor', 'two', 'pc', 'time', 'could', 'create', 'threeway', 'rotating', 'scatter', 'plot', 'several', 'principal', 'component', 'variable', 'feel', 'free', 'try', 'plot', 'looking', 'output', 'outlier', 'analysis', 'decide', 'four', 'observation', 'outlier', 'choose', 'continue', 'screening', 'data', 'preparation', 'complete', 'set', 'data', 'restricted', 'range', 'group', 'size', 'use', 'data_set', 'sandwich', 'investigate', 'variable', 'restricted', 'range', 'unequal', 'group', 'size', 'selected', 'weight', 'concerned', 'enough', 'variation', 'weight', 'sandwich', 'selected', 'category', 'concerned', 'may', 'type', 'sandwich', 'underrepresented', 'data', '1\tselect', 'sandwich', 'data_set', 'window', 'menu', '2\tcreate', 'histogram', 'weight', 'variable', 'selecting', 'plot', '', 'create', 'histogram', '', 'weight', '', 'set', 'x', 'histogram', 'weight', 'displayed']"
95,"PROC CANDISC	calls the CANDISC procedure and specifies how the analysis is to be performed. CLASS	specifies the classification variable that you are trying to predict. VAR	specifies the set of continuous variables that you are using to discriminate among the groups specified by the CLASS variable. Selected option for the PROC CANDISC statement: OUT = data-set	creates an output data set that contains the original data and the canonical scores. OUTSTAT = data-set	creates a TYPE = CORR output SAS data set that contains various statistics including class-level statistics, correlations, canonical correlations, canonical structures, canonical coefficients, and means of canonical variates for each class. NOPRINT	suppresses display of output. NCAN = n	specifies the number of canonical variates to be computed. The value must be less than or equal to the maximum number of possible variates. The default is to compute all possible variates.",AM,942,"['proc', 'candisc\tcalls', 'candisc', 'procedure', 'specifies', 'analysis', 'performed', 'class\tspecifies', 'classification', 'variable', 'trying', 'predict', 'var\tspecifies', 'set', 'continuous', 'variable', 'using', 'discriminate', 'among', 'group', 'specified', 'class', 'variable', 'selected', 'option', 'proc', 'candisc', 'statement', '', 'dataset\tcreates', 'output', 'data_set', 'contains', 'original', 'data', 'canonical', 'score', 'outstat', '', 'dataset\tcreates', 'type', '', 'corr', 'output', 'sa', 'data_set', 'contains', 'various', 'statistic', 'including', 'classlevel', 'statistic', 'correlation', 'canonical', 'correlation', 'canonical', 'structure', 'canonical', 'coefficient', 'mean', 'canonical', 'variate', 'class', 'noprint\tsuppresses', 'display', 'output', 'ncan', '', 'n\tspecifies', 'number', 'canonical', 'variate', 'computed', 'value', 'must', 'le', 'equal', 'maximum', 'number', 'possible', 'variate', 'default', 'compute', 'possible', 'variate']"
96,"A natural extension of the MANOVA research question ?How do my continuous responses differ as a function of group levels?? is the discriminant analysis research question ?How do my continuous variables predict membership in groups? With discriminant analysis, you can use parametric or nonparametric methods to *	find linear combinations of continuous variables (discriminant functions) that predict group membership *	estimate the expected misclassification rate based on the discriminant functions *	test the discriminant functions on a new sample to determine the extent to which the functions correctly and incorrectly classify observations Canonical discriminant analysis has the advantage of conceptual and computational simplicity, while Fisher linear discriminant analysis is powerful enough to allow you to find the discriminant functions and test or crossvalidate your results using one simple procedure. You learned to use two procedures in SAS to perform discriminant analysis: PROC CANDISC performs canonical discriminant analysis to find linear combinations of variables that best discriminate among groups. PROC DISCRIM performs linear and quadratic discriminant analysis and produces a prediction function to help classify observations in to groups based on a set of predictors. Remember that discriminant analysis and other predictive modeling techniques capitalize on chance associations among the predictors in your data to find the discriminant functions. For this reason it is important always to perform empirical validation on a new sample of data, or at least use crossvalidation before using the discriminant functions for prediction and scoring.",AM,1671,"['natural', 'extension', 'manova', 'research', 'question', 'continuous', 'response', 'differ', 'function', 'group', 'level', 'discriminant_analysis', 'research', 'question', 'continuous', 'variable', 'predict', 'membership', 'group', 'discriminant_analysis', 'use', 'parametric', 'nonparametric', 'method', '\tfind', 'linear', 'combination', 'continuous', 'variable', 'discriminant_function', 'predict', 'group', 'membership', '\testimate', 'expected', 'misclassification', 'rate', 'based', 'discriminant_function', '\ttest', 'discriminant_function', 'new', 'sample', 'determine', 'extent', 'function', 'correctly', 'incorrectly', 'classify', 'observation', 'canonical', 'discriminant_analysis', 'ha', 'advantage', 'conceptual', 'computational', 'simplicity', 'fisher', 'linear', 'discriminant_analysis', 'powerful', 'enough', 'allow', 'find', 'discriminant_function', 'test', 'crossvalidate', 'result', 'using', 'one', 'simple', 'procedure', 'learned', 'use', 'two', 'procedure', 'sa', 'perform', 'discriminant_analysis', 'proc', 'candisc', 'performs', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'variable', 'best', 'discriminate', 'among', 'group', 'proc', 'discrim', 'performs', 'linear', 'quadratic', 'discriminant_analysis', 'produce', 'prediction', 'function', 'help', 'classify', 'observation', 'group', 'based', 'set', 'predictor', 'remember', 'discriminant_analysis', 'predictive', 'modeling', 'technique', 'capitalize', 'chance', 'association', 'among', 'predictor', 'data', 'find', 'discriminant_function', 'reason', 'important', 'always', 'perform', 'empirical', 'validation', 'new', 'sample', 'data', 'least', 'use', 'crossvalidation', 'using', 'discriminant_function', 'prediction', 'scoring']"
97,"Be careful not to confuse discriminant analysis with cluster analysis, which is another commonly used dimension-reduction technique. Discriminant analysis requires prior knowledge of the groups, usually in the form of a sample from each group. In cluster analysis, the data do not include information on group membership; the purpose of cluster analysis is to create the groups. This distinction between knowledge of groups versus creation of groups highlights the difference between supervised and unsupervised analyses. Most of the analyses in scientific research and inferential statistical analysis involve the use of supervised data analytic techniques. MANOVA, canonical correlation, and discriminant analysis are all examples of supervised analyses. In contrast, unsupervised analytic methods are more typical of the kinds of research questions in which statistical inference is not a primary goal, such as in market segmentation, or during the exploratory phase of a scientific investigation. Principal components analysis and cluster analysis are examples of unsupervised analyses.",AM,1090,"['careful', 'confuse', 'discriminant_analysis', 'cluster', 'analysis', 'another', 'commonly', 'used', 'dimensionreduction', 'technique', 'discriminant_analysis', 'requires', 'prior', 'knowledge', 'group', 'usually', 'form', 'sample', 'group', 'cluster', 'analysis', 'data', 'include', 'information', 'group', 'membership', 'purpose', 'cluster', 'analysis', 'create', 'group', 'distinction', 'knowledge', 'group', 'versus', 'creation', 'group', 'highlight', 'difference', 'supervised', 'unsupervised', 'analysis', 'analysis', 'scientific', 'research', 'inferential', 'statistical', 'analysis', 'involve', 'use', 'supervised', 'data', 'analytic', 'technique', 'manova', 'canonical', 'correlation', 'discriminant_analysis', 'example', 'supervised', 'analysis', 'contrast', 'unsupervised', 'analytic', 'method', 'typical', 'kind', 'research', 'question', 'statistical', 'inference', 'primary', 'goal', 'market', 'segmentation', 'exploratory', 'phase', 'scientific', 'investigation', 'principal', 'component', 'analysis', 'cluster', 'analysis', 'example', 'unsupervised', 'analysis']"
98,"Consider an agricultural example. Suppose you were interested in predicting crop type (corn, cotton, and soybeans) based on a series of remote sensing measures. You could perform canonical correlation analysis for this data set by recoding the groups with values of 0,1 creating dummy codes, or indicator variables. You would have two indicator variables for three crops. You could treat these variables as one group, V, and the set of predictors (the remote sensing measures) as a second set of variables, W. The plot above shows the two canonical variates. Canonical correlation analysis on the data would help you find the first linear combination of each set of variables that maximizes the correlation between them, then find the second combination, uncorrelated with the first, that maximizes the correlation among the second pair of variates, and so on. Canonical correlation analysis with a set of indicator variables is the same as canonical discriminant analysis.",AM,973,"['consider', 'agricultural', 'example', 'suppose', 'interested', 'predicting', 'crop', 'type', 'corn', 'cotton', 'soybean', 'based', 'series', 'remote', 'sensing', 'measure', 'could', 'perform', 'canonical', 'correlation', 'analysis', 'data_set', 'recoding', 'group', 'value', '01', 'creating', 'dummy', 'code', 'indicator', 'variable', 'would', 'two', 'indicator', 'variable', 'three', 'crop', 'could', 'treat', 'variable', 'one', 'group', 'v', 'set', 'predictor', 'remote', 'sensing', 'measure', 'second', 'set', 'variable', 'w', 'plot', 'show', 'two', 'canonical', 'variate', 'canonical', 'correlation', 'analysis', 'data', 'would', 'help', 'find', 'first', 'linear', 'combination', 'set', 'variable', 'maximizes', 'correlation', 'find', 'second', 'combination', 'uncorrelated', 'first', 'maximizes', 'correlation', 'among', 'second', 'pair', 'variate', 'canonical', 'correlation', 'analysis', 'set', 'indicator', 'variable', 'canonical', 'discriminant_analysis']"
99,"PROC CANDISC	calls the CANDISC procedure and specifies how the analysis is to be performed. CLASS	specifies the classification variable that you are trying to predict. VAR	specifies the set of continuous variables that you are using to discriminate among the groups specified by the CLASS variable. Selected option for the PROC CANDISC statement: OUT = data-set	creates an output data set that contains the original data and the canonical scores. OUTSTAT = data-set	creates a TYPE = CORR output SAS data set that contains various statistics including class-level statistics, correlations, canonical correlations, canonical structures, canonical coefficients, and means of canonical variates for each class. NOPRINT	suppresses display of output. NCAN = n	specifies the number of canonical variates to be computed. The value must be less than or equal to the maximum number of possible variates. The default is to compute all possible variates.",AM,942,"['proc', 'candisc\tcalls', 'candisc', 'procedure', 'specifies', 'analysis', 'performed', 'class\tspecifies', 'classification', 'variable', 'trying', 'predict', 'var\tspecifies', 'set', 'continuous', 'variable', 'using', 'discriminate', 'among', 'group', 'specified', 'class', 'variable', 'selected', 'option', 'proc', 'candisc', 'statement', '', 'dataset\tcreates', 'output', 'data_set', 'contains', 'original', 'data', 'canonical', 'score', 'outstat', '', 'dataset\tcreates', 'type', '', 'corr', 'output', 'sa', 'data_set', 'contains', 'various', 'statistic', 'including', 'classlevel', 'statistic', 'correlation', 'canonical', 'correlation', 'canonical', 'structure', 'canonical', 'coefficient', 'mean', 'canonical', 'variate', 'class', 'noprint\tsuppresses', 'display', 'output', 'ncan', '', 'n\tspecifies', 'number', 'canonical', 'variate', 'computed', 'value', 'must', 'le', 'equal', 'maximum', 'number', 'possible', 'variate', 'default', 'compute', 'possible', 'variate']"
100,"Where ANOVA tests for differences among group means, MANOVA tests for differences among the multivariate centroids of groups. In MANOVA, correlations among dependent variables can have dramatic effects on the inference based on the resulting linear model.",AM,255,"['anova', 'test', 'difference', 'among', 'group', 'mean', 'manova', 'test', 'difference', 'among', 'multivariate', 'centroid', 'group', 'manova', 'correlation', 'among', 'dependent', 'variable', 'dramatic', 'effect', 'inference', 'based', 'resulting', 'linear', 'model']"
101,"Many of the recommendations for restricted ranges apply to unequal group sizes. Careful planning is key to avoiding the problem of unequal group sizes. If you have enough small groups that are reasonably similar, you may be able to combine smaller groups and compare them to the larger group(s).",AM,295,"['many', 'recommendation', 'restricted', 'range', 'apply', 'unequal', 'group', 'size', 'careful', 'planning', 'key', 'avoiding', 'problem', 'unequal', 'group', 'size', 'enough', 'small', 'group', 'reasonably', 'similar', 'may', 'able', 'combine', 'smaller', 'group', 'compare', 'larger', 'group']"
102,"You used PROC CANDISC to assess the extent to which the variables discriminate between the groups. If this is your primary research goal, then you are advised to use PROC CANDISC. However, if your primary goal is to assess and apply the discriminant functions to future data in the interest of predicting group membership, then you are advised to use the DISCRIM procedure. PROC DISCRIM can be used for canonical discriminant analysis as well as other applications. Although PROC DISCRIM is capable of a wider range of analyses, the output from PROC CANDISC is generally simpler than output from PROC DISCRIM.",AM,609,"['used', 'proc', 'candisc', 'ass', 'extent', 'variable', 'discriminate', 'group', 'primary', 'research', 'goal', 'advised', 'use', 'proc', 'candisc', 'however', 'primary', 'goal', 'ass', 'apply', 'discriminant_function', 'future', 'data', 'interest', 'predicting', 'group', 'membership', 'advised', 'use', 'discrim', 'procedure', 'proc', 'discrim', 'used', 'canonical', 'discriminant_analysis', 'well', 'application', 'although', 'proc', 'discrim', 'capable', 'wider', 'range', 'analysis', 'output', 'proc', 'candisc', 'generally', 'simpler', 'output', 'proc', 'discrim']"
103,"Since the Chi-Square value is significant at the 0.05 level, the within covariance matrices will be used in the discriminant function. Reference: Morrison, D.F. (1976) Multivariate Statistical Methods p252. Documentation for the test of equality of covariance matrices is provided in the DISCRIM output. Recall that the null hypothesis is that the covariance matrices are homogeneous, or that the covariance matrices are equal to the pooled covariance matrix. You reject this hypothesis. Quadratic discriminant analysis is more appropriate than linear discriminant analysis in this example, and a note in the output tells you that within covariance matrices are used in the discriminant function. Pairwise Generalized Squared Distances Between Groups",AM,750,"['since', 'chisquare', 'value', 'significant', '005', 'level', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'reference', 'morrison', 'df', '1976', 'multivariate', 'statistical', 'method', 'p252', 'documentation', 'test', 'equality', 'covariance', 'matrix', 'provided', 'discrim', 'output', 'recall', 'null', 'hypothesis', 'covariance', 'matrix', 'homogeneous', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'reject', 'hypothesis', 'quadratic', 'discriminant_analysis', 'appropriate', 'linear', 'discriminant_analysis', 'example', 'note', 'output', 'tell', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
104,"CLASS	names the classification variables to be used in the model. If you specify a CLASS statement, it must appear before the MODEL statement. MODEL	names the dependent variables and independent effects. Variable names are separated by a space. Crossed independent effects are indicated with asterisks (*). The bar operator (|) can be used to simplify effect specification for large factorial models. In PROC GLM, you can specify only one MODEL statement. MANOVA	performs multivariate analysis of variance when multiple dependent variables are listed in the MODEL statement. When the MANOVA statement is specified before the first RUN statement, GLM uses a multivariate method of handling missing values. This means that if a case is missing any values for a variable specified in the model, the entire case is deleted from the analysis. Selected test option for the MANOVA statement: H = effects | INTERCEPT | _ALL_ specifies the effects in the model to use as hypothesis (H) matrices. The H= option displays the eigenvalues and eigenvectors associated with E-1H and the four multivariate test statistics. To use all the effects in the model, specify the _ALL_ option. Selected detail options for the MANOVA statement: MSTAT = EXACT|FAPPROX specifies the method of evaluating the multivariate test statistics. The default is MSTAT=FAPPROX, which specifies that the multivariate tests are evaluated using the usual approximations based on the F distribution. MSTAT=EXACT computes exact p-values for three of the four tests (Wilks' Lambda, the Hotelling-Lawley Trace, and Roy's Greatest Root) and an improved F-approximation for the fourth (Pillai's Trace). PRINTE	displays the error SSCP matrix, E. Also produces a table of partial correlations of the dependent variables given the independent variables when the residual matrix from the analysis is the E matrix. PRINTH	displays the hypothesis SSCP matrix H associated with each effect in the H= specification. Selected option for the MODEL statement: NOUNI	suppresses univariate ANOVA output.",AM,2044,"['class\tnames', 'classification', 'variable', 'used', 'model', 'specify', 'class', 'statement', 'must', 'appear', 'model_statement', 'model\tnames', 'dependent', 'variable', 'independent', 'effect', 'variable', 'name', 'separated', 'space', 'crossed', 'independent', 'effect', 'indicated', 'asterisk', '', 'bar', 'operator', '', 'used', 'simplify', 'effect', 'specification', 'large', 'factorial', 'model', 'proc', 'glm', 'specify', 'one', 'model_statement', 'manova\tperforms', 'multivariate', 'analysis', 'variance', 'multiple', 'dependent', 'variable', 'listed', 'model_statement', 'manova', 'statement', 'specified', 'first', 'run', 'statement', 'glm', 'us', 'multivariate', 'method', 'handling', 'missing', 'value', 'mean', 'case', 'missing', 'value', 'variable', 'specified', 'model', 'entire', 'case', 'deleted', 'analysis', 'selected', 'test', 'option', 'manova', 'statement', 'h', '', 'effect', '', 'intercept', '', 'specifies', 'effect', 'model', 'use', 'hypothesis', 'h', 'matrix', 'h', 'option', 'display', 'eigenvalue', 'eigenvectors', 'associated', 'e1h', 'four', 'multivariate', 'test', 'statistic', 'use', 'effect', 'model', 'specify', 'option', 'selected', 'detail', 'option', 'manova', 'statement', 'mstat', '', 'exactfapprox', 'specifies', 'method', 'evaluating', 'multivariate', 'test', 'statistic', 'default', 'mstatfapprox', 'specifies', 'multivariate', 'test', 'evaluated', 'using', 'usual', 'approximation', 'based', 'f', 'distribution', 'mstatexact', 'computes', 'exact', 'pvalues', 'three', 'four', 'test', 'wilks', 'lambda', 'hotellinglawley', 'trace', 'roys', 'greatest', 'root', 'improved', 'fapproximation', 'fourth', 'pillais', 'trace', 'printe\tdisplays', 'error', 'sscp', 'matrix', 'e', 'also', 'produce', 'table', 'partial', 'correlation', 'dependent', 'variable', 'given', 'independent', 'variable', 'residual', 'matrix', 'analysis', 'e', 'matrix', 'printh\tdisplays', 'hypothesis', 'sscp', 'matrix', 'h', 'associated', 'effect', 'h', 'specification', 'selected', 'option', 'model_statement', 'nouni\tsuppresses', 'univariate', 'anova', 'output']"
105,"NOTE: F Statistic for Roy's Greatest Root is an upper bound. NOTE: F Statistic for Wilks' Lambda is exact. The multivariate statistics test the null hypothesis that all the canonical correlations are simultaneously zero, which is the same as the hypothesis that there is no linear prediction of group membership from the predictor variables. You reject this null hypothesis. Adjusted Approximate Squared Canonical Canonical Standard Canonical Correlation Correlation Error Correlation",AM,484,"['note', 'f', 'statistic', 'roys', 'greatest', 'root', 'upper', 'bound', 'note', 'f', 'statistic', 'wilks', 'lambda', 'exact', 'multivariate', 'statistic', 'test', 'null', 'hypothesis', 'canonical', 'correlation', 'simultaneously', 'zero', 'hypothesis', 'linear', 'prediction', 'group', 'membership', 'predictor_variable', 'reject', 'null', 'hypothesis', 'adjusted', 'approximate', 'squared', 'canonical', 'canonical', 'standard', 'canonical', 'correlation', 'correlation', 'error', 'correlation']"
106,"You express the coefficients as integers by multiplying them by a constant. There are situations when you want to use the CONTRAST statement and the ESTIMATE statement together, such as when you are performing comparisons with more than one degree of freedom and you want the estimates from the tests. If you were only interested in the significance test from the contrast and not in the estimates, then you would use the CONTRAST statement only. The ESTIMATE statement for this contrast would be the same as the CONTRAST statement, except you would also include the DIVISOR= option to tell SAS to divide each estimate by 3 (so you can get the mean of the cell, instead of 3 ? the mean of the cell): In the following example, you will see both the CONTRAST and the ESTIMATE statements used. Using Contrasts for Custom Hypothesis Tests",AM,834,"['express', 'coefficient', 'integer', 'multiplying', 'constant', 'situation', 'want', 'use', 'contrast', 'statement', 'estimate', 'statement', 'together', 'performing', 'comparison', 'one', 'degree', 'freedom', 'want', 'estimate', 'test', 'interested', 'significance', 'test', 'contrast', 'estimate', 'would', 'use', 'contrast', 'statement', 'estimate', 'statement', 'contrast', 'would', 'contrast', 'statement', 'except', 'would', 'also', 'include', 'divisor', 'option', 'tell', 'sa', 'divide', 'estimate', '3', 'get', 'mean', 'cell', 'instead', '3', '', 'mean', 'cell', 'following', 'example', 'see', 'contrast', 'estimate', 'statement', 'used', 'using', 'contrast', 'custom', 'hypothesis', 'test']"
107,"If the homogeneity of covariance matrices assumption is violated, it is possible to perform the discriminant analysis using information about each of the groups separately. In this case, a third term is added to the generalized squared distance formula: the natural log of the determinant of the covariance matrix for each group. This is known as quadratic discriminant analysis. If the determinant of a covariance matrix for a group is large, this suggests large within-group variability. Using g1(t) results in the generalized squared distance from observations to group centroids being larger for that group than for groups with smaller within-group variability. Recall in the example you saw in the first section that the control group had the widest variability on the CDA plot. The Steady group had the smallest variability. It is possible that in this example, the assumption of homogeneity of covariance matrices was violated.",AM,934,"['homogeneity', 'covariance', 'matrix', 'assumption', 'violated', 'possible', 'perform', 'discriminant_analysis', 'using', 'information', 'group', 'separately', 'case', 'third', 'term', 'added', 'generalized', 'squared', 'distance', 'formula', 'natural', 'log', 'determinant', 'covariance', 'matrix', 'group', 'known', 'quadratic', 'discriminant_analysis', 'determinant', 'covariance', 'matrix', 'group', 'large', 'suggests', 'large', 'withingroup', 'variability', 'using', 'g1t', 'result', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'larger', 'group', 'group', 'smaller', 'withingroup', 'variability', 'recall', 'example', 'saw', 'first', 'section', 'control', 'group', 'widest', 'variability', 'cda', 'plot', 'steady', 'group', 'smallest', 'variability', 'possible', 'example', 'assumption', 'homogeneity', 'covariance', 'matrix', 'wa', 'violated']"
108,"Many of the recommendations for restricted ranges apply to unequal group sizes. Careful planning is key to avoiding the problem of unequal group sizes. If you have enough small groups that are reasonably similar, you may be able to combine smaller groups and compare them to the larger group(s).",AM,295,"['many', 'recommendation', 'restricted', 'range', 'apply', 'unequal', 'group', 'size', 'careful', 'planning', 'key', 'avoiding', 'problem', 'unequal', 'group', 'size', 'enough', 'small', 'group', 'reasonably', 'similar', 'may', 'able', 'combine', 'smaller', 'group', 'compare', 'larger', 'group']"
109,"CLASS	names the classification variables to be used in the model. If you specify a CLASS statement, it must appear before the MODEL statement. MODEL	names the dependent variables and independent effects. Variable names are separated by a space. Crossed independent effects are indicated with asterisks (*). The bar operator (|) can be used to simplify effect specification for large factorial models. In PROC GLM, you can specify only one MODEL statement. MANOVA	performs multivariate analysis of variance when multiple dependent variables are listed in the MODEL statement. When the MANOVA statement is specified before the first RUN statement, GLM uses a multivariate method of handling missing values. This means that if a case is missing any values for a variable specified in the model, the entire case is deleted from the analysis. Selected test option for the MANOVA statement: H = effects | INTERCEPT | _ALL_ specifies the effects in the model to use as hypothesis (H) matrices. The H= option displays the eigenvalues and eigenvectors associated with E-1H and the four multivariate test statistics. To use all the effects in the model, specify the _ALL_ option. Selected detail options for the MANOVA statement: MSTAT = EXACT|FAPPROX specifies the method of evaluating the multivariate test statistics. The default is MSTAT=FAPPROX, which specifies that the multivariate tests are evaluated using the usual approximations based on the F distribution. MSTAT=EXACT computes exact p-values for three of the four tests (Wilks' Lambda, the Hotelling-Lawley Trace, and Roy's Greatest Root) and an improved F-approximation for the fourth (Pillai's Trace). PRINTE	displays the error SSCP matrix, E. Also produces a table of partial correlations of the dependent variables given the independent variables when the residual matrix from the analysis is the E matrix. PRINTH	displays the hypothesis SSCP matrix H associated with each effect in the H= specification. Selected option for the MODEL statement: NOUNI	suppresses univariate ANOVA output.",AM,2044,"['class\tnames', 'classification', 'variable', 'used', 'model', 'specify', 'class', 'statement', 'must', 'appear', 'model_statement', 'model\tnames', 'dependent', 'variable', 'independent', 'effect', 'variable', 'name', 'separated', 'space', 'crossed', 'independent', 'effect', 'indicated', 'asterisk', '', 'bar', 'operator', '', 'used', 'simplify', 'effect', 'specification', 'large', 'factorial', 'model', 'proc', 'glm', 'specify', 'one', 'model_statement', 'manova\tperforms', 'multivariate', 'analysis', 'variance', 'multiple', 'dependent', 'variable', 'listed', 'model_statement', 'manova', 'statement', 'specified', 'first', 'run', 'statement', 'glm', 'us', 'multivariate', 'method', 'handling', 'missing', 'value', 'mean', 'case', 'missing', 'value', 'variable', 'specified', 'model', 'entire', 'case', 'deleted', 'analysis', 'selected', 'test', 'option', 'manova', 'statement', 'h', '', 'effect', '', 'intercept', '', 'specifies', 'effect', 'model', 'use', 'hypothesis', 'h', 'matrix', 'h', 'option', 'display', 'eigenvalue', 'eigenvectors', 'associated', 'e1h', 'four', 'multivariate', 'test', 'statistic', 'use', 'effect', 'model', 'specify', 'option', 'selected', 'detail', 'option', 'manova', 'statement', 'mstat', '', 'exactfapprox', 'specifies', 'method', 'evaluating', 'multivariate', 'test', 'statistic', 'default', 'mstatfapprox', 'specifies', 'multivariate', 'test', 'evaluated', 'using', 'usual', 'approximation', 'based', 'f', 'distribution', 'mstatexact', 'computes', 'exact', 'pvalues', 'three', 'four', 'test', 'wilks', 'lambda', 'hotellinglawley', 'trace', 'roys', 'greatest', 'root', 'improved', 'fapproximation', 'fourth', 'pillais', 'trace', 'printe\tdisplays', 'error', 'sscp', 'matrix', 'e', 'also', 'produce', 'table', 'partial', 'correlation', 'dependent', 'variable', 'given', 'independent', 'variable', 'residual', 'matrix', 'analysis', 'e', 'matrix', 'printh\tdisplays', 'hypothesis', 'sscp', 'matrix', 'h', 'associated', 'effect', 'h', 'specification', 'selected', 'option', 'model_statement', 'nouni\tsuppresses', 'univariate', 'anova', 'output']"
110,"It is easy to see the pattern of how the groups fall on the discriminant functions. As you saw before, the first function distinguishes between Steady and Binge gamblers, while the second function discriminates between Controls and Steady gamblers.",AM,248,"['easy', 'see', 'pattern', 'group', 'fall', 'discriminant_function', 'saw', 'first', 'function', 'distinguishes', 'steady', 'binge', 'gambler', 'second', 'function', 'discriminates', 'control', 'steady', 'gambler']"
111,"The CLASS and VAR statements serve the same purpose as they do in PROC CANDISC. Selection options for the PROC DISCRIM statement: LIST	classifies observations into groups based on the discriminant functions. ANOVA	performs univariate ANOVAs to see whether the groups differ significantly on each predictor variable. It can be useful in eliminating irrelevant variables from the analysis. CAN	specifies that canonical discriminant analysis be performed. To achieve the same analysis as the one you saw in PROC CANDISC, specify proportional priors in the PRIORS statement. ?	See Appendix C for an example of how to perform canonical discriminant analysis using PROC DISCRIM. The PRIORS statement is discussed on the next page.",AM,724,"['class', 'var', 'statement', 'serve', 'purpose', 'proc', 'candisc', 'selection', 'option', 'proc', 'discrim', 'statement', 'list\tclassifies', 'observation', 'group', 'based', 'discriminant_function', 'anova\tperforms', 'univariate', 'anova', 'see', 'whether', 'group', 'differ', 'significantly', 'predictor_variable', 'useful', 'eliminating', 'irrelevant', 'variable', 'analysis', 'can\tspecifies', 'canonical', 'discriminant_analysis', 'performed', 'achieve', 'analysis', 'one', 'saw', 'proc', 'candisc', 'specify', 'proportional', 'prior', 'prior', 'statement', '\tsee', 'appendix', 'c', 'example', 'perform', 'canonical', 'discriminant_analysis', 'using', 'proc', 'discrim', 'prior', 'statement', 'discussed', 'next', 'page']"
112,"It is useful to examine the means of the subgroups on each of the canonical discriminant functions. The space defined by the canonical discriminant functions is the space that maximally separates the group centroids (multivariate mean vectors). In this case, you see that the first canonical discriminant function seems to be mostly separating the Binge and the Steady gamblers, and the second canonical discriminant function appears to be separating the Control group from the Steady gamblers. If your data set is very large, it is often useful to plot the group centroids in the space defined by the canonical discriminant functions to get an idea of how well the group centroids are separated. In this case, the data set is sufficiently small that you can plot the individual observations in the space defined by the discriminant functions. ?	Although it is not shown here, you could use ODS to save the centroids from the Class Means on Canonical Variables table and plot them using the GPLOT procedure. An example program, CDA plot with centroids.sas, is included with the course data.",AM,1090,"['useful', 'examine', 'mean', 'subgroup', 'canonical', 'discriminant_function', 'space', 'defined', 'canonical', 'discriminant_function', 'space', 'maximally', 'separate', 'group', 'centroid', 'multivariate', 'mean', 'vector', 'case', 'see', 'first', 'canonical', 'discriminant_function', 'seems', 'mostly', 'separating', 'binge', 'steady', 'gambler', 'second', 'canonical', 'discriminant_function', 'appears', 'separating', 'control', 'group', 'steady', 'gambler', 'data_set', 'large', 'often', 'useful', 'plot', 'group', 'centroid', 'space', 'defined', 'canonical', 'discriminant_function', 'get', 'idea', 'well', 'group', 'centroid', 'separated', 'case', 'data_set', 'sufficiently', 'small', 'plot', 'individual', 'observation', 'space', 'defined', 'discriminant_function', '\talthough', 'shown', 'could', 'use', 'od', 'save', 'centroid', 'class', 'mean', 'canonical', 'variable', 'table', 'plot', 'using', 'gplot', 'procedure', 'example', 'program', 'cda', 'plot', 'centroidssas', 'included', 'course', 'data']"
113,?	You can also rotate without using the Graph Toolbar by holding down the Alt key on your keyboard and the left mouse button. Move the cursor over the picture to rotate it while holding these two buttons.,AM,204,"['\tyou', 'also', 'rotate', 'without', 'using', 'graph', 'toolbar', 'holding', 'alt', 'key', 'keyboard', 'left', 'mouse', 'button', 'move', 'cursor', 'picture', 'rotate', 'holding', 'two', 'button']"
114,"The contrast coefficients for all the terms in the linear model are shown above. However, coefficients must be expressed as integers or decimal values. Expressing 1/3 as a decimal value can be problematic, so the values must be multiplied by a constant.",AM,253,"['contrast', 'coefficient', 'term', 'linear', 'model', 'shown', 'however', 'coefficient', 'must', 'expressed', 'integer', 'decimal', 'value', 'expressing', '13', 'decimal', 'value', 'problematic', 'value', 'must', 'multiplied', 'constant']"
115,"There are potential problems in any kind of data. Computers crash, researchers enter erroneous factor settings, data entry coders make typographical errors, and research participants fall asleep. Human error, technical difficulties in automated systems, collinear variables, duplicated records, outlying observations, and a host of other problems can plague your data. The more time you invest in validating, cleaning, preparing and checking your data, the more you will be able to reap the rewards of your statistical analyses. In addition to making the data ready for your analyses, often preparing and evaluating the data provide you with insight that you may not have gained otherwise.",AM,689,"['potential', 'problem', 'kind', 'data', 'computer', 'crash', 'researcher', 'enter', 'erroneous', 'factor', 'setting', 'data', 'entry', 'coder', 'make', 'typographical', 'error', 'research', 'participant', 'fall', 'asleep', 'human', 'error', 'technical', 'difficulty', 'automated', 'system', 'collinear', 'variable', 'duplicated', 'record', 'outlying', 'observation', 'host', 'problem', 'plague', 'data', 'time', 'invest', 'validating', 'cleaning', 'preparing', 'checking', 'data', 'able', 'reap', 'reward', 'statistical', 'analysis', 'addition', 'making', 'data', 'ready', 'analysis', 'often', 'preparing', 'evaluating', 'data', 'provide', 'insight', 'may', 'gained', 'otherwise']"
116,"Recall that just as ANOVA assumes that groups have equal variances, MANOVA and linear discriminant analysis both assume that groups have homogeneous covariance matrices. Violating this assumption can result in incorrect inference about group differences in MANOVA and canonical discriminant analysis. In Fisher linear discriminant analysis, it can result in incorrect prediction of group membership. Consider the generalized squared distance between observations and group centroids, above. In this formula, a single (pooled) estimate of the covariance matrix is used and therefore the formula does not reflect group differences in variances and covariances.",AM,658,"['recall', 'anova', 'assumes', 'group', 'equal', 'variance', 'manova', 'linear', 'discriminant_analysis', 'assume', 'group', 'homogeneous', 'covariance', 'matrix', 'violating', 'assumption', 'result', 'incorrect', 'inference', 'group', 'difference', 'manova', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'result', 'incorrect', 'prediction', 'group', 'membership', 'consider', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'formula', 'single', 'pooled', 'estimate', 'covariance', 'matrix', 'used', 'therefore', 'formula', 'doe', 'reflect', 'group', 'difference', 'variance', 'covariance']"
117,"Since the Chi-Square value is significant at the 0.05 level, the within covariance matrices will be used in the discriminant function. Reference: Morrison, D.F. (1976) Multivariate Statistical Methods p252. Documentation for the test of equality of covariance matrices is provided in the DISCRIM output. Recall that the null hypothesis is that the covariance matrices are homogeneous, or that the covariance matrices are equal to the pooled covariance matrix. You reject this hypothesis. Quadratic discriminant analysis is more appropriate than linear discriminant analysis in this example, and a note in the output tells you that within covariance matrices are used in the discriminant function. Pairwise Generalized Squared Distances Between Groups",AM,750,"['since', 'chisquare', 'value', 'significant', '005', 'level', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'reference', 'morrison', 'df', '1976', 'multivariate', 'statistical', 'method', 'p252', 'documentation', 'test', 'equality', 'covariance', 'matrix', 'provided', 'discrim', 'output', 'recall', 'null', 'hypothesis', 'covariance', 'matrix', 'homogeneous', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'reject', 'hypothesis', 'quadratic', 'discriminant_analysis', 'appropriate', 'linear', 'discriminant_analysis', 'example', 'note', 'output', 'tell', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
118,"The research questions above share a common thread ? prediction of groups. These questions are conceptually similar to logistic regression, which models the odds of membership in one group versus another group based on values of predictors. Discriminant function analysis can be thought of as a multivariate generalization of logistic regression, although as you will see, the computation for discriminant analysis is more similar to MANOVA or canonical correlation analysis than to logistic regression.",AM,503,"['research', 'question', 'share', 'common', 'thread', '', 'prediction', 'group', 'question', 'conceptually', 'similar', 'logistic_regression_model', 'odds', 'membership', 'one', 'group', 'versus', 'another', 'group', 'based', 'value', 'predictor', 'discriminant_function', 'analysis', 'thought', 'multivariate', 'generalization', 'logistic_regression', 'although', 'see', 'computation', 'discriminant_analysis', 'similar', 'manova', 'canonical', 'correlation', 'analysis', 'logistic_regression']"
119,"PROC CANDISC	calls the CANDISC procedure and specifies how the analysis is to be performed. CLASS	specifies the classification variable that you are trying to predict. VAR	specifies the set of continuous variables that you are using to discriminate among the groups specified by the CLASS variable. Selected option for the PROC CANDISC statement: OUT = data-set	creates an output data set that contains the original data and the canonical scores. OUTSTAT = data-set	creates a TYPE = CORR output SAS data set that contains various statistics including class-level statistics, correlations, canonical correlations, canonical structures, canonical coefficients, and means of canonical variates for each class. NOPRINT	suppresses display of output. NCAN = n	specifies the number of canonical variates to be computed. The value must be less than or equal to the maximum number of possible variates. The default is to compute all possible variates.",AM,942,"['proc', 'candisc\tcalls', 'candisc', 'procedure', 'specifies', 'analysis', 'performed', 'class\tspecifies', 'classification', 'variable', 'trying', 'predict', 'var\tspecifies', 'set', 'continuous', 'variable', 'using', 'discriminate', 'among', 'group', 'specified', 'class', 'variable', 'selected', 'option', 'proc', 'candisc', 'statement', '', 'dataset\tcreates', 'output', 'data_set', 'contains', 'original', 'data', 'canonical', 'score', 'outstat', '', 'dataset\tcreates', 'type', '', 'corr', 'output', 'sa', 'data_set', 'contains', 'various', 'statistic', 'including', 'classlevel', 'statistic', 'correlation', 'canonical', 'correlation', 'canonical', 'structure', 'canonical', 'coefficient', 'mean', 'canonical', 'variate', 'class', 'noprint\tsuppresses', 'display', 'output', 'ncan', '', 'n\tspecifies', 'number', 'canonical', 'variate', 'computed', 'value', 'must', 'le', 'equal', 'maximum', 'number', 'possible', 'variate', 'default', 'compute', 'possible', 'variate']"
120,"Specifying contrasts using your full model, with intercept, drug, dose, drug*dose, can be difficult. This is especially true for large, complex models. In order to simplify the process of writing contrasts, you can re-specify the model as a cell means model. This is a model that estimates only one parameter for each group and sets the y-intercept to 0. If there is more than one independent variable, this model does not test main effects separately from interactions. Instead, interactions are pooled with all lower-order terms.",AM,531,"['specifying', 'contrast', 'using', 'full', 'model', 'intercept', 'drug', 'dose', 'drugdose', 'difficult', 'especially', 'true', 'large', 'complex', 'model', 'order', 'simplify', 'process', 'writing', 'contrast', 'respecify', 'model', 'cell', 'mean', 'model', 'model', 'estimate', 'one', 'parameter', 'group', 'set', 'yintercept', '0', 'one', 'independent', 'variable', 'model', 'doe', 'test', 'main_effect', 'separately', 'interaction', 'instead', 'interaction', 'pooled', 'lowerorder', 'term']"
121,"Specifying contrasts using your full model, with intercept, drug, dose, drug*dose, can be difficult. This is especially true for large, complex models. In order to simplify the process of writing contrasts, you can re-specify the model as a cell means model. This is a model that estimates only one parameter for each group and sets the y-intercept to 0. If there is more than one independent variable, this model does not test main effects separately from interactions. Instead, interactions are pooled with all lower-order terms.",AM,531,"['specifying', 'contrast', 'using', 'full', 'model', 'intercept', 'drug', 'dose', 'drugdose', 'difficult', 'especially', 'true', 'large', 'complex', 'model', 'order', 'simplify', 'process', 'writing', 'contrast', 'respecify', 'model', 'cell', 'mean', 'model', 'model', 'estimate', 'one', 'parameter', 'group', 'set', 'yintercept', '0', 'one', 'independent', 'variable', 'model', 'doe', 'test', 'main_effect', 'separately', 'interaction', 'instead', 'interaction', 'pooled', 'lowerorder', 'term']"
122,"Sometimes values fall within the possible range on a variable but far from the other values in the data. Sometimes, as in the picture above, an observation may fall within the normal ranges on several variables, but the pattern of several variables reveals a multivariate outlier. Outliers can be problematic for a variety of reasons. Many analyses that assume normality are sensitive to outliers. Linear statistical models such as ANOVA and regression are sensitive to the effects of outliers.",AM,494,"['sometimes', 'value', 'fall', 'within', 'possible', 'range', 'variable', 'far', 'value', 'data', 'sometimes', 'picture', 'observation', 'may', 'fall', 'within', 'normal', 'range', 'several', 'variable', 'pattern', 'several', 'variable', 'reveals', 'multivariate', 'outlier', 'outlier', 'problematic', 'variety', 'reason', 'many', 'analysis', 'assume', 'normality', 'sensitive', 'outlier', 'linear', 'statistical', 'model', 'anova', 'regression', 'sensitive', 'effect', 'outlier']"
123,"It is easy to see the pattern of how the groups fall on the discriminant functions. As you saw before, the first function distinguishes between Steady and Binge gamblers, while the second function discriminates between Controls and Steady gamblers.",AM,248,"['easy', 'see', 'pattern', 'group', 'fall', 'discriminant_function', 'saw', 'first', 'function', 'distinguishes', 'steady', 'binge', 'gambler', 'second', 'function', 'discriminates', 'control', 'steady', 'gambler']"
124,"In order for the test statistics in MANOVA to follow the theorized distribution, certain assumptions should be met: *	Observations are randomly sampled from the population. *	Observations are independent of one another; in other words, one observation does not provide information about other observations. *	The set of dependent variables follows a multivariate normal distribution conditional on the independent variables. This implies univariate conditional normality for each DV separately, but univariate normality alone is not sufficient for the assumption of multivariate normality to be met. *	The within-group covariance matrices are equal across groups. This implies equal variances across groups for each DV, and it also implies that all pairwise correlations between the DVs are equal across groups. As with ANOVA, MANOVA test statistics are robust to violations of some, but not all, of these assumptions. The robustness of each test statistic varies (Bray and Maxwell 1985). As a result, there is not a single test statistic that is uniformly preferred in all situations.",AM,1085,"['order', 'test', 'statistic', 'manova', 'follow', 'theorized', 'distribution', 'certain', 'assumption', 'met', '\tobservations', 'randomly', 'sampled', 'population', '\tobservations', 'independent', 'one', 'another', 'word', 'one', 'observation', 'doe', 'provide', 'information', 'observation', '\tthe', 'set', 'dependent', 'variable', 'follows', 'multivariate', 'normal', 'distribution', 'conditional', 'independent', 'variable', 'implies', 'univariate', 'conditional', 'normality', 'dv', 'separately', 'univariate', 'normality', 'alone', 'sufficient', 'assumption', 'multivariate', 'normality', 'met', '\tthe', 'withingroup', 'covariance', 'matrix', 'equal', 'across', 'group', 'implies', 'equal', 'variance', 'across', 'group', 'dv', 'also', 'implies', 'pairwise', 'correlation', 'dvs', 'equal', 'across', 'group', 'anova', 'manova', 'test', 'statistic', 'robust', 'violation', 'assumption', 'robustness', 'test', 'statistic', 'varies', 'bray', 'maxwell', '1985', 'result', 'single', 'test', 'statistic', 'uniformly', 'preferred', 'situation']"
125,"One way to handle outliers without deleting the observation from the analysis completely is to replace the value or values with something less extreme. For example, with univariate outliers, winsorized means are measures of central tendency in which the extreme values have been replaced with less extreme values. Trimmed means are measures of central tendency whose most extreme (upper and lower) values have been removed from calculations. You can obtain winsorized and trimmed means with the UNIVARIATE procedure. Outliers can pose real problems for your analyses. Regardless of how you choose to handle outliers, it is always important to document your actions carefully so that others know what you did.",AM,708,"['one', 'way', 'handle', 'outlier', 'without', 'deleting', 'observation', 'analysis', 'completely', 'replace', 'value', 'value', 'something', 'le', 'extreme', 'example', 'univariate', 'outlier', 'winsorized', 'mean', 'measure', 'central', 'tendency', 'extreme', 'value', 'replaced', 'le', 'extreme', 'value', 'trimmed', 'mean', 'measure', 'central', 'tendency', 'whose', 'extreme', 'upper', 'lower', 'value', 'removed', 'calculation', 'obtain', 'winsorized', 'trimmed', 'mean', 'univariate', 'procedure', 'outlier', 'pose', 'real', 'problem', 'analysis', 'regardless', 'choose', 'handle', 'outlier', 'always', 'important', 'document', 'action', 'carefully', 'others', 'know']"
126,"Discriminant analysis differs from logistic regression or canonical correlation because it is easy to use the discriminant functions to make predictions of groups when group information is not available (validation, crossvalidation, and classification). In other words, you might think of discriminant analysis as a way of learning what variables predict membership in various groups. The discriminant functions allow you to make well-informed decisions based on information from a set of predictor variables. The methods demonstrated in this course assume that your predictor variables follow a multivariate normal distribution. Parametric discriminant analysis is robust to the MV normality assumption much the way MANOVA is, although the user should be aware that nonnormality (particularly high kurtosis) could lead to biased predictions in discriminant analysis (Hosmer and Lemeshow 1989). If you have nonnormal (particularly categorical) predictors, you may prefer a nonparametric method or logistic regression.",AM,1017,"['discriminant_analysis', 'differs', 'logistic_regression', 'canonical', 'correlation', 'easy', 'use', 'discriminant_function', 'make', 'prediction', 'group', 'group', 'information', 'available', 'validation', 'crossvalidation', 'classification', 'word', 'might', 'think', 'discriminant_analysis', 'way', 'learning', 'variable', 'predict', 'membership', 'various', 'group', 'discriminant_function', 'allow', 'make', 'wellinformed', 'decision', 'based', 'information', 'set', 'predictor_variable', 'method', 'demonstrated', 'course', 'assume', 'predictor_variable', 'follow', 'multivariate', 'normal', 'distribution', 'parametric', 'discriminant_analysis', 'robust', 'mv', 'normality', 'assumption', 'much', 'way', 'manova', 'although', 'user', 'aware', 'nonnormality', 'particularly', 'high', 'kurtosis', 'could', 'lead', 'biased', 'prediction', 'discriminant_analysis', 'hosmer', 'lemeshow', '1989', 'nonnormal', 'particularly', 'categorical', 'predictor', 'may', 'prefer', 'nonparametric', 'method', 'logistic_regression']"
127,"When there are multiple dependent measures for a factorial design, multivariate analysis of variance (MANOVA) can be a very useful tool in determining whether groups differ on a set of measures. Sometimes you are interested in specific comparisons between pairs of groups, between one group and a combination of groups, or perhaps other comparisons. Contrasts in the GLM procedure enable you to test custom hypotheses about your population. After you learn to fit multivariate models using SAS, you learn to apply other multivariate methods using SAS such as factor analysis, structural equation models, and discriminant function analysis.",AM,639,"['multiple', 'dependent', 'measure', 'factorial', 'design', 'multivariate', 'analysis', 'variance', 'manova', 'useful', 'tool', 'determining', 'whether', 'group', 'differ', 'set', 'measure', 'sometimes', 'interested', 'specific', 'comparison', 'pair', 'group', 'one', 'group', 'combination', 'group', 'perhaps', 'comparison', 'contrast', 'glm', 'procedure', 'enable', 'test', 'custom', 'hypothesis', 'population', 'learn', 'fit', 'multivariate', 'model', 'using', 'sa', 'learn', 'apply', 'multivariate', 'method', 'using', 'sa', 'factor', 'analysis', 'structural', 'equation', 'model', 'discriminant_function', 'analysis']"
128,"Because of the unequal group sizes, you may want to consider combining similar groups together, and/or testing for equality of covariance matrices before performing any multivariate analyses with this variable.",AM,210,"['unequal', 'group', 'size', 'may', 'want', 'consider', 'combining', 'similar', 'group', 'together', 'andor', 'testing', 'equality', 'covariance', 'matrix', 'performing', 'multivariate', 'analysis', 'variable']"
129,"where Vt = St if using within-group covariance matrices, or Vt = Sp if using pooled covariance matrices, and mt is the mean vector of group t. ?	The default in PROC DISCRIM is to use pooled covariances in calculating the generalized squared distances. If you prefer to use within-class covariances, specify POOL = NO in the DISCRIM statement. You will learn to use this option later in the course for quadratic discriminant analysis.",AM,433,"['vt', '', 'st', 'using', 'withingroup', 'covariance', 'matrix', 'vt', '', 'sp', 'using', 'pooled', 'covariance', 'matrix', 'mt', 'mean', 'vector', 'group', '\tthe', 'default', 'proc', 'discrim', 'use', 'pooled', 'covariance', 'calculating', 'generalized', 'squared', 'distance', 'prefer', 'use', 'withinclass', 'covariance', 'specify', 'pool', '', 'discrim', 'statement', 'learn', 'use', 'option', 'later', 'course', 'quadratic', 'discriminant_analysis']"
130,"Create a table of the cell means in your model. The ordering of the variables is determined by the order of the variables in the CLASS statement. The first independent variable represents the rows. The second represents the columns. Specify the contrast hypothesis in terms of the cell means, as shown below:",AM,308,"['create', 'table', 'cell', 'mean', 'model', 'ordering', 'variable', 'determined', 'order', 'variable', 'class', 'statement', 'first', 'independent', 'variable', 'represents', 'row', 'second', 'represents', 'column', 'specify', 'contrast', 'hypothesis', 'term', 'cell', 'mean', 'shown']"
131,"There are many ways to specify a contrast. Perhaps the easiest method is by using the cell means model. Writing contrasts with the cell means model enables you to specify any contrast you are interested in. However, it is very important to understand that this model specification method is used for simplifying the contrasts, and it does not generally produce an overall test of model fit that researchers are interested in. In specifying coefficients for a CONTRAST or ESTIMATE statement, ordering of the terms is determined by the order in which variables appear in the CLASS statement. The levels of each factor are expressed in alphanumeric order. ?	If you are uncertain about the order of the terms in your model, specify the SOLUTION option in the MODEL statement in PROC GLM. This will display a table of parameter estimates, and you will see the order in which the contrast terms should be specified.",AM,909,"['many', 'way', 'specify', 'contrast', 'perhaps', 'easiest', 'method', 'using', 'cell', 'mean', 'model', 'writing', 'contrast', 'cell', 'mean', 'model', 'enables', 'specify', 'contrast', 'interested', 'however', 'important', 'understand', 'model', 'specification', 'method', 'used', 'simplifying', 'contrast', 'doe', 'generally', 'produce', 'overall', 'test', 'model', 'fit', 'researcher', 'interested', 'specifying', 'coefficient', 'contrast', 'estimate', 'statement', 'ordering', 'term', 'determined', 'order', 'variable', 'appear', 'class', 'statement', 'level', 'factor', 'expressed', 'alphanumeric', 'order', '\tif', 'uncertain', 'order', 'term', 'model', 'specify', 'solution', 'option', 'model_statement', 'proc', 'glm', 'display', 'table', 'parameter_estimate', 'see', 'order', 'contrast', 'term', 'specified']"
132,?	You can also rotate without using the Graph Toolbar by holding down the Alt key on your keyboard and the left mouse button. Move the cursor over the picture to rotate it while holding these two buttons.,AM,204,"['\tyou', 'also', 'rotate', 'without', 'using', 'graph', 'toolbar', 'holding', 'alt', 'key', 'keyboard', 'left', 'mouse', 'button', 'move', 'cursor', 'picture', 'rotate', 'holding', 'two', 'button']"
133,Only the first 20 out of 100 observations are shown here. PROC DISCRIM flags misclassified observations with an asterisk. You can see that observations 12 and 13 were misclassified. Classification Summary for Calibration Data: AMUL.GAMBLEGRP Resubstitution Summary using Linear Discriminant Function,AM,299,"['first', '20', '100', 'observation', 'shown', 'proc', 'discrim', 'flag', 'misclassified', 'observation', 'asterisk', 'see', 'observation', '12', '13', 'misclassified', 'classification', 'summary', 'calibration', 'data', 'amulgamblegrp', 'resubstitution', 'summary', 'using', 'linear', 'discriminant_function']"
134,"You express the coefficients as integers by multiplying them by a constant. There are situations when you want to use the CONTRAST statement and the ESTIMATE statement together, such as when you are performing comparisons with more than one degree of freedom and you want the estimates from the tests. If you were only interested in the significance test from the contrast and not in the estimates, then you would use the CONTRAST statement only. The ESTIMATE statement for this contrast would be the same as the CONTRAST statement, except you would also include the DIVISOR= option to tell SAS to divide each estimate by 3 (so you can get the mean of the cell, instead of 3 ? the mean of the cell): In the following example, you will see both the CONTRAST and the ESTIMATE statements used. Using Contrasts for Custom Hypothesis Tests",AM,834,"['express', 'coefficient', 'integer', 'multiplying', 'constant', 'situation', 'want', 'use', 'contrast', 'statement', 'estimate', 'statement', 'together', 'performing', 'comparison', 'one', 'degree', 'freedom', 'want', 'estimate', 'test', 'interested', 'significance', 'test', 'contrast', 'estimate', 'would', 'use', 'contrast', 'statement', 'estimate', 'statement', 'contrast', 'would', 'contrast', 'statement', 'except', 'would', 'also', 'include', 'divisor', 'option', 'tell', 'sa', 'divide', 'estimate', '3', 'get', 'mean', 'cell', 'instead', '3', '', 'mean', 'cell', 'following', 'example', 'see', 'contrast', 'estimate', 'statement', 'used', 'using', 'contrast', 'custom', 'hypothesis', 'test']"
135,"There are potential problems in any kind of data. Computers crash, researchers enter erroneous factor settings, data entry coders make typographical errors, and research participants fall asleep. Human error, technical difficulties in automated systems, collinear variables, duplicated records, outlying observations, and a host of other problems can plague your data. The more time you invest in validating, cleaning, preparing and checking your data, the more you will be able to reap the rewards of your statistical analyses. In addition to making the data ready for your analyses, often preparing and evaluating the data provide you with insight that you may not have gained otherwise.",AM,689,"['potential', 'problem', 'kind', 'data', 'computer', 'crash', 'researcher', 'enter', 'erroneous', 'factor', 'setting', 'data', 'entry', 'coder', 'make', 'typographical', 'error', 'research', 'participant', 'fall', 'asleep', 'human', 'error', 'technical', 'difficulty', 'automated', 'system', 'collinear', 'variable', 'duplicated', 'record', 'outlying', 'observation', 'host', 'problem', 'plague', 'data', 'time', 'invest', 'validating', 'cleaning', 'preparing', 'checking', 'data', 'able', 'reap', 'reward', 'statistical', 'analysis', 'addition', 'making', 'data', 'ready', 'analysis', 'often', 'preparing', 'evaluating', 'data', 'provide', 'insight', 'may', 'gained', 'otherwise']"
136,"Where ANOVA tests for differences among group means, MANOVA tests for differences among the multivariate centroids of groups. In MANOVA, correlations among dependent variables can have dramatic effects on the inference based on the resulting linear model.",AM,255,"['anova', 'test', 'difference', 'among', 'group', 'mean', 'manova', 'test', 'difference', 'among', 'multivariate', 'centroid', 'group', 'manova', 'correlation', 'among', 'dependent', 'variable', 'dramatic', 'effect', 'inference', 'based', 'resulting', 'linear', 'model']"
137,"With a CONTRAST statement, you specify L, in this case, a vector of coefficients for the effect to be tested. M is a transformation matrix that in this case is an identity matrix. For this reason, M is sometimes dropped from the null hypothesis specification. CONTRAST	enables you to perform custom hypothesis tests by specifying an L vector or matrix for testing the univariate hypothesis . There is no limit to the number of CONTRAST statements you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE	enables you to estimate linear functions of the parameters by multiplying the vector L by the parameter estimate vector b resulting in Lb. There is no limit to the number of ESTIMATE statements that you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE statements only perform 1-df univariate tests. In the CONTRAST and ESTIMATE statements, label	applies a label to the contrast (or estimate) on the output. A label is required for every contrast (or estimate) specified. Labels must be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement, or the INTERCEPT effect. The INTERCEPT effect can be used when an intercept is fitted in the model. You do not need to include all effects that are in the MODEL statement. values	are constants that are elements of the L vector associated with the effect. You do not need to include trailing zeros in the L vector.",AM,1490,"['contrast', 'statement', 'specify', 'l', 'case', 'vector', 'coefficient', 'effect', 'tested', 'transformation', 'matrix', 'case', 'identity', 'matrix', 'reason', 'sometimes', 'dropped', 'null', 'hypothesis', 'specification', 'contrast\tenables', 'perform', 'custom', 'hypothesis', 'test', 'specifying', 'l', 'vector', 'matrix', 'testing', 'univariate', 'hypothesis', '', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate\tenables', 'estimate', 'linear', 'function', 'parameter', 'multiplying', 'vector', 'l', 'parameter_estimate', 'vector', 'b', 'resulting', 'lb', 'limit', 'number', 'estimate', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate', 'statement', 'perform', '1df', 'univariate', 'test', 'contrast', 'estimate', 'statement', 'label\tapplies', 'label', 'contrast', 'estimate', 'output', 'label', 'required', 'every', 'contrast', 'estimate', 'specified', 'label', 'must', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'intercept', 'effect', 'intercept', 'effect', 'used', 'intercept', 'fitted', 'model', 'need', 'include', 'effect', 'model_statement', 'values\tare', 'constant', 'element', 'l', 'vector', 'associated', 'effect', 'need', 'include', 'trailing', 'zero', 'l', 'vector']"
138,"4.	You can also change the appearance of your object from the right-click menu. Take a moment to explore the options available to you with the right-click menu and the Graph Toolbar. By investigating the responses in the 3-D graph, you can see that changes in the two OC scales, ybocgain and nimhgain, are positively associated. It also seems that change in neither OC scale is associated with change in the depression scale, hdrsgain.",AM,435,"['4\tyou', 'also', 'change', 'appearance', 'object', 'rightclick', 'menu', 'take', 'moment', 'explore', 'option', 'available', 'rightclick', 'menu', 'graph', 'toolbar', 'investigating', 'response', '3d', 'graph', 'see', 'change', 'two', 'oc', 'scale', 'ybocgain', 'nimhgain', 'positively', 'associated', 'also', 'seems', 'change', 'neither', 'oc', 'scale', 'associated', 'change', 'depression', 'scale', 'hdrsgain']"
139,"You can see that the Fried Platter, Tuna Sub, and several others are bivariate outliers on more than one plot. Continue to explore the plots. You can change the colors of specific observations. For example, you may want to identify all the Frozen sandwiches on your plot. You can label the Frozen sandwiches with a special color to make them easier to find on the plots. 3.	In the data table, highlight the rows that are Frozen sandwiches by clicking on the row header and dragging the selection. Partial Display",AM,512,"['see', 'fried', 'platter', 'tuna', 'sub', 'several', 'others', 'bivariate', 'outlier', 'one', 'plot', 'continue', 'explore', 'plot', 'change', 'color', 'specific', 'observation', 'example', 'may', 'want', 'identify', 'frozen', 'sandwich', 'plot', 'label', 'frozen', 'sandwich', 'special', 'color', 'make', 'easier', 'find', 'plot', '3\tin', 'data', 'table', 'highlight', 'row', 'frozen', 'sandwich', 'clicking', 'row', 'header', 'dragging', 'selection', 'partial', 'display']"
140,"You used PROC CANDISC to assess the extent to which the variables discriminate between the groups. If this is your primary research goal, then you are advised to use PROC CANDISC. However, if your primary goal is to assess and apply the discriminant functions to future data in the interest of predicting group membership, then you are advised to use the DISCRIM procedure. PROC DISCRIM can be used for canonical discriminant analysis as well as other applications. Although PROC DISCRIM is capable of a wider range of analyses, the output from PROC CANDISC is generally simpler than output from PROC DISCRIM.",AM,609,"['used', 'proc', 'candisc', 'ass', 'extent', 'variable', 'discriminate', 'group', 'primary', 'research', 'goal', 'advised', 'use', 'proc', 'candisc', 'however', 'primary', 'goal', 'ass', 'apply', 'discriminant_function', 'future', 'data', 'interest', 'predicting', 'group', 'membership', 'advised', 'use', 'discrim', 'procedure', 'proc', 'discrim', 'used', 'canonical', 'discriminant_analysis', 'well', 'application', 'although', 'proc', 'discrim', 'capable', 'wider', 'range', 'analysis', 'output', 'proc', 'candisc', 'generally', 'simpler', 'output', 'proc', 'discrim']"
141,"Because of the unequal group sizes, you may want to consider combining similar groups together, and/or testing for equality of covariance matrices before performing any multivariate analyses with this variable.",AM,210,"['unequal', 'group', 'size', 'may', 'want', 'consider', 'combining', 'similar', 'group', 'together', 'andor', 'testing', 'equality', 'covariance', 'matrix', 'performing', 'multivariate', 'analysis', 'variable']"
142,"Specifying contrasts using your full model, with intercept, drug, dose, drug*dose, can be difficult. This is especially true for large, complex models. In order to simplify the process of writing contrasts, you can re-specify the model as a cell means model. This is a model that estimates only one parameter for each group and sets the y-intercept to 0. If there is more than one independent variable, this model does not test main effects separately from interactions. Instead, interactions are pooled with all lower-order terms.",AM,531,"['specifying', 'contrast', 'using', 'full', 'model', 'intercept', 'drug', 'dose', 'drugdose', 'difficult', 'especially', 'true', 'large', 'complex', 'model', 'order', 'simplify', 'process', 'writing', 'contrast', 'respecify', 'model', 'cell', 'mean', 'model', 'model', 'estimate', 'one', 'parameter', 'group', 'set', 'yintercept', '0', 'one', 'independent', 'variable', 'model', 'doe', 'test', 'main_effect', 'separately', 'interaction', 'instead', 'interaction', 'pooled', 'lowerorder', 'term']"
143,"Specifying contrasts using your full model, with intercept, drug, dose, drug*dose, can be difficult. This is especially true for large, complex models. In order to simplify the process of writing contrasts, you can re-specify the model as a cell means model. This is a model that estimates only one parameter for each group and sets the y-intercept to 0. If there is more than one independent variable, this model does not test main effects separately from interactions. Instead, interactions are pooled with all lower-order terms.",AM,531,"['specifying', 'contrast', 'using', 'full', 'model', 'intercept', 'drug', 'dose', 'drugdose', 'difficult', 'especially', 'true', 'large', 'complex', 'model', 'order', 'simplify', 'process', 'writing', 'contrast', 'respecify', 'model', 'cell', 'mean', 'model', 'model', 'estimate', 'one', 'parameter', 'group', 'set', 'yintercept', '0', 'one', 'independent', 'variable', 'model', 'doe', 'test', 'main_effect', 'separately', 'interaction', 'instead', 'interaction', 'pooled', 'lowerorder', 'term']"
144,"Multivariate analysis of variance (MANOVA) is an extension of the concepts and techniques of ANOVA to situations with multiple dependent variables. One-way MANOVA can be used to test for group differences on several dependent variables simultaneously. Factorial MANOVA can be used to identify main effects and interactions among factors on a set of dependent variables. Unlike ANOVA, MANOVA takes into account relationships among the dependent variables as well as the relationship between independent and dependent variables.",AM,526,"['multivariate', 'analysis', 'variance', 'manova', 'extension', 'concept', 'technique', 'anova', 'situation', 'multiple', 'dependent', 'variable', 'oneway', 'manova', 'used', 'test', 'group', 'difference', 'several', 'dependent', 'variable', 'simultaneously', 'factorial', 'manova', 'used', 'identify', 'main_effect', 'interaction', 'among', 'factor', 'set', 'dependent', 'variable', 'unlike', 'anova', 'manova', 'take', 'account', 'relationship', 'among', 'dependent', 'variable', 'well', 'relationship', 'independent', 'dependent', 'variable']"
145,"Canonical discriminant analysis is a classification technique closely tied to canonical correlation analysis. Given a classification variable and several quantitative variables, you can derive canonical variates that summarize between-class variation. As with canonical correlation analysis, the number of discriminant functions is to the smaller of the number of predictors or the number of groups minus one in the analysis. The canonical discriminant functions maximize the distances between the group centroids.",AM,514,"['canonical', 'discriminant_analysis', 'classification', 'technique', 'closely', 'tied', 'canonical', 'correlation', 'analysis', 'given', 'classification', 'variable', 'several', 'quantitative', 'variable', 'derive', 'canonical', 'variate', 'summarize', 'betweenclass', 'variation', 'canonical', 'correlation', 'analysis', 'number', 'discriminant_function', 'smaller', 'number', 'predictor', 'number', 'group', 'minus', 'one', 'analysis', 'canonical', 'discriminant_function', 'maximize', 'distance', 'group', 'centroid']"
146,"When planning a study, give special consideration to the problem of restricted range. For example, you may be interested in studying the effects of an intervention on behavioral and attitudinal symptoms of depression. If you only study depressed patients, then at the start of your study, you may have restricted range (ceiling effects) on your baseline symptom measures. It may be helpful to specifically recruit participants who are not depressed for your study and increase the variation in baseline depression in the overall group. Another possible solution for restricted range would be to classify participants based on the small amount of variation you have in the data. For example, you might compare the career success of university faculty with less than a doctoral degree, one doctoral degree, and more than one doctoral degree (for example, Ph.D. and J.D.). Of course, in this situation, you may encounter problems with unequal group sizes.",AM,952,"['planning', 'study', 'give', 'special', 'consideration', 'problem', 'restricted', 'range', 'example', 'may', 'interested', 'studying', 'effect', 'intervention', 'behavioral', 'attitudinal', 'symptom', 'depression', 'study', 'depressed', 'patient', 'start', 'study', 'may', 'restricted', 'range', 'ceiling', 'effect', 'baseline', 'symptom', 'measure', 'may', 'helpful', 'specifically', 'recruit', 'participant', 'depressed', 'study', 'increase', 'variation', 'baseline', 'depression', 'overall', 'group', 'another', 'possible', 'solution', 'restricted', 'range', 'would', 'classify', 'participant', 'based', 'small', 'amount', 'variation', 'data', 'example', 'might', 'compare', 'career', 'success', 'university', 'faculty', 'le', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'example', 'phd', 'jd', 'course', 'situation', 'may', 'encounter', 'problem', 'unequal', 'group', 'size']"
147,"Many of the important issues in this chapter such as data accuracy and missing data apply to all statistical analyses, including univariate statistics, inferential statistics, and descriptive statistics. Some issues are unique to multivariate statistics, and some topics are unique to inferential statistics.",AM,308,"['many', 'important', 'issue', 'chapter', 'data', 'accuracy', 'missing', 'data', 'apply', 'statistical', 'analysis', 'including', 'univariate', 'statistic', 'inferential', 'statistic', 'descriptive', 'statistic', 'issue', 'unique', 'multivariate', 'statistic', 'topic', 'unique', 'inferential', 'statistic']"
148,"There are two procedures in SAS that can be used to perform canonical discriminant analysis: the DISCRIM procedure and the CANDISC procedure. PROC DISCRIM is more general than PROC CANDISC and can be used to perform both steps of discriminant analysis shown above. PROC CANDISC performs the first step only. However, PROC CANDISC produces output that is generally more familiar to users and may be easier to interpret. If you are simply trying to find the combinations of variables that predict group membership, it is simpler to use PROC CANDISC. ?	You will learn to use PROC DISCRIM later in the chapter.",AM,606,"['two', 'procedure', 'sa', 'used', 'perform', 'canonical', 'discriminant_analysis', 'discrim', 'procedure', 'candisc', 'procedure', 'proc', 'discrim', 'general', 'proc', 'candisc', 'used', 'perform', 'step', 'discriminant_analysis', 'shown', 'proc', 'candisc', 'performs', 'first', 'step', 'however', 'proc', 'candisc', 'produce', 'output', 'generally', 'familiar', 'user', 'may', 'easier', 'interpret', 'simply', 'trying', 'find', 'combination', 'variable', 'predict', 'group', 'membership', 'simpler', 'use', 'proc', 'candisc', '\tyou', 'learn', 'use', 'proc', 'discrim', 'later', 'chapter']"
149,"The Pooled Within Canonical Structure table shows the correlations between the predictors and the discriminant functions after adjusting for group differences. In other words, the pooled within canonical structure shows the correlations among the canonical variates and the predictors within the groups. Examining the variables that correlate highly with the first discriminant function (dsm4, dsm8, dsm10, and dsm12) suggests that these variables are all consequences of gambling. Thus, it appears that variables that pertain to consequences of gambling are responsible for an important portion of the discrimination among the three groups. Examining the variables that correlate highly with the second discriminant function (dsm1, dsm2, dsm3, and dsm9) suggests that these variables involve thoughts about gambling. Thus, it appears that variables pertaining to thoughts about gambling are responsible for an important portion of the discrimination among the groups. Additionally, PROC CANDISC displays several tables of canonical coefficients. These coefficients are influenced by correlations among the variables and, in some cases, by the scale of the variables. For these reasons, the coefficients are problematic to interpret, and are thus not shown here. Class Means on Canonical Variables",AM,1297,"['pooled', 'within', 'canonical', 'structure', 'table', 'show', 'correlation', 'predictor', 'discriminant_function', 'adjusting', 'group', 'difference', 'word', 'pooled', 'within', 'canonical', 'structure', 'show', 'correlation', 'among', 'canonical', 'variate', 'predictor', 'within', 'group', 'examining', 'variable', 'correlate', 'highly', 'first', 'discriminant_function', 'dsm4', 'dsm8', 'dsm10', 'dsm12', 'suggests', 'variable', 'consequence', 'gambling', 'thus', 'appears', 'variable', 'pertain', 'consequence', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'three', 'group', 'examining', 'variable', 'correlate', 'highly', 'second', 'discriminant_function', 'dsm1', 'dsm2', 'dsm3', 'dsm9', 'suggests', 'variable', 'involve', 'thought', 'gambling', 'thus', 'appears', 'variable', 'pertaining', 'thought', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'group', 'additionally', 'proc', 'candisc', 'display', 'several', 'table', 'canonical', 'coefficient', 'coefficient', 'influenced', 'correlation', 'among', 'variable', 'case', 'scale', 'variable', 'reason', 'coefficient', 'problematic', 'interpret', 'thus', 'shown', 'class', 'mean', 'canonical', 'variable']"
150,"The CLASS and VAR statements serve the same purpose as they do in PROC CANDISC. Selection options for the PROC DISCRIM statement: LIST	classifies observations into groups based on the discriminant functions. ANOVA	performs univariate ANOVAs to see whether the groups differ significantly on each predictor variable. It can be useful in eliminating irrelevant variables from the analysis. CAN	specifies that canonical discriminant analysis be performed. To achieve the same analysis as the one you saw in PROC CANDISC, specify proportional priors in the PRIORS statement. ?	See Appendix C for an example of how to perform canonical discriminant analysis using PROC DISCRIM. The PRIORS statement is discussed on the next page.",AM,724,"['class', 'var', 'statement', 'serve', 'purpose', 'proc', 'candisc', 'selection', 'option', 'proc', 'discrim', 'statement', 'list\tclassifies', 'observation', 'group', 'based', 'discriminant_function', 'anova\tperforms', 'univariate', 'anova', 'see', 'whether', 'group', 'differ', 'significantly', 'predictor_variable', 'useful', 'eliminating', 'irrelevant', 'variable', 'analysis', 'can\tspecifies', 'canonical', 'discriminant_analysis', 'performed', 'achieve', 'analysis', 'one', 'saw', 'proc', 'candisc', 'specify', 'proportional', 'prior', 'prior', 'statement', '\tsee', 'appendix', 'c', 'example', 'perform', 'canonical', 'discriminant_analysis', 'using', 'proc', 'discrim', 'prior', 'statement', 'discussed', 'next', 'page']"
151,"It is easy to see the pattern of how the groups fall on the discriminant functions. As you saw before, the first function distinguishes between Steady and Binge gamblers, while the second function discriminates between Controls and Steady gamblers.",AM,248,"['easy', 'see', 'pattern', 'group', 'fall', 'discriminant_function', 'saw', 'first', 'function', 'distinguishes', 'steady', 'binge', 'gambler', 'second', 'function', 'discriminates', 'control', 'steady', 'gambler']"
152,"4.	You can also change the appearance of your object from the right-click menu. Take a moment to explore the options available to you with the right-click menu and the Graph Toolbar. By investigating the responses in the 3-D graph, you can see that changes in the two OC scales, ybocgain and nimhgain, are positively associated. It also seems that change in neither OC scale is associated with change in the depression scale, hdrsgain.",AM,435,"['4\tyou', 'also', 'change', 'appearance', 'object', 'rightclick', 'menu', 'take', 'moment', 'explore', 'option', 'available', 'rightclick', 'menu', 'graph', 'toolbar', 'investigating', 'response', '3d', 'graph', 'see', 'change', 'two', 'oc', 'scale', 'ybocgain', 'nimhgain', 'positively', 'associated', 'also', 'seems', 'change', 'neither', 'oc', 'scale', 'associated', 'change', 'depression', 'scale', 'hdrsgain']"
153,"Researchers want to determine whether a questionnaire measurement can adequately classify people identified as binge gamblers, steady gamblers, and nongamblers. A 12-item questionnaire based on DSM-IV diagnostic criteria for pathological gambling was administered to 100 people divided into the three groups. The variable type is a class variable that identifies each observation as *	Binge *	Steady *	Control. Canonical Discriminant Analysis",AM,442,"['researcher', 'want', 'determine', 'whether', 'questionnaire', 'measurement', 'adequately', 'classify', 'people', 'identified', 'binge', 'gambler', 'steady', 'gambler', 'nongamblers', '12item', 'questionnaire', 'based', 'dsmiv', 'diagnostic', 'criterion', 'pathological', 'gambling', 'wa', 'administered', '100', 'people', 'divided', 'three', 'group', 'variable', 'type', 'class', 'variable', 'identifies', 'observation', '\tbinge', '\tsteady', '\tcontrol', 'canonical', 'discriminant_analysis']"
154,"In order for the test statistics in MANOVA to follow the theorized distribution, certain assumptions should be met: *	Observations are randomly sampled from the population. *	Observations are independent of one another; in other words, one observation does not provide information about other observations. *	The set of dependent variables follows a multivariate normal distribution conditional on the independent variables. This implies univariate conditional normality for each DV separately, but univariate normality alone is not sufficient for the assumption of multivariate normality to be met. *	The within-group covariance matrices are equal across groups. This implies equal variances across groups for each DV, and it also implies that all pairwise correlations between the DVs are equal across groups. As with ANOVA, MANOVA test statistics are robust to violations of some, but not all, of these assumptions. The robustness of each test statistic varies (Bray and Maxwell 1985). As a result, there is not a single test statistic that is uniformly preferred in all situations.",AM,1085,"['order', 'test', 'statistic', 'manova', 'follow', 'theorized', 'distribution', 'certain', 'assumption', 'met', '\tobservations', 'randomly', 'sampled', 'population', '\tobservations', 'independent', 'one', 'another', 'word', 'one', 'observation', 'doe', 'provide', 'information', 'observation', '\tthe', 'set', 'dependent', 'variable', 'follows', 'multivariate', 'normal', 'distribution', 'conditional', 'independent', 'variable', 'implies', 'univariate', 'conditional', 'normality', 'dv', 'separately', 'univariate', 'normality', 'alone', 'sufficient', 'assumption', 'multivariate', 'normality', 'met', '\tthe', 'withingroup', 'covariance', 'matrix', 'equal', 'across', 'group', 'implies', 'equal', 'variance', 'across', 'group', 'dv', 'also', 'implies', 'pairwise', 'correlation', 'dvs', 'equal', 'across', 'group', 'anova', 'manova', 'test', 'statistic', 'robust', 'violation', 'assumption', 'robustness', 'test', 'statistic', 'varies', 'bray', 'maxwell', '1985', 'result', 'single', 'test', 'statistic', 'uniformly', 'preferred', 'situation']"
155,"Many of the important issues in this chapter such as data accuracy and missing data apply to all statistical analyses, including univariate statistics, inferential statistics, and descriptive statistics. Some issues are unique to multivariate statistics, and some topics are unique to inferential statistics.",AM,308,"['many', 'important', 'issue', 'chapter', 'data', 'accuracy', 'missing', 'data', 'apply', 'statistical', 'analysis', 'including', 'univariate', 'statistic', 'inferential', 'statistic', 'descriptive', 'statistic', 'issue', 'unique', 'multivariate', 'statistic', 'topic', 'unique', 'inferential', 'statistic']"
156,"Consider the example you just saw. Because the same data that are being classified are also used to create the discriminant functions, the analysis capitalizes on chance. You saw a predicted error rate of 4% in the population. However, that assumes that the population is exactly like the sample you observed and has exactly the priors that you specified. Both of these conditions are unlikely to be met, and the first one is certainly unreasonable. It is very important to empirically validate the results of a discriminant analysis on new data before using the results of a discriminant analysis to predict group membership. To do this, use the first data set as the calibration data set, and use the second data set as the validation data set. ?	If a new data set is not available, you can perform crossvalidation of the data by using a one-observation holdout method that computes the discriminant function for each data point from all the remaining data with that observation left out.",AM,990,"['consider', 'example', 'saw', 'data', 'classified', 'also', 'used', 'create', 'discriminant_function', 'analysis', 'capitalizes', 'chance', 'saw', 'predicted', 'error', 'rate', '4', 'population', 'however', 'assumes', 'population', 'exactly', 'like', 'sample', 'observed', 'ha', 'exactly', 'prior', 'specified', 'condition', 'unlikely', 'met', 'first', 'one', 'certainly', 'unreasonable', 'important', 'empirically', 'validate', 'result', 'discriminant_analysis', 'new', 'data', 'using', 'result', 'discriminant_analysis', 'predict', 'group', 'membership', 'use', 'first', 'data_set', 'calibration', 'data_set', 'use', 'second', 'data_set', 'validation', 'data_set', '\tif', 'new', 'data_set', 'available', 'perform', 'crossvalidation', 'data', 'using', 'oneobservation', 'holdout', 'method', 'computes', 'discriminant_function', 'data', 'point', 'remaining', 'data', 'observation', 'left']"
157,"The contrast coefficients for all the terms in the linear model are shown above. However, coefficients must be expressed as integers or decimal values. Expressing 1/3 as a decimal value can be problematic, so the values must be multiplied by a constant.",AM,253,"['contrast', 'coefficient', 'term', 'linear', 'model', 'shown', 'however', 'coefficient', 'must', 'expressed', 'integer', 'decimal', 'value', 'expressing', '13', 'decimal', 'value', 'problematic', 'value', 'must', 'multiplied', 'constant']"
158,"From the canonical discriminant analysis you ran in the previous section, you saw that there were two discriminant functions that both appear to have useful interpretations and that discriminate between different pairs of groups.",AM,229,"['canonical', 'discriminant_analysis', 'ran', 'previous', 'section', 'saw', 'two', 'discriminant_function', 'appear', 'useful', 'interpretation', 'discriminate', 'different', 'pair', 'group']"
159,"It is useful to examine the means of the subgroups on each of the canonical discriminant functions. The space defined by the canonical discriminant functions is the space that maximally separates the group centroids (multivariate mean vectors). In this case, you see that the first canonical discriminant function seems to be mostly separating the Binge and the Steady gamblers, and the second canonical discriminant function appears to be separating the Control group from the Steady gamblers. If your data set is very large, it is often useful to plot the group centroids in the space defined by the canonical discriminant functions to get an idea of how well the group centroids are separated. In this case, the data set is sufficiently small that you can plot the individual observations in the space defined by the discriminant functions. ?	Although it is not shown here, you could use ODS to save the centroids from the Class Means on Canonical Variables table and plot them using the GPLOT procedure. An example program, CDA plot with centroids.sas, is included with the course data.",AM,1090,"['useful', 'examine', 'mean', 'subgroup', 'canonical', 'discriminant_function', 'space', 'defined', 'canonical', 'discriminant_function', 'space', 'maximally', 'separate', 'group', 'centroid', 'multivariate', 'mean', 'vector', 'case', 'see', 'first', 'canonical', 'discriminant_function', 'seems', 'mostly', 'separating', 'binge', 'steady', 'gambler', 'second', 'canonical', 'discriminant_function', 'appears', 'separating', 'control', 'group', 'steady', 'gambler', 'data_set', 'large', 'often', 'useful', 'plot', 'group', 'centroid', 'space', 'defined', 'canonical', 'discriminant_function', 'get', 'idea', 'well', 'group', 'centroid', 'separated', 'case', 'data_set', 'sufficiently', 'small', 'plot', 'individual', 'observation', 'space', 'defined', 'discriminant_function', '\talthough', 'shown', 'could', 'use', 'od', 'save', 'centroid', 'class', 'mean', 'canonical', 'variable', 'table', 'plot', 'using', 'gplot', 'procedure', 'example', 'program', 'cda', 'plot', 'centroidssas', 'included', 'course', 'data']"
160,"Create a table of the cell means in your model. The ordering of the variables is determined by the order of the variables in the CLASS statement. The first independent variable represents the rows. The second represents the columns. Specify the contrast hypothesis in terms of the cell means, as shown below:",AM,308,"['create', 'table', 'cell', 'mean', 'model', 'ordering', 'variable', 'determined', 'order', 'variable', 'class', 'statement', 'first', 'independent', 'variable', 'represents', 'row', 'second', 'represents', 'column', 'specify', 'contrast', 'hypothesis', 'term', 'cell', 'mean', 'shown']"
161,"CLASS	names the classification variables to be used in the model. If you specify a CLASS statement, it must appear before the MODEL statement. MODEL	names the dependent variables and independent effects. Variable names are separated by a space. Crossed independent effects are indicated with asterisks (*). The bar operator (|) can be used to simplify effect specification for large factorial models. In PROC GLM, you can specify only one MODEL statement. MANOVA	performs multivariate analysis of variance when multiple dependent variables are listed in the MODEL statement. When the MANOVA statement is specified before the first RUN statement, GLM uses a multivariate method of handling missing values. This means that if a case is missing any values for a variable specified in the model, the entire case is deleted from the analysis. Selected test option for the MANOVA statement: H = effects | INTERCEPT | _ALL_ specifies the effects in the model to use as hypothesis (H) matrices. The H= option displays the eigenvalues and eigenvectors associated with E-1H and the four multivariate test statistics. To use all the effects in the model, specify the _ALL_ option. Selected detail options for the MANOVA statement: MSTAT = EXACT|FAPPROX specifies the method of evaluating the multivariate test statistics. The default is MSTAT=FAPPROX, which specifies that the multivariate tests are evaluated using the usual approximations based on the F distribution. MSTAT=EXACT computes exact p-values for three of the four tests (Wilks' Lambda, the Hotelling-Lawley Trace, and Roy's Greatest Root) and an improved F-approximation for the fourth (Pillai's Trace). PRINTE	displays the error SSCP matrix, E. Also produces a table of partial correlations of the dependent variables given the independent variables when the residual matrix from the analysis is the E matrix. PRINTH	displays the hypothesis SSCP matrix H associated with each effect in the H= specification. Selected option for the MODEL statement: NOUNI	suppresses univariate ANOVA output.",AM,2044,"['class\tnames', 'classification', 'variable', 'used', 'model', 'specify', 'class', 'statement', 'must', 'appear', 'model_statement', 'model\tnames', 'dependent', 'variable', 'independent', 'effect', 'variable', 'name', 'separated', 'space', 'crossed', 'independent', 'effect', 'indicated', 'asterisk', '', 'bar', 'operator', '', 'used', 'simplify', 'effect', 'specification', 'large', 'factorial', 'model', 'proc', 'glm', 'specify', 'one', 'model_statement', 'manova\tperforms', 'multivariate', 'analysis', 'variance', 'multiple', 'dependent', 'variable', 'listed', 'model_statement', 'manova', 'statement', 'specified', 'first', 'run', 'statement', 'glm', 'us', 'multivariate', 'method', 'handling', 'missing', 'value', 'mean', 'case', 'missing', 'value', 'variable', 'specified', 'model', 'entire', 'case', 'deleted', 'analysis', 'selected', 'test', 'option', 'manova', 'statement', 'h', '', 'effect', '', 'intercept', '', 'specifies', 'effect', 'model', 'use', 'hypothesis', 'h', 'matrix', 'h', 'option', 'display', 'eigenvalue', 'eigenvectors', 'associated', 'e1h', 'four', 'multivariate', 'test', 'statistic', 'use', 'effect', 'model', 'specify', 'option', 'selected', 'detail', 'option', 'manova', 'statement', 'mstat', '', 'exactfapprox', 'specifies', 'method', 'evaluating', 'multivariate', 'test', 'statistic', 'default', 'mstatfapprox', 'specifies', 'multivariate', 'test', 'evaluated', 'using', 'usual', 'approximation', 'based', 'f', 'distribution', 'mstatexact', 'computes', 'exact', 'pvalues', 'three', 'four', 'test', 'wilks', 'lambda', 'hotellinglawley', 'trace', 'roys', 'greatest', 'root', 'improved', 'fapproximation', 'fourth', 'pillais', 'trace', 'printe\tdisplays', 'error', 'sscp', 'matrix', 'e', 'also', 'produce', 'table', 'partial', 'correlation', 'dependent', 'variable', 'given', 'independent', 'variable', 'residual', 'matrix', 'analysis', 'e', 'matrix', 'printh\tdisplays', 'hypothesis', 'sscp', 'matrix', 'h', 'associated', 'effect', 'h', 'specification', 'selected', 'option', 'model_statement', 'nouni\tsuppresses', 'univariate', 'anova', 'output']"
162,"The first analysis you will perform uses PROC DISCRIM with the gamblegrp data you used earlier. The program ch4s2d1.sas is shown below. Notice that the PROP option in the PRIORS statement calculates prior probabilities from the proportion of observations in each group. proc discrim data = amul.gamblegrp list; class type; priors prop; var dsm1-dsm12; run; The output is shown below. The class level information shows the weights and the priors, which are equal to the proportion in each group. The DISCRIM Procedure",AM,516,"['first', 'analysis', 'perform', 'us', 'proc', 'discrim', 'gamblegrp', 'data', 'used', 'earlier', 'program', 'ch4s2d1sas', 'shown', 'notice', 'prop', 'option', 'prior', 'statement', 'calculates', 'prior', 'probability', 'proportion', 'observation', 'group', 'proc', 'discrim', 'data', '', 'amulgamblegrp', 'list', 'class', 'type', 'prior', 'prop', 'var', 'dsm1dsm12', 'run', 'output', 'shown', 'class', 'level', 'information', 'show', 'weight', 'prior', 'equal', 'proportion', 'group', 'discrim', 'procedure']"
163,Only the first 20 out of 100 observations are shown here. PROC DISCRIM flags misclassified observations with an asterisk. You can see that observations 12 and 13 were misclassified. Classification Summary for Calibration Data: AMUL.GAMBLEGRP Resubstitution Summary using Linear Discriminant Function,AM,299,"['first', '20', '100', 'observation', 'shown', 'proc', 'discrim', 'flag', 'misclassified', 'observation', 'asterisk', 'see', 'observation', '12', '13', 'misclassified', 'classification', 'summary', 'calibration', 'data', 'amulgamblegrp', 'resubstitution', 'summary', 'using', 'linear', 'discriminant_function']"
164,"The research questions above share a common thread ? prediction of groups. These questions are conceptually similar to logistic regression, which models the odds of membership in one group versus another group based on values of predictors. Discriminant function analysis can be thought of as a multivariate generalization of logistic regression, although as you will see, the computation for discriminant analysis is more similar to MANOVA or canonical correlation analysis than to logistic regression.",AM,503,"['research', 'question', 'share', 'common', 'thread', '', 'prediction', 'group', 'question', 'conceptually', 'similar', 'logistic_regression_model', 'odds', 'membership', 'one', 'group', 'versus', 'another', 'group', 'based', 'value', 'predictor', 'discriminant_function', 'analysis', 'thought', 'multivariate', 'generalization', 'logistic_regression', 'although', 'see', 'computation', 'discriminant_analysis', 'similar', 'manova', 'canonical', 'correlation', 'analysis', 'logistic_regression']"
165,"Sometimes you have a significant multivariate effect and no significant univariate effects. Sometime just the opposite occurs?nonsignificant multivariate effects and significant univariate effects. There are several reasons that this may occur, among them type-I error, type-II error, multivariate outliers, and collinearity among the responses. You can use univariate ANOVA to try to interpret your MV effects. By default, the univariate ANOVA for each response is shown. You can suppress the default univariate ANOVA output with the NOUNI option in the MODEL statement. You can obtain an abbreviated summary of the univariate ANOVAs by including the SUMMARY option in MANOVA statement. Later, you will learn to use discriminant analysis, which allows you a multivariate method for interpreting group differences that is often preferable to univariate ANOVA.",AM,859,"['sometimes', 'significant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'sometime', 'opposite', 'occursnonsignificant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'several', 'reason', 'may', 'occur', 'among', 'typei', 'error', 'typeii', 'error', 'multivariate', 'outlier', 'collinearity', 'among', 'response', 'use', 'univariate', 'anova', 'try', 'interpret', 'mv', 'effect', 'default', 'univariate', 'anova', 'response', 'shown', 'suppress', 'default', 'univariate', 'anova', 'output', 'nouni', 'option', 'model_statement', 'obtain', 'abbreviated', 'summary', 'univariate', 'anova', 'including', 'summary', 'option', 'manova', 'statement', 'later', 'learn', 'use', 'discriminant_analysis', 'allows', 'multivariate', 'method', 'interpreting', 'group', 'difference', 'often', 'preferable', 'univariate', 'anova']"
166,"From the canonical discriminant analysis you ran in the previous section, you saw that there were two discriminant functions that both appear to have useful interpretations and that discriminate between different pairs of groups.",AM,229,"['canonical', 'discriminant_analysis', 'ran', 'previous', 'section', 'saw', 'two', 'discriminant_function', 'appear', 'useful', 'interpretation', 'discriminate', 'different', 'pair', 'group']"
167,"A natural extension of the MANOVA research question ?How do my continuous responses differ as a function of group levels?? is the discriminant analysis research question ?How do my continuous variables predict membership in groups? With discriminant analysis, you can use parametric or nonparametric methods to *	find linear combinations of continuous variables (discriminant functions) that predict group membership *	estimate the expected misclassification rate based on the discriminant functions *	test the discriminant functions on a new sample to determine the extent to which the functions correctly and incorrectly classify observations Canonical discriminant analysis has the advantage of conceptual and computational simplicity, while Fisher linear discriminant analysis is powerful enough to allow you to find the discriminant functions and test or crossvalidate your results using one simple procedure. You learned to use two procedures in SAS to perform discriminant analysis: PROC CANDISC performs canonical discriminant analysis to find linear combinations of variables that best discriminate among groups. PROC DISCRIM performs linear and quadratic discriminant analysis and produces a prediction function to help classify observations in to groups based on a set of predictors. Remember that discriminant analysis and other predictive modeling techniques capitalize on chance associations among the predictors in your data to find the discriminant functions. For this reason it is important always to perform empirical validation on a new sample of data, or at least use crossvalidation before using the discriminant functions for prediction and scoring.",AM,1671,"['natural', 'extension', 'manova', 'research', 'question', 'continuous', 'response', 'differ', 'function', 'group', 'level', 'discriminant_analysis', 'research', 'question', 'continuous', 'variable', 'predict', 'membership', 'group', 'discriminant_analysis', 'use', 'parametric', 'nonparametric', 'method', '\tfind', 'linear', 'combination', 'continuous', 'variable', 'discriminant_function', 'predict', 'group', 'membership', '\testimate', 'expected', 'misclassification', 'rate', 'based', 'discriminant_function', '\ttest', 'discriminant_function', 'new', 'sample', 'determine', 'extent', 'function', 'correctly', 'incorrectly', 'classify', 'observation', 'canonical', 'discriminant_analysis', 'ha', 'advantage', 'conceptual', 'computational', 'simplicity', 'fisher', 'linear', 'discriminant_analysis', 'powerful', 'enough', 'allow', 'find', 'discriminant_function', 'test', 'crossvalidate', 'result', 'using', 'one', 'simple', 'procedure', 'learned', 'use', 'two', 'procedure', 'sa', 'perform', 'discriminant_analysis', 'proc', 'candisc', 'performs', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'variable', 'best', 'discriminate', 'among', 'group', 'proc', 'discrim', 'performs', 'linear', 'quadratic', 'discriminant_analysis', 'produce', 'prediction', 'function', 'help', 'classify', 'observation', 'group', 'based', 'set', 'predictor', 'remember', 'discriminant_analysis', 'predictive', 'modeling', 'technique', 'capitalize', 'chance', 'association', 'among', 'predictor', 'data', 'find', 'discriminant_function', 'reason', 'important', 'always', 'perform', 'empirical', 'validation', 'new', 'sample', 'data', 'least', 'use', 'crossvalidation', 'using', 'discriminant_function', 'prediction', 'scoring']"
168,"Because of the unequal group sizes, you may want to consider combining similar groups together, and/or testing for equality of covariance matrices before performing any multivariate analyses with this variable.",AM,210,"['unequal', 'group', 'size', 'may', 'want', 'consider', 'combining', 'similar', 'group', 'together', 'andor', 'testing', 'equality', 'covariance', 'matrix', 'performing', 'multivariate', 'analysis', 'variable']"
169,"You can see that the Fried Platter, Tuna Sub, and several others are bivariate outliers on more than one plot. Continue to explore the plots. You can change the colors of specific observations. For example, you may want to identify all the Frozen sandwiches on your plot. You can label the Frozen sandwiches with a special color to make them easier to find on the plots. 3.	In the data table, highlight the rows that are Frozen sandwiches by clicking on the row header and dragging the selection. Partial Display",AM,512,"['see', 'fried', 'platter', 'tuna', 'sub', 'several', 'others', 'bivariate', 'outlier', 'one', 'plot', 'continue', 'explore', 'plot', 'change', 'color', 'specific', 'observation', 'example', 'may', 'want', 'identify', 'frozen', 'sandwich', 'plot', 'label', 'frozen', 'sandwich', 'special', 'color', 'make', 'easier', 'find', 'plot', '3\tin', 'data', 'table', 'highlight', 'row', 'frozen', 'sandwich', 'clicking', 'row', 'header', 'dragging', 'selection', 'partial', 'display']"
170,"The first analysis you will perform uses PROC DISCRIM with the gamblegrp data you used earlier. The program ch4s2d1.sas is shown below. Notice that the PROP option in the PRIORS statement calculates prior probabilities from the proportion of observations in each group. proc discrim data = amul.gamblegrp list; class type; priors prop; var dsm1-dsm12; run; The output is shown below. The class level information shows the weights and the priors, which are equal to the proportion in each group. The DISCRIM Procedure",AM,516,"['first', 'analysis', 'perform', 'us', 'proc', 'discrim', 'gamblegrp', 'data', 'used', 'earlier', 'program', 'ch4s2d1sas', 'shown', 'notice', 'prop', 'option', 'prior', 'statement', 'calculates', 'prior', 'probability', 'proportion', 'observation', 'group', 'proc', 'discrim', 'data', '', 'amulgamblegrp', 'list', 'class', 'type', 'prior', 'prop', 'var', 'dsm1dsm12', 'run', 'output', 'shown', 'class', 'level', 'information', 'show', 'weight', 'prior', 'equal', 'proportion', 'group', 'discrim', 'procedure']"
171,"NOTE: F Statistic for Roy's Greatest Root is an upper bound. NOTE: F Statistic for Wilks' Lambda is exact. The multivariate statistics test the null hypothesis that all the canonical correlations are simultaneously zero, which is the same as the hypothesis that there is no linear prediction of group membership from the predictor variables. You reject this null hypothesis. Adjusted Approximate Squared Canonical Canonical Standard Canonical Correlation Correlation Error Correlation",AM,484,"['note', 'f', 'statistic', 'roys', 'greatest', 'root', 'upper', 'bound', 'note', 'f', 'statistic', 'wilks', 'lambda', 'exact', 'multivariate', 'statistic', 'test', 'null', 'hypothesis', 'canonical', 'correlation', 'simultaneously', 'zero', 'hypothesis', 'linear', 'prediction', 'group', 'membership', 'predictor_variable', 'reject', 'null', 'hypothesis', 'adjusted', 'approximate', 'squared', 'canonical', 'canonical', 'standard', 'canonical', 'correlation', 'correlation', 'error', 'correlation']"
172,Scoring in PROC DISCRIM is as easy as validation. Specify a valid data set name in the TESTOUT= option to save scored (classified) observations to an output data set. Testing Discriminant Functions on a New Data Set,AM,215,"['scoring', 'proc', 'discrim', 'easy', 'validation', 'specify', 'valid', 'data_set', 'name', 'testout', 'option', 'save', 'scored', 'classified', 'observation', 'output', 'data_set', 'testing', 'discriminant_function', 'new', 'data_set']"
173,"Many types of studies exhibit problems with restricted range on variables. If a variable demonstrates restricted range, it does not have enough variability to be useful as a continuous variable in your analyses. An example of restricted range is shown above. In your study of university professors, you suspect that more years of education would be associated with greater career success. However, the vast majority of university professors have many years of education. There are very few who have less than a doctoral or perhaps a master?s degree. The restriction of range demonstrated here is sometimes known as a ceiling effect because the restriction is at the high end (the ceiling) of the data. The opposite of the ceiling effect is known as a floor effect. For example, if you were interested in reducing the risk of heart attacks among women between 20-30 years of age, you would likely run into a floor effect because very few women between 20 and 30 years of age have heart attacks, and it would be difficult to reduce this amount further with an intervention.",AM,1071,"['many', 'type', 'study', 'exhibit', 'problem', 'restricted', 'range', 'variable', 'variable', 'demonstrates', 'restricted', 'range', 'doe', 'enough', 'variability', 'useful', 'continuous', 'variable', 'analysis', 'example', 'restricted', 'range', 'shown', 'study', 'university', 'professor', 'suspect', 'year', 'education', 'would', 'associated', 'greater', 'career', 'success', 'however', 'vast', 'majority', 'university', 'professor', 'many', 'year', 'education', 'le', 'doctoral', 'perhaps', 'master', 'degree', 'restriction', 'range', 'demonstrated', 'sometimes', 'known', 'ceiling', 'effect', 'restriction', 'high', 'end', 'ceiling', 'data', 'opposite', 'ceiling', 'effect', 'known', 'floor', 'effect', 'example', 'interested', 'reducing', 'risk', 'heart', 'attack', 'among', 'woman', '2030', 'year', 'age', 'would', 'likely', 'run', 'floor', 'effect', 'woman', '20', '30', 'year', 'age', 'heart', 'attack', 'would', 'difficult', 'reduce', 'amount', 'intervention']"
174,"Canonical discriminant analysis is a classification technique closely tied to canonical correlation analysis. Given a classification variable and several quantitative variables, you can derive canonical variates that summarize between-class variation. As with canonical correlation analysis, the number of discriminant functions is to the smaller of the number of predictors or the number of groups minus one in the analysis. The canonical discriminant functions maximize the distances between the group centroids.",AM,514,"['canonical', 'discriminant_analysis', 'classification', 'technique', 'closely', 'tied', 'canonical', 'correlation', 'analysis', 'given', 'classification', 'variable', 'several', 'quantitative', 'variable', 'derive', 'canonical', 'variate', 'summarize', 'betweenclass', 'variation', 'canonical', 'correlation', 'analysis', 'number', 'discriminant_function', 'smaller', 'number', 'predictor', 'number', 'group', 'minus', 'one', 'analysis', 'canonical', 'discriminant_function', 'maximize', 'distance', 'group', 'centroid']"
175,"The sandwiches data set includes nutritional information about several brands and types of sandwiches sold at fast-food restaurants and in grocery store freezer sections. The data are simulated but based on real nutritional information about sandwiches. The variables for the sandwiches data set are described below: Calories	The number of calories in the sandwich from testing TFat		Grams of fat Protein	Grams of protein Carb		Grams of carbohydrate Fiber		Grams of fiber	 Sodium	Milligrams of sodium Brand		Brand name of the sandwich (A, B, ?, I) (Character variable) Name		Name of the sandwich (Character variable) Category	Type of sandwich (Tuna, Chicken, Ham,?) (Character variable) Weight	Weight in ounces FatCal	Number of calories from fat CarbCal	Number of calories from carbohydrate ProCal	Number of calories from protein CalSum	Sum of FatCal, CarbCal, and ProCal ? to evaluate accuracy of the Calories measurement. You will perform analyses on some but not necessarily all of the variables in the data set. You may want to explore further with the data on your own to practice the methods demonstrated in this course. Outlier Analysis and Data Screening Using SAS/IML Workshop 2.1 You can use the SAS/IML Workshop to perform interactive graphical analysis of your data. In addition to graphical capabilities, you can use IML (Interactive Matrix Language) for customized analyses, and you can run SAS programs and view SAS output within the code editor in the SAS/IML Workshop. 1.	Open SAS/IML Workshop by selecting Start => Programs => IML Workshop 2.1. You see the SAS/IML workspace:",AM,1593,"['sandwich', 'data_set', 'includes', 'nutritional', 'information', 'several', 'brand', 'type', 'sandwich', 'sold', 'fastfood', 'restaurant', 'grocery', 'store', 'freezer', 'section', 'data', 'simulated', 'based', 'real', 'nutritional', 'information', 'sandwich', 'variable', 'sandwich', 'data_set', 'described', 'calories\tthe', 'number', 'calorie', 'sandwich', 'testing', 'tfat\t\tgrams', 'fat', 'protein\tgrams', 'protein', 'carb\t\tgrams', 'carbohydrate', 'fiber\t\tgrams', 'fiber\t', 'sodium\tmilligrams', 'sodium', 'brand\t\tbrand', 'name', 'sandwich', 'b', '', 'character', 'variable', 'name\t\tname', 'sandwich', 'character', 'variable', 'category\ttype', 'sandwich', 'tuna', 'chicken', 'ham', 'character', 'variable', 'weight\tweight', 'ounce', 'fatcal\tnumber', 'calorie', 'fat', 'carbcal\tnumber', 'calorie', 'carbohydrate', 'procal\tnumber', 'calorie', 'protein', 'calsum\tsum', 'fatcal', 'carbcal', 'procal', '', 'evaluate', 'accuracy', 'calorie', 'measurement', 'perform', 'analysis', 'necessarily', 'variable', 'data_set', 'may', 'want', 'explore', 'data', 'practice', 'method', 'demonstrated', 'course', 'outlier', 'analysis', 'data', 'screening', 'using', 'sasiml', 'workshop', '21', 'use', 'sasiml', 'workshop', 'perform', 'interactive', 'graphical', 'analysis', 'data', 'addition', 'graphical', 'capability', 'use', 'iml', 'interactive', 'matrix', 'language', 'customized', 'analysis', 'run', 'sa', 'program', 'view', 'sa', 'output', 'within', 'code', 'editor', 'sasiml', 'workshop', '1\topen', 'sasiml', 'workshop', 'selecting', 'start', '', 'program', '', 'iml', 'workshop', '21', 'see', 'sasiml', 'workspace']"
176,"4.	You can also change the appearance of your object from the right-click menu. Take a moment to explore the options available to you with the right-click menu and the Graph Toolbar. By investigating the responses in the 3-D graph, you can see that changes in the two OC scales, ybocgain and nimhgain, are positively associated. It also seems that change in neither OC scale is associated with change in the depression scale, hdrsgain.",AM,435,"['4\tyou', 'also', 'change', 'appearance', 'object', 'rightclick', 'menu', 'take', 'moment', 'explore', 'option', 'available', 'rightclick', 'menu', 'graph', 'toolbar', 'investigating', 'response', '3d', 'graph', 'see', 'change', 'two', 'oc', 'scale', 'ybocgain', 'nimhgain', 'positively', 'associated', 'also', 'seems', 'change', 'neither', 'oc', 'scale', 'associated', 'change', 'depression', 'scale', 'hdrsgain']"
177,"Repeat this to create plots of Carb*Calories, Carb*TFat and Carb* Protein. Select outliers on each plot and find the corresponding observations on the other plots.",AM,163,"['repeat', 'create', 'plot', 'carbcalories', 'carbtfat', 'carb', 'protein', 'select', 'outlier', 'plot', 'find', 'corresponding', 'observation', 'plot']"
178,"Where ANOVA tests for differences among group means, MANOVA tests for differences among the multivariate centroids of groups. In MANOVA, correlations among dependent variables can have dramatic effects on the inference based on the resulting linear model.",AM,255,"['anova', 'test', 'difference', 'among', 'group', 'mean', 'manova', 'test', 'difference', 'among', 'multivariate', 'centroid', 'group', 'manova', 'correlation', 'among', 'dependent', 'variable', 'dramatic', 'effect', 'inference', 'based', 'resulting', 'linear', 'model']"
179,"The contrast coefficients for all the terms in the linear model are shown above. However, coefficients must be expressed as integers or decimal values. Expressing 1/3 as a decimal value can be problematic, so the values must be multiplied by a constant.",AM,253,"['contrast', 'coefficient', 'term', 'linear', 'model', 'shown', 'however', 'coefficient', 'must', 'expressed', 'integer', 'decimal', 'value', 'expressing', '13', 'decimal', 'value', 'problematic', 'value', 'must', 'multiplied', 'constant']"
180,"From the canonical discriminant analysis you ran in the previous section, you saw that there were two discriminant functions that both appear to have useful interpretations and that discriminate between different pairs of groups.",AM,229,"['canonical', 'discriminant_analysis', 'ran', 'previous', 'section', 'saw', 'two', 'discriminant_function', 'appear', 'useful', 'interpretation', 'discriminate', 'different', 'pair', 'group']"
181,"For univariate statistics, there are many outlier detection tools available. Perhaps you already use the tools listed above regularly, in addition to others. In linear models, it is often useful to look at leverage and DFFITS statistics to find influential outliers on a set of predictor variables. These statistics are easy to obtain from the REG and GLM procedures. To evaluate one variable at a time for outliers, statistical and graphical tools can be useful. For example, you can standardize your variables (center them about the mean and scale them by the standard deviation) to get z-scores and find observations that are very far from the mean for the variable. For grouped data, you perform this analysis separately for each group. Schematic box plots provide a way to detect outliers visually. In schematic box plots, the box is drawn over the interquartile range (IQR). Whiskers extend from the ends of box out to 1.5 IQR units, or the range of the data. Any points beyond the whiskers are plotted as outliers.",AM,1021,"['univariate', 'statistic', 'many', 'outlier', 'detection', 'tool', 'available', 'perhaps', 'already', 'use', 'tool', 'listed', 'regularly', 'addition', 'others', 'linear', 'model', 'often', 'useful', 'look', 'leverage', 'dffits', 'statistic', 'find', 'influential', 'outlier', 'set', 'predictor_variable', 'statistic', 'easy', 'obtain', 'reg', 'glm', 'procedure', 'evaluate', 'one', 'variable', 'time', 'outlier', 'statistical', 'graphical', 'tool', 'useful', 'example', 'standardize', 'variable', 'center', 'mean', 'scale', 'standard', 'deviation', 'get', 'zscores', 'find', 'observation', 'far', 'mean', 'variable', 'grouped', 'data', 'perform', 'analysis', 'separately', 'group', 'schematic', 'box', 'plot', 'provide', 'way', 'detect', 'outlier', 'visually', 'schematic', 'box', 'plot', 'box', 'drawn', 'interquartile', 'range', 'iqr', 'whisker', 'extend', 'end', 'box', '15', 'iqr', 'unit', 'range', 'data', 'point', 'beyond', 'whisker', 'plotted', 'outlier']"
182,"Some of the bivariate outliers you saw earlier are also outliers on the PRIN variables. !	For more than two PCs at a time, you could create a three-way rotating scatter plot of several principal component variables. Feel free to try this plot on your own! After looking over the output for outlier analysis, you decide that you have four observations that are outliers. You choose to continue with your screening and data preparation with the complete set of data. Restricted Range and Group Size Use the data set sandwiches to investigate variables for restricted range and unequal group sizes. You selected Weight because you are concerned that there is not enough variation in the weight of sandwiches. You selected Category because you were concerned that there may be types of sandwiches that are underrepresented in the data. 1.	Select the sandwiches data set from the Window menu. 2.	Create a histogram for the Weight variable by selecting Plots => Create Histogram => Weight => Set X. The histogram for Weight is displayed below:",AM,1037,"['bivariate', 'outlier', 'saw', 'earlier', 'also', 'outlier', 'prin', 'variable', '\tfor', 'two', 'pc', 'time', 'could', 'create', 'threeway', 'rotating', 'scatter', 'plot', 'several', 'principal', 'component', 'variable', 'feel', 'free', 'try', 'plot', 'looking', 'output', 'outlier', 'analysis', 'decide', 'four', 'observation', 'outlier', 'choose', 'continue', 'screening', 'data', 'preparation', 'complete', 'set', 'data', 'restricted', 'range', 'group', 'size', 'use', 'data_set', 'sandwich', 'investigate', 'variable', 'restricted', 'range', 'unequal', 'group', 'size', 'selected', 'weight', 'concerned', 'enough', 'variation', 'weight', 'sandwich', 'selected', 'category', 'concerned', 'may', 'type', 'sandwich', 'underrepresented', 'data', '1\tselect', 'sandwich', 'data_set', 'window', 'menu', '2\tcreate', 'histogram', 'weight', 'variable', 'selecting', 'plot', '', 'create', 'histogram', '', 'weight', '', 'set', 'x', 'histogram', 'weight', 'displayed']"
183,"Canonical discriminant analysis is a classification technique closely tied to canonical correlation analysis. Given a classification variable and several quantitative variables, you can derive canonical variates that summarize between-class variation. As with canonical correlation analysis, the number of discriminant functions is to the smaller of the number of predictors or the number of groups minus one in the analysis. The canonical discriminant functions maximize the distances between the group centroids.",AM,514,"['canonical', 'discriminant_analysis', 'classification', 'technique', 'closely', 'tied', 'canonical', 'correlation', 'analysis', 'given', 'classification', 'variable', 'several', 'quantitative', 'variable', 'derive', 'canonical', 'variate', 'summarize', 'betweenclass', 'variation', 'canonical', 'correlation', 'analysis', 'number', 'discriminant_function', 'smaller', 'number', 'predictor', 'number', 'group', 'minus', 'one', 'analysis', 'canonical', 'discriminant_function', 'maximize', 'distance', 'group', 'centroid']"
184,"The PROC DISCRIM statement has options that make validation on a test data set or crossvalidation within the same data easy: TESTDATA=	specifies a SAS data set to be used in validation. TESTLIST	lists the observations in the TESTDATA= data set, along with predicted group membership based on the prediction equations developed using the data specified with the DATA= option. TESTOUT=	specifies a SAS data set where the TESTDATA= data are scored. Scores include the original data, classification, and posterior probabilities for each observation. CROSSLIST	lists the observations in the DATA= data set, along with predicted group membership, by classifying each observation in the DATA= data set using a discriminant function computed from the other observations in the DATA= data set, excluding the observation being classified. CROSSVALIDATE	 specifies that crossvalidation of the input data set be performed. This is used when you do not have a second sample upon which to calibrate/test. TESTCLASS	this statement names the CLASS variable from the TESTDATA= data set to be used in the analysis. It is not required if the CLASS variable name in the TESTDATA= data set matches the CLASS variable name in the DATA= data set.",AM,1223,"['proc', 'discrim', 'statement', 'ha', 'option', 'make', 'validation', 'test', 'data_set', 'crossvalidation', 'within', 'data', 'easy', 'testdata\tspecifies', 'sa', 'data_set', 'used', 'validation', 'testlist\tlists', 'observation', 'testdata', 'data_set', 'along', 'predicted', 'group', 'membership', 'based', 'prediction', 'equation', 'developed', 'using', 'data', 'specified', 'data', 'option', 'testout\tspecifies', 'sa', 'data_set', 'testdata', 'data', 'scored', 'score', 'include', 'original', 'data', 'classification', 'posterior', 'probability', 'observation', 'crosslist\tlists', 'observation', 'data', 'data_set', 'along', 'predicted', 'group', 'membership', 'classifying', 'observation', 'data', 'data_set', 'using', 'discriminant_function', 'computed', 'observation', 'data', 'data_set', 'excluding', 'observation', 'classified', 'crossvalidate\t', 'specifies', 'crossvalidation', 'input', 'data_set', 'performed', 'used', 'second', 'sample', 'upon', 'calibratetest', 'testclass\tthis', 'statement', 'name', 'class', 'variable', 'testdata', 'data_set', 'used', 'analysis', 'required', 'class', 'variable', 'name', 'testdata', 'data_set', 'match', 'class', 'variable', 'name', 'data', 'data_set']"
185,"Canonical discriminant analysis is a classification technique closely tied to canonical correlation analysis. Given a classification variable and several quantitative variables, you can derive canonical variates that summarize between-class variation. As with canonical correlation analysis, the number of discriminant functions is to the smaller of the number of predictors or the number of groups minus one in the analysis. The canonical discriminant functions maximize the distances between the group centroids.",AM,514,"['canonical', 'discriminant_analysis', 'classification', 'technique', 'closely', 'tied', 'canonical', 'correlation', 'analysis', 'given', 'classification', 'variable', 'several', 'quantitative', 'variable', 'derive', 'canonical', 'variate', 'summarize', 'betweenclass', 'variation', 'canonical', 'correlation', 'analysis', 'number', 'discriminant_function', 'smaller', 'number', 'predictor', 'number', 'group', 'minus', 'one', 'analysis', 'canonical', 'discriminant_function', 'maximize', 'distance', 'group', 'centroid']"
186,"Be careful not to confuse discriminant analysis with cluster analysis, which is another commonly used dimension-reduction technique. Discriminant analysis requires prior knowledge of the groups, usually in the form of a sample from each group. In cluster analysis, the data do not include information on group membership; the purpose of cluster analysis is to create the groups. This distinction between knowledge of groups versus creation of groups highlights the difference between supervised and unsupervised analyses. Most of the analyses in scientific research and inferential statistical analysis involve the use of supervised data analytic techniques. MANOVA, canonical correlation, and discriminant analysis are all examples of supervised analyses. In contrast, unsupervised analytic methods are more typical of the kinds of research questions in which statistical inference is not a primary goal, such as in market segmentation, or during the exploratory phase of a scientific investigation. Principal components analysis and cluster analysis are examples of unsupervised analyses.",AM,1090,"['careful', 'confuse', 'discriminant_analysis', 'cluster', 'analysis', 'another', 'commonly', 'used', 'dimensionreduction', 'technique', 'discriminant_analysis', 'requires', 'prior', 'knowledge', 'group', 'usually', 'form', 'sample', 'group', 'cluster', 'analysis', 'data', 'include', 'information', 'group', 'membership', 'purpose', 'cluster', 'analysis', 'create', 'group', 'distinction', 'knowledge', 'group', 'versus', 'creation', 'group', 'highlight', 'difference', 'supervised', 'unsupervised', 'analysis', 'analysis', 'scientific', 'research', 'inferential', 'statistical', 'analysis', 'involve', 'use', 'supervised', 'data', 'analytic', 'technique', 'manova', 'canonical', 'correlation', 'discriminant_analysis', 'example', 'supervised', 'analysis', 'contrast', 'unsupervised', 'analytic', 'method', 'typical', 'kind', 'research', 'question', 'statistical', 'inference', 'primary', 'goal', 'market', 'segmentation', 'exploratory', 'phase', 'scientific', 'investigation', 'principal', 'component', 'analysis', 'cluster', 'analysis', 'example', 'unsupervised', 'analysis']"
187,"In the GLM procedure, you may have used LSMEANS and MEANS statements to generate pairwise tests of group differences for a model. However, there are many times when pairwise differences are not the tests of interest in an analysis. Particularly in multivariate analyses, testing every possible pair of groups on several dependent variables can be very inefficient. For example, you may only be interested in the difference between a control group and one of the treatments on one of your dependent measures. Or you may want to compare the average of a few different control groups to a treatment group. The CONTRAST statement enables you to test any linear combination of cell means. The ESTIMATE statement enables you to estimate any linear combination as well as conduct the test.",AM,782,"['glm', 'procedure', 'may', 'used', 'lsmeans', 'mean', 'statement', 'generate', 'pairwise', 'test', 'group', 'difference', 'model', 'however', 'many', 'time', 'pairwise', 'difference', 'test', 'interest', 'analysis', 'particularly', 'multivariate', 'analysis', 'testing', 'every', 'possible', 'pair', 'group', 'several', 'dependent', 'variable', 'inefficient', 'example', 'may', 'interested', 'difference', 'control', 'group', 'one', 'treatment', 'one', 'dependent', 'measure', 'may', 'want', 'compare', 'average', 'different', 'control', 'group', 'treatment', 'group', 'contrast', 'statement', 'enables', 'test', 'linear', 'combination', 'cell', 'mean', 'estimate', 'statement', 'enables', 'estimate', 'linear', 'combination', 'well', 'conduct', 'test']"
188,"Sometimes values fall within the possible range on a variable but far from the other values in the data. Sometimes, as in the picture above, an observation may fall within the normal ranges on several variables, but the pattern of several variables reveals a multivariate outlier. Outliers can be problematic for a variety of reasons. Many analyses that assume normality are sensitive to outliers. Linear statistical models such as ANOVA and regression are sensitive to the effects of outliers.",AM,494,"['sometimes', 'value', 'fall', 'within', 'possible', 'range', 'variable', 'far', 'value', 'data', 'sometimes', 'picture', 'observation', 'may', 'fall', 'within', 'normal', 'range', 'several', 'variable', 'pattern', 'several', 'variable', 'reveals', 'multivariate', 'outlier', 'outlier', 'problematic', 'variety', 'reason', 'many', 'analysis', 'assume', 'normality', 'sensitive', 'outlier', 'linear', 'statistical', 'model', 'anova', 'regression', 'sensitive', 'effect', 'outlier']"
189,"Researchers want to determine whether a questionnaire measurement can adequately classify people identified as binge gamblers, steady gamblers, and nongamblers. A 12-item questionnaire based on DSM-IV diagnostic criteria for pathological gambling was administered to 100 people divided into the three groups. The variable type is a class variable that identifies each observation as *	Binge *	Steady *	Control. Canonical Discriminant Analysis",AM,442,"['researcher', 'want', 'determine', 'whether', 'questionnaire', 'measurement', 'adequately', 'classify', 'people', 'identified', 'binge', 'gambler', 'steady', 'gambler', 'nongamblers', '12item', 'questionnaire', 'based', 'dsmiv', 'diagnostic', 'criterion', 'pathological', 'gambling', 'wa', 'administered', '100', 'people', 'divided', 'three', 'group', 'variable', 'type', 'class', 'variable', 'identifies', 'observation', '\tbinge', '\tsteady', '\tcontrol', 'canonical', 'discriminant_analysis']"
190,"Multivariate analysis of variance (MANOVA) is an extension of the concepts and techniques of ANOVA to situations with multiple dependent variables. One-way MANOVA can be used to test for group differences on several dependent variables simultaneously. Factorial MANOVA can be used to identify main effects and interactions among factors on a set of dependent variables. Unlike ANOVA, MANOVA takes into account relationships among the dependent variables as well as the relationship between independent and dependent variables.",AM,526,"['multivariate', 'analysis', 'variance', 'manova', 'extension', 'concept', 'technique', 'anova', 'situation', 'multiple', 'dependent', 'variable', 'oneway', 'manova', 'used', 'test', 'group', 'difference', 'several', 'dependent', 'variable', 'simultaneously', 'factorial', 'manova', 'used', 'identify', 'main_effect', 'interaction', 'among', 'factor', 'set', 'dependent', 'variable', 'unlike', 'anova', 'manova', 'take', 'account', 'relationship', 'among', 'dependent', 'variable', 'well', 'relationship', 'independent', 'dependent', 'variable']"
191,"Since the Chi-Square value is significant at the 0.05 level, the within covariance matrices will be used in the discriminant function. Reference: Morrison, D.F. (1976) Multivariate Statistical Methods p252. Documentation for the test of equality of covariance matrices is provided in the DISCRIM output. Recall that the null hypothesis is that the covariance matrices are homogeneous, or that the covariance matrices are equal to the pooled covariance matrix. You reject this hypothesis. Quadratic discriminant analysis is more appropriate than linear discriminant analysis in this example, and a note in the output tells you that within covariance matrices are used in the discriminant function. Pairwise Generalized Squared Distances Between Groups",AM,750,"['since', 'chisquare', 'value', 'significant', '005', 'level', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'reference', 'morrison', 'df', '1976', 'multivariate', 'statistical', 'method', 'p252', 'documentation', 'test', 'equality', 'covariance', 'matrix', 'provided', 'discrim', 'output', 'recall', 'null', 'hypothesis', 'covariance', 'matrix', 'homogeneous', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'reject', 'hypothesis', 'quadratic', 'discriminant_analysis', 'appropriate', 'linear', 'discriminant_analysis', 'example', 'note', 'output', 'tell', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
192,"In the DISCRIM procedure, the POOL= option controls whether linear or quadratic discriminant analysis is performed. Is you specify POOL=YES (the default), DISCRIM performs linear discriminant analysis. POOL=NO requests quadratic discriminant analysis. You can also request a chi-square test of homogeneity of covariance matrices with the option POOL=TEST. The test for homogeneity of covariance matrices uses a chi-square statistic that assumes that the data are multivariate normal. The null hypothesis of the test is that the within-group covariance matrices are equal to the pooled covariance matrix. If you specify POOL=TEST, the default alpha for the test is 0.05. You can change this using the SLPOOL= option. If you reject the null hypothesis for this test, PROC DISCRIM automatically performs quadratic discriminant analysis. If the null hypothesis is not rejected, PROC DISCRIM performs linear discriminant analysis.",AM,925,"['discrim', 'procedure', 'pool', 'option', 'control', 'whether', 'linear', 'quadratic', 'discriminant_analysis', 'performed', 'specify', 'poolyes', 'default', 'discrim', 'performs', 'linear', 'discriminant_analysis', 'poolno', 'request', 'quadratic', 'discriminant_analysis', 'also', 'request', 'chisquare', 'test', 'homogeneity', 'covariance', 'matrix', 'option', 'pooltest', 'test', 'homogeneity', 'covariance', 'matrix', 'us', 'chisquare', 'statistic', 'assumes', 'data', 'multivariate', 'normal', 'null', 'hypothesis', 'test', 'withingroup', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'specify', 'pooltest', 'default', 'alpha', 'test', '005', 'change', 'using', 'slpool', 'option', 'reject', 'null', 'hypothesis', 'test', 'proc', 'discrim', 'automatically', 'performs', 'quadratic', 'discriminant_analysis', 'null', 'hypothesis', 'rejected', 'proc', 'discrim', 'performs', 'linear', 'discriminant_analysis']"
193,"Researchers want to determine whether a questionnaire measurement can adequately classify people identified as binge gamblers, steady gamblers, and nongamblers. A 12-item questionnaire based on DSM-IV diagnostic criteria for pathological gambling was administered to 100 people divided into the three groups. The variable type is a class variable that identifies each observation as *	Binge *	Steady *	Control. Canonical Discriminant Analysis",AM,442,"['researcher', 'want', 'determine', 'whether', 'questionnaire', 'measurement', 'adequately', 'classify', 'people', 'identified', 'binge', 'gambler', 'steady', 'gambler', 'nongamblers', '12item', 'questionnaire', 'based', 'dsmiv', 'diagnostic', 'criterion', 'pathological', 'gambling', 'wa', 'administered', '100', 'people', 'divided', 'three', 'group', 'variable', 'type', 'class', 'variable', 'identifies', 'observation', '\tbinge', '\tsteady', '\tcontrol', 'canonical', 'discriminant_analysis']"
194,"Create a table of the cell means in your model. The ordering of the variables is determined by the order of the variables in the CLASS statement. The first independent variable represents the rows. The second represents the columns. Specify the contrast hypothesis in terms of the cell means, as shown below:",AM,308,"['create', 'table', 'cell', 'mean', 'model', 'ordering', 'variable', 'determined', 'order', 'variable', 'class', 'statement', 'first', 'independent', 'variable', 'represents', 'row', 'second', 'represents', 'column', 'specify', 'contrast', 'hypothesis', 'term', 'cell', 'mean', 'shown']"
195,"Consider the example you just saw. Because the same data that are being classified are also used to create the discriminant functions, the analysis capitalizes on chance. You saw a predicted error rate of 4% in the population. However, that assumes that the population is exactly like the sample you observed and has exactly the priors that you specified. Both of these conditions are unlikely to be met, and the first one is certainly unreasonable. It is very important to empirically validate the results of a discriminant analysis on new data before using the results of a discriminant analysis to predict group membership. To do this, use the first data set as the calibration data set, and use the second data set as the validation data set. ?	If a new data set is not available, you can perform crossvalidation of the data by using a one-observation holdout method that computes the discriminant function for each data point from all the remaining data with that observation left out.",AM,990,"['consider', 'example', 'saw', 'data', 'classified', 'also', 'used', 'create', 'discriminant_function', 'analysis', 'capitalizes', 'chance', 'saw', 'predicted', 'error', 'rate', '4', 'population', 'however', 'assumes', 'population', 'exactly', 'like', 'sample', 'observed', 'ha', 'exactly', 'prior', 'specified', 'condition', 'unlikely', 'met', 'first', 'one', 'certainly', 'unreasonable', 'important', 'empirically', 'validate', 'result', 'discriminant_analysis', 'new', 'data', 'using', 'result', 'discriminant_analysis', 'predict', 'group', 'membership', 'use', 'first', 'data_set', 'calibration', 'data_set', 'use', 'second', 'data_set', 'validation', 'data_set', '\tif', 'new', 'data_set', 'available', 'perform', 'crossvalidation', 'data', 'using', 'oneobservation', 'holdout', 'method', 'computes', 'discriminant_function', 'data', 'point', 'remaining', 'data', 'observation', 'left']"
196,"Where ANOVA tests for differences among group means, MANOVA tests for differences among the multivariate centroids of groups. In MANOVA, correlations among dependent variables can have dramatic effects on the inference based on the resulting linear model.",AM,255,"['anova', 'test', 'difference', 'among', 'group', 'mean', 'manova', 'test', 'difference', 'among', 'multivariate', 'centroid', 'group', 'manova', 'correlation', 'among', 'dependent', 'variable', 'dramatic', 'effect', 'inference', 'based', 'resulting', 'linear', 'model']"
197,"Related to the problem of restricted range is the problem of zero or near-zero group sizes. Many kinds of statistical estimates are unstable at small samples. Furthermore, dramatically unequal group sizes pose a problem for models such as MANOVA, which assume equal variances and covariances across groups.",AM,306,"['related', 'problem', 'restricted', 'range', 'problem', 'zero', 'nearzero', 'group', 'size', 'many', 'kind', 'statistical', 'estimate', 'unstable', 'small', 'sample', 'furthermore', 'dramatically', 'unequal', 'group', 'size', 'pose', 'problem', 'model', 'manova', 'assume', 'equal', 'variance', 'covariance', 'across', 'group']"
198,"The Tofu Veg Delite does not appear to fit with the general pattern of the rest of the data. You also notice that the Frozen sandwiches are close to one another near the low end of Calories and Sodium. Principal Components and Outliers: SAS Code within the SAS/IML Workshop For more than three-dimensional space, the easiest way to spot outliers can be with a histogram of principal component scores. The program App_OutliersIML.iml is displayed below: libname amul 'C:\workshop\winsas\amul\data\';",AM,498,"['tofu', 'veg', 'delite', 'doe', 'appear', 'fit', 'general', 'pattern', 'rest', 'data', 'also', 'notice', 'frozen', 'sandwich', 'close', 'one', 'another', 'near', 'low', 'end', 'calorie', 'sodium', 'principal', 'component', 'outlier', 'sa', 'code', 'within', 'sasiml', 'workshop', 'threedimensional', 'space', 'easiest', 'way', 'spot', 'outlier', 'histogram', 'principal', 'component', 'score', 'program', 'appoutliersimliml', 'displayed', 'libname', 'amul', 'cworkshopwinsasamuldata']"
199,Only the first 20 out of 100 observations are shown here. PROC DISCRIM flags misclassified observations with an asterisk. You can see that observations 12 and 13 were misclassified. Classification Summary for Calibration Data: AMUL.GAMBLEGRP Resubstitution Summary using Linear Discriminant Function,AM,299,"['first', '20', '100', 'observation', 'shown', 'proc', 'discrim', 'flag', 'misclassified', 'observation', 'asterisk', 'see', 'observation', '12', '13', 'misclassified', 'classification', 'summary', 'calibration', 'data', 'amulgamblegrp', 'resubstitution', 'summary', 'using', 'linear', 'discriminant_function']"
200,"There are many ways to specify a contrast. Perhaps the easiest method is by using the cell means model. Writing contrasts with the cell means model enables you to specify any contrast you are interested in. However, it is very important to understand that this model specification method is used for simplifying the contrasts, and it does not generally produce an overall test of model fit that researchers are interested in. In specifying coefficients for a CONTRAST or ESTIMATE statement, ordering of the terms is determined by the order in which variables appear in the CLASS statement. The levels of each factor are expressed in alphanumeric order. ?	If you are uncertain about the order of the terms in your model, specify the SOLUTION option in the MODEL statement in PROC GLM. This will display a table of parameter estimates, and you will see the order in which the contrast terms should be specified.",AM,909,"['many', 'way', 'specify', 'contrast', 'perhaps', 'easiest', 'method', 'using', 'cell', 'mean', 'model', 'writing', 'contrast', 'cell', 'mean', 'model', 'enables', 'specify', 'contrast', 'interested', 'however', 'important', 'understand', 'model', 'specification', 'method', 'used', 'simplifying', 'contrast', 'doe', 'generally', 'produce', 'overall', 'test', 'model', 'fit', 'researcher', 'interested', 'specifying', 'coefficient', 'contrast', 'estimate', 'statement', 'ordering', 'term', 'determined', 'order', 'variable', 'appear', 'class', 'statement', 'level', 'factor', 'expressed', 'alphanumeric', 'order', '\tif', 'uncertain', 'order', 'term', 'model', 'specify', 'solution', 'option', 'model_statement', 'proc', 'glm', 'display', 'table', 'parameter_estimate', 'see', 'order', 'contrast', 'term', 'specified']"
201,"Univariate ANOVA as a method of interpreting multivariate effects often fails to produce the useful interpretation needed for data analysis. In this chapter, you will see ANOVA as a method of evaluating multivariate effects. Later you will learn to use canonical discriminant analysis to interpret multivariate group differences in a way that retains the multidimensional associations in the data. Multivariate Analysis of Variance",AM,431,"['univariate', 'anova', 'method', 'interpreting', 'multivariate', 'effect', 'often', 'fails', 'produce', 'useful', 'interpretation', 'needed', 'data', 'analysis', 'chapter', 'see', 'anova', 'method', 'evaluating', 'multivariate', 'effect', 'later', 'learn', 'use', 'canonical', 'discriminant_analysis', 'interpret', 'multivariate', 'group', 'difference', 'way', 'retains', 'multidimensional', 'association', 'data', 'multivariate', 'analysis', 'variance']"
202,"From the canonical discriminant analysis you ran in the previous section, you saw that there were two discriminant functions that both appear to have useful interpretations and that discriminate between different pairs of groups.",AM,229,"['canonical', 'discriminant_analysis', 'ran', 'previous', 'section', 'saw', 'two', 'discriminant_function', 'appear', 'useful', 'interpretation', 'discriminate', 'different', 'pair', 'group']"
203,"Related to the problem of restricted range is the problem of zero or near-zero group sizes. Many kinds of statistical estimates are unstable at small samples. Furthermore, dramatically unequal group sizes pose a problem for models such as MANOVA, which assume equal variances and covariances across groups.",AM,306,"['related', 'problem', 'restricted', 'range', 'problem', 'zero', 'nearzero', 'group', 'size', 'many', 'kind', 'statistical', 'estimate', 'unstable', 'small', 'sample', 'furthermore', 'dramatically', 'unequal', 'group', 'size', 'pose', 'problem', 'model', 'manova', 'assume', 'equal', 'variance', 'covariance', 'across', 'group']"
204,"The Pooled Within Canonical Structure table shows the correlations between the predictors and the discriminant functions after adjusting for group differences. In other words, the pooled within canonical structure shows the correlations among the canonical variates and the predictors within the groups. Examining the variables that correlate highly with the first discriminant function (dsm4, dsm8, dsm10, and dsm12) suggests that these variables are all consequences of gambling. Thus, it appears that variables that pertain to consequences of gambling are responsible for an important portion of the discrimination among the three groups. Examining the variables that correlate highly with the second discriminant function (dsm1, dsm2, dsm3, and dsm9) suggests that these variables involve thoughts about gambling. Thus, it appears that variables pertaining to thoughts about gambling are responsible for an important portion of the discrimination among the groups. Additionally, PROC CANDISC displays several tables of canonical coefficients. These coefficients are influenced by correlations among the variables and, in some cases, by the scale of the variables. For these reasons, the coefficients are problematic to interpret, and are thus not shown here. Class Means on Canonical Variables",AM,1297,"['pooled', 'within', 'canonical', 'structure', 'table', 'show', 'correlation', 'predictor', 'discriminant_function', 'adjusting', 'group', 'difference', 'word', 'pooled', 'within', 'canonical', 'structure', 'show', 'correlation', 'among', 'canonical', 'variate', 'predictor', 'within', 'group', 'examining', 'variable', 'correlate', 'highly', 'first', 'discriminant_function', 'dsm4', 'dsm8', 'dsm10', 'dsm12', 'suggests', 'variable', 'consequence', 'gambling', 'thus', 'appears', 'variable', 'pertain', 'consequence', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'three', 'group', 'examining', 'variable', 'correlate', 'highly', 'second', 'discriminant_function', 'dsm1', 'dsm2', 'dsm3', 'dsm9', 'suggests', 'variable', 'involve', 'thought', 'gambling', 'thus', 'appears', 'variable', 'pertaining', 'thought', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'group', 'additionally', 'proc', 'candisc', 'display', 'several', 'table', 'canonical', 'coefficient', 'coefficient', 'influenced', 'correlation', 'among', 'variable', 'case', 'scale', 'variable', 'reason', 'coefficient', 'problematic', 'interpret', 'thus', 'shown', 'class', 'mean', 'canonical', 'variable']"
205,"There are potential problems in any kind of data. Computers crash, researchers enter erroneous factor settings, data entry coders make typographical errors, and research participants fall asleep. Human error, technical difficulties in automated systems, collinear variables, duplicated records, outlying observations, and a host of other problems can plague your data. The more time you invest in validating, cleaning, preparing and checking your data, the more you will be able to reap the rewards of your statistical analyses. In addition to making the data ready for your analyses, often preparing and evaluating the data provide you with insight that you may not have gained otherwise.",AM,689,"['potential', 'problem', 'kind', 'data', 'computer', 'crash', 'researcher', 'enter', 'erroneous', 'factor', 'setting', 'data', 'entry', 'coder', 'make', 'typographical', 'error', 'research', 'participant', 'fall', 'asleep', 'human', 'error', 'technical', 'difficulty', 'automated', 'system', 'collinear', 'variable', 'duplicated', 'record', 'outlying', 'observation', 'host', 'problem', 'plague', 'data', 'time', 'invest', 'validating', 'cleaning', 'preparing', 'checking', 'data', 'able', 'reap', 'reward', 'statistical', 'analysis', 'addition', 'making', 'data', 'ready', 'analysis', 'often', 'preparing', 'evaluating', 'data', 'provide', 'insight', 'may', 'gained', 'otherwise']"
206,"A natural extension of the MANOVA research question ?How do my continuous responses differ as a function of group levels?? is the discriminant analysis research question ?How do my continuous variables predict membership in groups? With discriminant analysis, you can use parametric or nonparametric methods to *	find linear combinations of continuous variables (discriminant functions) that predict group membership *	estimate the expected misclassification rate based on the discriminant functions *	test the discriminant functions on a new sample to determine the extent to which the functions correctly and incorrectly classify observations Canonical discriminant analysis has the advantage of conceptual and computational simplicity, while Fisher linear discriminant analysis is powerful enough to allow you to find the discriminant functions and test or crossvalidate your results using one simple procedure. You learned to use two procedures in SAS to perform discriminant analysis: PROC CANDISC performs canonical discriminant analysis to find linear combinations of variables that best discriminate among groups. PROC DISCRIM performs linear and quadratic discriminant analysis and produces a prediction function to help classify observations in to groups based on a set of predictors. Remember that discriminant analysis and other predictive modeling techniques capitalize on chance associations among the predictors in your data to find the discriminant functions. For this reason it is important always to perform empirical validation on a new sample of data, or at least use crossvalidation before using the discriminant functions for prediction and scoring.",AM,1671,"['natural', 'extension', 'manova', 'research', 'question', 'continuous', 'response', 'differ', 'function', 'group', 'level', 'discriminant_analysis', 'research', 'question', 'continuous', 'variable', 'predict', 'membership', 'group', 'discriminant_analysis', 'use', 'parametric', 'nonparametric', 'method', '\tfind', 'linear', 'combination', 'continuous', 'variable', 'discriminant_function', 'predict', 'group', 'membership', '\testimate', 'expected', 'misclassification', 'rate', 'based', 'discriminant_function', '\ttest', 'discriminant_function', 'new', 'sample', 'determine', 'extent', 'function', 'correctly', 'incorrectly', 'classify', 'observation', 'canonical', 'discriminant_analysis', 'ha', 'advantage', 'conceptual', 'computational', 'simplicity', 'fisher', 'linear', 'discriminant_analysis', 'powerful', 'enough', 'allow', 'find', 'discriminant_function', 'test', 'crossvalidate', 'result', 'using', 'one', 'simple', 'procedure', 'learned', 'use', 'two', 'procedure', 'sa', 'perform', 'discriminant_analysis', 'proc', 'candisc', 'performs', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'variable', 'best', 'discriminate', 'among', 'group', 'proc', 'discrim', 'performs', 'linear', 'quadratic', 'discriminant_analysis', 'produce', 'prediction', 'function', 'help', 'classify', 'observation', 'group', 'based', 'set', 'predictor', 'remember', 'discriminant_analysis', 'predictive', 'modeling', 'technique', 'capitalize', 'chance', 'association', 'among', 'predictor', 'data', 'find', 'discriminant_function', 'reason', 'important', 'always', 'perform', 'empirical', 'validation', 'new', 'sample', 'data', 'least', 'use', 'crossvalidation', 'using', 'discriminant_function', 'prediction', 'scoring']"
207,"Presume you are investigating variables that are related to career success among university faculty (number of publications, years experience, type of university, salary, job satisfaction). For the most part, higher salaries are associated with a higher number of publications. However, a few participants in your study have relatively low salaries and a somewhat large number of publications. These participants, although not necessarily outliers on any one variable, are outliers on the combination of these two variables. When you are interested specifically in multivariate outliers, there are myriad options. Two methods that are emphasized here are scatter plots and principal components analysis. Scatter plots of two or three variables at a time can reveal multivariate outliers that you might have missed using univariate plots only. Three-way rotatable plots enable you to look at the relationships among three variables at a time. Sometimes, however, even three-way plots can fail to reveal multivariate outliers in greater than three-dimensional space. Sometimes it is simply inefficient to create so many two-and three-way plots. In such situations, principal components analysis can be valuable. Recall that principal components are linear combinations of variables that account for the most variance with the first component, the second most with the second component, and so on. By consolidating most of the variance into one or two variables and looking over histograms of the components, you can easily spot multivariate outliers in your data.",AM,1561,"['presume', 'investigating', 'variable', 'related', 'career', 'success', 'among', 'university', 'faculty', 'number', 'publication', 'year', 'experience', 'type', 'university', 'salary', 'job', 'satisfaction', 'part', 'higher', 'salary', 'associated', 'higher', 'number', 'publication', 'however', 'participant', 'study', 'relatively', 'low', 'salary', 'somewhat', 'large', 'number', 'publication', 'participant', 'although', 'necessarily', 'outlier', 'one', 'variable', 'outlier', 'combination', 'two', 'variable', 'interested', 'specifically', 'multivariate', 'outlier', 'myriad', 'option', 'two', 'method', 'emphasized', 'scatter', 'plot', 'principal', 'component', 'analysis', 'scatter', 'plot', 'two', 'three', 'variable', 'time', 'reveal', 'multivariate', 'outlier', 'might', 'missed', 'using', 'univariate', 'plot', 'threeway', 'rotatable', 'plot', 'enable', 'look', 'relationship', 'among', 'three', 'variable', 'time', 'sometimes', 'however', 'even', 'threeway', 'plot', 'fail', 'reveal', 'multivariate', 'outlier', 'greater', 'threedimensional', 'space', 'sometimes', 'simply', 'inefficient', 'create', 'many', 'twoand', 'threeway', 'plot', 'situation', 'principal', 'component', 'analysis', 'valuable', 'recall', 'principal', 'component', 'linear', 'combination', 'variable', 'account', 'variance', 'first', 'component', 'second', 'second', 'component', 'consolidating', 'variance', 'one', 'two', 'variable', 'looking', 'histogram', 'component', 'easily', 'spot', 'multivariate', 'outlier', 'data']"
208,"Because of the unequal group sizes, you may want to consider combining similar groups together, and/or testing for equality of covariance matrices before performing any multivariate analyses with this variable.",AM,210,"['unequal', 'group', 'size', 'may', 'want', 'consider', 'combining', 'similar', 'group', 'together', 'andor', 'testing', 'equality', 'covariance', 'matrix', 'performing', 'multivariate', 'analysis', 'variable']"
209,Only the first 20 out of 100 observations are shown here. PROC DISCRIM flags misclassified observations with an asterisk. You can see that observations 12 and 13 were misclassified. Classification Summary for Calibration Data: AMUL.GAMBLEGRP Resubstitution Summary using Linear Discriminant Function,AM,299,"['first', '20', '100', 'observation', 'shown', 'proc', 'discrim', 'flag', 'misclassified', 'observation', 'asterisk', 'see', 'observation', '12', '13', 'misclassified', 'classification', 'summary', 'calibration', 'data', 'amulgamblegrp', 'resubstitution', 'summary', 'using', 'linear', 'discriminant_function']"
210,"where Vt = St if using within-group covariance matrices, or Vt = Sp if using pooled covariance matrices, and mt is the mean vector of group t. ?	The default in PROC DISCRIM is to use pooled covariances in calculating the generalized squared distances. If you prefer to use within-class covariances, specify POOL = NO in the DISCRIM statement. You will learn to use this option later in the course for quadratic discriminant analysis.",AM,433,"['vt', '', 'st', 'using', 'withingroup', 'covariance', 'matrix', 'vt', '', 'sp', 'using', 'pooled', 'covariance', 'matrix', 'mt', 'mean', 'vector', 'group', '\tthe', 'default', 'proc', 'discrim', 'use', 'pooled', 'covariance', 'calculating', 'generalized', 'squared', 'distance', 'prefer', 'use', 'withinclass', 'covariance', 'specify', 'pool', '', 'discrim', 'statement', 'learn', 'use', 'option', 'later', 'course', 'quadratic', 'discriminant_analysis']"
211,"Consider an agricultural example. Suppose you were interested in predicting crop type (corn, cotton, and soybeans) based on a series of remote sensing measures. You could perform canonical correlation analysis for this data set by recoding the groups with values of 0,1 creating dummy codes, or indicator variables. You would have two indicator variables for three crops. You could treat these variables as one group, V, and the set of predictors (the remote sensing measures) as a second set of variables, W. The plot above shows the two canonical variates. Canonical correlation analysis on the data would help you find the first linear combination of each set of variables that maximizes the correlation between them, then find the second combination, uncorrelated with the first, that maximizes the correlation among the second pair of variates, and so on. Canonical correlation analysis with a set of indicator variables is the same as canonical discriminant analysis.",AM,973,"['consider', 'agricultural', 'example', 'suppose', 'interested', 'predicting', 'crop', 'type', 'corn', 'cotton', 'soybean', 'based', 'series', 'remote', 'sensing', 'measure', 'could', 'perform', 'canonical', 'correlation', 'analysis', 'data_set', 'recoding', 'group', 'value', '01', 'creating', 'dummy', 'code', 'indicator', 'variable', 'would', 'two', 'indicator', 'variable', 'three', 'crop', 'could', 'treat', 'variable', 'one', 'group', 'v', 'set', 'predictor', 'remote', 'sensing', 'measure', 'second', 'set', 'variable', 'w', 'plot', 'show', 'two', 'canonical', 'variate', 'canonical', 'correlation', 'analysis', 'data', 'would', 'help', 'find', 'first', 'linear', 'combination', 'set', 'variable', 'maximizes', 'correlation', 'find', 'second', 'combination', 'uncorrelated', 'first', 'maximizes', 'correlation', 'among', 'second', 'pair', 'variate', 'canonical', 'correlation', 'analysis', 'set', 'indicator', 'variable', 'canonical', 'discriminant_analysis']"
212,"The Tofu Veg Delite does not appear to fit with the general pattern of the rest of the data. You also notice that the Frozen sandwiches are close to one another near the low end of Calories and Sodium. Principal Components and Outliers: SAS Code within the SAS/IML Workshop For more than three-dimensional space, the easiest way to spot outliers can be with a histogram of principal component scores. The program App_OutliersIML.iml is displayed below: libname amul 'C:\workshop\winsas\amul\data\';",AM,498,"['tofu', 'veg', 'delite', 'doe', 'appear', 'fit', 'general', 'pattern', 'rest', 'data', 'also', 'notice', 'frozen', 'sandwich', 'close', 'one', 'another', 'near', 'low', 'end', 'calorie', 'sodium', 'principal', 'component', 'outlier', 'sa', 'code', 'within', 'sasiml', 'workshop', 'threedimensional', 'space', 'easiest', 'way', 'spot', 'outlier', 'histogram', 'principal', 'component', 'score', 'program', 'appoutliersimliml', 'displayed', 'libname', 'amul', 'cworkshopwinsasamuldata']"
213,"In order for the test statistics in MANOVA to follow the theorized distribution, certain assumptions should be met: *	Observations are randomly sampled from the population. *	Observations are independent of one another; in other words, one observation does not provide information about other observations. *	The set of dependent variables follows a multivariate normal distribution conditional on the independent variables. This implies univariate conditional normality for each DV separately, but univariate normality alone is not sufficient for the assumption of multivariate normality to be met. *	The within-group covariance matrices are equal across groups. This implies equal variances across groups for each DV, and it also implies that all pairwise correlations between the DVs are equal across groups. As with ANOVA, MANOVA test statistics are robust to violations of some, but not all, of these assumptions. The robustness of each test statistic varies (Bray and Maxwell 1985). As a result, there is not a single test statistic that is uniformly preferred in all situations.",AM,1085,"['order', 'test', 'statistic', 'manova', 'follow', 'theorized', 'distribution', 'certain', 'assumption', 'met', '\tobservations', 'randomly', 'sampled', 'population', '\tobservations', 'independent', 'one', 'another', 'word', 'one', 'observation', 'doe', 'provide', 'information', 'observation', '\tthe', 'set', 'dependent', 'variable', 'follows', 'multivariate', 'normal', 'distribution', 'conditional', 'independent', 'variable', 'implies', 'univariate', 'conditional', 'normality', 'dv', 'separately', 'univariate', 'normality', 'alone', 'sufficient', 'assumption', 'multivariate', 'normality', 'met', '\tthe', 'withingroup', 'covariance', 'matrix', 'equal', 'across', 'group', 'implies', 'equal', 'variance', 'across', 'group', 'dv', 'also', 'implies', 'pairwise', 'correlation', 'dvs', 'equal', 'across', 'group', 'anova', 'manova', 'test', 'statistic', 'robust', 'violation', 'assumption', 'robustness', 'test', 'statistic', 'varies', 'bray', 'maxwell', '1985', 'result', 'single', 'test', 'statistic', 'uniformly', 'preferred', 'situation']"
214,"Sometimes values fall within the possible range on a variable but far from the other values in the data. Sometimes, as in the picture above, an observation may fall within the normal ranges on several variables, but the pattern of several variables reveals a multivariate outlier. Outliers can be problematic for a variety of reasons. Many analyses that assume normality are sensitive to outliers. Linear statistical models such as ANOVA and regression are sensitive to the effects of outliers.",AM,494,"['sometimes', 'value', 'fall', 'within', 'possible', 'range', 'variable', 'far', 'value', 'data', 'sometimes', 'picture', 'observation', 'may', 'fall', 'within', 'normal', 'range', 'several', 'variable', 'pattern', 'several', 'variable', 'reveals', 'multivariate', 'outlier', 'outlier', 'problematic', 'variety', 'reason', 'many', 'analysis', 'assume', 'normality', 'sensitive', 'outlier', 'linear', 'statistical', 'model', 'anova', 'regression', 'sensitive', 'effect', 'outlier']"
215,"Presume you are investigating variables that are related to career success among university faculty (number of publications, years experience, type of university, salary, job satisfaction). For the most part, higher salaries are associated with a higher number of publications. However, a few participants in your study have relatively low salaries and a somewhat large number of publications. These participants, although not necessarily outliers on any one variable, are outliers on the combination of these two variables. When you are interested specifically in multivariate outliers, there are myriad options. Two methods that are emphasized here are scatter plots and principal components analysis. Scatter plots of two or three variables at a time can reveal multivariate outliers that you might have missed using univariate plots only. Three-way rotatable plots enable you to look at the relationships among three variables at a time. Sometimes, however, even three-way plots can fail to reveal multivariate outliers in greater than three-dimensional space. Sometimes it is simply inefficient to create so many two-and three-way plots. In such situations, principal components analysis can be valuable. Recall that principal components are linear combinations of variables that account for the most variance with the first component, the second most with the second component, and so on. By consolidating most of the variance into one or two variables and looking over histograms of the components, you can easily spot multivariate outliers in your data.",AM,1561,"['presume', 'investigating', 'variable', 'related', 'career', 'success', 'among', 'university', 'faculty', 'number', 'publication', 'year', 'experience', 'type', 'university', 'salary', 'job', 'satisfaction', 'part', 'higher', 'salary', 'associated', 'higher', 'number', 'publication', 'however', 'participant', 'study', 'relatively', 'low', 'salary', 'somewhat', 'large', 'number', 'publication', 'participant', 'although', 'necessarily', 'outlier', 'one', 'variable', 'outlier', 'combination', 'two', 'variable', 'interested', 'specifically', 'multivariate', 'outlier', 'myriad', 'option', 'two', 'method', 'emphasized', 'scatter', 'plot', 'principal', 'component', 'analysis', 'scatter', 'plot', 'two', 'three', 'variable', 'time', 'reveal', 'multivariate', 'outlier', 'might', 'missed', 'using', 'univariate', 'plot', 'threeway', 'rotatable', 'plot', 'enable', 'look', 'relationship', 'among', 'three', 'variable', 'time', 'sometimes', 'however', 'even', 'threeway', 'plot', 'fail', 'reveal', 'multivariate', 'outlier', 'greater', 'threedimensional', 'space', 'sometimes', 'simply', 'inefficient', 'create', 'many', 'twoand', 'threeway', 'plot', 'situation', 'principal', 'component', 'analysis', 'valuable', 'recall', 'principal', 'component', 'linear', 'combination', 'variable', 'account', 'variance', 'first', 'component', 'second', 'second', 'component', 'consolidating', 'variance', 'one', 'two', 'variable', 'looking', 'histogram', 'component', 'easily', 'spot', 'multivariate', 'outlier', 'data']"
216,"With a CONTRAST statement, you specify L, in this case, a vector of coefficients for the effect to be tested. M is a transformation matrix that in this case is an identity matrix. For this reason, M is sometimes dropped from the null hypothesis specification. CONTRAST	enables you to perform custom hypothesis tests by specifying an L vector or matrix for testing the univariate hypothesis . There is no limit to the number of CONTRAST statements you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE	enables you to estimate linear functions of the parameters by multiplying the vector L by the parameter estimate vector b resulting in Lb. There is no limit to the number of ESTIMATE statements that you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE statements only perform 1-df univariate tests. In the CONTRAST and ESTIMATE statements, label	applies a label to the contrast (or estimate) on the output. A label is required for every contrast (or estimate) specified. Labels must be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement, or the INTERCEPT effect. The INTERCEPT effect can be used when an intercept is fitted in the model. You do not need to include all effects that are in the MODEL statement. values	are constants that are elements of the L vector associated with the effect. You do not need to include trailing zeros in the L vector.",AM,1490,"['contrast', 'statement', 'specify', 'l', 'case', 'vector', 'coefficient', 'effect', 'tested', 'transformation', 'matrix', 'case', 'identity', 'matrix', 'reason', 'sometimes', 'dropped', 'null', 'hypothesis', 'specification', 'contrast\tenables', 'perform', 'custom', 'hypothesis', 'test', 'specifying', 'l', 'vector', 'matrix', 'testing', 'univariate', 'hypothesis', '', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate\tenables', 'estimate', 'linear', 'function', 'parameter', 'multiplying', 'vector', 'l', 'parameter_estimate', 'vector', 'b', 'resulting', 'lb', 'limit', 'number', 'estimate', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate', 'statement', 'perform', '1df', 'univariate', 'test', 'contrast', 'estimate', 'statement', 'label\tapplies', 'label', 'contrast', 'estimate', 'output', 'label', 'required', 'every', 'contrast', 'estimate', 'specified', 'label', 'must', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'intercept', 'effect', 'intercept', 'effect', 'used', 'intercept', 'fitted', 'model', 'need', 'include', 'effect', 'model_statement', 'values\tare', 'constant', 'element', 'l', 'vector', 'associated', 'effect', 'need', 'include', 'trailing', 'zero', 'l', 'vector']"
217,"It is useful to examine the means of the subgroups on each of the canonical discriminant functions. The space defined by the canonical discriminant functions is the space that maximally separates the group centroids (multivariate mean vectors). In this case, you see that the first canonical discriminant function seems to be mostly separating the Binge and the Steady gamblers, and the second canonical discriminant function appears to be separating the Control group from the Steady gamblers. If your data set is very large, it is often useful to plot the group centroids in the space defined by the canonical discriminant functions to get an idea of how well the group centroids are separated. In this case, the data set is sufficiently small that you can plot the individual observations in the space defined by the discriminant functions. ?	Although it is not shown here, you could use ODS to save the centroids from the Class Means on Canonical Variables table and plot them using the GPLOT procedure. An example program, CDA plot with centroids.sas, is included with the course data.",AM,1090,"['useful', 'examine', 'mean', 'subgroup', 'canonical', 'discriminant_function', 'space', 'defined', 'canonical', 'discriminant_function', 'space', 'maximally', 'separate', 'group', 'centroid', 'multivariate', 'mean', 'vector', 'case', 'see', 'first', 'canonical', 'discriminant_function', 'seems', 'mostly', 'separating', 'binge', 'steady', 'gambler', 'second', 'canonical', 'discriminant_function', 'appears', 'separating', 'control', 'group', 'steady', 'gambler', 'data_set', 'large', 'often', 'useful', 'plot', 'group', 'centroid', 'space', 'defined', 'canonical', 'discriminant_function', 'get', 'idea', 'well', 'group', 'centroid', 'separated', 'case', 'data_set', 'sufficiently', 'small', 'plot', 'individual', 'observation', 'space', 'defined', 'discriminant_function', '\talthough', 'shown', 'could', 'use', 'od', 'save', 'centroid', 'class', 'mean', 'canonical', 'variable', 'table', 'plot', 'using', 'gplot', 'procedure', 'example', 'program', 'cda', 'plot', 'centroidssas', 'included', 'course', 'data']"
218,"It is easy to see the pattern of how the groups fall on the discriminant functions. As you saw before, the first function distinguishes between Steady and Binge gamblers, while the second function discriminates between Controls and Steady gamblers.",AM,248,"['easy', 'see', 'pattern', 'group', 'fall', 'discriminant_function', 'saw', 'first', 'function', 'distinguishes', 'steady', 'binge', 'gambler', 'second', 'function', 'discriminates', 'control', 'steady', 'gambler']"
219,"Sometimes values fall within the possible range on a variable but far from the other values in the data. Sometimes, as in the picture above, an observation may fall within the normal ranges on several variables, but the pattern of several variables reveals a multivariate outlier. Outliers can be problematic for a variety of reasons. Many analyses that assume normality are sensitive to outliers. Linear statistical models such as ANOVA and regression are sensitive to the effects of outliers.",AM,494,"['sometimes', 'value', 'fall', 'within', 'possible', 'range', 'variable', 'far', 'value', 'data', 'sometimes', 'picture', 'observation', 'may', 'fall', 'within', 'normal', 'range', 'several', 'variable', 'pattern', 'several', 'variable', 'reveals', 'multivariate', 'outlier', 'outlier', 'problematic', 'variety', 'reason', 'many', 'analysis', 'assume', 'normality', 'sensitive', 'outlier', 'linear', 'statistical', 'model', 'anova', 'regression', 'sensitive', 'effect', 'outlier']"
220,"The Pooled Within Canonical Structure table shows the correlations between the predictors and the discriminant functions after adjusting for group differences. In other words, the pooled within canonical structure shows the correlations among the canonical variates and the predictors within the groups. Examining the variables that correlate highly with the first discriminant function (dsm4, dsm8, dsm10, and dsm12) suggests that these variables are all consequences of gambling. Thus, it appears that variables that pertain to consequences of gambling are responsible for an important portion of the discrimination among the three groups. Examining the variables that correlate highly with the second discriminant function (dsm1, dsm2, dsm3, and dsm9) suggests that these variables involve thoughts about gambling. Thus, it appears that variables pertaining to thoughts about gambling are responsible for an important portion of the discrimination among the groups. Additionally, PROC CANDISC displays several tables of canonical coefficients. These coefficients are influenced by correlations among the variables and, in some cases, by the scale of the variables. For these reasons, the coefficients are problematic to interpret, and are thus not shown here. Class Means on Canonical Variables",AM,1297,"['pooled', 'within', 'canonical', 'structure', 'table', 'show', 'correlation', 'predictor', 'discriminant_function', 'adjusting', 'group', 'difference', 'word', 'pooled', 'within', 'canonical', 'structure', 'show', 'correlation', 'among', 'canonical', 'variate', 'predictor', 'within', 'group', 'examining', 'variable', 'correlate', 'highly', 'first', 'discriminant_function', 'dsm4', 'dsm8', 'dsm10', 'dsm12', 'suggests', 'variable', 'consequence', 'gambling', 'thus', 'appears', 'variable', 'pertain', 'consequence', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'three', 'group', 'examining', 'variable', 'correlate', 'highly', 'second', 'discriminant_function', 'dsm1', 'dsm2', 'dsm3', 'dsm9', 'suggests', 'variable', 'involve', 'thought', 'gambling', 'thus', 'appears', 'variable', 'pertaining', 'thought', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'group', 'additionally', 'proc', 'candisc', 'display', 'several', 'table', 'canonical', 'coefficient', 'coefficient', 'influenced', 'correlation', 'among', 'variable', 'case', 'scale', 'variable', 'reason', 'coefficient', 'problematic', 'interpret', 'thus', 'shown', 'class', 'mean', 'canonical', 'variable']"
221,"Since the Chi-Square value is significant at the 0.05 level, the within covariance matrices will be used in the discriminant function. Reference: Morrison, D.F. (1976) Multivariate Statistical Methods p252. Documentation for the test of equality of covariance matrices is provided in the DISCRIM output. Recall that the null hypothesis is that the covariance matrices are homogeneous, or that the covariance matrices are equal to the pooled covariance matrix. You reject this hypothesis. Quadratic discriminant analysis is more appropriate than linear discriminant analysis in this example, and a note in the output tells you that within covariance matrices are used in the discriminant function. Pairwise Generalized Squared Distances Between Groups",AM,750,"['since', 'chisquare', 'value', 'significant', '005', 'level', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'reference', 'morrison', 'df', '1976', 'multivariate', 'statistical', 'method', 'p252', 'documentation', 'test', 'equality', 'covariance', 'matrix', 'provided', 'discrim', 'output', 'recall', 'null', 'hypothesis', 'covariance', 'matrix', 'homogeneous', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'reject', 'hypothesis', 'quadratic', 'discriminant_analysis', 'appropriate', 'linear', 'discriminant_analysis', 'example', 'note', 'output', 'tell', 'within', 'covariance', 'matrix', 'used', 'discriminant_function', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
222,"PROC CANDISC	calls the CANDISC procedure and specifies how the analysis is to be performed. CLASS	specifies the classification variable that you are trying to predict. VAR	specifies the set of continuous variables that you are using to discriminate among the groups specified by the CLASS variable. Selected option for the PROC CANDISC statement: OUT = data-set	creates an output data set that contains the original data and the canonical scores. OUTSTAT = data-set	creates a TYPE = CORR output SAS data set that contains various statistics including class-level statistics, correlations, canonical correlations, canonical structures, canonical coefficients, and means of canonical variates for each class. NOPRINT	suppresses display of output. NCAN = n	specifies the number of canonical variates to be computed. The value must be less than or equal to the maximum number of possible variates. The default is to compute all possible variates.",AM,942,"['proc', 'candisc\tcalls', 'candisc', 'procedure', 'specifies', 'analysis', 'performed', 'class\tspecifies', 'classification', 'variable', 'trying', 'predict', 'var\tspecifies', 'set', 'continuous', 'variable', 'using', 'discriminate', 'among', 'group', 'specified', 'class', 'variable', 'selected', 'option', 'proc', 'candisc', 'statement', '', 'dataset\tcreates', 'output', 'data_set', 'contains', 'original', 'data', 'canonical', 'score', 'outstat', '', 'dataset\tcreates', 'type', '', 'corr', 'output', 'sa', 'data_set', 'contains', 'various', 'statistic', 'including', 'classlevel', 'statistic', 'correlation', 'canonical', 'correlation', 'canonical', 'structure', 'canonical', 'coefficient', 'mean', 'canonical', 'variate', 'class', 'noprint\tsuppresses', 'display', 'output', 'ncan', '', 'n\tspecifies', 'number', 'canonical', 'variate', 'computed', 'value', 'must', 'le', 'equal', 'maximum', 'number', 'possible', 'variate', 'default', 'compute', 'possible', 'variate']"
223,"When planning a study, give special consideration to the problem of restricted range. For example, you may be interested in studying the effects of an intervention on behavioral and attitudinal symptoms of depression. If you only study depressed patients, then at the start of your study, you may have restricted range (ceiling effects) on your baseline symptom measures. It may be helpful to specifically recruit participants who are not depressed for your study and increase the variation in baseline depression in the overall group. Another possible solution for restricted range would be to classify participants based on the small amount of variation you have in the data. For example, you might compare the career success of university faculty with less than a doctoral degree, one doctoral degree, and more than one doctoral degree (for example, Ph.D. and J.D.). Of course, in this situation, you may encounter problems with unequal group sizes.",AM,952,"['planning', 'study', 'give', 'special', 'consideration', 'problem', 'restricted', 'range', 'example', 'may', 'interested', 'studying', 'effect', 'intervention', 'behavioral', 'attitudinal', 'symptom', 'depression', 'study', 'depressed', 'patient', 'start', 'study', 'may', 'restricted', 'range', 'ceiling', 'effect', 'baseline', 'symptom', 'measure', 'may', 'helpful', 'specifically', 'recruit', 'participant', 'depressed', 'study', 'increase', 'variation', 'baseline', 'depression', 'overall', 'group', 'another', 'possible', 'solution', 'restricted', 'range', 'would', 'classify', 'participant', 'based', 'small', 'amount', 'variation', 'data', 'example', 'might', 'compare', 'career', 'success', 'university', 'faculty', 'le', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'example', 'phd', 'jd', 'course', 'situation', 'may', 'encounter', 'problem', 'unequal', 'group', 'size']"
224,"Sometimes you have a significant multivariate effect and no significant univariate effects. Sometime just the opposite occurs?nonsignificant multivariate effects and significant univariate effects. There are several reasons that this may occur, among them type-I error, type-II error, multivariate outliers, and collinearity among the responses. You can use univariate ANOVA to try to interpret your MV effects. By default, the univariate ANOVA for each response is shown. You can suppress the default univariate ANOVA output with the NOUNI option in the MODEL statement. You can obtain an abbreviated summary of the univariate ANOVAs by including the SUMMARY option in MANOVA statement. Later, you will learn to use discriminant analysis, which allows you a multivariate method for interpreting group differences that is often preferable to univariate ANOVA.",AM,859,"['sometimes', 'significant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'sometime', 'opposite', 'occursnonsignificant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'several', 'reason', 'may', 'occur', 'among', 'typei', 'error', 'typeii', 'error', 'multivariate', 'outlier', 'collinearity', 'among', 'response', 'use', 'univariate', 'anova', 'try', 'interpret', 'mv', 'effect', 'default', 'univariate', 'anova', 'response', 'shown', 'suppress', 'default', 'univariate', 'anova', 'output', 'nouni', 'option', 'model_statement', 'obtain', 'abbreviated', 'summary', 'univariate', 'anova', 'including', 'summary', 'option', 'manova', 'statement', 'later', 'learn', 'use', 'discriminant_analysis', 'allows', 'multivariate', 'method', 'interpreting', 'group', 'difference', 'often', 'preferable', 'univariate', 'anova']"
225,"Univariate ANOVA as a method of interpreting multivariate effects often fails to produce the useful interpretation needed for data analysis. In this chapter, you will see ANOVA as a method of evaluating multivariate effects. Later you will learn to use canonical discriminant analysis to interpret multivariate group differences in a way that retains the multidimensional associations in the data. Multivariate Analysis of Variance",AM,431,"['univariate', 'anova', 'method', 'interpreting', 'multivariate', 'effect', 'often', 'fails', 'produce', 'useful', 'interpretation', 'needed', 'data', 'analysis', 'chapter', 'see', 'anova', 'method', 'evaluating', 'multivariate', 'effect', 'later', 'learn', 'use', 'canonical', 'discriminant_analysis', 'interpret', 'multivariate', 'group', 'difference', 'way', 'retains', 'multidimensional', 'association', 'data', 'multivariate', 'analysis', 'variance']"
226,"Throughout this course, you have learned to use SAS to perform a variety of multivariate statistical analyses. It is important to understand how the analyses work, what the assumptions are, and how to interpret the results of the analyses. It is equally important to know how to evaluate the assumptions of the analyses and determine whether your data are appropriate for the kind of analysis you plan to perform. Real data is almost never as simple and straightforward as classroom data, so this chapter is devoted to helping you prepare your data for multivariate analysis.",AM,575,"['throughout', 'course', 'learned', 'use', 'sa', 'perform', 'variety', 'multivariate', 'statistical', 'analysis', 'important', 'understand', 'analysis', 'work', 'assumption', 'interpret', 'result', 'analysis', 'equally', 'important', 'know', 'evaluate', 'assumption', 'analysis', 'determine', 'whether', 'data', 'appropriate', 'kind', 'analysis', 'plan', 'perform', 'real', 'data', 'almost', 'never', 'simple', 'straightforward', 'classroom', 'data', 'chapter', 'devoted', 'helping', 'prepare', 'data', 'multivariate', 'analysis']"
227,"Consider an agricultural example. Suppose you were interested in predicting crop type (corn, cotton, and soybeans) based on a series of remote sensing measures. You could perform canonical correlation analysis for this data set by recoding the groups with values of 0,1 creating dummy codes, or indicator variables. You would have two indicator variables for three crops. You could treat these variables as one group, V, and the set of predictors (the remote sensing measures) as a second set of variables, W. The plot above shows the two canonical variates. Canonical correlation analysis on the data would help you find the first linear combination of each set of variables that maximizes the correlation between them, then find the second combination, uncorrelated with the first, that maximizes the correlation among the second pair of variates, and so on. Canonical correlation analysis with a set of indicator variables is the same as canonical discriminant analysis.",AM,973,"['consider', 'agricultural', 'example', 'suppose', 'interested', 'predicting', 'crop', 'type', 'corn', 'cotton', 'soybean', 'based', 'series', 'remote', 'sensing', 'measure', 'could', 'perform', 'canonical', 'correlation', 'analysis', 'data_set', 'recoding', 'group', 'value', '01', 'creating', 'dummy', 'code', 'indicator', 'variable', 'would', 'two', 'indicator', 'variable', 'three', 'crop', 'could', 'treat', 'variable', 'one', 'group', 'v', 'set', 'predictor', 'remote', 'sensing', 'measure', 'second', 'set', 'variable', 'w', 'plot', 'show', 'two', 'canonical', 'variate', 'canonical', 'correlation', 'analysis', 'data', 'would', 'help', 'find', 'first', 'linear', 'combination', 'set', 'variable', 'maximizes', 'correlation', 'find', 'second', 'combination', 'uncorrelated', 'first', 'maximizes', 'correlation', 'among', 'second', 'pair', 'variate', 'canonical', 'correlation', 'analysis', 'set', 'indicator', 'variable', 'canonical', 'discriminant_analysis']"
228,"The pooled covariance matrix, Sp, was used. Information about Sp is displayed above. There were 12 (noncollinear) predictors; the covariance matrix Sp is rank 12. Pairwise Generalized Squared Distances Between Groups",AM,216,"['pooled', 'covariance', 'matrix', 'sp', 'wa', 'used', 'information', 'sp', 'displayed', '12', 'noncollinear', 'predictor', 'covariance', 'matrix', 'sp', 'rank', '12', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
229,"If the homogeneity of covariance matrices assumption is violated, it is possible to perform the discriminant analysis using information about each of the groups separately. In this case, a third term is added to the generalized squared distance formula: the natural log of the determinant of the covariance matrix for each group. This is known as quadratic discriminant analysis. If the determinant of a covariance matrix for a group is large, this suggests large within-group variability. Using g1(t) results in the generalized squared distance from observations to group centroids being larger for that group than for groups with smaller within-group variability. Recall in the example you saw in the first section that the control group had the widest variability on the CDA plot. The Steady group had the smallest variability. It is possible that in this example, the assumption of homogeneity of covariance matrices was violated.",AM,934,"['homogeneity', 'covariance', 'matrix', 'assumption', 'violated', 'possible', 'perform', 'discriminant_analysis', 'using', 'information', 'group', 'separately', 'case', 'third', 'term', 'added', 'generalized', 'squared', 'distance', 'formula', 'natural', 'log', 'determinant', 'covariance', 'matrix', 'group', 'known', 'quadratic', 'discriminant_analysis', 'determinant', 'covariance', 'matrix', 'group', 'large', 'suggests', 'large', 'withingroup', 'variability', 'using', 'g1t', 'result', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'larger', 'group', 'group', 'smaller', 'withingroup', 'variability', 'recall', 'example', 'saw', 'first', 'section', 'control', 'group', 'widest', 'variability', 'cda', 'plot', 'steady', 'group', 'smallest', 'variability', 'possible', 'example', 'assumption', 'homogeneity', 'covariance', 'matrix', 'wa', 'violated']"
230,"For univariate statistics, there are many outlier detection tools available. Perhaps you already use the tools listed above regularly, in addition to others. In linear models, it is often useful to look at leverage and DFFITS statistics to find influential outliers on a set of predictor variables. These statistics are easy to obtain from the REG and GLM procedures. To evaluate one variable at a time for outliers, statistical and graphical tools can be useful. For example, you can standardize your variables (center them about the mean and scale them by the standard deviation) to get z-scores and find observations that are very far from the mean for the variable. For grouped data, you perform this analysis separately for each group. Schematic box plots provide a way to detect outliers visually. In schematic box plots, the box is drawn over the interquartile range (IQR). Whiskers extend from the ends of box out to 1.5 IQR units, or the range of the data. Any points beyond the whiskers are plotted as outliers.",AM,1021,"['univariate', 'statistic', 'many', 'outlier', 'detection', 'tool', 'available', 'perhaps', 'already', 'use', 'tool', 'listed', 'regularly', 'addition', 'others', 'linear', 'model', 'often', 'useful', 'look', 'leverage', 'dffits', 'statistic', 'find', 'influential', 'outlier', 'set', 'predictor_variable', 'statistic', 'easy', 'obtain', 'reg', 'glm', 'procedure', 'evaluate', 'one', 'variable', 'time', 'outlier', 'statistical', 'graphical', 'tool', 'useful', 'example', 'standardize', 'variable', 'center', 'mean', 'scale', 'standard', 'deviation', 'get', 'zscores', 'find', 'observation', 'far', 'mean', 'variable', 'grouped', 'data', 'perform', 'analysis', 'separately', 'group', 'schematic', 'box', 'plot', 'provide', 'way', 'detect', 'outlier', 'visually', 'schematic', 'box', 'plot', 'box', 'drawn', 'interquartile', 'range', 'iqr', 'whisker', 'extend', 'end', 'box', '15', 'iqr', 'unit', 'range', 'data', 'point', 'beyond', 'whisker', 'plotted', 'outlier']"
231,"The first analysis you will perform uses PROC DISCRIM with the gamblegrp data you used earlier. The program ch4s2d1.sas is shown below. Notice that the PROP option in the PRIORS statement calculates prior probabilities from the proportion of observations in each group. proc discrim data = amul.gamblegrp list; class type; priors prop; var dsm1-dsm12; run; The output is shown below. The class level information shows the weights and the priors, which are equal to the proportion in each group. The DISCRIM Procedure",AM,516,"['first', 'analysis', 'perform', 'us', 'proc', 'discrim', 'gamblegrp', 'data', 'used', 'earlier', 'program', 'ch4s2d1sas', 'shown', 'notice', 'prop', 'option', 'prior', 'statement', 'calculates', 'prior', 'probability', 'proportion', 'observation', 'group', 'proc', 'discrim', 'data', '', 'amulgamblegrp', 'list', 'class', 'type', 'prior', 'prop', 'var', 'dsm1dsm12', 'run', 'output', 'shown', 'class', 'level', 'information', 'show', 'weight', 'prior', 'equal', 'proportion', 'group', 'discrim', 'procedure']"
232,"In the GLM procedure, you may have used LSMEANS and MEANS statements to generate pairwise tests of group differences for a model. However, there are many times when pairwise differences are not the tests of interest in an analysis. Particularly in multivariate analyses, testing every possible pair of groups on several dependent variables can be very inefficient. For example, you may only be interested in the difference between a control group and one of the treatments on one of your dependent measures. Or you may want to compare the average of a few different control groups to a treatment group. The CONTRAST statement enables you to test any linear combination of cell means. The ESTIMATE statement enables you to estimate any linear combination as well as conduct the test.",AM,782,"['glm', 'procedure', 'may', 'used', 'lsmeans', 'mean', 'statement', 'generate', 'pairwise', 'test', 'group', 'difference', 'model', 'however', 'many', 'time', 'pairwise', 'difference', 'test', 'interest', 'analysis', 'particularly', 'multivariate', 'analysis', 'testing', 'every', 'possible', 'pair', 'group', 'several', 'dependent', 'variable', 'inefficient', 'example', 'may', 'interested', 'difference', 'control', 'group', 'one', 'treatment', 'one', 'dependent', 'measure', 'may', 'want', 'compare', 'average', 'different', 'control', 'group', 'treatment', 'group', 'contrast', 'statement', 'enables', 'test', 'linear', 'combination', 'cell', 'mean', 'estimate', 'statement', 'enables', 'estimate', 'linear', 'combination', 'well', 'conduct', 'test']"
233,"For univariate statistics, there are many outlier detection tools available. Perhaps you already use the tools listed above regularly, in addition to others. In linear models, it is often useful to look at leverage and DFFITS statistics to find influential outliers on a set of predictor variables. These statistics are easy to obtain from the REG and GLM procedures. To evaluate one variable at a time for outliers, statistical and graphical tools can be useful. For example, you can standardize your variables (center them about the mean and scale them by the standard deviation) to get z-scores and find observations that are very far from the mean for the variable. For grouped data, you perform this analysis separately for each group. Schematic box plots provide a way to detect outliers visually. In schematic box plots, the box is drawn over the interquartile range (IQR). Whiskers extend from the ends of box out to 1.5 IQR units, or the range of the data. Any points beyond the whiskers are plotted as outliers.",AM,1021,"['univariate', 'statistic', 'many', 'outlier', 'detection', 'tool', 'available', 'perhaps', 'already', 'use', 'tool', 'listed', 'regularly', 'addition', 'others', 'linear', 'model', 'often', 'useful', 'look', 'leverage', 'dffits', 'statistic', 'find', 'influential', 'outlier', 'set', 'predictor_variable', 'statistic', 'easy', 'obtain', 'reg', 'glm', 'procedure', 'evaluate', 'one', 'variable', 'time', 'outlier', 'statistical', 'graphical', 'tool', 'useful', 'example', 'standardize', 'variable', 'center', 'mean', 'scale', 'standard', 'deviation', 'get', 'zscores', 'find', 'observation', 'far', 'mean', 'variable', 'grouped', 'data', 'perform', 'analysis', 'separately', 'group', 'schematic', 'box', 'plot', 'provide', 'way', 'detect', 'outlier', 'visually', 'schematic', 'box', 'plot', 'box', 'drawn', 'interquartile', 'range', 'iqr', 'whisker', 'extend', 'end', 'box', '15', 'iqr', 'unit', 'range', 'data', 'point', 'beyond', 'whisker', 'plotted', 'outlier']"
234,"Create a table of the cell means in your model. The ordering of the variables is determined by the order of the variables in the CLASS statement. The first independent variable represents the rows. The second represents the columns. Specify the contrast hypothesis in terms of the cell means, as shown below:",AM,308,"['create', 'table', 'cell', 'mean', 'model', 'ordering', 'variable', 'determined', 'order', 'variable', 'class', 'statement', 'first', 'independent', 'variable', 'represents', 'row', 'second', 'represents', 'column', 'specify', 'contrast', 'hypothesis', 'term', 'cell', 'mean', 'shown']"
235,"In order for the test statistics in MANOVA to follow the theorized distribution, certain assumptions should be met: *	Observations are randomly sampled from the population. *	Observations are independent of one another; in other words, one observation does not provide information about other observations. *	The set of dependent variables follows a multivariate normal distribution conditional on the independent variables. This implies univariate conditional normality for each DV separately, but univariate normality alone is not sufficient for the assumption of multivariate normality to be met. *	The within-group covariance matrices are equal across groups. This implies equal variances across groups for each DV, and it also implies that all pairwise correlations between the DVs are equal across groups. As with ANOVA, MANOVA test statistics are robust to violations of some, but not all, of these assumptions. The robustness of each test statistic varies (Bray and Maxwell 1985). As a result, there is not a single test statistic that is uniformly preferred in all situations.",AM,1085,"['order', 'test', 'statistic', 'manova', 'follow', 'theorized', 'distribution', 'certain', 'assumption', 'met', '\tobservations', 'randomly', 'sampled', 'population', '\tobservations', 'independent', 'one', 'another', 'word', 'one', 'observation', 'doe', 'provide', 'information', 'observation', '\tthe', 'set', 'dependent', 'variable', 'follows', 'multivariate', 'normal', 'distribution', 'conditional', 'independent', 'variable', 'implies', 'univariate', 'conditional', 'normality', 'dv', 'separately', 'univariate', 'normality', 'alone', 'sufficient', 'assumption', 'multivariate', 'normality', 'met', '\tthe', 'withingroup', 'covariance', 'matrix', 'equal', 'across', 'group', 'implies', 'equal', 'variance', 'across', 'group', 'dv', 'also', 'implies', 'pairwise', 'correlation', 'dvs', 'equal', 'across', 'group', 'anova', 'manova', 'test', 'statistic', 'robust', 'violation', 'assumption', 'robustness', 'test', 'statistic', 'varies', 'bray', 'maxwell', '1985', 'result', 'single', 'test', 'statistic', 'uniformly', 'preferred', 'situation']"
236,"The Pooled Within Canonical Structure table shows the correlations between the predictors and the discriminant functions after adjusting for group differences. In other words, the pooled within canonical structure shows the correlations among the canonical variates and the predictors within the groups. Examining the variables that correlate highly with the first discriminant function (dsm4, dsm8, dsm10, and dsm12) suggests that these variables are all consequences of gambling. Thus, it appears that variables that pertain to consequences of gambling are responsible for an important portion of the discrimination among the three groups. Examining the variables that correlate highly with the second discriminant function (dsm1, dsm2, dsm3, and dsm9) suggests that these variables involve thoughts about gambling. Thus, it appears that variables pertaining to thoughts about gambling are responsible for an important portion of the discrimination among the groups. Additionally, PROC CANDISC displays several tables of canonical coefficients. These coefficients are influenced by correlations among the variables and, in some cases, by the scale of the variables. For these reasons, the coefficients are problematic to interpret, and are thus not shown here. Class Means on Canonical Variables",AM,1297,"['pooled', 'within', 'canonical', 'structure', 'table', 'show', 'correlation', 'predictor', 'discriminant_function', 'adjusting', 'group', 'difference', 'word', 'pooled', 'within', 'canonical', 'structure', 'show', 'correlation', 'among', 'canonical', 'variate', 'predictor', 'within', 'group', 'examining', 'variable', 'correlate', 'highly', 'first', 'discriminant_function', 'dsm4', 'dsm8', 'dsm10', 'dsm12', 'suggests', 'variable', 'consequence', 'gambling', 'thus', 'appears', 'variable', 'pertain', 'consequence', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'three', 'group', 'examining', 'variable', 'correlate', 'highly', 'second', 'discriminant_function', 'dsm1', 'dsm2', 'dsm3', 'dsm9', 'suggests', 'variable', 'involve', 'thought', 'gambling', 'thus', 'appears', 'variable', 'pertaining', 'thought', 'gambling', 'responsible', 'important', 'portion', 'discrimination', 'among', 'group', 'additionally', 'proc', 'candisc', 'display', 'several', 'table', 'canonical', 'coefficient', 'coefficient', 'influenced', 'correlation', 'among', 'variable', 'case', 'scale', 'variable', 'reason', 'coefficient', 'problematic', 'interpret', 'thus', 'shown', 'class', 'mean', 'canonical', 'variable']"
237,"4.	You can also change the appearance of your object from the right-click menu. Take a moment to explore the options available to you with the right-click menu and the Graph Toolbar. By investigating the responses in the 3-D graph, you can see that changes in the two OC scales, ybocgain and nimhgain, are positively associated. It also seems that change in neither OC scale is associated with change in the depression scale, hdrsgain.",AM,435,"['4\tyou', 'also', 'change', 'appearance', 'object', 'rightclick', 'menu', 'take', 'moment', 'explore', 'option', 'available', 'rightclick', 'menu', 'graph', 'toolbar', 'investigating', 'response', '3d', 'graph', 'see', 'change', 'two', 'oc', 'scale', 'ybocgain', 'nimhgain', 'positively', 'associated', 'also', 'seems', 'change', 'neither', 'oc', 'scale', 'associated', 'change', 'depression', 'scale', 'hdrsgain']"
238,"When planning a study, give special consideration to the problem of restricted range. For example, you may be interested in studying the effects of an intervention on behavioral and attitudinal symptoms of depression. If you only study depressed patients, then at the start of your study, you may have restricted range (ceiling effects) on your baseline symptom measures. It may be helpful to specifically recruit participants who are not depressed for your study and increase the variation in baseline depression in the overall group. Another possible solution for restricted range would be to classify participants based on the small amount of variation you have in the data. For example, you might compare the career success of university faculty with less than a doctoral degree, one doctoral degree, and more than one doctoral degree (for example, Ph.D. and J.D.). Of course, in this situation, you may encounter problems with unequal group sizes.",AM,952,"['planning', 'study', 'give', 'special', 'consideration', 'problem', 'restricted', 'range', 'example', 'may', 'interested', 'studying', 'effect', 'intervention', 'behavioral', 'attitudinal', 'symptom', 'depression', 'study', 'depressed', 'patient', 'start', 'study', 'may', 'restricted', 'range', 'ceiling', 'effect', 'baseline', 'symptom', 'measure', 'may', 'helpful', 'specifically', 'recruit', 'participant', 'depressed', 'study', 'increase', 'variation', 'baseline', 'depression', 'overall', 'group', 'another', 'possible', 'solution', 'restricted', 'range', 'would', 'classify', 'participant', 'based', 'small', 'amount', 'variation', 'data', 'example', 'might', 'compare', 'career', 'success', 'university', 'faculty', 'le', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'example', 'phd', 'jd', 'course', 'situation', 'may', 'encounter', 'problem', 'unequal', 'group', 'size']"
239,"In the DISCRIM procedure, the POOL= option controls whether linear or quadratic discriminant analysis is performed. Is you specify POOL=YES (the default), DISCRIM performs linear discriminant analysis. POOL=NO requests quadratic discriminant analysis. You can also request a chi-square test of homogeneity of covariance matrices with the option POOL=TEST. The test for homogeneity of covariance matrices uses a chi-square statistic that assumes that the data are multivariate normal. The null hypothesis of the test is that the within-group covariance matrices are equal to the pooled covariance matrix. If you specify POOL=TEST, the default alpha for the test is 0.05. You can change this using the SLPOOL= option. If you reject the null hypothesis for this test, PROC DISCRIM automatically performs quadratic discriminant analysis. If the null hypothesis is not rejected, PROC DISCRIM performs linear discriminant analysis.",AM,925,"['discrim', 'procedure', 'pool', 'option', 'control', 'whether', 'linear', 'quadratic', 'discriminant_analysis', 'performed', 'specify', 'poolyes', 'default', 'discrim', 'performs', 'linear', 'discriminant_analysis', 'poolno', 'request', 'quadratic', 'discriminant_analysis', 'also', 'request', 'chisquare', 'test', 'homogeneity', 'covariance', 'matrix', 'option', 'pooltest', 'test', 'homogeneity', 'covariance', 'matrix', 'us', 'chisquare', 'statistic', 'assumes', 'data', 'multivariate', 'normal', 'null', 'hypothesis', 'test', 'withingroup', 'covariance', 'matrix', 'equal', 'pooled', 'covariance', 'matrix', 'specify', 'pooltest', 'default', 'alpha', 'test', '005', 'change', 'using', 'slpool', 'option', 'reject', 'null', 'hypothesis', 'test', 'proc', 'discrim', 'automatically', 'performs', 'quadratic', 'discriminant_analysis', 'null', 'hypothesis', 'rejected', 'proc', 'discrim', 'performs', 'linear', 'discriminant_analysis']"
240,"Related to the problem of restricted range is the problem of zero or near-zero group sizes. Many kinds of statistical estimates are unstable at small samples. Furthermore, dramatically unequal group sizes pose a problem for models such as MANOVA, which assume equal variances and covariances across groups.",AM,306,"['related', 'problem', 'restricted', 'range', 'problem', 'zero', 'nearzero', 'group', 'size', 'many', 'kind', 'statistical', 'estimate', 'unstable', 'small', 'sample', 'furthermore', 'dramatically', 'unequal', 'group', 'size', 'pose', 'problem', 'model', 'manova', 'assume', 'equal', 'variance', 'covariance', 'across', 'group']"
241,"You used PROC CANDISC to assess the extent to which the variables discriminate between the groups. If this is your primary research goal, then you are advised to use PROC CANDISC. However, if your primary goal is to assess and apply the discriminant functions to future data in the interest of predicting group membership, then you are advised to use the DISCRIM procedure. PROC DISCRIM can be used for canonical discriminant analysis as well as other applications. Although PROC DISCRIM is capable of a wider range of analyses, the output from PROC CANDISC is generally simpler than output from PROC DISCRIM.",AM,609,"['used', 'proc', 'candisc', 'ass', 'extent', 'variable', 'discriminate', 'group', 'primary', 'research', 'goal', 'advised', 'use', 'proc', 'candisc', 'however', 'primary', 'goal', 'ass', 'apply', 'discriminant_function', 'future', 'data', 'interest', 'predicting', 'group', 'membership', 'advised', 'use', 'discrim', 'procedure', 'proc', 'discrim', 'used', 'canonical', 'discriminant_analysis', 'well', 'application', 'although', 'proc', 'discrim', 'capable', 'wider', 'range', 'analysis', 'output', 'proc', 'candisc', 'generally', 'simpler', 'output', 'proc', 'discrim']"
242,"PROC CANDISC	calls the CANDISC procedure and specifies how the analysis is to be performed. CLASS	specifies the classification variable that you are trying to predict. VAR	specifies the set of continuous variables that you are using to discriminate among the groups specified by the CLASS variable. Selected option for the PROC CANDISC statement: OUT = data-set	creates an output data set that contains the original data and the canonical scores. OUTSTAT = data-set	creates a TYPE = CORR output SAS data set that contains various statistics including class-level statistics, correlations, canonical correlations, canonical structures, canonical coefficients, and means of canonical variates for each class. NOPRINT	suppresses display of output. NCAN = n	specifies the number of canonical variates to be computed. The value must be less than or equal to the maximum number of possible variates. The default is to compute all possible variates.",AM,942,"['proc', 'candisc\tcalls', 'candisc', 'procedure', 'specifies', 'analysis', 'performed', 'class\tspecifies', 'classification', 'variable', 'trying', 'predict', 'var\tspecifies', 'set', 'continuous', 'variable', 'using', 'discriminate', 'among', 'group', 'specified', 'class', 'variable', 'selected', 'option', 'proc', 'candisc', 'statement', '', 'dataset\tcreates', 'output', 'data_set', 'contains', 'original', 'data', 'canonical', 'score', 'outstat', '', 'dataset\tcreates', 'type', '', 'corr', 'output', 'sa', 'data_set', 'contains', 'various', 'statistic', 'including', 'classlevel', 'statistic', 'correlation', 'canonical', 'correlation', 'canonical', 'structure', 'canonical', 'coefficient', 'mean', 'canonical', 'variate', 'class', 'noprint\tsuppresses', 'display', 'output', 'ncan', '', 'n\tspecifies', 'number', 'canonical', 'variate', 'computed', 'value', 'must', 'le', 'equal', 'maximum', 'number', 'possible', 'variate', 'default', 'compute', 'possible', 'variate']"
243,"Univariate ANOVA as a method of interpreting multivariate effects often fails to produce the useful interpretation needed for data analysis. In this chapter, you will see ANOVA as a method of evaluating multivariate effects. Later you will learn to use canonical discriminant analysis to interpret multivariate group differences in a way that retains the multidimensional associations in the data. Multivariate Analysis of Variance",AM,431,"['univariate', 'anova', 'method', 'interpreting', 'multivariate', 'effect', 'often', 'fails', 'produce', 'useful', 'interpretation', 'needed', 'data', 'analysis', 'chapter', 'see', 'anova', 'method', 'evaluating', 'multivariate', 'effect', 'later', 'learn', 'use', 'canonical', 'discriminant_analysis', 'interpret', 'multivariate', 'group', 'difference', 'way', 'retains', 'multidimensional', 'association', 'data', 'multivariate', 'analysis', 'variance']"
244,"In the GLM procedure, you may have used LSMEANS and MEANS statements to generate pairwise tests of group differences for a model. However, there are many times when pairwise differences are not the tests of interest in an analysis. Particularly in multivariate analyses, testing every possible pair of groups on several dependent variables can be very inefficient. For example, you may only be interested in the difference between a control group and one of the treatments on one of your dependent measures. Or you may want to compare the average of a few different control groups to a treatment group. The CONTRAST statement enables you to test any linear combination of cell means. The ESTIMATE statement enables you to estimate any linear combination as well as conduct the test.",AM,782,"['glm', 'procedure', 'may', 'used', 'lsmeans', 'mean', 'statement', 'generate', 'pairwise', 'test', 'group', 'difference', 'model', 'however', 'many', 'time', 'pairwise', 'difference', 'test', 'interest', 'analysis', 'particularly', 'multivariate', 'analysis', 'testing', 'every', 'possible', 'pair', 'group', 'several', 'dependent', 'variable', 'inefficient', 'example', 'may', 'interested', 'difference', 'control', 'group', 'one', 'treatment', 'one', 'dependent', 'measure', 'may', 'want', 'compare', 'average', 'different', 'control', 'group', 'treatment', 'group', 'contrast', 'statement', 'enables', 'test', 'linear', 'combination', 'cell', 'mean', 'estimate', 'statement', 'enables', 'estimate', 'linear', 'combination', 'well', 'conduct', 'test']"
245,"When planning a study, give special consideration to the problem of restricted range. For example, you may be interested in studying the effects of an intervention on behavioral and attitudinal symptoms of depression. If you only study depressed patients, then at the start of your study, you may have restricted range (ceiling effects) on your baseline symptom measures. It may be helpful to specifically recruit participants who are not depressed for your study and increase the variation in baseline depression in the overall group. Another possible solution for restricted range would be to classify participants based on the small amount of variation you have in the data. For example, you might compare the career success of university faculty with less than a doctoral degree, one doctoral degree, and more than one doctoral degree (for example, Ph.D. and J.D.). Of course, in this situation, you may encounter problems with unequal group sizes.",AM,952,"['planning', 'study', 'give', 'special', 'consideration', 'problem', 'restricted', 'range', 'example', 'may', 'interested', 'studying', 'effect', 'intervention', 'behavioral', 'attitudinal', 'symptom', 'depression', 'study', 'depressed', 'patient', 'start', 'study', 'may', 'restricted', 'range', 'ceiling', 'effect', 'baseline', 'symptom', 'measure', 'may', 'helpful', 'specifically', 'recruit', 'participant', 'depressed', 'study', 'increase', 'variation', 'baseline', 'depression', 'overall', 'group', 'another', 'possible', 'solution', 'restricted', 'range', 'would', 'classify', 'participant', 'based', 'small', 'amount', 'variation', 'data', 'example', 'might', 'compare', 'career', 'success', 'university', 'faculty', 'le', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'one', 'doctoral', 'degree', 'example', 'phd', 'jd', 'course', 'situation', 'may', 'encounter', 'problem', 'unequal', 'group', 'size']"
246,"The pooled covariance matrix, Sp, was used. Information about Sp is displayed above. There were 12 (noncollinear) predictors; the covariance matrix Sp is rank 12. Pairwise Generalized Squared Distances Between Groups",AM,216,"['pooled', 'covariance', 'matrix', 'sp', 'wa', 'used', 'information', 'sp', 'displayed', '12', 'noncollinear', 'predictor', 'covariance', 'matrix', 'sp', 'rank', '12', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
247,"Multivariate analysis of variance (MANOVA) is an extension of the concepts and techniques of ANOVA to situations with multiple dependent variables. One-way MANOVA can be used to test for group differences on several dependent variables simultaneously. Factorial MANOVA can be used to identify main effects and interactions among factors on a set of dependent variables. Unlike ANOVA, MANOVA takes into account relationships among the dependent variables as well as the relationship between independent and dependent variables.",AM,526,"['multivariate', 'analysis', 'variance', 'manova', 'extension', 'concept', 'technique', 'anova', 'situation', 'multiple', 'dependent', 'variable', 'oneway', 'manova', 'used', 'test', 'group', 'difference', 'several', 'dependent', 'variable', 'simultaneously', 'factorial', 'manova', 'used', 'identify', 'main_effect', 'interaction', 'among', 'factor', 'set', 'dependent', 'variable', 'unlike', 'anova', 'manova', 'take', 'account', 'relationship', 'among', 'dependent', 'variable', 'well', 'relationship', 'independent', 'dependent', 'variable']"
248,"*	examining group differences on predictor variables *	forming linear discriminant functions useful for predicting groups *	assessing error rates in predictions *	saving out statistics to apply the functions to a new set of data *	assessing how well the functions discriminate on new data *	performing quadratic discriminant analysis *	performing nearest-neighbor type and nonparametric analyses similar to discriminant analysis. Details For parametric discriminant analysis (including canonical discriminant analysis, Fisher linear discriminant analysis and quadratic discriminant analysis), the DISCRIM procedure develops a classification criterion using a method of generalized squared distance. Accounting for prior probabilities, each observation is classified in the group to which it has the smallest generalized squared distance. The generalized squared distance from an observation x to a group t is",AM,908,"['\texamining', 'group', 'difference', 'predictor_variable', '\tforming', 'linear', 'discriminant_function', 'useful', 'predicting', 'group', '\tassessing', 'error', 'rate', 'prediction', '\tsaving', 'statistic', 'apply', 'function', 'new', 'set', 'data', '\tassessing', 'well', 'function', 'discriminate', 'new', 'data', '\tperforming', 'quadratic', 'discriminant_analysis', '\tperforming', 'nearestneighbor', 'type', 'nonparametric', 'analysis', 'similar', 'discriminant_analysis', 'detail', 'parametric', 'discriminant_analysis', 'including', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'quadratic', 'discriminant_analysis', 'discrim', 'procedure', 'develops', 'classification', 'criterion', 'using', 'method', 'generalized', 'squared', 'distance', 'accounting', 'prior', 'probability', 'observation', 'classified', 'group', 'ha', 'smallest', 'generalized', 'squared', 'distance', 'generalized', 'squared', 'distance', 'observation', 'x', 'group']"
249,"The Tofu Veg Delite does not appear to fit with the general pattern of the rest of the data. You also notice that the Frozen sandwiches are close to one another near the low end of Calories and Sodium. Principal Components and Outliers: SAS Code within the SAS/IML Workshop For more than three-dimensional space, the easiest way to spot outliers can be with a histogram of principal component scores. The program App_OutliersIML.iml is displayed below: libname amul 'C:\workshop\winsas\amul\data\';",AM,498,"['tofu', 'veg', 'delite', 'doe', 'appear', 'fit', 'general', 'pattern', 'rest', 'data', 'also', 'notice', 'frozen', 'sandwich', 'close', 'one', 'another', 'near', 'low', 'end', 'calorie', 'sodium', 'principal', 'component', 'outlier', 'sa', 'code', 'within', 'sasiml', 'workshop', 'threedimensional', 'space', 'easiest', 'way', 'spot', 'outlier', 'histogram', 'principal', 'component', 'score', 'program', 'appoutliersimliml', 'displayed', 'libname', 'amul', 'cworkshopwinsasamuldata']"
250,"Discriminant analysis differs from logistic regression or canonical correlation because it is easy to use the discriminant functions to make predictions of groups when group information is not available (validation, crossvalidation, and classification). In other words, you might think of discriminant analysis as a way of learning what variables predict membership in various groups. The discriminant functions allow you to make well-informed decisions based on information from a set of predictor variables. The methods demonstrated in this course assume that your predictor variables follow a multivariate normal distribution. Parametric discriminant analysis is robust to the MV normality assumption much the way MANOVA is, although the user should be aware that nonnormality (particularly high kurtosis) could lead to biased predictions in discriminant analysis (Hosmer and Lemeshow 1989). If you have nonnormal (particularly categorical) predictors, you may prefer a nonparametric method or logistic regression.",AM,1017,"['discriminant_analysis', 'differs', 'logistic_regression', 'canonical', 'correlation', 'easy', 'use', 'discriminant_function', 'make', 'prediction', 'group', 'group', 'information', 'available', 'validation', 'crossvalidation', 'classification', 'word', 'might', 'think', 'discriminant_analysis', 'way', 'learning', 'variable', 'predict', 'membership', 'various', 'group', 'discriminant_function', 'allow', 'make', 'wellinformed', 'decision', 'based', 'information', 'set', 'predictor_variable', 'method', 'demonstrated', 'course', 'assume', 'predictor_variable', 'follow', 'multivariate', 'normal', 'distribution', 'parametric', 'discriminant_analysis', 'robust', 'mv', 'normality', 'assumption', 'much', 'way', 'manova', 'although', 'user', 'aware', 'nonnormality', 'particularly', 'high', 'kurtosis', 'could', 'lead', 'biased', 'prediction', 'discriminant_analysis', 'hosmer', 'lemeshow', '1989', 'nonnormal', 'particularly', 'categorical', 'predictor', 'may', 'prefer', 'nonparametric', 'method', 'logistic_regression']"
251,"Presume you are investigating variables that are related to career success among university faculty (number of publications, years experience, type of university, salary, job satisfaction). For the most part, higher salaries are associated with a higher number of publications. However, a few participants in your study have relatively low salaries and a somewhat large number of publications. These participants, although not necessarily outliers on any one variable, are outliers on the combination of these two variables. When you are interested specifically in multivariate outliers, there are myriad options. Two methods that are emphasized here are scatter plots and principal components analysis. Scatter plots of two or three variables at a time can reveal multivariate outliers that you might have missed using univariate plots only. Three-way rotatable plots enable you to look at the relationships among three variables at a time. Sometimes, however, even three-way plots can fail to reveal multivariate outliers in greater than three-dimensional space. Sometimes it is simply inefficient to create so many two-and three-way plots. In such situations, principal components analysis can be valuable. Recall that principal components are linear combinations of variables that account for the most variance with the first component, the second most with the second component, and so on. By consolidating most of the variance into one or two variables and looking over histograms of the components, you can easily spot multivariate outliers in your data.",AM,1561,"['presume', 'investigating', 'variable', 'related', 'career', 'success', 'among', 'university', 'faculty', 'number', 'publication', 'year', 'experience', 'type', 'university', 'salary', 'job', 'satisfaction', 'part', 'higher', 'salary', 'associated', 'higher', 'number', 'publication', 'however', 'participant', 'study', 'relatively', 'low', 'salary', 'somewhat', 'large', 'number', 'publication', 'participant', 'although', 'necessarily', 'outlier', 'one', 'variable', 'outlier', 'combination', 'two', 'variable', 'interested', 'specifically', 'multivariate', 'outlier', 'myriad', 'option', 'two', 'method', 'emphasized', 'scatter', 'plot', 'principal', 'component', 'analysis', 'scatter', 'plot', 'two', 'three', 'variable', 'time', 'reveal', 'multivariate', 'outlier', 'might', 'missed', 'using', 'univariate', 'plot', 'threeway', 'rotatable', 'plot', 'enable', 'look', 'relationship', 'among', 'three', 'variable', 'time', 'sometimes', 'however', 'even', 'threeway', 'plot', 'fail', 'reveal', 'multivariate', 'outlier', 'greater', 'threedimensional', 'space', 'sometimes', 'simply', 'inefficient', 'create', 'many', 'twoand', 'threeway', 'plot', 'situation', 'principal', 'component', 'analysis', 'valuable', 'recall', 'principal', 'component', 'linear', 'combination', 'variable', 'account', 'variance', 'first', 'component', 'second', 'second', 'component', 'consolidating', 'variance', 'one', 'two', 'variable', 'looking', 'histogram', 'component', 'easily', 'spot', 'multivariate', 'outlier', 'data']"
252,"Discriminant analysis differs from logistic regression or canonical correlation because it is easy to use the discriminant functions to make predictions of groups when group information is not available (validation, crossvalidation, and classification). In other words, you might think of discriminant analysis as a way of learning what variables predict membership in various groups. The discriminant functions allow you to make well-informed decisions based on information from a set of predictor variables. The methods demonstrated in this course assume that your predictor variables follow a multivariate normal distribution. Parametric discriminant analysis is robust to the MV normality assumption much the way MANOVA is, although the user should be aware that nonnormality (particularly high kurtosis) could lead to biased predictions in discriminant analysis (Hosmer and Lemeshow 1989). If you have nonnormal (particularly categorical) predictors, you may prefer a nonparametric method or logistic regression.",AM,1017,"['discriminant_analysis', 'differs', 'logistic_regression', 'canonical', 'correlation', 'easy', 'use', 'discriminant_function', 'make', 'prediction', 'group', 'group', 'information', 'available', 'validation', 'crossvalidation', 'classification', 'word', 'might', 'think', 'discriminant_analysis', 'way', 'learning', 'variable', 'predict', 'membership', 'various', 'group', 'discriminant_function', 'allow', 'make', 'wellinformed', 'decision', 'based', 'information', 'set', 'predictor_variable', 'method', 'demonstrated', 'course', 'assume', 'predictor_variable', 'follow', 'multivariate', 'normal', 'distribution', 'parametric', 'discriminant_analysis', 'robust', 'mv', 'normality', 'assumption', 'much', 'way', 'manova', 'although', 'user', 'aware', 'nonnormality', 'particularly', 'high', 'kurtosis', 'could', 'lead', 'biased', 'prediction', 'discriminant_analysis', 'hosmer', 'lemeshow', '1989', 'nonnormal', 'particularly', 'categorical', 'predictor', 'may', 'prefer', 'nonparametric', 'method', 'logistic_regression']"
253,"CLASS	names the classification variables to be used in the model. If you specify a CLASS statement, it must appear before the MODEL statement. MODEL	names the dependent variables and independent effects. Variable names are separated by a space. Crossed independent effects are indicated with asterisks (*). The bar operator (|) can be used to simplify effect specification for large factorial models. In PROC GLM, you can specify only one MODEL statement. MANOVA	performs multivariate analysis of variance when multiple dependent variables are listed in the MODEL statement. When the MANOVA statement is specified before the first RUN statement, GLM uses a multivariate method of handling missing values. This means that if a case is missing any values for a variable specified in the model, the entire case is deleted from the analysis. Selected test option for the MANOVA statement: H = effects | INTERCEPT | _ALL_ specifies the effects in the model to use as hypothesis (H) matrices. The H= option displays the eigenvalues and eigenvectors associated with E-1H and the four multivariate test statistics. To use all the effects in the model, specify the _ALL_ option. Selected detail options for the MANOVA statement: MSTAT = EXACT|FAPPROX specifies the method of evaluating the multivariate test statistics. The default is MSTAT=FAPPROX, which specifies that the multivariate tests are evaluated using the usual approximations based on the F distribution. MSTAT=EXACT computes exact p-values for three of the four tests (Wilks' Lambda, the Hotelling-Lawley Trace, and Roy's Greatest Root) and an improved F-approximation for the fourth (Pillai's Trace). PRINTE	displays the error SSCP matrix, E. Also produces a table of partial correlations of the dependent variables given the independent variables when the residual matrix from the analysis is the E matrix. PRINTH	displays the hypothesis SSCP matrix H associated with each effect in the H= specification. Selected option for the MODEL statement: NOUNI	suppresses univariate ANOVA output.",AM,2044,"['class\tnames', 'classification', 'variable', 'used', 'model', 'specify', 'class', 'statement', 'must', 'appear', 'model_statement', 'model\tnames', 'dependent', 'variable', 'independent', 'effect', 'variable', 'name', 'separated', 'space', 'crossed', 'independent', 'effect', 'indicated', 'asterisk', '', 'bar', 'operator', '', 'used', 'simplify', 'effect', 'specification', 'large', 'factorial', 'model', 'proc', 'glm', 'specify', 'one', 'model_statement', 'manova\tperforms', 'multivariate', 'analysis', 'variance', 'multiple', 'dependent', 'variable', 'listed', 'model_statement', 'manova', 'statement', 'specified', 'first', 'run', 'statement', 'glm', 'us', 'multivariate', 'method', 'handling', 'missing', 'value', 'mean', 'case', 'missing', 'value', 'variable', 'specified', 'model', 'entire', 'case', 'deleted', 'analysis', 'selected', 'test', 'option', 'manova', 'statement', 'h', '', 'effect', '', 'intercept', '', 'specifies', 'effect', 'model', 'use', 'hypothesis', 'h', 'matrix', 'h', 'option', 'display', 'eigenvalue', 'eigenvectors', 'associated', 'e1h', 'four', 'multivariate', 'test', 'statistic', 'use', 'effect', 'model', 'specify', 'option', 'selected', 'detail', 'option', 'manova', 'statement', 'mstat', '', 'exactfapprox', 'specifies', 'method', 'evaluating', 'multivariate', 'test', 'statistic', 'default', 'mstatfapprox', 'specifies', 'multivariate', 'test', 'evaluated', 'using', 'usual', 'approximation', 'based', 'f', 'distribution', 'mstatexact', 'computes', 'exact', 'pvalues', 'three', 'four', 'test', 'wilks', 'lambda', 'hotellinglawley', 'trace', 'roys', 'greatest', 'root', 'improved', 'fapproximation', 'fourth', 'pillais', 'trace', 'printe\tdisplays', 'error', 'sscp', 'matrix', 'e', 'also', 'produce', 'table', 'partial', 'correlation', 'dependent', 'variable', 'given', 'independent', 'variable', 'residual', 'matrix', 'analysis', 'e', 'matrix', 'printh\tdisplays', 'hypothesis', 'sscp', 'matrix', 'h', 'associated', 'effect', 'h', 'specification', 'selected', 'option', 'model_statement', 'nouni\tsuppresses', 'univariate', 'anova', 'output']"
254,Scoring in PROC DISCRIM is as easy as validation. Specify a valid data set name in the TESTOUT= option to save scored (classified) observations to an output data set. Testing Discriminant Functions on a New Data Set,AM,215,"['scoring', 'proc', 'discrim', 'easy', 'validation', 'specify', 'valid', 'data_set', 'name', 'testout', 'option', 'save', 'scored', 'classified', 'observation', 'output', 'data_set', 'testing', 'discriminant_function', 'new', 'data_set']"
255,"NOTE: F Statistic for Roy's Greatest Root is an upper bound. NOTE: F Statistic for Wilks' Lambda is exact. The multivariate statistics test the null hypothesis that all the canonical correlations are simultaneously zero, which is the same as the hypothesis that there is no linear prediction of group membership from the predictor variables. You reject this null hypothesis. Adjusted Approximate Squared Canonical Canonical Standard Canonical Correlation Correlation Error Correlation",AM,484,"['note', 'f', 'statistic', 'roys', 'greatest', 'root', 'upper', 'bound', 'note', 'f', 'statistic', 'wilks', 'lambda', 'exact', 'multivariate', 'statistic', 'test', 'null', 'hypothesis', 'canonical', 'correlation', 'simultaneously', 'zero', 'hypothesis', 'linear', 'prediction', 'group', 'membership', 'predictor_variable', 'reject', 'null', 'hypothesis', 'adjusted', 'approximate', 'squared', 'canonical', 'canonical', 'standard', 'canonical', 'correlation', 'correlation', 'error', 'correlation']"
256,"Discriminant analysis differs from logistic regression or canonical correlation because it is easy to use the discriminant functions to make predictions of groups when group information is not available (validation, crossvalidation, and classification). In other words, you might think of discriminant analysis as a way of learning what variables predict membership in various groups. The discriminant functions allow you to make well-informed decisions based on information from a set of predictor variables. The methods demonstrated in this course assume that your predictor variables follow a multivariate normal distribution. Parametric discriminant analysis is robust to the MV normality assumption much the way MANOVA is, although the user should be aware that nonnormality (particularly high kurtosis) could lead to biased predictions in discriminant analysis (Hosmer and Lemeshow 1989). If you have nonnormal (particularly categorical) predictors, you may prefer a nonparametric method or logistic regression.",AM,1017,"['discriminant_analysis', 'differs', 'logistic_regression', 'canonical', 'correlation', 'easy', 'use', 'discriminant_function', 'make', 'prediction', 'group', 'group', 'information', 'available', 'validation', 'crossvalidation', 'classification', 'word', 'might', 'think', 'discriminant_analysis', 'way', 'learning', 'variable', 'predict', 'membership', 'various', 'group', 'discriminant_function', 'allow', 'make', 'wellinformed', 'decision', 'based', 'information', 'set', 'predictor_variable', 'method', 'demonstrated', 'course', 'assume', 'predictor_variable', 'follow', 'multivariate', 'normal', 'distribution', 'parametric', 'discriminant_analysis', 'robust', 'mv', 'normality', 'assumption', 'much', 'way', 'manova', 'although', 'user', 'aware', 'nonnormality', 'particularly', 'high', 'kurtosis', 'could', 'lead', 'biased', 'prediction', 'discriminant_analysis', 'hosmer', 'lemeshow', '1989', 'nonnormal', 'particularly', 'categorical', 'predictor', 'may', 'prefer', 'nonparametric', 'method', 'logistic_regression']"
257,"Many of the recommendations for restricted ranges apply to unequal group sizes. Careful planning is key to avoiding the problem of unequal group sizes. If you have enough small groups that are reasonably similar, you may be able to combine smaller groups and compare them to the larger group(s).",AM,295,"['many', 'recommendation', 'restricted', 'range', 'apply', 'unequal', 'group', 'size', 'careful', 'planning', 'key', 'avoiding', 'problem', 'unequal', 'group', 'size', 'enough', 'small', 'group', 'reasonably', 'similar', 'may', 'able', 'combine', 'smaller', 'group', 'compare', 'larger', 'group']"
258,"Consider the example you just saw. Because the same data that are being classified are also used to create the discriminant functions, the analysis capitalizes on chance. You saw a predicted error rate of 4% in the population. However, that assumes that the population is exactly like the sample you observed and has exactly the priors that you specified. Both of these conditions are unlikely to be met, and the first one is certainly unreasonable. It is very important to empirically validate the results of a discriminant analysis on new data before using the results of a discriminant analysis to predict group membership. To do this, use the first data set as the calibration data set, and use the second data set as the validation data set. ?	If a new data set is not available, you can perform crossvalidation of the data by using a one-observation holdout method that computes the discriminant function for each data point from all the remaining data with that observation left out.",AM,990,"['consider', 'example', 'saw', 'data', 'classified', 'also', 'used', 'create', 'discriminant_function', 'analysis', 'capitalizes', 'chance', 'saw', 'predicted', 'error', 'rate', '4', 'population', 'however', 'assumes', 'population', 'exactly', 'like', 'sample', 'observed', 'ha', 'exactly', 'prior', 'specified', 'condition', 'unlikely', 'met', 'first', 'one', 'certainly', 'unreasonable', 'important', 'empirically', 'validate', 'result', 'discriminant_analysis', 'new', 'data', 'using', 'result', 'discriminant_analysis', 'predict', 'group', 'membership', 'use', 'first', 'data_set', 'calibration', 'data_set', 'use', 'second', 'data_set', 'validation', 'data_set', '\tif', 'new', 'data_set', 'available', 'perform', 'crossvalidation', 'data', 'using', 'oneobservation', 'holdout', 'method', 'computes', 'discriminant_function', 'data', 'point', 'remaining', 'data', 'observation', 'left']"
259,"The first analysis you will perform uses PROC DISCRIM with the gamblegrp data you used earlier. The program ch4s2d1.sas is shown below. Notice that the PROP option in the PRIORS statement calculates prior probabilities from the proportion of observations in each group. proc discrim data = amul.gamblegrp list; class type; priors prop; var dsm1-dsm12; run; The output is shown below. The class level information shows the weights and the priors, which are equal to the proportion in each group. The DISCRIM Procedure",AM,516,"['first', 'analysis', 'perform', 'us', 'proc', 'discrim', 'gamblegrp', 'data', 'used', 'earlier', 'program', 'ch4s2d1sas', 'shown', 'notice', 'prop', 'option', 'prior', 'statement', 'calculates', 'prior', 'probability', 'proportion', 'observation', 'group', 'proc', 'discrim', 'data', '', 'amulgamblegrp', 'list', 'class', 'type', 'prior', 'prop', 'var', 'dsm1dsm12', 'run', 'output', 'shown', 'class', 'level', 'information', 'show', 'weight', 'prior', 'equal', 'proportion', 'group', 'discrim', 'procedure']"
260,"The first problem, accuracy of the data file, is a problem for essentially any statistical analysis. Investigate summary reports using the MEANS procedure and frequency tables using the FREQ procedure. Look for observations that are outside of the reasonable range for the variables. Drop duplicated observations in the data using the SORT procedure with the NODUPKEY option. You can also use PROC FORMAT to specify a formatted value for any values of your variable that are not in a specified range or on a specified list. This enables you to quickly and easily identify many of your incorrect data values. If you find problems, document them and try to learn what caused the problem. Correct any mis- keyed values, filter out duplicated observations, and so on. !	If you are interested in learning more about screening data files for accuracy, Cody?s Data Cleaning Techniques Using SAS Software by Ron Cody or the instructor-based course Data Cleaning Techniques are strongly recommended.",AM,990,"['first', 'problem', 'accuracy', 'data', 'file', 'problem', 'essentially', 'statistical', 'analysis', 'investigate', 'summary', 'report', 'using', 'mean', 'procedure', 'frequency', 'table', 'using', 'freq', 'procedure', 'look', 'observation', 'outside', 'reasonable', 'range', 'variable', 'drop', 'duplicated', 'observation', 'data', 'using', 'sort', 'procedure', 'nodupkey', 'option', 'also', 'use', 'proc', 'format', 'specify', 'formatted', 'value', 'value', 'variable', 'specified', 'range', 'specified', 'list', 'enables', 'quickly', 'easily', 'identify', 'many', 'incorrect', 'data', 'value', 'find', 'problem', 'document', 'try', 'learn', 'caused', 'problem', 'correct', 'mi', 'keyed', 'value', 'filter', 'duplicated', 'observation', '\tif', 'interested', 'learning', 'screening', 'data', 'file', 'accuracy', 'cody', 'data', 'cleaning', 'technique', 'using', 'sa', 'software', 'ron', 'cody', 'instructorbased', 'course', 'data', 'cleaning', 'technique', 'strongly', 'recommended']"
261,"The PROC DISCRIM statement has options that make validation on a test data set or crossvalidation within the same data easy: TESTDATA=	specifies a SAS data set to be used in validation. TESTLIST	lists the observations in the TESTDATA= data set, along with predicted group membership based on the prediction equations developed using the data specified with the DATA= option. TESTOUT=	specifies a SAS data set where the TESTDATA= data are scored. Scores include the original data, classification, and posterior probabilities for each observation. CROSSLIST	lists the observations in the DATA= data set, along with predicted group membership, by classifying each observation in the DATA= data set using a discriminant function computed from the other observations in the DATA= data set, excluding the observation being classified. CROSSVALIDATE	 specifies that crossvalidation of the input data set be performed. This is used when you do not have a second sample upon which to calibrate/test. TESTCLASS	this statement names the CLASS variable from the TESTDATA= data set to be used in the analysis. It is not required if the CLASS variable name in the TESTDATA= data set matches the CLASS variable name in the DATA= data set.",AM,1223,"['proc', 'discrim', 'statement', 'ha', 'option', 'make', 'validation', 'test', 'data_set', 'crossvalidation', 'within', 'data', 'easy', 'testdata\tspecifies', 'sa', 'data_set', 'used', 'validation', 'testlist\tlists', 'observation', 'testdata', 'data_set', 'along', 'predicted', 'group', 'membership', 'based', 'prediction', 'equation', 'developed', 'using', 'data', 'specified', 'data', 'option', 'testout\tspecifies', 'sa', 'data_set', 'testdata', 'data', 'scored', 'score', 'include', 'original', 'data', 'classification', 'posterior', 'probability', 'observation', 'crosslist\tlists', 'observation', 'data', 'data_set', 'along', 'predicted', 'group', 'membership', 'classifying', 'observation', 'data', 'data_set', 'using', 'discriminant_function', 'computed', 'observation', 'data', 'data_set', 'excluding', 'observation', 'classified', 'crossvalidate\t', 'specifies', 'crossvalidation', 'input', 'data_set', 'performed', 'used', 'second', 'sample', 'upon', 'calibratetest', 'testclass\tthis', 'statement', 'name', 'class', 'variable', 'testdata', 'data_set', 'used', 'analysis', 'required', 'class', 'variable', 'name', 'testdata', 'data_set', 'match', 'class', 'variable', 'name', 'data', 'data_set']"
262,"The sandwiches data set includes nutritional information about several brands and types of sandwiches sold at fast-food restaurants and in grocery store freezer sections. The data are simulated but based on real nutritional information about sandwiches. The variables for the sandwiches data set are described below: Calories	The number of calories in the sandwich from testing TFat		Grams of fat Protein	Grams of protein Carb		Grams of carbohydrate Fiber		Grams of fiber	 Sodium	Milligrams of sodium Brand		Brand name of the sandwich (A, B, ?, I) (Character variable) Name		Name of the sandwich (Character variable) Category	Type of sandwich (Tuna, Chicken, Ham,?) (Character variable) Weight	Weight in ounces FatCal	Number of calories from fat CarbCal	Number of calories from carbohydrate ProCal	Number of calories from protein CalSum	Sum of FatCal, CarbCal, and ProCal ? to evaluate accuracy of the Calories measurement. You will perform analyses on some but not necessarily all of the variables in the data set. You may want to explore further with the data on your own to practice the methods demonstrated in this course. Outlier Analysis and Data Screening Using SAS/IML Workshop 2.1 You can use the SAS/IML Workshop to perform interactive graphical analysis of your data. In addition to graphical capabilities, you can use IML (Interactive Matrix Language) for customized analyses, and you can run SAS programs and view SAS output within the code editor in the SAS/IML Workshop. 1.	Open SAS/IML Workshop by selecting Start => Programs => IML Workshop 2.1. You see the SAS/IML workspace:",AM,1593,"['sandwich', 'data_set', 'includes', 'nutritional', 'information', 'several', 'brand', 'type', 'sandwich', 'sold', 'fastfood', 'restaurant', 'grocery', 'store', 'freezer', 'section', 'data', 'simulated', 'based', 'real', 'nutritional', 'information', 'sandwich', 'variable', 'sandwich', 'data_set', 'described', 'calories\tthe', 'number', 'calorie', 'sandwich', 'testing', 'tfat\t\tgrams', 'fat', 'protein\tgrams', 'protein', 'carb\t\tgrams', 'carbohydrate', 'fiber\t\tgrams', 'fiber\t', 'sodium\tmilligrams', 'sodium', 'brand\t\tbrand', 'name', 'sandwich', 'b', '', 'character', 'variable', 'name\t\tname', 'sandwich', 'character', 'variable', 'category\ttype', 'sandwich', 'tuna', 'chicken', 'ham', 'character', 'variable', 'weight\tweight', 'ounce', 'fatcal\tnumber', 'calorie', 'fat', 'carbcal\tnumber', 'calorie', 'carbohydrate', 'procal\tnumber', 'calorie', 'protein', 'calsum\tsum', 'fatcal', 'carbcal', 'procal', '', 'evaluate', 'accuracy', 'calorie', 'measurement', 'perform', 'analysis', 'necessarily', 'variable', 'data_set', 'may', 'want', 'explore', 'data', 'practice', 'method', 'demonstrated', 'course', 'outlier', 'analysis', 'data', 'screening', 'using', 'sasiml', 'workshop', '21', 'use', 'sasiml', 'workshop', 'perform', 'interactive', 'graphical', 'analysis', 'data', 'addition', 'graphical', 'capability', 'use', 'iml', 'interactive', 'matrix', 'language', 'customized', 'analysis', 'run', 'sa', 'program', 'view', 'sa', 'output', 'within', 'code', 'editor', 'sasiml', 'workshop', '1\topen', 'sasiml', 'workshop', 'selecting', 'start', '', 'program', '', 'iml', 'workshop', '21', 'see', 'sasiml', 'workspace']"
263,"To understand exactly how canonical discriminant analysis is performed, consider the model for one-way MANOVA. The goal for MANOVA is to test for equality of the mean vector across class levels. In canonical discriminant analyses, you find linear combinations of the quantitative variables that provide maximal separation between the groups. This is done by deriving canonical variates.",AM,386,"['understand', 'exactly', 'canonical', 'discriminant_analysis', 'performed', 'consider', 'model', 'oneway', 'manova', 'goal', 'manova', 'test', 'equality', 'mean', 'vector', 'across', 'class', 'level', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'quantitative', 'variable', 'provide', 'maximal', 'separation', 'group', 'done', 'deriving', 'canonical', 'variate']"
264,"*	examining group differences on predictor variables *	forming linear discriminant functions useful for predicting groups *	assessing error rates in predictions *	saving out statistics to apply the functions to a new set of data *	assessing how well the functions discriminate on new data *	performing quadratic discriminant analysis *	performing nearest-neighbor type and nonparametric analyses similar to discriminant analysis. Details For parametric discriminant analysis (including canonical discriminant analysis, Fisher linear discriminant analysis and quadratic discriminant analysis), the DISCRIM procedure develops a classification criterion using a method of generalized squared distance. Accounting for prior probabilities, each observation is classified in the group to which it has the smallest generalized squared distance. The generalized squared distance from an observation x to a group t is",AM,908,"['\texamining', 'group', 'difference', 'predictor_variable', '\tforming', 'linear', 'discriminant_function', 'useful', 'predicting', 'group', '\tassessing', 'error', 'rate', 'prediction', '\tsaving', 'statistic', 'apply', 'function', 'new', 'set', 'data', '\tassessing', 'well', 'function', 'discriminate', 'new', 'data', '\tperforming', 'quadratic', 'discriminant_analysis', '\tperforming', 'nearestneighbor', 'type', 'nonparametric', 'analysis', 'similar', 'discriminant_analysis', 'detail', 'parametric', 'discriminant_analysis', 'including', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'quadratic', 'discriminant_analysis', 'discrim', 'procedure', 'develops', 'classification', 'criterion', 'using', 'method', 'generalized', 'squared', 'distance', 'accounting', 'prior', 'probability', 'observation', 'classified', 'group', 'ha', 'smallest', 'generalized', 'squared', 'distance', 'generalized', 'squared', 'distance', 'observation', 'x', 'group']"
265,"You used PROC CANDISC to assess the extent to which the variables discriminate between the groups. If this is your primary research goal, then you are advised to use PROC CANDISC. However, if your primary goal is to assess and apply the discriminant functions to future data in the interest of predicting group membership, then you are advised to use the DISCRIM procedure. PROC DISCRIM can be used for canonical discriminant analysis as well as other applications. Although PROC DISCRIM is capable of a wider range of analyses, the output from PROC CANDISC is generally simpler than output from PROC DISCRIM.",AM,609,"['used', 'proc', 'candisc', 'ass', 'extent', 'variable', 'discriminate', 'group', 'primary', 'research', 'goal', 'advised', 'use', 'proc', 'candisc', 'however', 'primary', 'goal', 'ass', 'apply', 'discriminant_function', 'future', 'data', 'interest', 'predicting', 'group', 'membership', 'advised', 'use', 'discrim', 'procedure', 'proc', 'discrim', 'used', 'canonical', 'discriminant_analysis', 'well', 'application', 'although', 'proc', 'discrim', 'capable', 'wider', 'range', 'analysis', 'output', 'proc', 'candisc', 'generally', 'simpler', 'output', 'proc', 'discrim']"
266,"Researchers want to determine whether a questionnaire measurement can adequately classify people identified as binge gamblers, steady gamblers, and nongamblers. A 12-item questionnaire based on DSM-IV diagnostic criteria for pathological gambling was administered to 100 people divided into the three groups. The variable type is a class variable that identifies each observation as *	Binge *	Steady *	Control. Canonical Discriminant Analysis",AM,442,"['researcher', 'want', 'determine', 'whether', 'questionnaire', 'measurement', 'adequately', 'classify', 'people', 'identified', 'binge', 'gambler', 'steady', 'gambler', 'nongamblers', '12item', 'questionnaire', 'based', 'dsmiv', 'diagnostic', 'criterion', 'pathological', 'gambling', 'wa', 'administered', '100', 'people', 'divided', 'three', 'group', 'variable', 'type', 'class', 'variable', 'identifies', 'observation', '\tbinge', '\tsteady', '\tcontrol', 'canonical', 'discriminant_analysis']"
267,"Multivariate analysis of variance (MANOVA) is an extension of the concepts and techniques of ANOVA to situations with multiple dependent variables. One-way MANOVA can be used to test for group differences on several dependent variables simultaneously. Factorial MANOVA can be used to identify main effects and interactions among factors on a set of dependent variables. Unlike ANOVA, MANOVA takes into account relationships among the dependent variables as well as the relationship between independent and dependent variables.",AM,526,"['multivariate', 'analysis', 'variance', 'manova', 'extension', 'concept', 'technique', 'anova', 'situation', 'multiple', 'dependent', 'variable', 'oneway', 'manova', 'used', 'test', 'group', 'difference', 'several', 'dependent', 'variable', 'simultaneously', 'factorial', 'manova', 'used', 'identify', 'main_effect', 'interaction', 'among', 'factor', 'set', 'dependent', 'variable', 'unlike', 'anova', 'manova', 'take', 'account', 'relationship', 'among', 'dependent', 'variable', 'well', 'relationship', 'independent', 'dependent', 'variable']"
268,"The sandwiches data set includes nutritional information about several brands and types of sandwiches sold at fast-food restaurants and in grocery store freezer sections. The data are simulated but based on real nutritional information about sandwiches. The variables for the sandwiches data set are described below: Calories	The number of calories in the sandwich from testing TFat		Grams of fat Protein	Grams of protein Carb		Grams of carbohydrate Fiber		Grams of fiber	 Sodium	Milligrams of sodium Brand		Brand name of the sandwich (A, B, ?, I) (Character variable) Name		Name of the sandwich (Character variable) Category	Type of sandwich (Tuna, Chicken, Ham,?) (Character variable) Weight	Weight in ounces FatCal	Number of calories from fat CarbCal	Number of calories from carbohydrate ProCal	Number of calories from protein CalSum	Sum of FatCal, CarbCal, and ProCal ? to evaluate accuracy of the Calories measurement. You will perform analyses on some but not necessarily all of the variables in the data set. You may want to explore further with the data on your own to practice the methods demonstrated in this course. Outlier Analysis and Data Screening Using SAS/IML Workshop 2.1 You can use the SAS/IML Workshop to perform interactive graphical analysis of your data. In addition to graphical capabilities, you can use IML (Interactive Matrix Language) for customized analyses, and you can run SAS programs and view SAS output within the code editor in the SAS/IML Workshop. 1.	Open SAS/IML Workshop by selecting Start => Programs => IML Workshop 2.1. You see the SAS/IML workspace:",AM,1593,"['sandwich', 'data_set', 'includes', 'nutritional', 'information', 'several', 'brand', 'type', 'sandwich', 'sold', 'fastfood', 'restaurant', 'grocery', 'store', 'freezer', 'section', 'data', 'simulated', 'based', 'real', 'nutritional', 'information', 'sandwich', 'variable', 'sandwich', 'data_set', 'described', 'calories\tthe', 'number', 'calorie', 'sandwich', 'testing', 'tfat\t\tgrams', 'fat', 'protein\tgrams', 'protein', 'carb\t\tgrams', 'carbohydrate', 'fiber\t\tgrams', 'fiber\t', 'sodium\tmilligrams', 'sodium', 'brand\t\tbrand', 'name', 'sandwich', 'b', '', 'character', 'variable', 'name\t\tname', 'sandwich', 'character', 'variable', 'category\ttype', 'sandwich', 'tuna', 'chicken', 'ham', 'character', 'variable', 'weight\tweight', 'ounce', 'fatcal\tnumber', 'calorie', 'fat', 'carbcal\tnumber', 'calorie', 'carbohydrate', 'procal\tnumber', 'calorie', 'protein', 'calsum\tsum', 'fatcal', 'carbcal', 'procal', '', 'evaluate', 'accuracy', 'calorie', 'measurement', 'perform', 'analysis', 'necessarily', 'variable', 'data_set', 'may', 'want', 'explore', 'data', 'practice', 'method', 'demonstrated', 'course', 'outlier', 'analysis', 'data', 'screening', 'using', 'sasiml', 'workshop', '21', 'use', 'sasiml', 'workshop', 'perform', 'interactive', 'graphical', 'analysis', 'data', 'addition', 'graphical', 'capability', 'use', 'iml', 'interactive', 'matrix', 'language', 'customized', 'analysis', 'run', 'sa', 'program', 'view', 'sa', 'output', 'within', 'code', 'editor', 'sasiml', 'workshop', '1\topen', 'sasiml', 'workshop', 'selecting', 'start', '', 'program', '', 'iml', 'workshop', '21', 'see', 'sasiml', 'workspace']"
269,"When there are multiple dependent measures for a factorial design, multivariate analysis of variance (MANOVA) can be a very useful tool in determining whether groups differ on a set of measures. Sometimes you are interested in specific comparisons between pairs of groups, between one group and a combination of groups, or perhaps other comparisons. Contrasts in the GLM procedure enable you to test custom hypotheses about your population. After you learn to fit multivariate models using SAS, you learn to apply other multivariate methods using SAS such as factor analysis, structural equation models, and discriminant function analysis.",AM,639,"['multiple', 'dependent', 'measure', 'factorial', 'design', 'multivariate', 'analysis', 'variance', 'manova', 'useful', 'tool', 'determining', 'whether', 'group', 'differ', 'set', 'measure', 'sometimes', 'interested', 'specific', 'comparison', 'pair', 'group', 'one', 'group', 'combination', 'group', 'perhaps', 'comparison', 'contrast', 'glm', 'procedure', 'enable', 'test', 'custom', 'hypothesis', 'population', 'learn', 'fit', 'multivariate', 'model', 'using', 'sa', 'learn', 'apply', 'multivariate', 'method', 'using', 'sa', 'factor', 'analysis', 'structural', 'equation', 'model', 'discriminant_function', 'analysis']"
270,?	You can also rotate without using the Graph Toolbar by holding down the Alt key on your keyboard and the left mouse button. Move the cursor over the picture to rotate it while holding these two buttons.,AM,204,"['\tyou', 'also', 'rotate', 'without', 'using', 'graph', 'toolbar', 'holding', 'alt', 'key', 'keyboard', 'left', 'mouse', 'button', 'move', 'cursor', 'picture', 'rotate', 'holding', 'two', 'button']"
271,"Presume you are investigating variables that are related to career success among university faculty (number of publications, years experience, type of university, salary, job satisfaction). For the most part, higher salaries are associated with a higher number of publications. However, a few participants in your study have relatively low salaries and a somewhat large number of publications. These participants, although not necessarily outliers on any one variable, are outliers on the combination of these two variables. When you are interested specifically in multivariate outliers, there are myriad options. Two methods that are emphasized here are scatter plots and principal components analysis. Scatter plots of two or three variables at a time can reveal multivariate outliers that you might have missed using univariate plots only. Three-way rotatable plots enable you to look at the relationships among three variables at a time. Sometimes, however, even three-way plots can fail to reveal multivariate outliers in greater than three-dimensional space. Sometimes it is simply inefficient to create so many two-and three-way plots. In such situations, principal components analysis can be valuable. Recall that principal components are linear combinations of variables that account for the most variance with the first component, the second most with the second component, and so on. By consolidating most of the variance into one or two variables and looking over histograms of the components, you can easily spot multivariate outliers in your data.",AM,1561,"['presume', 'investigating', 'variable', 'related', 'career', 'success', 'among', 'university', 'faculty', 'number', 'publication', 'year', 'experience', 'type', 'university', 'salary', 'job', 'satisfaction', 'part', 'higher', 'salary', 'associated', 'higher', 'number', 'publication', 'however', 'participant', 'study', 'relatively', 'low', 'salary', 'somewhat', 'large', 'number', 'publication', 'participant', 'although', 'necessarily', 'outlier', 'one', 'variable', 'outlier', 'combination', 'two', 'variable', 'interested', 'specifically', 'multivariate', 'outlier', 'myriad', 'option', 'two', 'method', 'emphasized', 'scatter', 'plot', 'principal', 'component', 'analysis', 'scatter', 'plot', 'two', 'three', 'variable', 'time', 'reveal', 'multivariate', 'outlier', 'might', 'missed', 'using', 'univariate', 'plot', 'threeway', 'rotatable', 'plot', 'enable', 'look', 'relationship', 'among', 'three', 'variable', 'time', 'sometimes', 'however', 'even', 'threeway', 'plot', 'fail', 'reveal', 'multivariate', 'outlier', 'greater', 'threedimensional', 'space', 'sometimes', 'simply', 'inefficient', 'create', 'many', 'twoand', 'threeway', 'plot', 'situation', 'principal', 'component', 'analysis', 'valuable', 'recall', 'principal', 'component', 'linear', 'combination', 'variable', 'account', 'variance', 'first', 'component', 'second', 'second', 'component', 'consolidating', 'variance', 'one', 'two', 'variable', 'looking', 'histogram', 'component', 'easily', 'spot', 'multivariate', 'outlier', 'data']"
272,"Sometimes you have a significant multivariate effect and no significant univariate effects. Sometime just the opposite occurs?nonsignificant multivariate effects and significant univariate effects. There are several reasons that this may occur, among them type-I error, type-II error, multivariate outliers, and collinearity among the responses. You can use univariate ANOVA to try to interpret your MV effects. By default, the univariate ANOVA for each response is shown. You can suppress the default univariate ANOVA output with the NOUNI option in the MODEL statement. You can obtain an abbreviated summary of the univariate ANOVAs by including the SUMMARY option in MANOVA statement. Later, you will learn to use discriminant analysis, which allows you a multivariate method for interpreting group differences that is often preferable to univariate ANOVA.",AM,859,"['sometimes', 'significant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'sometime', 'opposite', 'occursnonsignificant', 'multivariate', 'effect', 'significant', 'univariate', 'effect', 'several', 'reason', 'may', 'occur', 'among', 'typei', 'error', 'typeii', 'error', 'multivariate', 'outlier', 'collinearity', 'among', 'response', 'use', 'univariate', 'anova', 'try', 'interpret', 'mv', 'effect', 'default', 'univariate', 'anova', 'response', 'shown', 'suppress', 'default', 'univariate', 'anova', 'output', 'nouni', 'option', 'model_statement', 'obtain', 'abbreviated', 'summary', 'univariate', 'anova', 'including', 'summary', 'option', 'manova', 'statement', 'later', 'learn', 'use', 'discriminant_analysis', 'allows', 'multivariate', 'method', 'interpreting', 'group', 'difference', 'often', 'preferable', 'univariate', 'anova']"
273,"Repeat this to create plots of Carb*Calories, Carb*TFat and Carb* Protein. Select outliers on each plot and find the corresponding observations on the other plots.",AM,163,"['repeat', 'create', 'plot', 'carbcalories', 'carbtfat', 'carb', 'protein', 'select', 'outlier', 'plot', 'find', 'corresponding', 'observation', 'plot']"
274,"It is easy to see the pattern of how the groups fall on the discriminant functions. As you saw before, the first function distinguishes between Steady and Binge gamblers, while the second function discriminates between Controls and Steady gamblers.",AM,248,"['easy', 'see', 'pattern', 'group', 'fall', 'discriminant_function', 'saw', 'first', 'function', 'distinguishes', 'steady', 'binge', 'gambler', 'second', 'function', 'discriminates', 'control', 'steady', 'gambler']"
275,"You can see that the Fried Platter, Tuna Sub, and several others are bivariate outliers on more than one plot. Continue to explore the plots. You can change the colors of specific observations. For example, you may want to identify all the Frozen sandwiches on your plot. You can label the Frozen sandwiches with a special color to make them easier to find on the plots. 3.	In the data table, highlight the rows that are Frozen sandwiches by clicking on the row header and dragging the selection. Partial Display",AM,512,"['see', 'fried', 'platter', 'tuna', 'sub', 'several', 'others', 'bivariate', 'outlier', 'one', 'plot', 'continue', 'explore', 'plot', 'change', 'color', 'specific', 'observation', 'example', 'may', 'want', 'identify', 'frozen', 'sandwich', 'plot', 'label', 'frozen', 'sandwich', 'special', 'color', 'make', 'easier', 'find', 'plot', '3\tin', 'data', 'table', 'highlight', 'row', 'frozen', 'sandwich', 'clicking', 'row', 'header', 'dragging', 'selection', 'partial', 'display']"
276,"Discriminant analysis differs from logistic regression or canonical correlation because it is easy to use the discriminant functions to make predictions of groups when group information is not available (validation, crossvalidation, and classification). In other words, you might think of discriminant analysis as a way of learning what variables predict membership in various groups. The discriminant functions allow you to make well-informed decisions based on information from a set of predictor variables. The methods demonstrated in this course assume that your predictor variables follow a multivariate normal distribution. Parametric discriminant analysis is robust to the MV normality assumption much the way MANOVA is, although the user should be aware that nonnormality (particularly high kurtosis) could lead to biased predictions in discriminant analysis (Hosmer and Lemeshow 1989). If you have nonnormal (particularly categorical) predictors, you may prefer a nonparametric method or logistic regression.",AM,1017,"['discriminant_analysis', 'differs', 'logistic_regression', 'canonical', 'correlation', 'easy', 'use', 'discriminant_function', 'make', 'prediction', 'group', 'group', 'information', 'available', 'validation', 'crossvalidation', 'classification', 'word', 'might', 'think', 'discriminant_analysis', 'way', 'learning', 'variable', 'predict', 'membership', 'various', 'group', 'discriminant_function', 'allow', 'make', 'wellinformed', 'decision', 'based', 'information', 'set', 'predictor_variable', 'method', 'demonstrated', 'course', 'assume', 'predictor_variable', 'follow', 'multivariate', 'normal', 'distribution', 'parametric', 'discriminant_analysis', 'robust', 'mv', 'normality', 'assumption', 'much', 'way', 'manova', 'although', 'user', 'aware', 'nonnormality', 'particularly', 'high', 'kurtosis', 'could', 'lead', 'biased', 'prediction', 'discriminant_analysis', 'hosmer', 'lemeshow', '1989', 'nonnormal', 'particularly', 'categorical', 'predictor', 'may', 'prefer', 'nonparametric', 'method', 'logistic_regression']"
277,"Throughout this course, you have learned to use SAS to perform a variety of multivariate statistical analyses. It is important to understand how the analyses work, what the assumptions are, and how to interpret the results of the analyses. It is equally important to know how to evaluate the assumptions of the analyses and determine whether your data are appropriate for the kind of analysis you plan to perform. Real data is almost never as simple and straightforward as classroom data, so this chapter is devoted to helping you prepare your data for multivariate analysis.",AM,575,"['throughout', 'course', 'learned', 'use', 'sa', 'perform', 'variety', 'multivariate', 'statistical', 'analysis', 'important', 'understand', 'analysis', 'work', 'assumption', 'interpret', 'result', 'analysis', 'equally', 'important', 'know', 'evaluate', 'assumption', 'analysis', 'determine', 'whether', 'data', 'appropriate', 'kind', 'analysis', 'plan', 'perform', 'real', 'data', 'almost', 'never', 'simple', 'straightforward', 'classroom', 'data', 'chapter', 'devoted', 'helping', 'prepare', 'data', 'multivariate', 'analysis']"
278,"4.	You can also change the appearance of your object from the right-click menu. Take a moment to explore the options available to you with the right-click menu and the Graph Toolbar. By investigating the responses in the 3-D graph, you can see that changes in the two OC scales, ybocgain and nimhgain, are positively associated. It also seems that change in neither OC scale is associated with change in the depression scale, hdrsgain.",AM,435,"['4\tyou', 'also', 'change', 'appearance', 'object', 'rightclick', 'menu', 'take', 'moment', 'explore', 'option', 'available', 'rightclick', 'menu', 'graph', 'toolbar', 'investigating', 'response', '3d', 'graph', 'see', 'change', 'two', 'oc', 'scale', 'ybocgain', 'nimhgain', 'positively', 'associated', 'also', 'seems', 'change', 'neither', 'oc', 'scale', 'associated', 'change', 'depression', 'scale', 'hdrsgain']"
279,"The CLASS and VAR statements serve the same purpose as they do in PROC CANDISC. Selection options for the PROC DISCRIM statement: LIST	classifies observations into groups based on the discriminant functions. ANOVA	performs univariate ANOVAs to see whether the groups differ significantly on each predictor variable. It can be useful in eliminating irrelevant variables from the analysis. CAN	specifies that canonical discriminant analysis be performed. To achieve the same analysis as the one you saw in PROC CANDISC, specify proportional priors in the PRIORS statement. ?	See Appendix C for an example of how to perform canonical discriminant analysis using PROC DISCRIM. The PRIORS statement is discussed on the next page.",AM,724,"['class', 'var', 'statement', 'serve', 'purpose', 'proc', 'candisc', 'selection', 'option', 'proc', 'discrim', 'statement', 'list\tclassifies', 'observation', 'group', 'based', 'discriminant_function', 'anova\tperforms', 'univariate', 'anova', 'see', 'whether', 'group', 'differ', 'significantly', 'predictor_variable', 'useful', 'eliminating', 'irrelevant', 'variable', 'analysis', 'can\tspecifies', 'canonical', 'discriminant_analysis', 'performed', 'achieve', 'analysis', 'one', 'saw', 'proc', 'candisc', 'specify', 'proportional', 'prior', 'prior', 'statement', '\tsee', 'appendix', 'c', 'example', 'perform', 'canonical', 'discriminant_analysis', 'using', 'proc', 'discrim', 'prior', 'statement', 'discussed', 'next', 'page']"
280,"There are two procedures in SAS that can be used to perform canonical discriminant analysis: the DISCRIM procedure and the CANDISC procedure. PROC DISCRIM is more general than PROC CANDISC and can be used to perform both steps of discriminant analysis shown above. PROC CANDISC performs the first step only. However, PROC CANDISC produces output that is generally more familiar to users and may be easier to interpret. If you are simply trying to find the combinations of variables that predict group membership, it is simpler to use PROC CANDISC. ?	You will learn to use PROC DISCRIM later in the chapter.",AM,606,"['two', 'procedure', 'sa', 'used', 'perform', 'canonical', 'discriminant_analysis', 'discrim', 'procedure', 'candisc', 'procedure', 'proc', 'discrim', 'general', 'proc', 'candisc', 'used', 'perform', 'step', 'discriminant_analysis', 'shown', 'proc', 'candisc', 'performs', 'first', 'step', 'however', 'proc', 'candisc', 'produce', 'output', 'generally', 'familiar', 'user', 'may', 'easier', 'interpret', 'simply', 'trying', 'find', 'combination', 'variable', 'predict', 'group', 'membership', 'simpler', 'use', 'proc', 'candisc', '\tyou', 'learn', 'use', 'proc', 'discrim', 'later', 'chapter']"
281,"Researchers want to determine whether a questionnaire measurement can adequately classify people identified as binge gamblers, steady gamblers, and nongamblers. A 12-item questionnaire based on DSM-IV diagnostic criteria for pathological gambling was administered to 100 people divided into the three groups. The variable type is a class variable that identifies each observation as *	Binge *	Steady *	Control. Canonical Discriminant Analysis",AM,442,"['researcher', 'want', 'determine', 'whether', 'questionnaire', 'measurement', 'adequately', 'classify', 'people', 'identified', 'binge', 'gambler', 'steady', 'gambler', 'nongamblers', '12item', 'questionnaire', 'based', 'dsmiv', 'diagnostic', 'criterion', 'pathological', 'gambling', 'wa', 'administered', '100', 'people', 'divided', 'three', 'group', 'variable', 'type', 'class', 'variable', 'identifies', 'observation', '\tbinge', '\tsteady', '\tcontrol', 'canonical', 'discriminant_analysis']"
282,"Some of the bivariate outliers you saw earlier are also outliers on the PRIN variables. !	For more than two PCs at a time, you could create a three-way rotating scatter plot of several principal component variables. Feel free to try this plot on your own! After looking over the output for outlier analysis, you decide that you have four observations that are outliers. You choose to continue with your screening and data preparation with the complete set of data. Restricted Range and Group Size Use the data set sandwiches to investigate variables for restricted range and unequal group sizes. You selected Weight because you are concerned that there is not enough variation in the weight of sandwiches. You selected Category because you were concerned that there may be types of sandwiches that are underrepresented in the data. 1.	Select the sandwiches data set from the Window menu. 2.	Create a histogram for the Weight variable by selecting Plots => Create Histogram => Weight => Set X. The histogram for Weight is displayed below:",AM,1037,"['bivariate', 'outlier', 'saw', 'earlier', 'also', 'outlier', 'prin', 'variable', '\tfor', 'two', 'pc', 'time', 'could', 'create', 'threeway', 'rotating', 'scatter', 'plot', 'several', 'principal', 'component', 'variable', 'feel', 'free', 'try', 'plot', 'looking', 'output', 'outlier', 'analysis', 'decide', 'four', 'observation', 'outlier', 'choose', 'continue', 'screening', 'data', 'preparation', 'complete', 'set', 'data', 'restricted', 'range', 'group', 'size', 'use', 'data_set', 'sandwich', 'investigate', 'variable', 'restricted', 'range', 'unequal', 'group', 'size', 'selected', 'weight', 'concerned', 'enough', 'variation', 'weight', 'sandwich', 'selected', 'category', 'concerned', 'may', 'type', 'sandwich', 'underrepresented', 'data', '1\tselect', 'sandwich', 'data_set', 'window', 'menu', '2\tcreate', 'histogram', 'weight', 'variable', 'selecting', 'plot', '', 'create', 'histogram', '', 'weight', '', 'set', 'x', 'histogram', 'weight', 'displayed']"
283,"Consider the example you just saw. Because the same data that are being classified are also used to create the discriminant functions, the analysis capitalizes on chance. You saw a predicted error rate of 4% in the population. However, that assumes that the population is exactly like the sample you observed and has exactly the priors that you specified. Both of these conditions are unlikely to be met, and the first one is certainly unreasonable. It is very important to empirically validate the results of a discriminant analysis on new data before using the results of a discriminant analysis to predict group membership. To do this, use the first data set as the calibration data set, and use the second data set as the validation data set. ?	If a new data set is not available, you can perform crossvalidation of the data by using a one-observation holdout method that computes the discriminant function for each data point from all the remaining data with that observation left out.",AM,990,"['consider', 'example', 'saw', 'data', 'classified', 'also', 'used', 'create', 'discriminant_function', 'analysis', 'capitalizes', 'chance', 'saw', 'predicted', 'error', 'rate', '4', 'population', 'however', 'assumes', 'population', 'exactly', 'like', 'sample', 'observed', 'ha', 'exactly', 'prior', 'specified', 'condition', 'unlikely', 'met', 'first', 'one', 'certainly', 'unreasonable', 'important', 'empirically', 'validate', 'result', 'discriminant_analysis', 'new', 'data', 'using', 'result', 'discriminant_analysis', 'predict', 'group', 'membership', 'use', 'first', 'data_set', 'calibration', 'data_set', 'use', 'second', 'data_set', 'validation', 'data_set', '\tif', 'new', 'data_set', 'available', 'perform', 'crossvalidation', 'data', 'using', 'oneobservation', 'holdout', 'method', 'computes', 'discriminant_function', 'data', 'point', 'remaining', 'data', 'observation', 'left']"
284,"The first analysis you will perform uses PROC DISCRIM with the gamblegrp data you used earlier. The program ch4s2d1.sas is shown below. Notice that the PROP option in the PRIORS statement calculates prior probabilities from the proportion of observations in each group. proc discrim data = amul.gamblegrp list; class type; priors prop; var dsm1-dsm12; run; The output is shown below. The class level information shows the weights and the priors, which are equal to the proportion in each group. The DISCRIM Procedure",AM,516,"['first', 'analysis', 'perform', 'us', 'proc', 'discrim', 'gamblegrp', 'data', 'used', 'earlier', 'program', 'ch4s2d1sas', 'shown', 'notice', 'prop', 'option', 'prior', 'statement', 'calculates', 'prior', 'probability', 'proportion', 'observation', 'group', 'proc', 'discrim', 'data', '', 'amulgamblegrp', 'list', 'class', 'type', 'prior', 'prop', 'var', 'dsm1dsm12', 'run', 'output', 'shown', 'class', 'level', 'information', 'show', 'weight', 'prior', 'equal', 'proportion', 'group', 'discrim', 'procedure']"
285,"Recall that just as ANOVA assumes that groups have equal variances, MANOVA and linear discriminant analysis both assume that groups have homogeneous covariance matrices. Violating this assumption can result in incorrect inference about group differences in MANOVA and canonical discriminant analysis. In Fisher linear discriminant analysis, it can result in incorrect prediction of group membership. Consider the generalized squared distance between observations and group centroids, above. In this formula, a single (pooled) estimate of the covariance matrix is used and therefore the formula does not reflect group differences in variances and covariances.",AM,658,"['recall', 'anova', 'assumes', 'group', 'equal', 'variance', 'manova', 'linear', 'discriminant_analysis', 'assume', 'group', 'homogeneous', 'covariance', 'matrix', 'violating', 'assumption', 'result', 'incorrect', 'inference', 'group', 'difference', 'manova', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'result', 'incorrect', 'prediction', 'group', 'membership', 'consider', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'formula', 'single', 'pooled', 'estimate', 'covariance', 'matrix', 'used', 'therefore', 'formula', 'doe', 'reflect', 'group', 'difference', 'variance', 'covariance']"
286,"The first problem, accuracy of the data file, is a problem for essentially any statistical analysis. Investigate summary reports using the MEANS procedure and frequency tables using the FREQ procedure. Look for observations that are outside of the reasonable range for the variables. Drop duplicated observations in the data using the SORT procedure with the NODUPKEY option. You can also use PROC FORMAT to specify a formatted value for any values of your variable that are not in a specified range or on a specified list. This enables you to quickly and easily identify many of your incorrect data values. If you find problems, document them and try to learn what caused the problem. Correct any mis- keyed values, filter out duplicated observations, and so on. !	If you are interested in learning more about screening data files for accuracy, Cody?s Data Cleaning Techniques Using SAS Software by Ron Cody or the instructor-based course Data Cleaning Techniques are strongly recommended.",AM,990,"['first', 'problem', 'accuracy', 'data', 'file', 'problem', 'essentially', 'statistical', 'analysis', 'investigate', 'summary', 'report', 'using', 'mean', 'procedure', 'frequency', 'table', 'using', 'freq', 'procedure', 'look', 'observation', 'outside', 'reasonable', 'range', 'variable', 'drop', 'duplicated', 'observation', 'data', 'using', 'sort', 'procedure', 'nodupkey', 'option', 'also', 'use', 'proc', 'format', 'specify', 'formatted', 'value', 'value', 'variable', 'specified', 'range', 'specified', 'list', 'enables', 'quickly', 'easily', 'identify', 'many', 'incorrect', 'data', 'value', 'find', 'problem', 'document', 'try', 'learn', 'caused', 'problem', 'correct', 'mi', 'keyed', 'value', 'filter', 'duplicated', 'observation', '\tif', 'interested', 'learning', 'screening', 'data', 'file', 'accuracy', 'cody', 'data', 'cleaning', 'technique', 'using', 'sa', 'software', 'ron', 'cody', 'instructorbased', 'course', 'data', 'cleaning', 'technique', 'strongly', 'recommended']"
287,"Many types of studies exhibit problems with restricted range on variables. If a variable demonstrates restricted range, it does not have enough variability to be useful as a continuous variable in your analyses. An example of restricted range is shown above. In your study of university professors, you suspect that more years of education would be associated with greater career success. However, the vast majority of university professors have many years of education. There are very few who have less than a doctoral or perhaps a master?s degree. The restriction of range demonstrated here is sometimes known as a ceiling effect because the restriction is at the high end (the ceiling) of the data. The opposite of the ceiling effect is known as a floor effect. For example, if you were interested in reducing the risk of heart attacks among women between 20-30 years of age, you would likely run into a floor effect because very few women between 20 and 30 years of age have heart attacks, and it would be difficult to reduce this amount further with an intervention.",AM,1071,"['many', 'type', 'study', 'exhibit', 'problem', 'restricted', 'range', 'variable', 'variable', 'demonstrates', 'restricted', 'range', 'doe', 'enough', 'variability', 'useful', 'continuous', 'variable', 'analysis', 'example', 'restricted', 'range', 'shown', 'study', 'university', 'professor', 'suspect', 'year', 'education', 'would', 'associated', 'greater', 'career', 'success', 'however', 'vast', 'majority', 'university', 'professor', 'many', 'year', 'education', 'le', 'doctoral', 'perhaps', 'master', 'degree', 'restriction', 'range', 'demonstrated', 'sometimes', 'known', 'ceiling', 'effect', 'restriction', 'high', 'end', 'ceiling', 'data', 'opposite', 'ceiling', 'effect', 'known', 'floor', 'effect', 'example', 'interested', 'reducing', 'risk', 'heart', 'attack', 'among', 'woman', '2030', 'year', 'age', 'would', 'likely', 'run', 'floor', 'effect', 'woman', '20', '30', 'year', 'age', 'heart', 'attack', 'would', 'difficult', 'reduce', 'amount', 'intervention']"
288,?	You can also rotate without using the Graph Toolbar by holding down the Alt key on your keyboard and the left mouse button. Move the cursor over the picture to rotate it while holding these two buttons.,AM,204,"['\tyou', 'also', 'rotate', 'without', 'using', 'graph', 'toolbar', 'holding', 'alt', 'key', 'keyboard', 'left', 'mouse', 'button', 'move', 'cursor', 'picture', 'rotate', 'holding', 'two', 'button']"
289,"The sandwiches data set includes nutritional information about several brands and types of sandwiches sold at fast-food restaurants and in grocery store freezer sections. The data are simulated but based on real nutritional information about sandwiches. The variables for the sandwiches data set are described below: Calories	The number of calories in the sandwich from testing TFat		Grams of fat Protein	Grams of protein Carb		Grams of carbohydrate Fiber		Grams of fiber	 Sodium	Milligrams of sodium Brand		Brand name of the sandwich (A, B, ?, I) (Character variable) Name		Name of the sandwich (Character variable) Category	Type of sandwich (Tuna, Chicken, Ham,?) (Character variable) Weight	Weight in ounces FatCal	Number of calories from fat CarbCal	Number of calories from carbohydrate ProCal	Number of calories from protein CalSum	Sum of FatCal, CarbCal, and ProCal ? to evaluate accuracy of the Calories measurement. You will perform analyses on some but not necessarily all of the variables in the data set. You may want to explore further with the data on your own to practice the methods demonstrated in this course. Outlier Analysis and Data Screening Using SAS/IML Workshop 2.1 You can use the SAS/IML Workshop to perform interactive graphical analysis of your data. In addition to graphical capabilities, you can use IML (Interactive Matrix Language) for customized analyses, and you can run SAS programs and view SAS output within the code editor in the SAS/IML Workshop. 1.	Open SAS/IML Workshop by selecting Start => Programs => IML Workshop 2.1. You see the SAS/IML workspace:",AM,1593,"['sandwich', 'data_set', 'includes', 'nutritional', 'information', 'several', 'brand', 'type', 'sandwich', 'sold', 'fastfood', 'restaurant', 'grocery', 'store', 'freezer', 'section', 'data', 'simulated', 'based', 'real', 'nutritional', 'information', 'sandwich', 'variable', 'sandwich', 'data_set', 'described', 'calories\tthe', 'number', 'calorie', 'sandwich', 'testing', 'tfat\t\tgrams', 'fat', 'protein\tgrams', 'protein', 'carb\t\tgrams', 'carbohydrate', 'fiber\t\tgrams', 'fiber\t', 'sodium\tmilligrams', 'sodium', 'brand\t\tbrand', 'name', 'sandwich', 'b', '', 'character', 'variable', 'name\t\tname', 'sandwich', 'character', 'variable', 'category\ttype', 'sandwich', 'tuna', 'chicken', 'ham', 'character', 'variable', 'weight\tweight', 'ounce', 'fatcal\tnumber', 'calorie', 'fat', 'carbcal\tnumber', 'calorie', 'carbohydrate', 'procal\tnumber', 'calorie', 'protein', 'calsum\tsum', 'fatcal', 'carbcal', 'procal', '', 'evaluate', 'accuracy', 'calorie', 'measurement', 'perform', 'analysis', 'necessarily', 'variable', 'data_set', 'may', 'want', 'explore', 'data', 'practice', 'method', 'demonstrated', 'course', 'outlier', 'analysis', 'data', 'screening', 'using', 'sasiml', 'workshop', '21', 'use', 'sasiml', 'workshop', 'perform', 'interactive', 'graphical', 'analysis', 'data', 'addition', 'graphical', 'capability', 'use', 'iml', 'interactive', 'matrix', 'language', 'customized', 'analysis', 'run', 'sa', 'program', 'view', 'sa', 'output', 'within', 'code', 'editor', 'sasiml', 'workshop', '1\topen', 'sasiml', 'workshop', 'selecting', 'start', '', 'program', '', 'iml', 'workshop', '21', 'see', 'sasiml', 'workspace']"
290,"There are potential problems in any kind of data. Computers crash, researchers enter erroneous factor settings, data entry coders make typographical errors, and research participants fall asleep. Human error, technical difficulties in automated systems, collinear variables, duplicated records, outlying observations, and a host of other problems can plague your data. The more time you invest in validating, cleaning, preparing and checking your data, the more you will be able to reap the rewards of your statistical analyses. In addition to making the data ready for your analyses, often preparing and evaluating the data provide you with insight that you may not have gained otherwise.",AM,689,"['potential', 'problem', 'kind', 'data', 'computer', 'crash', 'researcher', 'enter', 'erroneous', 'factor', 'setting', 'data', 'entry', 'coder', 'make', 'typographical', 'error', 'research', 'participant', 'fall', 'asleep', 'human', 'error', 'technical', 'difficulty', 'automated', 'system', 'collinear', 'variable', 'duplicated', 'record', 'outlying', 'observation', 'host', 'problem', 'plague', 'data', 'time', 'invest', 'validating', 'cleaning', 'preparing', 'checking', 'data', 'able', 'reap', 'reward', 'statistical', 'analysis', 'addition', 'making', 'data', 'ready', 'analysis', 'often', 'preparing', 'evaluating', 'data', 'provide', 'insight', 'may', 'gained', 'otherwise']"
291,"There are many ways to specify a contrast. Perhaps the easiest method is by using the cell means model. Writing contrasts with the cell means model enables you to specify any contrast you are interested in. However, it is very important to understand that this model specification method is used for simplifying the contrasts, and it does not generally produce an overall test of model fit that researchers are interested in. In specifying coefficients for a CONTRAST or ESTIMATE statement, ordering of the terms is determined by the order in which variables appear in the CLASS statement. The levels of each factor are expressed in alphanumeric order. ?	If you are uncertain about the order of the terms in your model, specify the SOLUTION option in the MODEL statement in PROC GLM. This will display a table of parameter estimates, and you will see the order in which the contrast terms should be specified.",AM,909,"['many', 'way', 'specify', 'contrast', 'perhaps', 'easiest', 'method', 'using', 'cell', 'mean', 'model', 'writing', 'contrast', 'cell', 'mean', 'model', 'enables', 'specify', 'contrast', 'interested', 'however', 'important', 'understand', 'model', 'specification', 'method', 'used', 'simplifying', 'contrast', 'doe', 'generally', 'produce', 'overall', 'test', 'model', 'fit', 'researcher', 'interested', 'specifying', 'coefficient', 'contrast', 'estimate', 'statement', 'ordering', 'term', 'determined', 'order', 'variable', 'appear', 'class', 'statement', 'level', 'factor', 'expressed', 'alphanumeric', 'order', '\tif', 'uncertain', 'order', 'term', 'model', 'specify', 'solution', 'option', 'model_statement', 'proc', 'glm', 'display', 'table', 'parameter_estimate', 'see', 'order', 'contrast', 'term', 'specified']"
292,"For univariate statistics, there are many outlier detection tools available. Perhaps you already use the tools listed above regularly, in addition to others. In linear models, it is often useful to look at leverage and DFFITS statistics to find influential outliers on a set of predictor variables. These statistics are easy to obtain from the REG and GLM procedures. To evaluate one variable at a time for outliers, statistical and graphical tools can be useful. For example, you can standardize your variables (center them about the mean and scale them by the standard deviation) to get z-scores and find observations that are very far from the mean for the variable. For grouped data, you perform this analysis separately for each group. Schematic box plots provide a way to detect outliers visually. In schematic box plots, the box is drawn over the interquartile range (IQR). Whiskers extend from the ends of box out to 1.5 IQR units, or the range of the data. Any points beyond the whiskers are plotted as outliers.",AM,1021,"['univariate', 'statistic', 'many', 'outlier', 'detection', 'tool', 'available', 'perhaps', 'already', 'use', 'tool', 'listed', 'regularly', 'addition', 'others', 'linear', 'model', 'often', 'useful', 'look', 'leverage', 'dffits', 'statistic', 'find', 'influential', 'outlier', 'set', 'predictor_variable', 'statistic', 'easy', 'obtain', 'reg', 'glm', 'procedure', 'evaluate', 'one', 'variable', 'time', 'outlier', 'statistical', 'graphical', 'tool', 'useful', 'example', 'standardize', 'variable', 'center', 'mean', 'scale', 'standard', 'deviation', 'get', 'zscores', 'find', 'observation', 'far', 'mean', 'variable', 'grouped', 'data', 'perform', 'analysis', 'separately', 'group', 'schematic', 'box', 'plot', 'provide', 'way', 'detect', 'outlier', 'visually', 'schematic', 'box', 'plot', 'box', 'drawn', 'interquartile', 'range', 'iqr', 'whisker', 'extend', 'end', 'box', '15', 'iqr', 'unit', 'range', 'data', 'point', 'beyond', 'whisker', 'plotted', 'outlier']"
293,"NOTE: F Statistic for Roy's Greatest Root is an upper bound. NOTE: F Statistic for Wilks' Lambda is exact. The multivariate statistics test the null hypothesis that all the canonical correlations are simultaneously zero, which is the same as the hypothesis that there is no linear prediction of group membership from the predictor variables. You reject this null hypothesis. Adjusted Approximate Squared Canonical Canonical Standard Canonical Correlation Correlation Error Correlation",AM,484,"['note', 'f', 'statistic', 'roys', 'greatest', 'root', 'upper', 'bound', 'note', 'f', 'statistic', 'wilks', 'lambda', 'exact', 'multivariate', 'statistic', 'test', 'null', 'hypothesis', 'canonical', 'correlation', 'simultaneously', 'zero', 'hypothesis', 'linear', 'prediction', 'group', 'membership', 'predictor_variable', 'reject', 'null', 'hypothesis', 'adjusted', 'approximate', 'squared', 'canonical', 'canonical', 'standard', 'canonical', 'correlation', 'correlation', 'error', 'correlation']"
294,"The pooled covariance matrix, Sp, was used. Information about Sp is displayed above. There were 12 (noncollinear) predictors; the covariance matrix Sp is rank 12. Pairwise Generalized Squared Distances Between Groups",AM,216,"['pooled', 'covariance', 'matrix', 'sp', 'wa', 'used', 'information', 'sp', 'displayed', '12', 'noncollinear', 'predictor', 'covariance', 'matrix', 'sp', 'rank', '12', 'pairwise', 'generalized', 'squared', 'distance', 'group']"
295,"Many of the recommendations for restricted ranges apply to unequal group sizes. Careful planning is key to avoiding the problem of unequal group sizes. If you have enough small groups that are reasonably similar, you may be able to combine smaller groups and compare them to the larger group(s).",AM,295,"['many', 'recommendation', 'restricted', 'range', 'apply', 'unequal', 'group', 'size', 'careful', 'planning', 'key', 'avoiding', 'problem', 'unequal', 'group', 'size', 'enough', 'small', 'group', 'reasonably', 'similar', 'may', 'able', 'combine', 'smaller', 'group', 'compare', 'larger', 'group']"
296,"The contrast coefficients for all the terms in the linear model are shown above. However, coefficients must be expressed as integers or decimal values. Expressing 1/3 as a decimal value can be problematic, so the values must be multiplied by a constant.",AM,253,"['contrast', 'coefficient', 'term', 'linear', 'model', 'shown', 'however', 'coefficient', 'must', 'expressed', 'integer', 'decimal', 'value', 'expressing', '13', 'decimal', 'value', 'problematic', 'value', 'must', 'multiplied', 'constant']"
297,"You can see that the Fried Platter, Tuna Sub, and several others are bivariate outliers on more than one plot. Continue to explore the plots. You can change the colors of specific observations. For example, you may want to identify all the Frozen sandwiches on your plot. You can label the Frozen sandwiches with a special color to make them easier to find on the plots. 3.	In the data table, highlight the rows that are Frozen sandwiches by clicking on the row header and dragging the selection. Partial Display",AM,512,"['see', 'fried', 'platter', 'tuna', 'sub', 'several', 'others', 'bivariate', 'outlier', 'one', 'plot', 'continue', 'explore', 'plot', 'change', 'color', 'specific', 'observation', 'example', 'may', 'want', 'identify', 'frozen', 'sandwich', 'plot', 'label', 'frozen', 'sandwich', 'special', 'color', 'make', 'easier', 'find', 'plot', '3\tin', 'data', 'table', 'highlight', 'row', 'frozen', 'sandwich', 'clicking', 'row', 'header', 'dragging', 'selection', 'partial', 'display']"
298,"With a CONTRAST statement, you specify L, in this case, a vector of coefficients for the effect to be tested. M is a transformation matrix that in this case is an identity matrix. For this reason, M is sometimes dropped from the null hypothesis specification. CONTRAST	enables you to perform custom hypothesis tests by specifying an L vector or matrix for testing the univariate hypothesis . There is no limit to the number of CONTRAST statements you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE	enables you to estimate linear functions of the parameters by multiplying the vector L by the parameter estimate vector b resulting in Lb. There is no limit to the number of ESTIMATE statements that you can specify, but they must appear after the MODEL statement and before the MANOVA statement. ESTIMATE statements only perform 1-df univariate tests. In the CONTRAST and ESTIMATE statements, label	applies a label to the contrast (or estimate) on the output. A label is required for every contrast (or estimate) specified. Labels must be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement, or the INTERCEPT effect. The INTERCEPT effect can be used when an intercept is fitted in the model. You do not need to include all effects that are in the MODEL statement. values	are constants that are elements of the L vector associated with the effect. You do not need to include trailing zeros in the L vector.",AM,1490,"['contrast', 'statement', 'specify', 'l', 'case', 'vector', 'coefficient', 'effect', 'tested', 'transformation', 'matrix', 'case', 'identity', 'matrix', 'reason', 'sometimes', 'dropped', 'null', 'hypothesis', 'specification', 'contrast\tenables', 'perform', 'custom', 'hypothesis', 'test', 'specifying', 'l', 'vector', 'matrix', 'testing', 'univariate', 'hypothesis', '', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate\tenables', 'estimate', 'linear', 'function', 'parameter', 'multiplying', 'vector', 'l', 'parameter_estimate', 'vector', 'b', 'resulting', 'lb', 'limit', 'number', 'estimate', 'statement', 'specify', 'must', 'appear', 'model_statement', 'manova', 'statement', 'estimate', 'statement', 'perform', '1df', 'univariate', 'test', 'contrast', 'estimate', 'statement', 'label\tapplies', 'label', 'contrast', 'estimate', 'output', 'label', 'required', 'every', 'contrast', 'estimate', 'specified', 'label', 'must', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'intercept', 'effect', 'intercept', 'effect', 'used', 'intercept', 'fitted', 'model', 'need', 'include', 'effect', 'model_statement', 'values\tare', 'constant', 'element', 'l', 'vector', 'associated', 'effect', 'need', 'include', 'trailing', 'zero', 'l', 'vector']"
299,"There are two procedures in SAS that can be used to perform canonical discriminant analysis: the DISCRIM procedure and the CANDISC procedure. PROC DISCRIM is more general than PROC CANDISC and can be used to perform both steps of discriminant analysis shown above. PROC CANDISC performs the first step only. However, PROC CANDISC produces output that is generally more familiar to users and may be easier to interpret. If you are simply trying to find the combinations of variables that predict group membership, it is simpler to use PROC CANDISC. ?	You will learn to use PROC DISCRIM later in the chapter.",AM,606,"['two', 'procedure', 'sa', 'used', 'perform', 'canonical', 'discriminant_analysis', 'discrim', 'procedure', 'candisc', 'procedure', 'proc', 'discrim', 'general', 'proc', 'candisc', 'used', 'perform', 'step', 'discriminant_analysis', 'shown', 'proc', 'candisc', 'performs', 'first', 'step', 'however', 'proc', 'candisc', 'produce', 'output', 'generally', 'familiar', 'user', 'may', 'easier', 'interpret', 'simply', 'trying', 'find', 'combination', 'variable', 'predict', 'group', 'membership', 'simpler', 'use', 'proc', 'candisc', '\tyou', 'learn', 'use', 'proc', 'discrim', 'later', 'chapter']"
300,"You express the coefficients as integers by multiplying them by a constant. There are situations when you want to use the CONTRAST statement and the ESTIMATE statement together, such as when you are performing comparisons with more than one degree of freedom and you want the estimates from the tests. If you were only interested in the significance test from the contrast and not in the estimates, then you would use the CONTRAST statement only. The ESTIMATE statement for this contrast would be the same as the CONTRAST statement, except you would also include the DIVISOR= option to tell SAS to divide each estimate by 3 (so you can get the mean of the cell, instead of 3 ? the mean of the cell): In the following example, you will see both the CONTRAST and the ESTIMATE statements used. Using Contrasts for Custom Hypothesis Tests",AM,834,"['express', 'coefficient', 'integer', 'multiplying', 'constant', 'situation', 'want', 'use', 'contrast', 'statement', 'estimate', 'statement', 'together', 'performing', 'comparison', 'one', 'degree', 'freedom', 'want', 'estimate', 'test', 'interested', 'significance', 'test', 'contrast', 'estimate', 'would', 'use', 'contrast', 'statement', 'estimate', 'statement', 'contrast', 'would', 'contrast', 'statement', 'except', 'would', 'also', 'include', 'divisor', 'option', 'tell', 'sa', 'divide', 'estimate', '3', 'get', 'mean', 'cell', 'instead', '3', '', 'mean', 'cell', 'following', 'example', 'see', 'contrast', 'estimate', 'statement', 'used', 'using', 'contrast', 'custom', 'hypothesis', 'test']"
301,"One way to handle outliers without deleting the observation from the analysis completely is to replace the value or values with something less extreme. For example, with univariate outliers, winsorized means are measures of central tendency in which the extreme values have been replaced with less extreme values. Trimmed means are measures of central tendency whose most extreme (upper and lower) values have been removed from calculations. You can obtain winsorized and trimmed means with the UNIVARIATE procedure. Outliers can pose real problems for your analyses. Regardless of how you choose to handle outliers, it is always important to document your actions carefully so that others know what you did.",AM,708,"['one', 'way', 'handle', 'outlier', 'without', 'deleting', 'observation', 'analysis', 'completely', 'replace', 'value', 'value', 'something', 'le', 'extreme', 'example', 'univariate', 'outlier', 'winsorized', 'mean', 'measure', 'central', 'tendency', 'extreme', 'value', 'replaced', 'le', 'extreme', 'value', 'trimmed', 'mean', 'measure', 'central', 'tendency', 'whose', 'extreme', 'upper', 'lower', 'value', 'removed', 'calculation', 'obtain', 'winsorized', 'trimmed', 'mean', 'univariate', 'procedure', 'outlier', 'pose', 'real', 'problem', 'analysis', 'regardless', 'choose', 'handle', 'outlier', 'always', 'important', 'document', 'action', 'carefully', 'others', 'know']"
302,"The first problem, accuracy of the data file, is a problem for essentially any statistical analysis. Investigate summary reports using the MEANS procedure and frequency tables using the FREQ procedure. Look for observations that are outside of the reasonable range for the variables. Drop duplicated observations in the data using the SORT procedure with the NODUPKEY option. You can also use PROC FORMAT to specify a formatted value for any values of your variable that are not in a specified range or on a specified list. This enables you to quickly and easily identify many of your incorrect data values. If you find problems, document them and try to learn what caused the problem. Correct any mis- keyed values, filter out duplicated observations, and so on. !	If you are interested in learning more about screening data files for accuracy, Cody?s Data Cleaning Techniques Using SAS Software by Ron Cody or the instructor-based course Data Cleaning Techniques are strongly recommended.",AM,990,"['first', 'problem', 'accuracy', 'data', 'file', 'problem', 'essentially', 'statistical', 'analysis', 'investigate', 'summary', 'report', 'using', 'mean', 'procedure', 'frequency', 'table', 'using', 'freq', 'procedure', 'look', 'observation', 'outside', 'reasonable', 'range', 'variable', 'drop', 'duplicated', 'observation', 'data', 'using', 'sort', 'procedure', 'nodupkey', 'option', 'also', 'use', 'proc', 'format', 'specify', 'formatted', 'value', 'value', 'variable', 'specified', 'range', 'specified', 'list', 'enables', 'quickly', 'easily', 'identify', 'many', 'incorrect', 'data', 'value', 'find', 'problem', 'document', 'try', 'learn', 'caused', 'problem', 'correct', 'mi', 'keyed', 'value', 'filter', 'duplicated', 'observation', '\tif', 'interested', 'learning', 'screening', 'data', 'file', 'accuracy', 'cody', 'data', 'cleaning', 'technique', 'using', 'sa', 'software', 'ron', 'cody', 'instructorbased', 'course', 'data', 'cleaning', 'technique', 'strongly', 'recommended']"
303,"Many of the important issues in this chapter such as data accuracy and missing data apply to all statistical analyses, including univariate statistics, inferential statistics, and descriptive statistics. Some issues are unique to multivariate statistics, and some topics are unique to inferential statistics.",AM,308,"['many', 'important', 'issue', 'chapter', 'data', 'accuracy', 'missing', 'data', 'apply', 'statistical', 'analysis', 'including', 'univariate', 'statistic', 'inferential', 'statistic', 'descriptive', 'statistic', 'issue', 'unique', 'multivariate', 'statistic', 'topic', 'unique', 'inferential', 'statistic']"
304,"where Vt = St if using within-group covariance matrices, or Vt = Sp if using pooled covariance matrices, and mt is the mean vector of group t. ?	The default in PROC DISCRIM is to use pooled covariances in calculating the generalized squared distances. If you prefer to use within-class covariances, specify POOL = NO in the DISCRIM statement. You will learn to use this option later in the course for quadratic discriminant analysis.",AM,433,"['vt', '', 'st', 'using', 'withingroup', 'covariance', 'matrix', 'vt', '', 'sp', 'using', 'pooled', 'covariance', 'matrix', 'mt', 'mean', 'vector', 'group', '\tthe', 'default', 'proc', 'discrim', 'use', 'pooled', 'covariance', 'calculating', 'generalized', 'squared', 'distance', 'prefer', 'use', 'withinclass', 'covariance', 'specify', 'pool', '', 'discrim', 'statement', 'learn', 'use', 'option', 'later', 'course', 'quadratic', 'discriminant_analysis']"
305,"Be careful not to confuse discriminant analysis with cluster analysis, which is another commonly used dimension-reduction technique. Discriminant analysis requires prior knowledge of the groups, usually in the form of a sample from each group. In cluster analysis, the data do not include information on group membership; the purpose of cluster analysis is to create the groups. This distinction between knowledge of groups versus creation of groups highlights the difference between supervised and unsupervised analyses. Most of the analyses in scientific research and inferential statistical analysis involve the use of supervised data analytic techniques. MANOVA, canonical correlation, and discriminant analysis are all examples of supervised analyses. In contrast, unsupervised analytic methods are more typical of the kinds of research questions in which statistical inference is not a primary goal, such as in market segmentation, or during the exploratory phase of a scientific investigation. Principal components analysis and cluster analysis are examples of unsupervised analyses.",AM,1090,"['careful', 'confuse', 'discriminant_analysis', 'cluster', 'analysis', 'another', 'commonly', 'used', 'dimensionreduction', 'technique', 'discriminant_analysis', 'requires', 'prior', 'knowledge', 'group', 'usually', 'form', 'sample', 'group', 'cluster', 'analysis', 'data', 'include', 'information', 'group', 'membership', 'purpose', 'cluster', 'analysis', 'create', 'group', 'distinction', 'knowledge', 'group', 'versus', 'creation', 'group', 'highlight', 'difference', 'supervised', 'unsupervised', 'analysis', 'analysis', 'scientific', 'research', 'inferential', 'statistical', 'analysis', 'involve', 'use', 'supervised', 'data', 'analytic', 'technique', 'manova', 'canonical', 'correlation', 'discriminant_analysis', 'example', 'supervised', 'analysis', 'contrast', 'unsupervised', 'analytic', 'method', 'typical', 'kind', 'research', 'question', 'statistical', 'inference', 'primary', 'goal', 'market', 'segmentation', 'exploratory', 'phase', 'scientific', 'investigation', 'principal', 'component', 'analysis', 'cluster', 'analysis', 'example', 'unsupervised', 'analysis']"
306,"The Tofu Veg Delite does not appear to fit with the general pattern of the rest of the data. You also notice that the Frozen sandwiches are close to one another near the low end of Calories and Sodium. Principal Components and Outliers: SAS Code within the SAS/IML Workshop For more than three-dimensional space, the easiest way to spot outliers can be with a histogram of principal component scores. The program App_OutliersIML.iml is displayed below: libname amul 'C:\workshop\winsas\amul\data\';",AM,498,"['tofu', 'veg', 'delite', 'doe', 'appear', 'fit', 'general', 'pattern', 'rest', 'data', 'also', 'notice', 'frozen', 'sandwich', 'close', 'one', 'another', 'near', 'low', 'end', 'calorie', 'sodium', 'principal', 'component', 'outlier', 'sa', 'code', 'within', 'sasiml', 'workshop', 'threedimensional', 'space', 'easiest', 'way', 'spot', 'outlier', 'histogram', 'principal', 'component', 'score', 'program', 'appoutliersimliml', 'displayed', 'libname', 'amul', 'cworkshopwinsasamuldata']"
307,"From the canonical discriminant analysis you ran in the previous section, you saw that there were two discriminant functions that both appear to have useful interpretations and that discriminate between different pairs of groups.",AM,229,"['canonical', 'discriminant_analysis', 'ran', 'previous', 'section', 'saw', 'two', 'discriminant_function', 'appear', 'useful', 'interpretation', 'discriminate', 'different', 'pair', 'group']"
308,"where Vt = St if using within-group covariance matrices, or Vt = Sp if using pooled covariance matrices, and mt is the mean vector of group t. ?	The default in PROC DISCRIM is to use pooled covariances in calculating the generalized squared distances. If you prefer to use within-class covariances, specify POOL = NO in the DISCRIM statement. You will learn to use this option later in the course for quadratic discriminant analysis.",AM,433,"['vt', '', 'st', 'using', 'withingroup', 'covariance', 'matrix', 'vt', '', 'sp', 'using', 'pooled', 'covariance', 'matrix', 'mt', 'mean', 'vector', 'group', '\tthe', 'default', 'proc', 'discrim', 'use', 'pooled', 'covariance', 'calculating', 'generalized', 'squared', 'distance', 'prefer', 'use', 'withinclass', 'covariance', 'specify', 'pool', '', 'discrim', 'statement', 'learn', 'use', 'option', 'later', 'course', 'quadratic', 'discriminant_analysis']"
309,"If the homogeneity of covariance matrices assumption is violated, it is possible to perform the discriminant analysis using information about each of the groups separately. In this case, a third term is added to the generalized squared distance formula: the natural log of the determinant of the covariance matrix for each group. This is known as quadratic discriminant analysis. If the determinant of a covariance matrix for a group is large, this suggests large within-group variability. Using g1(t) results in the generalized squared distance from observations to group centroids being larger for that group than for groups with smaller within-group variability. Recall in the example you saw in the first section that the control group had the widest variability on the CDA plot. The Steady group had the smallest variability. It is possible that in this example, the assumption of homogeneity of covariance matrices was violated.",AM,934,"['homogeneity', 'covariance', 'matrix', 'assumption', 'violated', 'possible', 'perform', 'discriminant_analysis', 'using', 'information', 'group', 'separately', 'case', 'third', 'term', 'added', 'generalized', 'squared', 'distance', 'formula', 'natural', 'log', 'determinant', 'covariance', 'matrix', 'group', 'known', 'quadratic', 'discriminant_analysis', 'determinant', 'covariance', 'matrix', 'group', 'large', 'suggests', 'large', 'withingroup', 'variability', 'using', 'g1t', 'result', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'larger', 'group', 'group', 'smaller', 'withingroup', 'variability', 'recall', 'example', 'saw', 'first', 'section', 'control', 'group', 'widest', 'variability', 'cda', 'plot', 'steady', 'group', 'smallest', 'variability', 'possible', 'example', 'assumption', 'homogeneity', 'covariance', 'matrix', 'wa', 'violated']"
310,"One way to handle outliers without deleting the observation from the analysis completely is to replace the value or values with something less extreme. For example, with univariate outliers, winsorized means are measures of central tendency in which the extreme values have been replaced with less extreme values. Trimmed means are measures of central tendency whose most extreme (upper and lower) values have been removed from calculations. You can obtain winsorized and trimmed means with the UNIVARIATE procedure. Outliers can pose real problems for your analyses. Regardless of how you choose to handle outliers, it is always important to document your actions carefully so that others know what you did.",AM,708,"['one', 'way', 'handle', 'outlier', 'without', 'deleting', 'observation', 'analysis', 'completely', 'replace', 'value', 'value', 'something', 'le', 'extreme', 'example', 'univariate', 'outlier', 'winsorized', 'mean', 'measure', 'central', 'tendency', 'extreme', 'value', 'replaced', 'le', 'extreme', 'value', 'trimmed', 'mean', 'measure', 'central', 'tendency', 'whose', 'extreme', 'upper', 'lower', 'value', 'removed', 'calculation', 'obtain', 'winsorized', 'trimmed', 'mean', 'univariate', 'procedure', 'outlier', 'pose', 'real', 'problem', 'analysis', 'regardless', 'choose', 'handle', 'outlier', 'always', 'important', 'document', 'action', 'carefully', 'others', 'know']"
311,"A natural extension of the MANOVA research question ?How do my continuous responses differ as a function of group levels?? is the discriminant analysis research question ?How do my continuous variables predict membership in groups? With discriminant analysis, you can use parametric or nonparametric methods to *	find linear combinations of continuous variables (discriminant functions) that predict group membership *	estimate the expected misclassification rate based on the discriminant functions *	test the discriminant functions on a new sample to determine the extent to which the functions correctly and incorrectly classify observations Canonical discriminant analysis has the advantage of conceptual and computational simplicity, while Fisher linear discriminant analysis is powerful enough to allow you to find the discriminant functions and test or crossvalidate your results using one simple procedure. You learned to use two procedures in SAS to perform discriminant analysis: PROC CANDISC performs canonical discriminant analysis to find linear combinations of variables that best discriminate among groups. PROC DISCRIM performs linear and quadratic discriminant analysis and produces a prediction function to help classify observations in to groups based on a set of predictors. Remember that discriminant analysis and other predictive modeling techniques capitalize on chance associations among the predictors in your data to find the discriminant functions. For this reason it is important always to perform empirical validation on a new sample of data, or at least use crossvalidation before using the discriminant functions for prediction and scoring.",AM,1671,"['natural', 'extension', 'manova', 'research', 'question', 'continuous', 'response', 'differ', 'function', 'group', 'level', 'discriminant_analysis', 'research', 'question', 'continuous', 'variable', 'predict', 'membership', 'group', 'discriminant_analysis', 'use', 'parametric', 'nonparametric', 'method', '\tfind', 'linear', 'combination', 'continuous', 'variable', 'discriminant_function', 'predict', 'group', 'membership', '\testimate', 'expected', 'misclassification', 'rate', 'based', 'discriminant_function', '\ttest', 'discriminant_function', 'new', 'sample', 'determine', 'extent', 'function', 'correctly', 'incorrectly', 'classify', 'observation', 'canonical', 'discriminant_analysis', 'ha', 'advantage', 'conceptual', 'computational', 'simplicity', 'fisher', 'linear', 'discriminant_analysis', 'powerful', 'enough', 'allow', 'find', 'discriminant_function', 'test', 'crossvalidate', 'result', 'using', 'one', 'simple', 'procedure', 'learned', 'use', 'two', 'procedure', 'sa', 'perform', 'discriminant_analysis', 'proc', 'candisc', 'performs', 'canonical', 'discriminant_analysis', 'find', 'linear', 'combination', 'variable', 'best', 'discriminate', 'among', 'group', 'proc', 'discrim', 'performs', 'linear', 'quadratic', 'discriminant_analysis', 'produce', 'prediction', 'function', 'help', 'classify', 'observation', 'group', 'based', 'set', 'predictor', 'remember', 'discriminant_analysis', 'predictive', 'modeling', 'technique', 'capitalize', 'chance', 'association', 'among', 'predictor', 'data', 'find', 'discriminant_function', 'reason', 'important', 'always', 'perform', 'empirical', 'validation', 'new', 'sample', 'data', 'least', 'use', 'crossvalidation', 'using', 'discriminant_function', 'prediction', 'scoring']"
312,"Recall that just as ANOVA assumes that groups have equal variances, MANOVA and linear discriminant analysis both assume that groups have homogeneous covariance matrices. Violating this assumption can result in incorrect inference about group differences in MANOVA and canonical discriminant analysis. In Fisher linear discriminant analysis, it can result in incorrect prediction of group membership. Consider the generalized squared distance between observations and group centroids, above. In this formula, a single (pooled) estimate of the covariance matrix is used and therefore the formula does not reflect group differences in variances and covariances.",AM,658,"['recall', 'anova', 'assumes', 'group', 'equal', 'variance', 'manova', 'linear', 'discriminant_analysis', 'assume', 'group', 'homogeneous', 'covariance', 'matrix', 'violating', 'assumption', 'result', 'incorrect', 'inference', 'group', 'difference', 'manova', 'canonical', 'discriminant_analysis', 'fisher', 'linear', 'discriminant_analysis', 'result', 'incorrect', 'prediction', 'group', 'membership', 'consider', 'generalized', 'squared', 'distance', 'observation', 'group', 'centroid', 'formula', 'single', 'pooled', 'estimate', 'covariance', 'matrix', 'used', 'therefore', 'formula', 'doe', 'reflect', 'group', 'difference', 'variance', 'covariance']"
313,"Be careful not to confuse discriminant analysis with cluster analysis, which is another commonly used dimension-reduction technique. Discriminant analysis requires prior knowledge of the groups, usually in the form of a sample from each group. In cluster analysis, the data do not include information on group membership; the purpose of cluster analysis is to create the groups. This distinction between knowledge of groups versus creation of groups highlights the difference between supervised and unsupervised analyses. Most of the analyses in scientific research and inferential statistical analysis involve the use of supervised data analytic techniques. MANOVA, canonical correlation, and discriminant analysis are all examples of supervised analyses. In contrast, unsupervised analytic methods are more typical of the kinds of research questions in which statistical inference is not a primary goal, such as in market segmentation, or during the exploratory phase of a scientific investigation. Principal components analysis and cluster analysis are examples of unsupervised analyses.",AM,1090,"['careful', 'confuse', 'discriminant_analysis', 'cluster', 'analysis', 'another', 'commonly', 'used', 'dimensionreduction', 'technique', 'discriminant_analysis', 'requires', 'prior', 'knowledge', 'group', 'usually', 'form', 'sample', 'group', 'cluster', 'analysis', 'data', 'include', 'information', 'group', 'membership', 'purpose', 'cluster', 'analysis', 'create', 'group', 'distinction', 'knowledge', 'group', 'versus', 'creation', 'group', 'highlight', 'difference', 'supervised', 'unsupervised', 'analysis', 'analysis', 'scientific', 'research', 'inferential', 'statistical', 'analysis', 'involve', 'use', 'supervised', 'data', 'analytic', 'technique', 'manova', 'canonical', 'correlation', 'discriminant_analysis', 'example', 'supervised', 'analysis', 'contrast', 'unsupervised', 'analytic', 'method', 'typical', 'kind', 'research', 'question', 'statistical', 'inference', 'primary', 'goal', 'market', 'segmentation', 'exploratory', 'phase', 'scientific', 'investigation', 'principal', 'component', 'analysis', 'cluster', 'analysis', 'example', 'unsupervised', 'analysis']"
314,"The p-value is the probability of getting an equal or less likely statistic. Thus, you would add the probabilities less than or equal to the probability of obtaining the vector of the observed sufficient statistics.",CD,215,"['pvalue', 'probability', 'getting', 'equal', 'le', 'likely', 'statistic', 'thus', 'would', 'add', 'probability', 'le', 'equal', 'probability', 'obtaining', 'vector', 'observed', 'sufficient', 'statistic']"
315,The number of observations in the contingency table prev_pretrm by low controlling for uterine_irr=1 is fairly small. This may be a problem for the Breslow-Day test and the asymptotic confidence limits for the odds ratio. Statistics for Table 2 of prev_pretrm by low Controlling for uterine_irr=1,CD,296,"['number', 'observation', 'contingency', 'table', 'prevpretrm', 'low', 'controlling', 'uterineirr1', 'fairly', 'small', 'may', 'problem', 'breslowday', 'test', 'asymptotic', 'confidence', 'limit', 'odds_ratio', 'statistic', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
316,"The TRACE statement produces a trace record of each output object, including the name and label. The LISTING option writes this information, interleaved with the procedure output, to the SAS listing. Partial Output Low Birth Weight Model",CD,237,"['trace', 'statement', 'produce', 'trace', 'record', 'output', 'object', 'including', 'name', 'label', 'listing', 'option', 'writes', 'information', 'interleaved', 'procedure', 'output', 'sa', 'listing', 'partial', 'output', 'low', 'birth', 'weight', 'model']"
317,"The LOGISTIC procedure fits logistic regression models for binary, ordinal, or nominal response data. Enhancements to PROC LOGISTIC in SAS?9 include the STRATA statement, which enables you to perform a conditional logistic regression on binary response data, and the SCORE statement, which enables you to score a data set using a previously fitted model. PROC LOGISTIC has options that control how to select effects (either variables or interactions) in and out of the model. When there are no interaction terms, a CLASS variable can enter or leave a model in a single step. When there are interaction terms, the selection process also depends on whether you want to preserve model hierarchy (which is explained later in the course). For example, you can specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. PROC LOGISTIC provides a CONTRAST statement for specifying customized hypothesis tests concerning the model parameters. The CONTRAST statement can also be used to obtain odds ratio estimates for various levels of the CLASS variables and confidence intervals around odds ratios for variables that are involved in an interaction. In the MODEL statement, the response variable can be specified in two ways. *	The events/trials syntax represents a ratio of variables where the event variable indicates the number of observations with the response of interest for a particular combination of predictor variable values and the trial variable indicates the number of observations in the same combination of predictor variable values. This response is useful when you have a summarized data set where each observation represents a unique combination of predictor variable values. *	The response variable can also be specified as a positive or negative response for each observation. In other words, each observation represents a single case. Selected PROC LOGISTIC statement options: NOPRINT	suppresses all displayed output. This option temporarily disables the Output Delivery System (ODS). NAMELEN=	specifies the length of effect names in tables and output data sets to be n characters, where n is a value between 20 and 200. Because the default length is 20 characters, you may have to increase the length for some interaction terms. Selected LOGISTIC procedure statements: CLASS	specifies the classification variables to be used in the analysis. The CLASS statement must precede the MODEL statement. MODEL	specifies the response variable (which can be binary, ordinal, or nominal) and the predictor variables (which can be character or numeric). The MODEL statement is required, and only one is allowed with each invocation of PROC LOGISTIC. CONTRAST	provides a mechanism for obtaining customized hypothesis tests. There is no limit to the number of CONTRAST statements that you can specify, but they must appear after the MODEL statement. EXACT	performs exact tests of the parameters for the specified effects and optionally estimates the parameters and outputs the exact conditional distributions. You can specify several EXACT statements, but they must follow the MODEL statement. SCORE	creates a data set that contains all the data in the DATA= data set together with posterior probabilities and, optionally, prediction confidence intervals. You can specify several SCORE statements. STRATA	names the variables that define strata or matched sets to use in a stratified conditional logistic regression of binary response data. The STRATA variables can be either character or numeric, and the formatted values of the STRATA variables determine the levels. You can use formats to group values into levels. UNITS	enables you to obtain an odds ratio estimate for a specified change in a predictor variable. The unit of change can be a number, standard deviation (SD) or a number times the standard deviation (2*SD). OUTPUT	creates an output data set containing all the variables from the input data set and the requested statistics.",CD,4045,"['logistic', 'procedure', 'fit', 'logistic_regression_model', 'binary', 'ordinal', 'nominal', 'response', 'data', 'enhancement', 'proc_logistic', 'sas9', 'include', 'stratum', 'statement', 'enables', 'perform', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'score', 'statement', 'enables', 'score', 'data_set', 'using', 'previously', 'fitted', 'model', 'proc_logistic', 'ha', 'option', 'control', 'select', 'effect', 'either', 'variable', 'interaction', 'model', 'interaction', 'term', 'class', 'variable', 'enter', 'leave', 'model', 'single', 'step', 'interaction', 'term', 'selection', 'process', 'also', 'depends', 'whether', 'want', 'preserve', 'model', 'hierarchy', 'explained', 'later', 'course', 'example', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'proc_logistic', 'provides', 'contrast', 'statement', 'specifying', 'customized', 'hypothesis', 'test', 'concerning', 'model', 'parameter', 'contrast', 'statement', 'also', 'used', 'obtain', 'odds_ratio', 'estimate', 'various', 'level', 'class', 'variable', 'confidence', 'interval', 'around', 'odds_ratio', 'variable', 'involved', 'interaction', 'model_statement', 'response_variable', 'specified', 'two', 'way', '\tthe', 'eventstrials', 'syntax', 'represents', 'ratio', 'variable', 'event', 'variable', 'indicates', 'number', 'observation', 'response', 'interest', 'particular', 'combination', 'predictor_variable', 'value', 'trial', 'variable', 'indicates', 'number', 'observation', 'combination', 'predictor_variable', 'value', 'response', 'useful', 'summarized', 'data_set', 'observation', 'represents', 'unique', 'combination', 'predictor_variable', 'value', '\tthe', 'response_variable', 'also', 'specified', 'positive', 'negative', 'response', 'observation', 'word', 'observation', 'represents', 'single', 'case', 'selected', 'proc_logistic', 'statement', 'option', 'noprint\tsuppresses', 'displayed', 'output', 'option', 'temporarily', 'disables', 'output', 'delivery', 'system', 'od', 'namelen\tspecifies', 'length', 'effect', 'name', 'table', 'output', 'data_set', 'n', 'character', 'n', 'value', '20', '200', 'default', 'length', '20', 'character', 'may', 'increase', 'length', 'interaction', 'term', 'selected', 'logistic', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'must', 'precede', 'model_statement', 'model\tspecifies', 'response_variable', 'binary', 'ordinal', 'nominal', 'predictor_variable', 'character', 'numeric', 'model_statement', 'required', 'one', 'allowed', 'invocation', 'proc_logistic', 'contrast\tprovides', 'mechanism', 'obtaining', 'customized', 'hypothesis', 'test', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'exact\tperforms', 'exact', 'test', 'parameter', 'specified', 'effect', 'optionally', 'estimate', 'parameter', 'output', 'exact', 'conditional', 'distribution', 'specify', 'several', 'exact', 'statement', 'must', 'follow', 'model_statement', 'score\tcreates', 'data_set', 'contains', 'data', 'data', 'data_set', 'together', 'posterior', 'probability', 'optionally', 'prediction', 'confidence', 'interval', 'specify', 'several', 'score', 'statement', 'strata\tnames', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'stratified', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'stratum', 'variable', 'either', 'character', 'numeric', 'formatted', 'value', 'stratum', 'variable', 'determine', 'level', 'use', 'format', 'group', 'value', 'level', 'units\tenables', 'obtain', 'odds_ratio', 'estimate', 'specified', 'change', 'predictor_variable', 'unit', 'change', 'number', 'standard', 'deviation', 'sd', 'number', 'time', 'standard', 'deviation', '2sd', 'output\tcreates', 'output', 'data_set', 'containing', 'variable', 'input', 'data_set', 'requested', 'statistic']"
318,"Because there is a common slope for each predictor variable, the odds ratio is constant for all the categories. The odds ratios can be interpreted as the effect of the predictor variable on the odds of being in a lower ordered value category rather than in a higher ordered value category, regardless of what cumulative logit you are examining. If you use the DESCENDING option in the PROC LOGISTIC statement, the odds ratio is the effect of the predictor variable on the odds of being in a higher rather than a lower category. For example, suppose the odds ratio for bending is 3.0 and you used the DESCENDING option (category=severe is the first ordered category and category=none is the last ordered category). You can interpret the odds ratio by stating the women who say that bending aggravates their back pain have 3 times the odds of being in a higher pain severity category compared to women who say that bending does not aggravate their back pain.",CD,956,"['common', 'slope', 'predictor_variable', 'odds_ratio', 'constant', 'category', 'odds_ratio', 'interpreted', 'effect', 'predictor_variable', 'odds', 'lower', 'ordered', 'value', 'category', 'rather', 'higher', 'ordered', 'value', 'category', 'regardless', 'cumulative', 'logit', 'examining', 'use', 'descending', 'option', 'proc_logistic', 'statement', 'odds_ratio', 'effect', 'predictor_variable', 'odds', 'higher', 'rather', 'lower', 'category', 'example', 'suppose', 'odds_ratio', 'bending', '30', 'used', 'descending', 'option', 'categorysevere', 'first', 'ordered', 'category', 'categorynone', 'last', 'ordered', 'category', 'interpret', 'odds_ratio', 'stating', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '3', 'time', 'odds', 'higher', 'pain', 'severity', 'category', 'compared', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain']"
319,SUBJECT=	identifies subjects in the input data set. This is a required option and the variables used in defining the subjects must be listed in the CLASS statement. The input data set does not need to be sorted by subject. TYPE=	specifies the structure of the working correlation matrix used to model the correlation of responses from subjects. The default working correlation type is the independent correlation structure.,CD,423,"['subject\tidentifies', 'subject', 'input', 'data_set', 'required', 'option', 'variable', 'used', 'defining', 'subject', 'must', 'listed', 'class', 'statement', 'input', 'data_set', 'doe', 'need', 'sorted', 'subject', 'type\tspecifies', 'structure', 'working', 'correlation', 'matrix', 'used', 'model', 'correlation', 'response', 'subject', 'default', 'working', 'correlation', 'type', 'independent', 'correlation_structure']"
320,"The forward selection method selected three different models when you changed the options. Allowing single effects to enter the model at one step did not detect any significant interactions, whereas allowing multiple effects to enter the model at one step put two nonsignificant interactions in the model.",CD,305,"['forward', 'selection', 'method', 'selected', 'three', 'different', 'model', 'changed', 'option', 'allowing', 'single', 'effect', 'enter', 'model', 'one', 'step', 'detect', 'significant', 'interaction', 'whereas', 'allowing', 'multiple', 'effect', 'enter', 'model', 'one', 'step', 'put', 'two', 'nonsignificant', 'interaction', 'model']"
321,"Generating the exact conditional distribution becomes unfeasible with a large number of observations. For example, if you had 30 observations you would have to scan 230 or more than a billion different sequences of the binary response values. However, PROC LOGISTIC has several numerical algorithms that use faster methods of generating and counting the response value vectors for larger problems. The multivariate shift algorithm developed by Hirji, Mehta, and Patel (1987) is invoked using the METHOD=DIRECT option. This method uses a number of shortcuts in a brand and bound algorithm to build the exact distribution, but it may require an excessive amount of memory in its intermediate stages. The METHOD=NETWORK option invokes a method (described in Mehta, Patel, and Senchaudhuri (1992)) that is faster and requires less memory than the DIRECT method. The NETWORK method is invoked by default for most analyses. Finally, the METHOD=NETWORKMC option invokes a hybrid network and a Monte Carlo sampling algorithm (described in Mehta, Patel, and Senchaudhuri (2000)) that samples from the combined network to estimate the exact distribution. This method is most useful for producing parameter estimates for problems that are too large for the DIRECT and NETWORK methods to handle and for which the asymptotic methods are invalid (sparse data on a large grid). ?	Monte Carlo simulation is performed using random sampling from the probability density functions. This is different than a bootstrapped sample where you sample with replacement from a given data set, compute statistics, and repeat many times. With bootstrapping, you are basically creating a distribution for a target statistic. The Monte Carlo algorithm starts with a network where every path through the network corresponds to a sequence with the correct sufficient statistics. Then the algorithm does a weighted random traversal of the network to sample a binary sequence to create a sampled distribution.",CD,1973,"['generating', 'exact', 'conditional', 'distribution', 'becomes', 'unfeasible', 'large', 'number', 'observation', 'example', '30', 'observation', 'would', 'scan', '230', 'billion', 'different', 'sequence', 'binary', 'response', 'value', 'however', 'proc_logistic', 'ha', 'several', 'numerical', 'algorithm', 'use', 'faster', 'method', 'generating', 'counting', 'response', 'value', 'vector', 'larger', 'problem', 'multivariate', 'shift', 'algorithm', 'developed', 'hirji', 'mehta', 'patel', '1987', 'invoked', 'using', 'methoddirect', 'option', 'method', 'us', 'number', 'shortcut', 'brand', 'bound', 'algorithm', 'build', 'exact', 'distribution', 'may', 'require', 'excessive', 'amount', 'memory', 'intermediate', 'stage', 'methodnetwork', 'option', 'invokes', 'method', 'described', 'mehta', 'patel', 'senchaudhuri', '1992', 'faster', 'requires', 'le', 'memory', 'direct', 'method', 'network', 'method', 'invoked', 'default', 'analysis', 'finally', 'methodnetworkmc', 'option', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'sampling', 'algorithm', 'described', 'mehta', 'patel', 'senchaudhuri', '2000', 'sample', 'combined', 'network', 'estimate', 'exact', 'distribution', 'method', 'useful', 'producing', 'parameter_estimate', 'problem', 'large', 'direct', 'network', 'method', 'handle', 'asymptotic', 'method', 'invalid', 'sparse', 'data', 'large', 'grid', '\tmonte', 'carlo', 'simulation', 'performed', 'using', 'random', 'sampling', 'probability', 'density', 'function', 'different', 'bootstrapped', 'sample', 'sample', 'replacement', 'given', 'data_set', 'compute', 'statistic', 'repeat', 'many', 'time', 'bootstrapping', 'basically', 'creating', 'distribution', 'target', 'statistic', 'monte', 'carlo', 'algorithm', 'start', 'network', 'every', 'path', 'network', 'corresponds', 'sequence', 'correct', 'sufficient', 'statistic', 'algorithm', 'doe', 'weighted', 'random', 'traversal', 'network', 'sample', 'binary', 'sequence', 'create', 'sampled', 'distribution']"
322,"The CONTRAST statement is made up of the following components: label	identifies the contrast in the output. A label is required for every contrast specified, and it must 	be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement. You do not need to include all effects that are included in the MODEL statement. values	identifies the coefficients associated with the effect. To correctly specify your contrast, it is crucial to know the ordering of the parameters within each effect and the variable levels associated with each parameter. If an effect is not specified in the CONTRAST statement, all of its coefficients are set to 0. If too many values are specified for an effect, the extra ones are ignored. If too few values are specified, the remaining ones are set to 0.",CD,803,"['contrast', 'statement', 'made', 'following', 'component', 'label\tidentifies', 'contrast', 'output', 'label', 'required', 'every', 'contrast', 'specified', 'must', '\tbe', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'need', 'include', 'effect', 'included', 'model_statement', 'values\tidentifies', 'coefficient', 'associated', 'effect', 'correctly', 'specify', 'contrast', 'crucial', 'know', 'ordering', 'parameter', 'within', 'effect', 'variable', 'level', 'associated', 'parameter', 'effect', 'specified', 'contrast', 'statement', 'coefficient', 'set', '0', 'many', 'value', 'specified', 'effect', 'extra', 'one', 'ignored', 'value', 'specified', 'remaining', 'one', 'set', '0']"
323,"The TRACE statement produces a trace record of each output object, including the name and label. The LISTING option writes this information, interleaved with the procedure output, to the SAS listing. Partial Output Low Birth Weight Model",CD,237,"['trace', 'statement', 'produce', 'trace', 'record', 'output', 'object', 'including', 'name', 'label', 'listing', 'option', 'writes', 'information', 'interleaved', 'procedure', 'output', 'sa', 'listing', 'partial', 'output', 'low', 'birth', 'weight', 'model']"
324,"In Chapter 1, you saw how the quasi-complete separation of data points leads to convergence problems in logistic regression. In the example above, level B is a perfect predictor of the outcome. In this situation, the log-likelihood function cannot be maximized but approaches a finite upper bound as the parameter estimate for B goes to negative infinity. You cannot evaluate the first and second derivatives of the log-likelihood at the maximum likelihood estimates, and it is not possible to estimate the parameter estimate for the contrast of level B to C or its confidence interval by conventional maximum likelihood methods. However, exact inference is possible and can provide valid inferences in this situation. Notice that the contrast of level B to C had a p-value approaching 1 with the asymptotic methods but is statistically significant with the exact methods. Note that the exact tests do not produce standard errors for the estimates. Furthermore, the parameter estimate for the contrast of level B to C is a median unbiased estimate, which will be discussed later. ?	In SAS 9.2 PROC LOGISTIC will compute standard errors for the exact estimates.",CD,1160,"['chapter', '1', 'saw', 'quasicomplete', 'separation', 'data', 'point', 'lead', 'convergence', 'problem', 'logistic_regression', 'example', 'level', 'b', 'perfect', 'predictor', 'outcome', 'situation', 'loglikelihood', 'function', 'cannot', 'maximized', 'approach', 'finite', 'upper', 'bound', 'parameter_estimate', 'b', 'go', 'negative', 'infinity', 'cannot', 'evaluate', 'first', 'second', 'derivative', 'loglikelihood', 'maximum', 'likelihood', 'estimate', 'possible', 'estimate', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'confidence', 'interval', 'conventional', 'maximum', 'likelihood', 'method', 'however', 'exact', 'inference', 'possible', 'provide', 'valid', 'inference', 'situation', 'notice', 'contrast', 'level', 'b', 'c', 'pvalue', 'approaching', '1', 'asymptotic', 'method', 'statistically', 'significant', 'exact', 'method', 'note', 'exact', 'test', 'produce', 'standard_error', 'estimate', 'furthermore', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'median', 'unbiased', 'estimate', 'discussed', 'later', '\tin', 'sa', '92', 'proc_logistic', 'compute', 'standard_error', 'exact', 'estimate']"
325,"Based on subject-matter knowledge, one variable was selected from each cluster. Backache in previous pregnancy is a class variable because the levels can be considered nominal (1=not applicable, 2=no, 3=yes). The next step is to build an ordinal logistic regression model in PROC LOGISTIC. A reasonable approach is to search for interactions using forward selection with a very conservative significance level for entry. Then eliminate predictor variables that are not involved in any interactions, are clearly not significant, are not potential confounders, and have no subject-matter importance. Fitting Multiple Ordinal Logistic Regression Models",CD,649,"['based', 'subjectmatter', 'knowledge', 'one', 'variable', 'wa', 'selected', 'cluster', 'backache', 'previous', 'pregnancy', 'class', 'variable', 'level', 'considered', 'nominal', '1not', 'applicable', '2no', '3yes', 'next', 'step', 'build', 'ordinal', 'logistic_regression_model', 'proc_logistic', 'reasonable', 'approach', 'search', 'interaction', 'using', 'forward', 'selection', 'conservative', 'significance', 'level', 'entry', 'eliminate', 'predictor_variable', 'involved', 'interaction', 'clearly', 'significant', 'potential', 'confounders', 'subjectmatter', 'importance', 'fitting', 'multiple', 'ordinal', 'logistic_regression_model']"
326,"The table shown above shows the difference between discordant and concordant pairs. For all pairs of observations with different outcomes (in this example, having a low birth weight baby), a comparison is made of the predicted outcome probabilities. If the observation with the outcome has a higher predicted outcome probability compared to an observation without the outcome, the pair is concordant. However, if the observation with the outcome has a lower predicted outcome probability compared to the predicted outcome probability of an observation without the outcome, the pair is discordant. If the predicted outcome probabilities are the same, the pair is tied. Binary Logistic Regression (continued)",CD,706,"['table', 'shown', 'show', 'difference', 'discordant', 'concordant', 'pair', 'pair', 'observation', 'different', 'outcome', 'example', 'low', 'birth', 'weight', 'baby', 'comparison', 'made', 'predicted', 'outcome', 'probability', 'observation', 'outcome', 'ha', 'higher', 'predicted', 'outcome', 'probability', 'compared', 'observation', 'without', 'outcome', 'pair', 'concordant', 'however', 'observation', 'outcome', 'ha', 'lower', 'predicted', 'outcome', 'probability', 'compared', 'predicted', 'outcome', 'probability', 'observation', 'without', 'outcome', 'pair', 'discordant', 'predicted', 'outcome', 'probability', 'pair', 'tied', 'binary', 'logistic_regression', 'continued']"
327,"In this course, contrasts are used to compute the odds ratio that compares one level of a CLASS variable to another level. However, in order to construct a contrast, you need to be able to define the coefficients for the test of the hypothesis. For example, to compute the odds ratio that compares low to medium for the variable socio in a CONTRAST statement, you should first write the model equation for each of the levels.",CD,425,"['course', 'contrast', 'used', 'compute', 'odds_ratio', 'compare', 'one', 'level', 'class', 'variable', 'another', 'level', 'however', 'order', 'construct', 'contrast', 'need', 'able', 'define', 'coefficient', 'test', 'hypothesis', 'example', 'compute', 'odds_ratio', 'compare', 'low', 'medium', 'variable', 'socio', 'contrast', 'statement', 'first', 'write', 'model', 'equation', 'level']"
328,"GEE regression models are very popular because clustered data is common in many fields of research. For example, a physician might evaluate patients at weekly intervals in a clinical drug trial. A family study on liver cancer might want to estimate the degree of association between liver cancer and members of the same family to examine the possible genetic explanation of the disease process. A dental study might measure the extent of tooth decay for each tooth in a subject?s mouth. A common feature of these studies is that repeated categorical response data is collected and the independence assumption is violated.",CD,621,"['gee', 'regression_model', 'popular', 'clustered', 'data', 'common', 'many', 'field', 'research', 'example', 'physician', 'might', 'evaluate', 'patient', 'weekly', 'interval', 'clinical', 'drug', 'trial', 'family', 'study', 'liver', 'cancer', 'might', 'want', 'estimate', 'degree', 'association', 'liver', 'cancer', 'member', 'family', 'examine', 'possible', 'genetic', 'explanation', 'disease', 'process', 'dental', 'study', 'might', 'measure', 'extent', 'tooth', 'decay', 'tooth', 'subject', 'mouth', 'common', 'feature', 'study', 'repeated', 'categorical', 'response', 'data', 'collected', 'independence', 'assumption', 'violated']"
329,"The exchangeable correlation structure (TYPE=EXCH) assumes that the correlations are equal across time points. Although this structure may not be justified in longitudinal studies, it is often reasonable in situations where the repeated measurements are not obtained over time (Allison 1999). For example, the exchangeable correlation structure might be a good choice if the independent experimental units were classrooms and the responses obtained were from each student in the classroom (Davis 2002).",CD,502,"['exchangeable', 'correlation_structure', 'typeexch', 'assumes', 'correlation', 'equal', 'across', 'time', 'point', 'although', 'structure', 'may', 'justified', 'longitudinal', 'study', 'often', 'reasonable', 'situation', 'repeated', 'measurement', 'obtained', 'time', 'allison', '1999', 'example', 'exchangeable', 'correlation_structure', 'might', 'good', 'choice', 'independent', 'experimental', 'unit', 'classroom', 'response', 'obtained', 'student', 'classroom', 'davis', '2002']"
330,Total Proportion Minimum Maximum Minimum Maximum Number Variation of Variation Proportion Second R-squared 1-R**2 Ratio of Explained Explained Explained Eigenvalue for a for a Clusters by Clusters by Clusters by a Cluster in a Cluster Variable Variable,CD,252,"['total', 'proportion', 'minimum', 'maximum', 'minimum', 'maximum', 'number', 'variation', 'variation', 'proportion', 'second', 'rsquared', '1r2', 'ratio', 'explained', 'explained', 'explained', 'eigenvalue', 'cluster', 'cluster', 'cluster', 'cluster', 'cluster', 'variable', 'variable']"
331,"PROC LOGISTIC also produces statistics that measure predictive power. These statistics are not the same as the goodness-of-fit statistics because models with high predictive power do not necessarily have a good fit to the data (and vice versa). One statistic that measures predictive power is the generalized R2. It is based on the likelihood ratio chi-square for testing the null hypothesis that all of the slope parameters are 0. However, it uses the likelihood values (L1 and L0) rather than the log- likelihood values and it is adjusted by the sample size n. It can be interpreted in the same way as the rank correlation statistics in PROC LOGISTIC. The higher the statistic, the more predictive power your model has. However, it cannot be interpreted as the proportion of variance explained by the predictor variables. Therefore, it is inappropriate to compare the generalized R2 to the linear model?s R2 (Allison 1999). Goodness-of-Fit Statistics and Predictive Power",CD,973,"['proc_logistic', 'also', 'produce', 'statistic', 'measure', 'predictive', 'power', 'statistic', 'goodnessoffit', 'statistic', 'model', 'high', 'predictive', 'power', 'necessarily', 'good', 'fit', 'data', 'vice', 'versa', 'one', 'statistic', 'measure', 'predictive', 'power', 'generalized', 'r2', 'based', 'likelihood', 'ratio', 'chisquare', 'testing', 'null', 'hypothesis', 'slope', 'parameter', '0', 'however', 'us', 'likelihood', 'value', 'l1', 'l0', 'rather', 'log', 'likelihood', 'value', 'adjusted', 'sample_size', 'n', 'interpreted', 'way', 'rank', 'correlation', 'statistic', 'proc_logistic', 'higher', 'statistic', 'predictive', 'power', 'model', 'ha', 'however', 'cannot', 'interpreted', 'proportion', 'variance', 'explained', 'predictor_variable', 'therefore', 'inappropriate', 'compare', 'generalized', 'r2', 'linear', 'model', 'r2', 'allison', '1999', 'goodnessoffit', 'statistic', 'predictive', 'power']"
332,"One way to identify possible contributing factors to low birth weight is to build a linear probability model where the outcome is the probability of having a low birth weight baby. Such a model implies that the probability of low birth weight is a linear function of the predictor variables. The regression coefficients would therefore have a straightforward interpretation in this model. For example, you can estimate the change in the probability of low birth weight, given a one-unit change in alcohol. Unfortunately, the linear probability model has some serious shortcomings. The predicted values from a linear model can assume, theoretically, any value. However, probabilities are by definition bounded between 0 and 1. Thus, the model can only be valid over a finite range of predictor variable values. A more appropriate model would somehow constrain the predicted probabilities to be between 0 and 1. Another shortcoming is that the observed relationship between the probability of an outcome and the predictor variables is usually nonlinear rather than linear. For example, a one-unit change in the predictor variable may have less impact when the probability is near 0 or 1 than when the probability is near .50. In fact, the relationship often resembles an S-shaped curve rather than a linear function (Hosmer and Lemeshow 2000).",CD,1341,"['one', 'way', 'identify', 'possible', 'contributing', 'factor', 'low', 'birth', 'weight', 'build', 'linear', 'probability', 'model', 'outcome', 'probability', 'low', 'birth', 'weight', 'baby', 'model', 'implies', 'probability', 'low', 'birth', 'weight', 'linear', 'function', 'predictor_variable', 'regression', 'coefficient', 'would', 'therefore', 'straightforward', 'interpretation', 'model', 'example', 'estimate', 'change', 'probability', 'low', 'birth', 'weight', 'given', 'oneunit', 'change', 'alcohol', 'unfortunately', 'linear', 'probability', 'model', 'ha', 'serious', 'shortcoming', 'predicted', 'value', 'linear', 'model', 'assume', 'theoretically', 'value', 'however', 'probability', 'definition', 'bounded', '0', '1', 'thus', 'model', 'valid', 'finite', 'range', 'predictor_variable', 'value', 'appropriate', 'model', 'would', 'somehow', 'constrain', 'predicted', 'probability', '0', '1', 'another', 'shortcoming', 'observed', 'relationship', 'probability', 'outcome', 'predictor_variable', 'usually', 'nonlinear', 'rather', 'linear', 'example', 'oneunit', 'change', 'predictor_variable', 'may', 'le', 'impact', 'probability', 'near', '0', '1', 'probability', 'near', '50', 'fact', 'relationship', 'often', 'resembles', 'sshaped', 'curve', 'rather', 'linear', 'function', 'hosmer', 'lemeshow', '2000']"
333,"The equation for the logistic regression model that refers directly to the probability of the outcome is shown above. This equation has the desired property that the predicted probabilities will always be between 0 and 1. This model is nonlinear because the parameter estimates do not enter the model equation linearly. Furthermore, the model permits the rate of change of the probabilities to vary as the predictor variable values vary.",CD,437,"['equation', 'logistic_regression_model', 'refers', 'directly', 'probability', 'outcome', 'shown', 'equation', 'ha', 'desired', 'property', 'predicted', 'probability', 'always', '0', '1', 'model', 'nonlinear', 'parameter_estimate', 'enter', 'model', 'equation', 'linearly', 'furthermore', 'model', 'permit', 'rate', 'change', 'probability', 'vary', 'predictor_variable', 'value', 'vary']"
334,HISTOGRAM	creates histograms using high-resolution graphics. Selected HISTOGRAM statement options: CFILL=	specifies the color to fill the histogram bars. CBARLINE=	specifies the color of the outline of the histogram bars.,CD,221,"['histogram\tcreates', 'histogram', 'using', 'highresolution', 'graphic', 'selected', 'histogram', 'statement', 'option', 'cfill\tspecifies', 'color', 'fill', 'histogram', 'bar', 'cbarline\tspecifies', 'color', 'outline', 'histogram', 'bar']"
335,"The conditional logistic model takes into account the dependence of the matched pairs with the stratum-specific intercepts. Ignoring the strata will bias the inferences just like ignoring the clusters in the GEE models. However, dummy-coding the strata is not satisfactory either, unless there is a small number of clusters and a large number of observations per cluster. In the asymptotic theory of maximum likelihood estimation, it is assumed that as the number of observations gets large the number of parameters remains constant. In a matched 1:1 case-control study, you would have to estimate n-1 intercepts (n equaling the number of strata). This leads to the incidental parameters problem where the number of parameters increases as the number of observations increases (Kalbfleisch and Sprott 1970). This will lead to very substantial bias in the parameter estimates because you need a large sample size relative to the number of parameters.",CD,949,"['conditional', 'logistic', 'model', 'take', 'account', 'dependence', 'matched', 'pair', 'stratumspecific', 'intercept', 'ignoring', 'stratum', 'bias', 'inference', 'like', 'ignoring', 'cluster', 'gee', 'model', 'however', 'dummycoding', 'stratum', 'satisfactory', 'either', 'unless', 'small', 'number', 'cluster', 'large', 'number', 'observation', 'per', 'cluster', 'asymptotic', 'theory', 'maximum', 'likelihood', 'estimation', 'assumed', 'number', 'observation', 'get', 'large', 'number', 'parameter', 'remains', 'constant', 'matched', '11', 'casecontrol', 'study', 'would', 'estimate', 'n1', 'intercept', 'n', 'equaling', 'number', 'stratum', 'lead', 'incidental', 'parameter', 'problem', 'number', 'parameter', 'increase', 'number', 'observation', 'increase', 'kalbfleisch', 'sprott', '1970', 'lead', 'substantial', 'bias', 'parameter_estimate', 'need', 'large', 'sample_size', 'relative', 'number', 'parameter']"
336,"Example:	An insurance company wants to relate the safety of vehicles to several other variables. A score has been given to each vehicle model, using the frequency of insurance claims as a basis. The data is in the sasuser.safety data set. The variables in the data set are safety	safety score (1=Below Average, 0=Average or Above) type	type of vehicle (Sports, Small, Medium, Large, and Sport/Utility) region	manufacturing region (Asia, N America) weight	weight of the vehicle in thousands of pounds. Recall from the exercises that the logistic model for the car safety data detected quasi-complete separation of data. This occurred because none of the large cars had below average safety records. The parameter estimate and standard error for the large effect were deemed unreliable. Fitting Exact Logistic Regression Models with the Hybrid Network ? Monte Carlo Algorithm Example:	Fit an exact logistic regression model using the Monte Carlo algorithm with safety as the response variable and type, region, and weight as the predictor variables. Model the probability of below average safety scores and request that the individual parameters and the odds ratios be estimated. Specify type and region as classification variables using reference cell coding. Specify Small as the reference level for type and Asia as the reference level for region. Also, add the observed sufficient statistic to the sampled exact distribution, specify that 100,000 Monte Carlo samples be taken, and set the seed at 27514. /* c3demo19a */ proc logistic data=sasuser.safety exactoptions(method=networkmc addtobs n=100000 seed=27514); class type (param=ref ref='Small') region (param=ref ref='Asia'); model safety = type region weight; exact type weight region / estimate=both; title 'Car Safety Model'; run; PROC LOGISTIC statement options: EXACTOPTIONS(options)	specifies options that apply to every EXACT statement in the program. Selected EXACTOPTIONS options: ADDTOBS	adds the observed sufficient statistic to the sampled exact distribution if the statistic was not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified and the ESTIMATE option is specified in the EXACT statement. If the observed statistic has not been sampled, then the parameter estimate does not exist: by specifying this option, you can produce (biased) estimates. METHOD=	specifies which exact conditional algorithm to use for every EXACT statement specified. The keywords are DIRECT (invokes the multivariate shift algorithm), NETWORK (invokes a network algorithm) and NETWORKMC (invokes the hybrid network and Monte Carlo algorithm). N=	specifies the number of Monte Carlo samples to take when METHOD=NETWORKMC. By default n=10,000. SEED=	specifies the initial seed for the random number generator used to take the Monte Carlo samples for METHOD=NETWORKMC. The value of the SEED= option must be an integer. If you do not specify a seed, or if you specify a value less than or equal to zero, then PROC LOGISTIC uses the time of day from the computer?s clock to generate the initial seed. Car Safety Model",CD,3092,"['example\tan', 'insurance', 'company', 'want', 'relate', 'safety', 'vehicle', 'several', 'variable', 'score', 'ha', 'given', 'vehicle', 'model', 'using', 'frequency', 'insurance', 'claim', 'basis', 'data', 'sasusersafety', 'data_set', 'variable', 'data_set', 'safety\tsafety', 'score', '1below', 'average', '0average', 'type\ttype', 'vehicle', 'sport', 'small', 'medium', 'large', 'sportutility', 'region\tmanufacturing', 'region', 'asia', 'n', 'america', 'weight\tweight', 'vehicle', 'thousand', 'pound', 'recall', 'exercise', 'logistic', 'model', 'car', 'safety', 'data', 'detected', 'quasicomplete', 'separation', 'data', 'occurred', 'none', 'large', 'car', 'average', 'safety', 'record', 'parameter_estimate', 'standard_error', 'large', 'effect', 'deemed', 'unreliable', 'fitting', 'exact', 'logistic_regression_model', 'hybrid', 'network', '', 'monte', 'carlo', 'algorithm', 'example\tfit', 'exact', 'logistic_regression_model', 'using', 'monte', 'carlo', 'algorithm', 'safety', 'response_variable', 'type', 'region', 'weight', 'predictor_variable', 'model', 'probability', 'average', 'safety', 'score', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'specify', 'type', 'region', 'classification', 'variable', 'using', 'reference', 'cell', 'coding', 'specify', 'small', 'reference', 'level', 'type', 'asia', 'reference', 'level', 'region', 'also', 'add', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'specify', '100000', 'monte', 'carlo', 'sample', 'taken', 'set', 'seed', '27514', '', 'c3demo19a', '', 'proc_logistic', 'datasasusersafety', 'exactoptionsmethodnetworkmc', 'addtobs', 'n100000', 'seed27514', 'class', 'type', 'paramref', 'refsmall', 'region', 'paramref', 'refasia', 'model', 'safety', '', 'type', 'region', 'weight', 'exact', 'type', 'weight', 'region', '', 'estimateboth', 'title', 'car', 'safety', 'model', 'run', 'proc_logistic', 'statement', 'option', 'exactoptionsoptions\tspecifies', 'option', 'apply', 'every', 'exact', 'statement', 'program', 'selected', 'exactoptions', 'option', 'addtobs\tadds', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'statistic', 'wa', 'sampled', 'option', 'ha', 'effect', 'unless', 'methodnetworkmc', 'option', 'specified', 'estimate', 'option', 'specified', 'exact', 'statement', 'observed', 'statistic', 'ha', 'sampled', 'parameter_estimate', 'doe', 'exist', 'specifying', 'option', 'produce', 'biased', 'estimate', 'method\tspecifies', 'exact', 'conditional', 'algorithm', 'use', 'every', 'exact', 'statement', 'specified', 'keywords', 'direct', 'invokes', 'multivariate', 'shift', 'algorithm', 'network', 'invokes', 'network', 'algorithm', 'networkmc', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'algorithm', 'n\tspecifies', 'number', 'monte', 'carlo', 'sample', 'take', 'methodnetworkmc', 'default', 'n10000', 'seed\tspecifies', 'initial', 'seed', 'random', 'number', 'generator', 'used', 'take', 'monte', 'carlo', 'sample', 'methodnetworkmc', 'value', 'seed', 'option', 'must', 'integer', 'specify', 'seed', 'specify', 'value', 'le', 'equal', 'zero', 'proc_logistic', 'us', 'time', 'day', 'computer', 'clock', 'generate', 'initial', 'seed', 'car', 'safety', 'model']"
337,"The DIFDEV and DIFCHISQ are diagnostics for detecting which observations contribute heavily to the disagreement between the data and the predicted values of the fitted model. The range of DIFCHISQ is much greater then DIFDEV. DFBETAS are diagnostics that can be used to assess the effect of an individual observation on each estimated parameter of the fitted model. These statistics are useful in detecting observations that are causing instability in the selected parameter estimates. Instead of re-estimating the parameter each time an observation is deleted, PROC LOGISTIC uses the one-step estimate. C and CBAR are confidence interval displacement diagnostics. These statistics are based on the same idea as the Cook distance in linear regression. PROC LOGISTIC also computes these using the one-step estimate. H is the hat matrix diagonal. The diagonal elements of the hat matrix are useful in detecting extreme points in the design space. However, if the estimated probability is extreme (less than 0.1 and greater than 0.9), then the hat diagonal may be greatly reduced in value. Consequently, when an observation has a very large or very small estimated probability, its hat diagonal value is not a good indicator of the observation?s distance from the design space (Hosmer and Lemeshow 2000). The deviance residuals (contribution of each observation to the deviance chi-square) and Pearson residuals (contribution of each observation to the Pearson chi-square) can also be used to determine which observations are poorly fit by the model.",CD,1547,"['difdev', 'difchisq', 'diagnostics', 'detecting', 'observation', 'contribute', 'heavily', 'disagreement', 'data', 'predicted', 'value', 'fitted', 'model', 'range', 'difchisq', 'much', 'greater', 'difdev', 'dfbetas', 'diagnostics', 'used', 'ass', 'effect', 'individual', 'observation', 'estimated', 'parameter', 'fitted', 'model', 'statistic', 'useful', 'detecting', 'observation', 'causing', 'instability', 'selected', 'parameter_estimate', 'instead', 'reestimating', 'parameter', 'time', 'observation', 'deleted', 'proc_logistic', 'us', 'onestep', 'estimate', 'c', 'cbar', 'confidence', 'interval', 'displacement', 'diagnostics', 'statistic', 'based', 'idea', 'cook', 'distance', 'linear', 'regression', 'proc_logistic', 'also', 'computes', 'using', 'onestep', 'estimate', 'h', 'hat', 'matrix', 'diagonal', 'diagonal', 'element', 'hat', 'matrix', 'useful', 'detecting', 'extreme', 'point', 'design', 'space', 'however', 'estimated', 'probability', 'extreme', 'le', '01', 'greater', '09', 'hat', 'diagonal', 'may', 'greatly', 'reduced', 'value', 'consequently', 'observation', 'ha', 'large', 'small', 'estimated', 'probability', 'hat', 'diagonal', 'value', 'good', 'indicator', 'observation', 'distance', 'design', 'space', 'hosmer', 'lemeshow', '2000', 'deviance', 'residual', 'contribution', 'observation', 'deviance', 'chisquare', 'pearson', 'residual', 'contribution', 'observation', 'pearson', 'chisquare', 'also', 'used', 'determine', 'observation', 'poorly', 'fit', 'model']"
338,"The exchangeable correlation structure (TYPE=EXCH) assumes that the correlations are equal across time points. Although this structure may not be justified in longitudinal studies, it is often reasonable in situations where the repeated measurements are not obtained over time (Allison 1999). For example, the exchangeable correlation structure might be a good choice if the independent experimental units were classrooms and the responses obtained were from each student in the classroom (Davis 2002).",CD,502,"['exchangeable', 'correlation_structure', 'typeexch', 'assumes', 'correlation', 'equal', 'across', 'time', 'point', 'although', 'structure', 'may', 'justified', 'longitudinal', 'study', 'often', 'reasonable', 'situation', 'repeated', 'measurement', 'obtained', 'time', 'allison', '1999', 'example', 'exchangeable', 'correlation_structure', 'might', 'good', 'choice', 'independent', 'experimental', 'unit', 'classroom', 'response', 'obtained', 'student', 'classroom', 'davis', '2002']"
339,"For continuous predictor variables with a large number of unique values, binning the data (collapsing data values into groups) is necessary to compute the logit. The bin size should have an adequate number of observations to reduce the sample variability of the logits. If the standard logistic regression model adequately fits the data, the logit plots should be fairly linear. The above graph shows a predictor variable that meets the assumption of linearity in the logit.",CD,474,"['continuous', 'predictor_variable', 'large', 'number', 'unique', 'value', 'binning', 'data', 'collapsing', 'data', 'value', 'group', 'necessary', 'compute', 'logit', 'bin', 'size', 'adequate', 'number', 'observation', 'reduce', 'sample', 'variability', 'logits', 'standard', 'logistic_regression_model', 'adequately', 'fit', 'data', 'logit', 'plot', 'fairly', 'linear', 'graph', 'show', 'predictor_variable', 'meet', 'assumption', 'linearity', 'logit']"
340,"In nominal logistic regression, the logit is now a generalized logit. If k is the number of categories for the outcome variable, then the number of generalized logits is k-1. The last category is the reference category or the denominator of each logit.",CD,252,"['nominal', 'logistic_regression', 'logit', 'generalized', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'generalized', 'logits', 'k1', 'last', 'category', 'reference', 'category', 'denominator', 'logit']"
341,"Because the mother_age*phy_visit interaction is significant, you need to compute two odds ratios for mother?s age. One odds ratio is for mothers who did visit the physician during the first trimester; the other is for mothers who did not visit the physician during the first trimester. These odds ratios can be computed using the coefficients in the model. To compute the odds ratio of interest, write out the equation for the odds ratio. Solve the expression algebraically and exponentiate the final estimate. The example above shows that among women who went to a physician during the first trimester, women who are 10 years younger are 4.95 times more likely to have a low birth weight baby.",CD,694,"['motheragephyvisit', 'interaction', 'significant', 'need', 'compute', 'two', 'odds_ratio', 'mother', 'age', 'one', 'odds_ratio', 'mother', 'visit', 'physician', 'first', 'trimester', 'mother', 'visit', 'physician', 'first', 'trimester', 'odds_ratio', 'computed', 'using', 'coefficient', 'model', 'compute', 'odds_ratio', 'interest', 'write', 'equation', 'odds_ratio', 'solve', 'expression', 'algebraically', 'exponentiate', 'final', 'estimate', 'example', 'show', 'among', 'woman', 'went', 'physician', 'first', 'trimester', 'woman', '10', 'year', 'younger', '495', 'time', 'likely', 'low', 'birth', 'weight', 'baby']"
342,"Mother_age is the matching variable that is constant within the strata. Therefore, the parameter estimate for Mother_age is 0. The matching variable can be used in interactions however. Model Fit Statistics",CD,206,"['motherage', 'matching', 'variable', 'constant', 'within', 'stratum', 'therefore', 'parameter_estimate', 'motherage', '0', 'matching', 'variable', 'used', 'interaction', 'however', 'model', 'fit', 'statistic']"
343,"The LOGISTIC procedure enables you to specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. Model hierarchy refers to the requirement that for any effect in the model, all effects it contains must also be in the model. For example, in order for the interaction A*B to enter the model, the main effects A and B must be in the model. Model hierarchy is desirable because models that are hierarchically well formulated have inferences that are invariant to the coding you choose for your predictor variables (Kleinbaum, Kupper, and Muller 1988). If the model is not hierarchically well formulated, then the tests for the lower order terms will depend on the coding (reference versus effect coding for categorical variables). The HIERARCHY= option specifies whether hierarchy is maintained and whether a single effect or multiple effects are allowed to enter or leave the model in one step for SELECTION=FORWARD, SELECTION=BACKWARD, and SELECTION=STEPWISE. For HIERARCHY=SINGLE, only one effect can enter or leave the model at one time, subject to model hierarchy. For example, suppose that you specify the main effects A and B and the interaction of A*B in the model. For backward elimination, the interaction A*B must first be removed before the main effects are removed. For forward selection, the main effects must enter the model before the interaction. For HIERARCHY=MULTIPLE, more than one effect can enter or leave the model at one time, subject to model hierarchy. For forward selection, a single main effect can enter the model or an interaction can enter the model together with all the effects that are contained in the interaction. Backward selection can remove an interaction itself or the interaction together with all the effects that the interaction contains. If you do not want to have model hierarchy, specify HIERARCHY=NONE. In that case, any single effect can enter or leave the model at any given step of the selection process. The default is HIERARCHY=SINGLE.",CD,2087,"['logistic', 'procedure', 'enables', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'model', 'hierarchy', 'refers', 'requirement', 'effect', 'model', 'effect', 'contains', 'must', 'also', 'model', 'example', 'order', 'interaction', 'ab', 'enter', 'model', 'main_effect', 'b', 'must', 'model', 'model', 'hierarchy', 'desirable', 'model', 'hierarchically', 'well', 'formulated', 'inference', 'invariant', 'coding', 'choose', 'predictor_variable', 'kleinbaum', 'kupper', 'muller', '1988', 'model', 'hierarchically', 'well', 'formulated', 'test', 'lower', 'order', 'term', 'depend', 'coding', 'reference', 'versus', 'effect', 'coding', 'categorical', 'variable', 'hierarchy', 'option', 'specifies', 'whether', 'hierarchy', 'maintained', 'whether', 'single', 'effect', 'multiple', 'effect', 'allowed', 'enter', 'leave', 'model', 'one', 'step', 'selectionforward', 'selectionbackward', 'selectionstepwise', 'hierarchysingle', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'example', 'suppose', 'specify', 'main_effect', 'b', 'interaction', 'ab', 'model', 'backward', 'elimination', 'interaction', 'ab', 'must', 'first', 'removed', 'main_effect', 'removed', 'forward', 'selection', 'main_effect', 'must', 'enter', 'model', 'interaction', 'hierarchymultiple', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'forward', 'selection', 'single', 'main_effect', 'enter', 'model', 'interaction', 'enter', 'model', 'together', 'effect', 'contained', 'interaction', 'backward', 'selection', 'remove', 'interaction', 'interaction', 'together', 'effect', 'interaction', 'contains', 'want', 'model', 'hierarchy', 'specify', 'hierarchynone', 'case', 'single', 'effect', 'enter', 'leave', 'model', 'given', 'step', 'selection', 'process', 'default', 'hierarchysingle']"
344,"MAXEIGEN=n	specifies the largest permissible value of the second eigenvalue in each cluster. SHORT	suppresses printing of the cluster structure, scoring coefficient, and intercluster correlation matrices. Selected VARCLUS procedure statement: VAR	specifies the variables to be clustered. If you do not specify the VAR statement, all numeric variables not listed in other statements are processed. Variable Clustering",CD,416,"['maxeigenn\tspecifies', 'largest', 'permissible', 'value', 'second', 'eigenvalue', 'cluster', 'short\tsuppresses', 'printing', 'cluster', 'structure', 'scoring', 'coefficient', 'intercluster', 'correlation', 'matrix', 'selected', 'varclus', 'procedure', 'statement', 'var\tspecifies', 'variable', 'clustered', 'specify', 'var', 'statement', 'numeric', 'variable', 'listed', 'statement', 'processed', 'variable', 'clustering']"
345,"Generating the exact conditional distribution becomes unfeasible with a large number of observations. For example, if you had 30 observations you would have to scan 230 or more than a billion different sequences of the binary response values. However, PROC LOGISTIC has several numerical algorithms that use faster methods of generating and counting the response value vectors for larger problems. The multivariate shift algorithm developed by Hirji, Mehta, and Patel (1987) is invoked using the METHOD=DIRECT option. This method uses a number of shortcuts in a brand and bound algorithm to build the exact distribution, but it may require an excessive amount of memory in its intermediate stages. The METHOD=NETWORK option invokes a method (described in Mehta, Patel, and Senchaudhuri (1992)) that is faster and requires less memory than the DIRECT method. The NETWORK method is invoked by default for most analyses. Finally, the METHOD=NETWORKMC option invokes a hybrid network and a Monte Carlo sampling algorithm (described in Mehta, Patel, and Senchaudhuri (2000)) that samples from the combined network to estimate the exact distribution. This method is most useful for producing parameter estimates for problems that are too large for the DIRECT and NETWORK methods to handle and for which the asymptotic methods are invalid (sparse data on a large grid). ?	Monte Carlo simulation is performed using random sampling from the probability density functions. This is different than a bootstrapped sample where you sample with replacement from a given data set, compute statistics, and repeat many times. With bootstrapping, you are basically creating a distribution for a target statistic. The Monte Carlo algorithm starts with a network where every path through the network corresponds to a sequence with the correct sufficient statistics. Then the algorithm does a weighted random traversal of the network to sample a binary sequence to create a sampled distribution.",CD,1973,"['generating', 'exact', 'conditional', 'distribution', 'becomes', 'unfeasible', 'large', 'number', 'observation', 'example', '30', 'observation', 'would', 'scan', '230', 'billion', 'different', 'sequence', 'binary', 'response', 'value', 'however', 'proc_logistic', 'ha', 'several', 'numerical', 'algorithm', 'use', 'faster', 'method', 'generating', 'counting', 'response', 'value', 'vector', 'larger', 'problem', 'multivariate', 'shift', 'algorithm', 'developed', 'hirji', 'mehta', 'patel', '1987', 'invoked', 'using', 'methoddirect', 'option', 'method', 'us', 'number', 'shortcut', 'brand', 'bound', 'algorithm', 'build', 'exact', 'distribution', 'may', 'require', 'excessive', 'amount', 'memory', 'intermediate', 'stage', 'methodnetwork', 'option', 'invokes', 'method', 'described', 'mehta', 'patel', 'senchaudhuri', '1992', 'faster', 'requires', 'le', 'memory', 'direct', 'method', 'network', 'method', 'invoked', 'default', 'analysis', 'finally', 'methodnetworkmc', 'option', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'sampling', 'algorithm', 'described', 'mehta', 'patel', 'senchaudhuri', '2000', 'sample', 'combined', 'network', 'estimate', 'exact', 'distribution', 'method', 'useful', 'producing', 'parameter_estimate', 'problem', 'large', 'direct', 'network', 'method', 'handle', 'asymptotic', 'method', 'invalid', 'sparse', 'data', 'large', 'grid', '\tmonte', 'carlo', 'simulation', 'performed', 'using', 'random', 'sampling', 'probability', 'density', 'function', 'different', 'bootstrapped', 'sample', 'sample', 'replacement', 'given', 'data_set', 'compute', 'statistic', 'repeat', 'many', 'time', 'bootstrapping', 'basically', 'creating', 'distribution', 'target', 'statistic', 'monte', 'carlo', 'algorithm', 'start', 'network', 'every', 'path', 'network', 'corresponds', 'sequence', 'correct', 'sufficient', 'statistic', 'algorithm', 'doe', 'weighted', 'random', 'traversal', 'network', 'sample', 'binary', 'sequence', 'create', 'sampled', 'distribution']"
346,"The LOGISTIC procedure enables you to specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. Model hierarchy refers to the requirement that for any effect in the model, all effects it contains must also be in the model. For example, in order for the interaction A*B to enter the model, the main effects A and B must be in the model. Model hierarchy is desirable because models that are hierarchically well formulated have inferences that are invariant to the coding you choose for your predictor variables (Kleinbaum, Kupper, and Muller 1988). If the model is not hierarchically well formulated, then the tests for the lower order terms will depend on the coding (reference versus effect coding for categorical variables). The HIERARCHY= option specifies whether hierarchy is maintained and whether a single effect or multiple effects are allowed to enter or leave the model in one step for SELECTION=FORWARD, SELECTION=BACKWARD, and SELECTION=STEPWISE. For HIERARCHY=SINGLE, only one effect can enter or leave the model at one time, subject to model hierarchy. For example, suppose that you specify the main effects A and B and the interaction of A*B in the model. For backward elimination, the interaction A*B must first be removed before the main effects are removed. For forward selection, the main effects must enter the model before the interaction. For HIERARCHY=MULTIPLE, more than one effect can enter or leave the model at one time, subject to model hierarchy. For forward selection, a single main effect can enter the model or an interaction can enter the model together with all the effects that are contained in the interaction. Backward selection can remove an interaction itself or the interaction together with all the effects that the interaction contains. If you do not want to have model hierarchy, specify HIERARCHY=NONE. In that case, any single effect can enter or leave the model at any given step of the selection process. The default is HIERARCHY=SINGLE.",CD,2087,"['logistic', 'procedure', 'enables', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'model', 'hierarchy', 'refers', 'requirement', 'effect', 'model', 'effect', 'contains', 'must', 'also', 'model', 'example', 'order', 'interaction', 'ab', 'enter', 'model', 'main_effect', 'b', 'must', 'model', 'model', 'hierarchy', 'desirable', 'model', 'hierarchically', 'well', 'formulated', 'inference', 'invariant', 'coding', 'choose', 'predictor_variable', 'kleinbaum', 'kupper', 'muller', '1988', 'model', 'hierarchically', 'well', 'formulated', 'test', 'lower', 'order', 'term', 'depend', 'coding', 'reference', 'versus', 'effect', 'coding', 'categorical', 'variable', 'hierarchy', 'option', 'specifies', 'whether', 'hierarchy', 'maintained', 'whether', 'single', 'effect', 'multiple', 'effect', 'allowed', 'enter', 'leave', 'model', 'one', 'step', 'selectionforward', 'selectionbackward', 'selectionstepwise', 'hierarchysingle', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'example', 'suppose', 'specify', 'main_effect', 'b', 'interaction', 'ab', 'model', 'backward', 'elimination', 'interaction', 'ab', 'must', 'first', 'removed', 'main_effect', 'removed', 'forward', 'selection', 'main_effect', 'must', 'enter', 'model', 'interaction', 'hierarchymultiple', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'forward', 'selection', 'single', 'main_effect', 'enter', 'model', 'interaction', 'enter', 'model', 'together', 'effect', 'contained', 'interaction', 'backward', 'selection', 'remove', 'interaction', 'interaction', 'together', 'effect', 'interaction', 'contains', 'want', 'model', 'hierarchy', 'specify', 'hierarchynone', 'case', 'single', 'effect', 'enter', 'leave', 'model', 'given', 'step', 'selection', 'process', 'default', 'hierarchysingle']"
347,"If you do not know which working correlation structure to choose, one recommendation is to compare the parameter estimates and standard errors from several different correlation structures. This might indicate whether there is sensitivity to the misspecification of the correlation structure. PROC GENMOD also enables you to choose a user-defined correlation matrix.",CD,366,"['know', 'working', 'correlation_structure', 'choose', 'one', 'recommendation', 'compare', 'parameter_estimate', 'standard_error', 'several', 'different', 'correlation_structure', 'might', 'indicate', 'whether', 'sensitivity', 'misspecification', 'correlation_structure', 'proc', 'genmod', 'also', 'enables', 'choose', 'userdefined', 'correlation', 'matrix']"
348,"The routine use of matching is seldom justified (Rothman 1986). For example, if matching does not improve study efficiency, then the effort expended in finding matched subjects would have been better spent in gathering information for a greater number of unmatched subjects. Furthermore, matching does not prevent confounding but rather introduces confounding. Therefore, it is recommended to use an analysis that removes the confounding by the matching factors since matching might cause confounding even when none existed. Finally, matching might lead to overmatching which will increase the number of uninformative strata and decrease study efficiency. For example, matching on a variable that has a strong correlation with an important exposure variable and that has no relation to the outcome might lead to overmatching because it will lead to relatively few informative strata with no offsetting gain (Rothman 1986). Kleinbaum (1991) recommends that the safest strategy is to match only on strong risk factors expected to cause confounding in the data.",CD,1058,"['routine', 'use', 'matching', 'seldom', 'justified', 'rothman', '1986', 'example', 'matching', 'doe', 'improve', 'study', 'efficiency', 'effort', 'expended', 'finding', 'matched', 'subject', 'would', 'better', 'spent', 'gathering', 'information', 'greater', 'number', 'unmatched', 'subject', 'furthermore', 'matching', 'doe', 'prevent', 'confounding', 'rather', 'introduces', 'confounding', 'therefore', 'recommended', 'use', 'analysis', 'remove', 'confounding', 'matching', 'factor', 'since', 'matching', 'might', 'cause', 'confounding', 'even', 'none', 'existed', 'finally', 'matching', 'might', 'lead', 'overmatching', 'increase', 'number', 'uninformative', 'stratum', 'decrease', 'study', 'efficiency', 'example', 'matching', 'variable', 'ha', 'strong', 'correlation', 'important', 'exposure', 'variable', 'ha', 'relation', 'outcome', 'might', 'lead', 'overmatching', 'lead', 'relatively', 'informative', 'stratum', 'offsetting', 'gain', 'rothman', '1986', 'kleinbaum', '1991', 'recommends', 'safest', 'strategy', 'match', 'strong', 'risk', 'factor', 'expected', 'cause', 'confounding', 'data']"
349,"The distribution of predicted probabilities is slightly skewed, but each bar has an adequate percentage of observations. Therefore, create a classification table where the cutoffs range from .1 to .9 by .1.",CD,206,"['distribution', 'predicted', 'probability', 'slightly', 'skewed', 'bar', 'ha', 'adequate', 'percentage', 'observation', 'therefore', 'create', 'classification', 'table', 'cutoff', 'range', '1', '9', '1']"
350,HISTOGRAM	creates histograms using high-resolution graphics. Selected HISTOGRAM statement options: CFILL=	specifies the color to fill the histogram bars. CBARLINE=	specifies the color of the outline of the histogram bars.,CD,221,"['histogram\tcreates', 'histogram', 'using', 'highresolution', 'graphic', 'selected', 'histogram', 'statement', 'option', 'cfill\tspecifies', 'color', 'fill', 'histogram', 'bar', 'cbarline\tspecifies', 'color', 'outline', 'histogram', 'bar']"
351,"The CONTRAST statement is made up of the following components: label	identifies the contrast in the output. A label is required for every contrast specified, and it must 	be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement. You do not need to include all effects that are included in the MODEL statement. values	identifies the coefficients associated with the effect. To correctly specify your contrast, it is crucial to know the ordering of the parameters within each effect and the variable levels associated with each parameter. If an effect is not specified in the CONTRAST statement, all of its coefficients are set to 0. If too many values are specified for an effect, the extra ones are ignored. If too few values are specified, the remaining ones are set to 0.",CD,803,"['contrast', 'statement', 'made', 'following', 'component', 'label\tidentifies', 'contrast', 'output', 'label', 'required', 'every', 'contrast', 'specified', 'must', '\tbe', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'need', 'include', 'effect', 'included', 'model_statement', 'values\tidentifies', 'coefficient', 'associated', 'effect', 'correctly', 'specify', 'contrast', 'crucial', 'know', 'ordering', 'parameter', 'within', 'effect', 'variable', 'level', 'associated', 'parameter', 'effect', 'specified', 'contrast', 'statement', 'coefficient', 'set', '0', 'many', 'value', 'specified', 'effect', 'extra', 'one', 'ignored', 'value', 'specified', 'remaining', 'one', 'set', '0']"
352,The chi-square test of association shows that there is strong evidence that an association exists between prev_pretrm and low. Fisher?s exact test is not needed because of the large sample size. Statistics for Table of prev_pretrm by low,CD,237,"['chisquare', 'test', 'association', 'show', 'strong', 'evidence', 'association', 'exists', 'prevpretrm', 'low', 'fisher', 'exact', 'test', 'needed', 'large', 'sample_size', 'statistic', 'table', 'prevpretrm', 'low']"
353,"Finally, the unstructured correlation structure (TYPE=UNSTR) is completely unspecified. Therefore, there are t(t?1)/2 parameters to be estimated (where t is the number of time points). Although the unstructured working correlation structure is the most efficient, it is useful only when there are very few observation times. If there were many time points, you would probably want to impose some structure to the correlation matrix by selecting one of the other correlation structures (Allison 1999). Furthermore, when there are missing values or a varying number of observations per subject, a nonpositive definite matrix may occur, which would stop the parameter estimation process (Stokes, Davis, and Koch 2000).",CD,715,"['finally', 'unstructured', 'correlation_structure', 'typeunstr', 'completely', 'unspecified', 'therefore', 'tt12', 'parameter', 'estimated', 'number', 'time', 'point', 'although', 'unstructured', 'working', 'correlation_structure', 'efficient', 'useful', 'observation', 'time', 'many', 'time', 'point', 'would', 'probably', 'want', 'impose', 'structure', 'correlation', 'matrix', 'selecting', 'one', 'correlation_structure', 'allison', '1999', 'furthermore', 'missing', 'value', 'varying', 'number', 'observation', 'per', 'subject', 'nonpositive', 'definite', 'matrix', 'may', 'occur', 'would', 'stop', 'parameter', 'estimation', 'process', 'stokes', 'davis', 'koch', '2000']"
354,"Least squares estimators for the model parameters are not used in logistic regression because the variance of the outcome is not constant across the values of the predictor variable. Because of the nonconstant variance, least squares parameter estimates are not efficient (other estimation methods yield smaller standard errors) and the standard error estimates are not consistent (the estimated standard errors could be biased). Therefore, the method of maximum likelihood is used to produce estimators that are consistent, asymptotically efficient, and asymptotically normal. This method finds the parameter estimates that are most likely to occur, given the data, by maximizing the likelihood function, which expresses the probability of the observed data as a function of the unknown parameters.",CD,799,"['least', 'square', 'estimator', 'model', 'parameter', 'used', 'logistic_regression', 'variance', 'outcome', 'constant', 'across', 'value', 'predictor_variable', 'nonconstant', 'variance', 'least', 'square', 'parameter_estimate', 'efficient', 'estimation', 'method', 'yield', 'smaller', 'standard_error', 'standard_error', 'estimate', 'consistent', 'estimated', 'standard_error', 'could', 'biased', 'therefore', 'method', 'maximum', 'likelihood', 'used', 'produce', 'estimator', 'consistent', 'asymptotically', 'efficient', 'asymptotically', 'normal', 'method', 'find', 'parameter_estimate', 'likely', 'occur', 'given', 'data', 'maximizing', 'likelihood', 'function', 'express', 'probability', 'observed', 'data', 'function', 'unknown', 'parameter']"
355,"Example:	Compute the deviance and Pearson chi-square statistics, the Hosmer-Lemeshow test, and the generalized R2 statistic on the model with all of the main effects and the mother_age*phy_visit interaction. /* c2demo09a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / aggregate scale=none lackfit rsq; title 'Low Birth Weight Model'; run; Selected MODEL statement options: AGGREGATE	requests that PROC LOGISTIC treat each unique combination of the predictor variable values as a distinct group in computing the goodness-of-fit statistics. SCALE=	specifies the value of the dispersion parameter or the method for estimating the dispersion parameter. This option is normally used to correct for overdispersion or underdispersion, but in this case it is required to display the goodness-of-fit statistics. LACKFIT	performs the Hosmer and Lemeshow goodness-of-fit test for the case of a binary outcome model. RSQ	requests a generalized R2 for the fitted model. Partial Output Deviance and Pearson Goodness-of-Fit Statistics",CD,1131,"['example\tcompute', 'deviance', 'pearson', 'chisquare', 'statistic', 'hosmerlemeshow', 'test', 'generalized', 'r2', 'statistic', 'model', 'main_effect', 'motheragephyvisit', 'interaction', '', 'c2demo09a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'aggregate', 'scalenone', 'lackfit', 'rsq', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'aggregate\trequests', 'proc_logistic', 'treat', 'unique', 'combination', 'predictor_variable', 'value', 'distinct', 'group', 'computing', 'goodnessoffit', 'statistic', 'scale\tspecifies', 'value', 'dispersion', 'parameter', 'method', 'estimating', 'dispersion', 'parameter', 'option', 'normally', 'used', 'correct', 'overdispersion', 'underdispersion', 'case', 'required', 'display', 'goodnessoffit', 'statistic', 'lackfit\tperforms', 'hosmer', 'lemeshow', 'goodnessoffit', 'test', 'case', 'binary', 'outcome', 'model', 'rsq\trequests', 'generalized', 'r2', 'fitted', 'model', 'partial', 'output', 'deviance', 'pearson', 'goodnessoffit', 'statistic']"
356,"Variable clustering is based on principal components. Principal components are weighted linear combinations of the predictor variables where the weights are chosen to account for the largest amount of variation in the data; total variation in this case is the sum of the sample variances of the predictor variables. The principal components are numbered according to how much variation in the data is accounted for (first principal component accounts for the largest, second principal component accounts for the second largest, and so on) and each principal component accounts for a unique portion of the variation in the data. In other words, they are not correlated.",CD,668,"['variable', 'clustering', 'based', 'principal', 'component', 'principal', 'component', 'weighted', 'linear', 'combination', 'predictor_variable', 'weight', 'chosen', 'account', 'largest', 'amount', 'variation', 'data', 'total', 'variation', 'case', 'sum', 'sample', 'variance', 'predictor_variable', 'principal', 'component', 'numbered', 'according', 'much', 'variation', 'data', 'accounted', 'first', 'principal', 'component', 'account', 'largest', 'second', 'principal', 'component', 'account', 'second', 'largest', 'principal', 'component', 'account', 'unique', 'portion', 'variation', 'data', 'word', 'correlated']"
357,"The stepwise selection with HIERARCHY=SINGLE selected the same model as the forward selection method with HIERARCHY=SINGLE. This makes sense because both methods start with an empty model and select variables based on their significance. Stepwise selection has a backward component, which was not used in this case because all of the selected variables maintained their significance. The six techniques (not including forward and backward selection that included the main effects) selected four different models. This illustrates the precariousness of relying on these techniques to formulate a final model. However, the problem is not in the selection techniques, but rather in the analyst who fails to carefully scrutinize the resulting model and reports the results as the best model. Hosmer and Lemeshow (2000) commented as follows: The wide availability and ease with which stepwise methods can be used has undoubtedly reduced some analysts to a role where they are assisting the computer in model selection rather than the more appropriate alternative. It is only when the analyst understands the strengths, and especially the limitations, of the methods that these methods can serve as a useful tool in the model-building process. Best Subsets Selection",CD,1260,"['stepwise', 'selection', 'hierarchysingle', 'selected', 'model', 'forward', 'selection', 'method', 'hierarchysingle', 'make', 'sense', 'method', 'start', 'empty', 'model', 'select', 'variable', 'based', 'significance', 'stepwise', 'selection', 'ha', 'backward', 'component', 'wa', 'used', 'case', 'selected', 'variable', 'maintained', 'significance', 'six', 'technique', 'including', 'forward', 'backward', 'selection', 'included', 'main_effect', 'selected', 'four', 'different', 'model', 'illustrates', 'precariousness', 'relying', 'technique', 'formulate', 'final', 'model', 'however', 'problem', 'selection', 'technique', 'rather', 'analyst', 'fails', 'carefully', 'scrutinize', 'resulting', 'model', 'report', 'result', 'best', 'model', 'hosmer', 'lemeshow', '2000', 'commented', 'follows', 'wide', 'availability', 'ease', 'stepwise', 'method', 'used', 'ha', 'undoubtedly', 'reduced', 'analyst', 'role', 'assisting', 'computer', 'model', 'selection', 'rather', 'appropriate', 'alternative', 'analyst', 'understands', 'strength', 'especially', 'limitation', 'method', 'method', 'serve', 'useful', 'tool', 'modelbuilding', 'process', 'best', 'subset', 'selection']"
358,"The contingency table analysis revealed that several variables had very small numbers in their levels (the details of the analysis were omitted to save time and space). Therefore, several variables had levels collapsed and several predictor variables were eliminated from the analysis. For example, there was only one woman whose bowel action aggravated her back pain. Therefore, a total of 16 predictor variables were selected for the analysis.",CD,445,"['contingency', 'table', 'analysis', 'revealed', 'several', 'variable', 'small', 'number', 'level', 'detail', 'analysis', 'omitted', 'save', 'time', 'space', 'therefore', 'several', 'variable', 'level', 'collapsed', 'several', 'predictor_variable', 'eliminated', 'analysis', 'example', 'wa', 'one', 'woman', 'whose', 'bowel', 'action', 'aggravated', 'back', 'pain', 'therefore', 'total', '16', 'predictor_variable', 'selected', 'analysis']"
359,"The independent correlation structure (TYPE=IND) forces the off-diagonals to be 0. Therefore, no working correlation structure is estimated in this case. Under this constraint, the coefficients and model-based standard errors (requested by the MODELSE option in the REPEATED statement) are the same as those reported in the LOGISTIC procedure. However, PROC GENMOD, by default, computes robust standard error estimates. These estimates take into account the correlations among the repeated measurements and usually are different from the model-based standard errors assuming independence. The independent correlation structure might be a good choice when you have a large number of subjects with few measurements per subject. The correlation influence is often small enough to have little impact on the regression coefficients, but the robust standard errors will give the correct inferences. This model gives consistent estimates of the parameters and standard errors when the mean model is correctly specified (Davis 2002).",CD,1025,"['independent', 'correlation_structure', 'typeind', 'force', 'offdiagonals', '0', 'therefore', 'working', 'correlation_structure', 'estimated', 'case', 'constraint', 'coefficient', 'modelbased', 'standard_error', 'requested', 'modelse', 'option', 'repeated', 'statement', 'reported', 'logistic', 'procedure', 'however', 'proc', 'genmod', 'default', 'computes', 'robust', 'standard_error', 'estimate', 'estimate', 'take', 'account', 'correlation', 'among', 'repeated', 'measurement', 'usually', 'different', 'modelbased', 'standard_error', 'assuming', 'independence', 'independent', 'correlation_structure', 'might', 'good', 'choice', 'large', 'number', 'subject', 'measurement', 'per', 'subject', 'correlation', 'influence', 'often', 'small', 'enough', 'little', 'impact', 'regression', 'coefficient', 'robust', 'standard_error', 'give', 'correct', 'inference', 'model', 'give', 'consistent', 'estimate', 'parameter', 'standard_error', 'mean', 'model', 'correctly', 'specified', 'davis', '2002']"
360,"The distribution of predicted probabilities is slightly skewed, but each bar has an adequate percentage of observations. Therefore, create a classification table where the cutoffs range from .1 to .9 by .1.",CD,206,"['distribution', 'predicted', 'probability', 'slightly', 'skewed', 'bar', 'ha', 'adequate', 'percentage', 'observation', 'therefore', 'create', 'classification', 'table', 'cutoff', 'range', '1', '9', '1']"
361,"An estimator of a parameter is said to be median unbiased if 	 and	 The formula shows that if the probability is greater than or equal to .50 on both sides of beta, then the estimated beta is median unbiased. The median unbiased estimators (MUE) of the parameters of a logistic model can be computed from the distribution of sufficient statistics for the parameters. A Newton-Raphson-type algorithm is used to perform the search for the MUE that corresponds to the median of the conditional distribution of the sufficient statistics for the parameters. Hirji, Tsiatis, and Mehta (1989) compared the accuracy of the MUE with that of the maximum likelihood estimator (MLE) for a logistic regression model with two binary covariates. The MUE was shown to be uniformly more accurate than MLE for small to moderately large sample sizes and a broad range of parameter values. The authors recommend that median unbiased estimation be used as an alternative to maximum likelihood estimation when the data structure is sparse.",CD,1017,"['estimator', 'parameter', 'said', 'median', 'unbiased', '\t', 'and\t', 'formula', 'show', 'probability', 'greater', 'equal', '50', 'side', 'beta', 'estimated', 'beta', 'median', 'unbiased', 'median', 'unbiased', 'estimator', 'mue', 'parameter', 'logistic', 'model', 'computed', 'distribution', 'sufficient', 'statistic', 'parameter', 'newtonraphsontype', 'algorithm', 'used', 'perform', 'search', 'mue', 'corresponds', 'median', 'conditional', 'distribution', 'sufficient', 'statistic', 'parameter', 'hirji', 'tsiatis', 'mehta', '1989', 'compared', 'accuracy', 'mue', 'maximum', 'likelihood', 'estimator', 'mle', 'logistic_regression_model', 'two', 'binary', 'covariates', 'mue', 'wa', 'shown', 'uniformly', 'accurate', 'mle', 'small', 'moderately', 'large', 'sample_size', 'broad', 'range', 'parameter', 'value', 'author', 'recommend', 'median', 'unbiased', 'estimation', 'used', 'alternative', 'maximum', 'likelihood', 'estimation', 'data', 'structure', 'sparse']"
362,"The deviance and Pearson chi-squares are two goodness-of-fit statistics produced in PROC LOGISTIC. These statistics compare the fitted model to a saturated model. The saturated model, which has one parameter for every predicted probability, always fits the data better. However, if these statistics are not significant, then the difference in fit could be explained by chance. A significant chi-square means that there is a model that fits the data better than your model. With the AGGREGATE and SCALE=NONE options, PROC LOGISTIC computes the chi-squares by cross-classifying all the levels of the predictor variables. For each combination of levels, the observed and expected frequencies for each level of the outcome variable are then calculated based on the fitted model. The deviance chi-square is then calculated as where Oj and Ej are the observed and expected frequencies in cell j. The Pearson chi-square is calculated as , which is testing the same null hypothesis as the deviance chi-square test. A problem with these statistics is the sample size requirements. For these statistics to follow a chi- square distribution, there must be an average of at least 10 observations in each cell. Furthermore, at least 80% of the expected frequencies should be 5 or more and all other expected counts should be greater than 2. There should also be no empty cells (Stokes, Davis, Koch 2000).",CD,1391,"['deviance', 'pearson', 'chisquares', 'two', 'goodnessoffit', 'statistic', 'produced', 'proc_logistic', 'statistic', 'compare', 'fitted', 'model', 'saturated', 'model', 'saturated', 'model', 'ha', 'one', 'parameter', 'every', 'predicted', 'probability', 'always', 'fit', 'data', 'better', 'however', 'statistic', 'significant', 'difference', 'fit', 'could', 'explained', 'chance', 'significant', 'chisquare', 'mean', 'model', 'fit', 'data', 'better', 'model', 'aggregate', 'scalenone', 'option', 'proc_logistic', 'computes', 'chisquares', 'crossclassifying', 'level', 'predictor_variable', 'combination', 'level', 'observed', 'expected', 'frequency', 'level', 'outcome', 'variable', 'calculated', 'based', 'fitted', 'model', 'deviance', 'chisquare', 'calculated', 'oj', 'ej', 'observed', 'expected', 'frequency', 'cell', 'j', 'pearson', 'chisquare', 'calculated', '', 'testing', 'null', 'hypothesis', 'deviance', 'chisquare', 'test', 'problem', 'statistic', 'sample_size', 'requirement', 'statistic', 'follow', 'chi', 'square', 'distribution', 'must', 'average', 'least', '10', 'observation', 'cell', 'furthermore', 'least', '80', 'expected', 'frequency', '5', 'expected', 'count', 'greater', '2', 'also', 'empty', 'cell', 'stokes', 'davis', 'koch', '2000']"
363,"After the model fit has been assessed using summary statistics, it is important to identify which observations are poorly fit and which observations have a great deal of influence on the values of the estimated parameters. The LOGISTIC procedure produces a number of statistics that are designed to detect outliers and influential observations. Most of these statistics measure how much some aspect of the model changes when a particular observation is deleted. After identifying these observations, you can begin to address the role they play in the analysis.",CD,560,"['model', 'fit', 'ha', 'assessed', 'using', 'summary', 'statistic', 'important', 'identify', 'observation', 'poorly', 'fit', 'observation', 'great', 'deal', 'influence', 'value', 'estimated', 'parameter', 'logistic', 'procedure', 'produce', 'number', 'statistic', 'designed', 'detect', 'outlier', 'influential', 'observation', 'statistic', 'measure', 'much', 'aspect', 'model', 'change', 'particular', 'observation', 'deleted', 'identifying', 'observation', 'begin', 'address', 'role', 'play', 'analysis']"
364,"PROC LOGISTIC estimates a separate intercept for each cumulative logit. However, PROC LOGISTIC does not estimate a separate slope for each cumulative logit, but rather a common slope across the cumulative logits for each predictor variable. This common slope is a weighted average across the logits. Therefore, a parallel-lines regression model is fitted in which each curve that describes the cumulative probabilities has the same shape. The only difference in the curves is the difference between the values of the intercept parameters. This model is called a proportional odds model.",CD,586,"['proc_logistic', 'estimate', 'separate', 'intercept', 'cumulative', 'logit', 'however', 'proc_logistic', 'doe', 'estimate', 'separate', 'slope', 'cumulative', 'logit', 'rather', 'common', 'slope', 'across', 'cumulative', 'logits', 'predictor_variable', 'common', 'slope', 'weighted', 'average', 'across', 'logits', 'therefore', 'parallellines', 'regression_model', 'fitted', 'curve', 'describes', 'cumulative', 'probability', 'ha', 'shape', 'difference', 'curve', 'difference', 'value', 'intercept', 'parameter', 'model', 'called', 'proportional', 'odds', 'model']"
365,"Unfortunately, the distributions of the diagnostic statistics are not known, so cutoff values cannot be given for determining when the values are large (Pregibon 1981). Therefore, you have to rely on visual inspection of these statistics. Hosmer and Lemeshow (2000) recommend plotting the influence statistics such as the change in the Pearson chi-square against the predicted values. Graphing these influence statistics may enable you to identify those covariate patterns (subjects) that are poorly fit by the model. Examination of these patterns may indicate that important variables are missing from the model or that some of the variables in the model have not been entered in the correct scale. These patterns may also identify erroneous data values. The plot above is a plot of the change in the Pearson chi-square statistic by the predicted probabilities. The points on the curve going from the upper-left to the lower-right corner correspond to the covariate patterns with a response value of 1. The points on the curve going from the upper- right to the lower-left corners correspond to the covariate patterns with a response value of 0. Covariate patterns that are poorly fit by the model will lie in the upper-right and left corners of the plot. Hosmer and Lemeshow (2000) suggest that values of the change in the Pearson chi-square statistic above 4 are potential outliers. ?	Another graph that can be used to identify influential observations and outliers in relatively small data sets is the index plot. In an index plot, the diagnostic statistic is plotted against the observation number. This enables visual inspection and comparison of the values across observations. If the model is correctly specified and fits all observations well, then no extreme points should appear. The IPLOTS option in the MODEL statement requests an index plot for each regression diagnostic statistic.",CD,1896,"['unfortunately', 'distribution', 'diagnostic', 'statistic', 'known', 'cutoff', 'value', 'cannot', 'given', 'determining', 'value', 'large', 'pregibon', '1981', 'therefore', 'rely', 'visual', 'inspection', 'statistic', 'hosmer', 'lemeshow', '2000', 'recommend', 'plotting', 'influence', 'statistic', 'change', 'pearson', 'chisquare', 'predicted', 'value', 'graphing', 'influence', 'statistic', 'may', 'enable', 'identify', 'covariate', 'pattern', 'subject', 'poorly', 'fit', 'model', 'examination', 'pattern', 'may', 'indicate', 'important', 'variable', 'missing', 'model', 'variable', 'model', 'entered', 'correct', 'scale', 'pattern', 'may', 'also', 'identify', 'erroneous', 'data', 'value', 'plot', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'point', 'curve', 'going', 'upperleft', 'lowerright', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '1', 'point', 'curve', 'going', 'upper', 'right', 'lowerleft', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '0', 'covariate', 'pattern', 'poorly', 'fit', 'model', 'lie', 'upperright', 'left', 'corner', 'plot', 'hosmer', 'lemeshow', '2000', 'suggest', 'value', 'change', 'pearson', 'chisquare', 'statistic', '4', 'potential', 'outlier', '\tanother', 'graph', 'used', 'identify', 'influential', 'observation', 'outlier', 'relatively', 'small', 'data_set', 'index', 'plot', 'index', 'plot', 'diagnostic', 'statistic', 'plotted', 'observation', 'number', 'enables', 'visual', 'inspection', 'comparison', 'value', 'across', 'observation', 'model', 'correctly', 'specified', 'fit', 'observation', 'well', 'extreme', 'point', 'appear', 'iplots', 'option', 'model_statement', 'request', 'index', 'plot', 'regression', 'diagnostic', 'statistic']"
366,"The table shown above shows the difference between discordant and concordant pairs. For all pairs of observations with different outcomes (in this example, having a low birth weight baby), a comparison is made of the predicted outcome probabilities. If the observation with the outcome has a higher predicted outcome probability compared to an observation without the outcome, the pair is concordant. However, if the observation with the outcome has a lower predicted outcome probability compared to the predicted outcome probability of an observation without the outcome, the pair is discordant. If the predicted outcome probabilities are the same, the pair is tied. Binary Logistic Regression (continued)",CD,706,"['table', 'shown', 'show', 'difference', 'discordant', 'concordant', 'pair', 'pair', 'observation', 'different', 'outcome', 'example', 'low', 'birth', 'weight', 'baby', 'comparison', 'made', 'predicted', 'outcome', 'probability', 'observation', 'outcome', 'ha', 'higher', 'predicted', 'outcome', 'probability', 'compared', 'observation', 'without', 'outcome', 'pair', 'concordant', 'however', 'observation', 'outcome', 'ha', 'lower', 'predicted', 'outcome', 'probability', 'compared', 'predicted', 'outcome', 'probability', 'observation', 'without', 'outcome', 'pair', 'discordant', 'predicted', 'outcome', 'probability', 'pair', 'tied', 'binary', 'logistic_regression', 'continued']"
367,"The process of fitting a GEE model can be summarized in a series of steps. First, a regression model is fitted that assumes independence and the Pearson standardized residuals are computed. These residuals are then used to estimate the parameters of the correlation matrix, which characterizes the correlation of the observations within subject. The correlation parameters are then incorporated into the GEE estimating equations, which generates new values for the regression coefficients and new Pearson residuals. These residuals are then used to re-estimate the correlation parameters. The cyclical process continues until the parameter estimates stabilize and model convergence is achieved. !	For more information, see the SAS online documentation.",CD,752,"['process', 'fitting', 'gee', 'model', 'summarized', 'series', 'step', 'first', 'regression_model', 'fitted', 'assumes', 'independence', 'pearson', 'standardized', 'residual', 'computed', 'residual', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'characterizes', 'correlation', 'observation', 'within', 'subject', 'correlation', 'parameter', 'incorporated', 'gee', 'estimating', 'equation', 'generates', 'new', 'value', 'regression', 'coefficient', 'new', 'pearson', 'residual', 'residual', 'used', 'reestimate', 'correlation', 'parameter', 'cyclical', 'process', 'continues', 'parameter_estimate', 'stabilize', 'model', 'convergence', 'achieved', '\tfor', 'information', 'see', 'sa', 'online', 'documentation']"
368,"Conditional logistic regression is a useful technique when you have paired observations. One example is the matched case-control studies. In the past, the PHREG procedure was usually used to fit a conditional logistic regression model. However, in SAS?9 the STRATA statement in PROC LOGISTIC can be used to fit conditional logistic regression models. An important feature of the conditional logistic model is that the model requires the matched data to be considered in strata. The strata represent the matched sets (paired observations). These models also allow the probabilities to vary by observation within strata. Therefore, the models permit the strata to have their own probability distributions and they account for the dependence of the matched pairs. These models are known as the conditional models because the parameter estimate ? is defined conditional on the subject. The effect is subject-specific, because it is defined at the subject level. This is in contrast to the GEE models which were marginal models. The effects in those models are population-averaged because they refer to averaging over the entire population rather than to individual subjects. For example, in a matched case-control study the probabilities modeled refer to the distribution of Y given X. Although the model permits stratum-specific distributions, it assumes a common effect ?. The parameter ? compares the response distributions. It follows that the conditional model is restricted to estimating ? that are within stratum effects. Thus only the predictor variables that vary within stratum contribute to the likelihood. Conditional models do not estimate a between-stratum effect. Therefore, a predictor variable that is constant within stratum contributes nothing to the likelihood. This is why a coefficient is not estimated for the matching variables. However, the stratum-constant variables are still being controlled for in the model. It should be noted that when there are several observations per stratum, then the GEE models can be used. For 1:1 matched case-control studies, the estimated values in the working correlation matrix are ?1 and the GEE method breaks down. Therefore, the conditional model is the only way to go for case-control matching. A good discussion about the differences between GEE models and conditional logistic models can be found in Allison (1999).",CD,2376,"['conditional', 'logistic_regression', 'useful', 'technique', 'paired', 'observation', 'one', 'example', 'matched', 'casecontrol', 'study', 'past', 'phreg', 'procedure', 'wa', 'usually', 'used', 'fit', 'conditional', 'logistic_regression_model', 'however', 'sas9', 'stratum', 'statement', 'proc_logistic', 'used', 'fit', 'conditional', 'logistic_regression_model', 'important', 'feature', 'conditional', 'logistic', 'model', 'model', 'requires', 'matched', 'data', 'considered', 'stratum', 'stratum', 'represent', 'matched', 'set', 'paired', 'observation', 'model', 'also', 'allow', 'probability', 'vary', 'observation', 'within', 'stratum', 'therefore', 'model', 'permit', 'stratum', 'probability', 'distribution', 'account', 'dependence', 'matched', 'pair', 'model', 'known', 'conditional', 'model', 'parameter_estimate', '', 'defined', 'conditional', 'subject', 'effect', 'subjectspecific', 'defined', 'subject', 'level', 'contrast', 'gee', 'model', 'marginal', 'model', 'effect', 'model', 'populationaveraged', 'refer', 'averaging', 'entire', 'population', 'rather', 'individual', 'subject', 'example', 'matched', 'casecontrol', 'study', 'probability', 'modeled', 'refer', 'distribution', 'given', 'x', 'although', 'model', 'permit', 'stratumspecific', 'distribution', 'assumes', 'common', 'effect', '', 'parameter', '', 'compare', 'response', 'distribution', 'follows', 'conditional', 'model', 'restricted', 'estimating', '', 'within', 'stratum', 'effect', 'thus', 'predictor_variable', 'vary', 'within', 'stratum', 'contribute', 'likelihood', 'conditional', 'model', 'estimate', 'betweenstratum', 'effect', 'therefore', 'predictor_variable', 'constant', 'within', 'stratum', 'contributes', 'nothing', 'likelihood', 'coefficient', 'estimated', 'matching', 'variable', 'however', 'stratumconstant', 'variable', 'still', 'controlled', 'model', 'noted', 'several', 'observation', 'per', 'stratum', 'gee', 'model', 'used', '11', 'matched', 'casecontrol', 'study', 'estimated', 'value', 'working', 'correlation', 'matrix', '1', 'gee', 'method', 'break', 'therefore', 'conditional', 'model', 'way', 'go', 'casecontrol', 'matching', 'good', 'discussion', 'difference', 'gee', 'model', 'conditional', 'logistic', 'model', 'found', 'allison', '1999']"
369,"One way to identify possible contributing factors to low birth weight is to build a linear probability model where the outcome is the probability of having a low birth weight baby. Such a model implies that the probability of low birth weight is a linear function of the predictor variables. The regression coefficients would therefore have a straightforward interpretation in this model. For example, you can estimate the change in the probability of low birth weight, given a one-unit change in alcohol. Unfortunately, the linear probability model has some serious shortcomings. The predicted values from a linear model can assume, theoretically, any value. However, probabilities are by definition bounded between 0 and 1. Thus, the model can only be valid over a finite range of predictor variable values. A more appropriate model would somehow constrain the predicted probabilities to be between 0 and 1. Another shortcoming is that the observed relationship between the probability of an outcome and the predictor variables is usually nonlinear rather than linear. For example, a one-unit change in the predictor variable may have less impact when the probability is near 0 or 1 than when the probability is near .50. In fact, the relationship often resembles an S-shaped curve rather than a linear function (Hosmer and Lemeshow 2000).",CD,1341,"['one', 'way', 'identify', 'possible', 'contributing', 'factor', 'low', 'birth', 'weight', 'build', 'linear', 'probability', 'model', 'outcome', 'probability', 'low', 'birth', 'weight', 'baby', 'model', 'implies', 'probability', 'low', 'birth', 'weight', 'linear', 'function', 'predictor_variable', 'regression', 'coefficient', 'would', 'therefore', 'straightforward', 'interpretation', 'model', 'example', 'estimate', 'change', 'probability', 'low', 'birth', 'weight', 'given', 'oneunit', 'change', 'alcohol', 'unfortunately', 'linear', 'probability', 'model', 'ha', 'serious', 'shortcoming', 'predicted', 'value', 'linear', 'model', 'assume', 'theoretically', 'value', 'however', 'probability', 'definition', 'bounded', '0', '1', 'thus', 'model', 'valid', 'finite', 'range', 'predictor_variable', 'value', 'appropriate', 'model', 'would', 'somehow', 'constrain', 'predicted', 'probability', '0', '1', 'another', 'shortcoming', 'observed', 'relationship', 'probability', 'outcome', 'predictor_variable', 'usually', 'nonlinear', 'rather', 'linear', 'example', 'oneunit', 'change', 'predictor_variable', 'may', 'le', 'impact', 'probability', 'near', '0', '1', 'probability', 'near', '50', 'fact', 'relationship', 'often', 'resembles', 'sshaped', 'curve', 'rather', 'linear', 'function', 'hosmer', 'lemeshow', '2000']"
370,Example: 	Illustrate the mother?s age by physician visit interaction. First create a data set with the plotting points for the interaction. Score the data set with the plotting points and plot the predicted logits and predicted probabilities by the plotting points. /* c1demo07a */ proc univariate data=sasuser.birth; var mother_age; run; Partial Output Quantile Estimate,CD,371,"['example', '\tillustrate', 'mother', 'age', 'physician', 'visit', 'interaction', 'first', 'create', 'data_set', 'plotting', 'point', 'interaction', 'score', 'data_set', 'plotting', 'point', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', '', 'c1demo07a', '', 'proc', 'univariate', 'datasasuserbirth', 'var', 'motherage', 'run', 'partial', 'output', 'quantile', 'estimate']"
371,"However, when the model is fit with the main effects and the interaction term, the parameter estimates for the stratification variable and the interaction term along with their associated standard errors increase dramatically. The reason for the model instability is the presence of the 0 cell count when you stratify on the predictor variable. This problem should be detected during the stratified analysis of the predictor variables.",CD,435,"['however', 'model', 'fit', 'main_effect', 'interaction', 'term', 'parameter_estimate', 'stratification', 'variable', 'interaction', 'term', 'along', 'associated', 'standard_error', 'increase', 'dramatically', 'reason', 'model', 'instability', 'presence', '0', 'cell', 'count', 'stratify', 'predictor_variable', 'problem', 'detected', 'stratified', 'analysis', 'predictor_variable']"
372,"The conditional logistic model takes into account the dependence of the matched pairs with the stratum-specific intercepts. Ignoring the strata will bias the inferences just like ignoring the clusters in the GEE models. However, dummy-coding the strata is not satisfactory either, unless there is a small number of clusters and a large number of observations per cluster. In the asymptotic theory of maximum likelihood estimation, it is assumed that as the number of observations gets large the number of parameters remains constant. In a matched 1:1 case-control study, you would have to estimate n-1 intercepts (n equaling the number of strata). This leads to the incidental parameters problem where the number of parameters increases as the number of observations increases (Kalbfleisch and Sprott 1970). This will lead to very substantial bias in the parameter estimates because you need a large sample size relative to the number of parameters.",CD,949,"['conditional', 'logistic', 'model', 'take', 'account', 'dependence', 'matched', 'pair', 'stratumspecific', 'intercept', 'ignoring', 'stratum', 'bias', 'inference', 'like', 'ignoring', 'cluster', 'gee', 'model', 'however', 'dummycoding', 'stratum', 'satisfactory', 'either', 'unless', 'small', 'number', 'cluster', 'large', 'number', 'observation', 'per', 'cluster', 'asymptotic', 'theory', 'maximum', 'likelihood', 'estimation', 'assumed', 'number', 'observation', 'get', 'large', 'number', 'parameter', 'remains', 'constant', 'matched', '11', 'casecontrol', 'study', 'would', 'estimate', 'n1', 'intercept', 'n', 'equaling', 'number', 'stratum', 'lead', 'incidental', 'parameter', 'problem', 'number', 'parameter', 'increase', 'number', 'observation', 'increase', 'kalbfleisch', 'sprott', '1970', 'lead', 'substantial', 'bias', 'parameter_estimate', 'need', 'large', 'sample_size', 'relative', 'number', 'parameter']"
373,"Because the GEE method is semiparametric (not nonparametric), the mean model and variance function needs to be correctly specified. Consistent results of the GEE models depend on the correct specification of the model for the mean. Furthermore, robust standard errors should only be used with a large number of subjects. Park (1993) compared GEE estimators with normal-theory maximum likelihood estimators and reported that GEE estimators were more sensitive to the occurrence of missing data. Several studies have shown that the bias and efficiency of the GEE method may depend on the number of subjects, number of repeated measurements, magnitudes of the correlations among repeated measurements, and number and type of covariates. Lipsitz et al. (1991) reported that the parameter estimates for a binary GEE model were biased slightly upward and the bias increased as the magnitude of the correlation increased. Paik (1988) reported that as the number of covariates increases, the number of subjects needs to increase for the point estimates and confidence intervals to perform satisfactorily (with 4 repeated measurements and 4 covariates, he recommended a sample size over 50). ?	One solution to the MCAR limitation is to use the MI procedure to impute the missing values. PROC MI invokes the MAR assumption. Then fit the GEE model in PROC GENMOD on the complete data.",CD,1373,"['gee', 'method', 'semiparametric', 'nonparametric', 'mean', 'model', 'variance', 'function', 'need', 'correctly', 'specified', 'consistent', 'result', 'gee', 'model', 'depend', 'correct', 'specification', 'model', 'mean', 'furthermore', 'robust', 'standard_error', 'used', 'large', 'number', 'subject', 'park', '1993', 'compared', 'gee', 'estimator', 'normaltheory', 'maximum', 'likelihood', 'estimator', 'reported', 'gee', 'estimator', 'sensitive', 'occurrence', 'missing', 'data', 'several', 'study', 'shown', 'bias', 'efficiency', 'gee', 'method', 'may', 'depend', 'number', 'subject', 'number', 'repeated', 'measurement', 'magnitude', 'correlation', 'among', 'repeated', 'measurement', 'number', 'type', 'covariates', 'lipsitz', 'et', 'al', '1991', 'reported', 'parameter_estimate', 'binary', 'gee', 'model', 'biased', 'slightly', 'upward', 'bias', 'increased', 'magnitude', 'correlation', 'increased', 'paik', '1988', 'reported', 'number', 'covariates', 'increase', 'number', 'subject', 'need', 'increase', 'point', 'estimate', 'confidence', 'interval', 'perform', 'satisfactorily', '4', 'repeated', 'measurement', '4', 'covariates', 'recommended', 'sample_size', '50', '\tone', 'solution', 'mcar', 'limitation', 'use', 'mi', 'procedure', 'impute', 'missing', 'value', 'proc', 'mi', 'invokes', 'mar', 'assumption', 'fit', 'gee', 'model', 'proc', 'genmod', 'complete', 'data']"
374,"Mother_age is the matching variable that is constant within the strata. Therefore, the parameter estimate for Mother_age is 0. The matching variable can be used in interactions however. Model Fit Statistics",CD,206,"['motherage', 'matching', 'variable', 'constant', 'within', 'stratum', 'therefore', 'parameter_estimate', 'motherage', '0', 'matching', 'variable', 'used', 'interaction', 'however', 'model', 'fit', 'statistic']"
375,"Because the GEE method is semiparametric (not nonparametric), the mean model and variance function needs to be correctly specified. Consistent results of the GEE models depend on the correct specification of the model for the mean. Furthermore, robust standard errors should only be used with a large number of subjects. Park (1993) compared GEE estimators with normal-theory maximum likelihood estimators and reported that GEE estimators were more sensitive to the occurrence of missing data. Several studies have shown that the bias and efficiency of the GEE method may depend on the number of subjects, number of repeated measurements, magnitudes of the correlations among repeated measurements, and number and type of covariates. Lipsitz et al. (1991) reported that the parameter estimates for a binary GEE model were biased slightly upward and the bias increased as the magnitude of the correlation increased. Paik (1988) reported that as the number of covariates increases, the number of subjects needs to increase for the point estimates and confidence intervals to perform satisfactorily (with 4 repeated measurements and 4 covariates, he recommended a sample size over 50). ?	One solution to the MCAR limitation is to use the MI procedure to impute the missing values. PROC MI invokes the MAR assumption. Then fit the GEE model in PROC GENMOD on the complete data.",CD,1373,"['gee', 'method', 'semiparametric', 'nonparametric', 'mean', 'model', 'variance', 'function', 'need', 'correctly', 'specified', 'consistent', 'result', 'gee', 'model', 'depend', 'correct', 'specification', 'model', 'mean', 'furthermore', 'robust', 'standard_error', 'used', 'large', 'number', 'subject', 'park', '1993', 'compared', 'gee', 'estimator', 'normaltheory', 'maximum', 'likelihood', 'estimator', 'reported', 'gee', 'estimator', 'sensitive', 'occurrence', 'missing', 'data', 'several', 'study', 'shown', 'bias', 'efficiency', 'gee', 'method', 'may', 'depend', 'number', 'subject', 'number', 'repeated', 'measurement', 'magnitude', 'correlation', 'among', 'repeated', 'measurement', 'number', 'type', 'covariates', 'lipsitz', 'et', 'al', '1991', 'reported', 'parameter_estimate', 'binary', 'gee', 'model', 'biased', 'slightly', 'upward', 'bias', 'increased', 'magnitude', 'correlation', 'increased', 'paik', '1988', 'reported', 'number', 'covariates', 'increase', 'number', 'subject', 'need', 'increase', 'point', 'estimate', 'confidence', 'interval', 'perform', 'satisfactorily', '4', 'repeated', 'measurement', '4', 'covariates', 'recommended', 'sample_size', '50', '\tone', 'solution', 'mcar', 'limitation', 'use', 'mi', 'procedure', 'impute', 'missing', 'value', 'proc', 'mi', 'invokes', 'mar', 'assumption', 'fit', 'gee', 'model', 'proc', 'genmod', 'complete', 'data']"
376,"The odds ratio indicates that among women with no uterine irritability, those with previous preterm deliveries are 5.5 times more likely to have a low birth weight baby. The exact confidence limits are not needed because of the large sample size. Table 2 of prev_pretrm by low Controlling for uterine_irr=1",CD,306,"['odds_ratio', 'indicates', 'among', 'woman', 'uterine', 'irritability', 'previous', 'preterm', 'delivery', '55', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'exact', 'confidence', 'limit', 'needed', 'large', 'sample_size', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
377,"In ordinal logistic regression, the logit is now a cumulative logit. If k is the number of categories for the outcome variable, then the number of cumulative logits is k-1. The model generates cumulative probabilities, which is the probability that an individual is in the jth ordered category or lower. If you use the DESCENDING option in PROC LOGISTIC, then the model generates probabilities that an individual is in the jth category or higher.",CD,446,"['ordinal', 'logistic_regression', 'logit', 'cumulative', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'cumulative', 'logits', 'k1', 'model', 'generates', 'cumulative', 'probability', 'probability', 'individual', 'jth', 'ordered', 'category', 'lower', 'use', 'descending', 'option', 'proc_logistic', 'model', 'generates', 'probability', 'individual', 'jth', 'category', 'higher']"
378,"PROC LOGISTIC also produces statistics that measure predictive power. These statistics are not the same as the goodness-of-fit statistics because models with high predictive power do not necessarily have a good fit to the data (and vice versa). One statistic that measures predictive power is the generalized R2. It is based on the likelihood ratio chi-square for testing the null hypothesis that all of the slope parameters are 0. However, it uses the likelihood values (L1 and L0) rather than the log- likelihood values and it is adjusted by the sample size n. It can be interpreted in the same way as the rank correlation statistics in PROC LOGISTIC. The higher the statistic, the more predictive power your model has. However, it cannot be interpreted as the proportion of variance explained by the predictor variables. Therefore, it is inappropriate to compare the generalized R2 to the linear model?s R2 (Allison 1999). Goodness-of-Fit Statistics and Predictive Power",CD,973,"['proc_logistic', 'also', 'produce', 'statistic', 'measure', 'predictive', 'power', 'statistic', 'goodnessoffit', 'statistic', 'model', 'high', 'predictive', 'power', 'necessarily', 'good', 'fit', 'data', 'vice', 'versa', 'one', 'statistic', 'measure', 'predictive', 'power', 'generalized', 'r2', 'based', 'likelihood', 'ratio', 'chisquare', 'testing', 'null', 'hypothesis', 'slope', 'parameter', '0', 'however', 'us', 'likelihood', 'value', 'l1', 'l0', 'rather', 'log', 'likelihood', 'value', 'adjusted', 'sample_size', 'n', 'interpreted', 'way', 'rank', 'correlation', 'statistic', 'proc_logistic', 'higher', 'statistic', 'predictive', 'power', 'model', 'ha', 'however', 'cannot', 'interpreted', 'proportion', 'variance', 'explained', 'predictor_variable', 'therefore', 'inappropriate', 'compare', 'generalized', 'r2', 'linear', 'model', 'r2', 'allison', '1999', 'goodnessoffit', 'statistic', 'predictive', 'power']"
379,"Subject-matter knowledge does not always enable you to choose the best predictor variables and the structure for how the predictor variables appear in the model. Thus you are often forced to use the data to make these decisions (Harrell 1997). A common approach in variable selection is to use univariate associations to detect significant predictor variables. Each predictor variable is screened individually and only those with a p-value below an established cutoff (such as .05) are retained for the analysis. However, this approach has serious shortcomings. Because univariate screening does not account for partial associations (effect of one variable changes in the presence of another variable), some predictor variables may be erroneously omitted. Furthermore, the presence of interactions can give misleading univariate associations. A better approach is to consider a subset of variables jointly.",CD,906,"['subjectmatter', 'knowledge', 'doe', 'always', 'enable', 'choose', 'best', 'predictor_variable', 'structure', 'predictor_variable', 'appear', 'model', 'thus', 'often', 'forced', 'use', 'data', 'make', 'decision', 'harrell', '1997', 'common', 'approach', 'variable', 'selection', 'use', 'univariate', 'association', 'detect', 'significant', 'predictor_variable', 'predictor_variable', 'screened', 'individually', 'pvalue', 'established', 'cutoff', '05', 'retained', 'analysis', 'however', 'approach', 'ha', 'serious', 'shortcoming', 'univariate', 'screening', 'doe', 'account', 'partial', 'association', 'effect', 'one', 'variable', 'change', 'presence', 'another', 'variable', 'predictor_variable', 'may', 'erroneously', 'omitted', 'furthermore', 'presence', 'interaction', 'give', 'misleading', 'univariate', 'association', 'better', 'approach', 'consider', 'subset', 'variable', 'jointly']"
380,Variables with the lowest 1 minus R-squared ratio are variables with a high correlation with their own cluster and with a low correlation with the other clusters. These variables may be good representative variables from each cluster.,CD,234,"['variable', 'lowest', '1', 'minus', 'rsquared', 'ratio', 'variable', 'high', 'correlation', 'cluster', 'low', 'correlation', 'cluster', 'variable', 'may', 'good', 'representative', 'variable', 'cluster']"
381,"The DIFDEV and DIFCHISQ are diagnostics for detecting which observations contribute heavily to the disagreement between the data and the predicted values of the fitted model. The range of DIFCHISQ is much greater then DIFDEV. DFBETAS are diagnostics that can be used to assess the effect of an individual observation on each estimated parameter of the fitted model. These statistics are useful in detecting observations that are causing instability in the selected parameter estimates. Instead of re-estimating the parameter each time an observation is deleted, PROC LOGISTIC uses the one-step estimate. C and CBAR are confidence interval displacement diagnostics. These statistics are based on the same idea as the Cook distance in linear regression. PROC LOGISTIC also computes these using the one-step estimate. H is the hat matrix diagonal. The diagonal elements of the hat matrix are useful in detecting extreme points in the design space. However, if the estimated probability is extreme (less than 0.1 and greater than 0.9), then the hat diagonal may be greatly reduced in value. Consequently, when an observation has a very large or very small estimated probability, its hat diagonal value is not a good indicator of the observation?s distance from the design space (Hosmer and Lemeshow 2000). The deviance residuals (contribution of each observation to the deviance chi-square) and Pearson residuals (contribution of each observation to the Pearson chi-square) can also be used to determine which observations are poorly fit by the model.",CD,1547,"['difdev', 'difchisq', 'diagnostics', 'detecting', 'observation', 'contribute', 'heavily', 'disagreement', 'data', 'predicted', 'value', 'fitted', 'model', 'range', 'difchisq', 'much', 'greater', 'difdev', 'dfbetas', 'diagnostics', 'used', 'ass', 'effect', 'individual', 'observation', 'estimated', 'parameter', 'fitted', 'model', 'statistic', 'useful', 'detecting', 'observation', 'causing', 'instability', 'selected', 'parameter_estimate', 'instead', 'reestimating', 'parameter', 'time', 'observation', 'deleted', 'proc_logistic', 'us', 'onestep', 'estimate', 'c', 'cbar', 'confidence', 'interval', 'displacement', 'diagnostics', 'statistic', 'based', 'idea', 'cook', 'distance', 'linear', 'regression', 'proc_logistic', 'also', 'computes', 'using', 'onestep', 'estimate', 'h', 'hat', 'matrix', 'diagonal', 'diagonal', 'element', 'hat', 'matrix', 'useful', 'detecting', 'extreme', 'point', 'design', 'space', 'however', 'estimated', 'probability', 'extreme', 'le', '01', 'greater', '09', 'hat', 'diagonal', 'may', 'greatly', 'reduced', 'value', 'consequently', 'observation', 'ha', 'large', 'small', 'estimated', 'probability', 'hat', 'diagonal', 'value', 'good', 'indicator', 'observation', 'distance', 'design', 'space', 'hosmer', 'lemeshow', '2000', 'deviance', 'residual', 'contribution', 'observation', 'deviance', 'chisquare', 'pearson', 'residual', 'contribution', 'observation', 'pearson', 'chisquare', 'also', 'used', 'determine', 'observation', 'poorly', 'fit', 'model']"
382,"The LOGISTIC procedure should not be used to analyze clustered data because PROC LOGISTIC assumes independent observations. In the past, the CATMOD procedure was used to analyze clustered data with a discrete response variable. However, GEE models offer some significant advantages over models fit in PROC CATMOD for the analysis of clustered data. For example, models fit in PROC CATMOD require that the data be balanced. Therefore, the measurements have to occur at the same times for all subjects and each subject has the same number of measurements. PROC CATMOD also uses complete case analysis, where only subjects with data at all time points are used. If a subject has one or more missing measurements, then PROC CATMOD deletes the entire subject. Models fit in PROC CATMOD model the distribution of the response variable (represented by the columns in an underlying contingency table) across the levels of the predictor variables (represented by the rows in an underlying contingency table). Computational difficulties might occur if you have a continuous covariate with a large number of unique values, because many rows will have a sample size of 1. PROC CATMOD might be less efficient and might be unable to allocate sufficient memory to handle this problem. GEE regression models fit in the GENMOD procedure use the all-available pairs method, where all nonmissing pairs of data are used to estimate the parameters in the correlation matrix. If there are missing values, then some correlations are computed using more observations and other correlations are computed using fewer observations.",CD,1604,"['logistic', 'procedure', 'used', 'analyze', 'clustered', 'data', 'proc_logistic', 'assumes', 'independent', 'observation', 'past', 'catmod', 'procedure', 'wa', 'used', 'analyze', 'clustered', 'data', 'discrete', 'response_variable', 'however', 'gee', 'model', 'offer', 'significant', 'advantage', 'model', 'fit', 'proc', 'catmod', 'analysis', 'clustered', 'data', 'example', 'model', 'fit', 'proc', 'catmod', 'require', 'data', 'balanced', 'therefore', 'measurement', 'occur', 'time', 'subject', 'subject', 'ha', 'number', 'measurement', 'proc', 'catmod', 'also', 'us', 'complete', 'case', 'analysis', 'subject', 'data', 'time', 'point', 'used', 'subject', 'ha', 'one', 'missing', 'measurement', 'proc', 'catmod', 'deletes', 'entire', 'subject', 'model', 'fit', 'proc', 'catmod', 'model', 'distribution', 'response_variable', 'represented', 'column', 'underlying', 'contingency', 'table', 'across', 'level', 'predictor_variable', 'represented', 'row', 'underlying', 'contingency', 'table', 'computational', 'difficulty', 'might', 'occur', 'continuous', 'covariate', 'large', 'number', 'unique', 'value', 'many', 'row', 'sample_size', '1', 'proc', 'catmod', 'might', 'le', 'efficient', 'might', 'unable', 'allocate', 'sufficient', 'memory', 'handle', 'problem', 'gee', 'regression_model', 'fit', 'genmod', 'procedure', 'use', 'allavailable', 'pair', 'method', 'nonmissing', 'pair', 'data', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'missing', 'value', 'correlation', 'computed', 'using', 'observation', 'correlation', 'computed', 'using', 'fewer', 'observation']"
383,"The distribution of predicted probabilities is slightly skewed, but each bar has an adequate percentage of observations. Therefore, create a classification table where the cutoffs range from .1 to .9 by .1.",CD,206,"['distribution', 'predicted', 'probability', 'slightly', 'skewed', 'bar', 'ha', 'adequate', 'percentage', 'observation', 'therefore', 'create', 'classification', 'table', 'cutoff', 'range', '1', '9', '1']"
384,"Example:	Fit a GEE model on the wheezing data and specify the probability of wheezing as the response of interest, the unstructured correlation structure, reference cell coding for smoker with No as the reference cell, and request the Type 3 score statistics, the final working correlation matrix, and the model-based standard errors. Also compute the odds ratio comparing smokers to non-smokers and a one-year decrease in age. /* c3demo13a */ proc genmod data=sasuser.wheeze desc; class case smoker(param=ref ref='No'); model wheeze = smoker age / dist=bin type3; repeated subject = case / corrw modelse type=unstr; estimate 'smoking' smoker 1 / exp; estimate 'age' age -1 / exp; title 'GEE Model of Wheezing among Children'; run; Selected PROC GENMOD statement option: DESC	reverses the sort order for the levels of the outcome variable. Selected CLASS statement options: PARAM= 	specifies the parameterization method for the classification variable or variables. The default is PARAM=GLM. REF=	specifies the reference level for PARAM=EFFECT, PARAM=REF, and their orthogonalizations. For an individual variable, you can specify the level of the variable to use as the reference level. For a global or individual variable, you can use one of the following keywords: 	FIRST	designates the first ordered level as the reference. 	LAST	designates the last ordered level as the reference. This is the default. Selected MODEL statement options: DIST= 	specifies the built-in probability distribution to use in the model. The default link function for the binomial distribution is the logit link function. TYPE3	requests that Type 3 score statistics be computed for each effect that is specified in the MODEL statement. Likelihood ratio statistics are produced for models that are not GEE models. Selected REPEATED statement options: CORRW	specifies that the final working correlation matrix be printed. MODELSE	displays an analysis of parameter estimates table using model-based standard errors. Selected ESTIMATE statement option: EXP	requests that the exponentiated contrast, its standard error, and the confidence bounds be computed. ?	If the repeated measurements are not in the proper order or if there are missing time points for some subjects, then the WITHIN= option in the REPEATED statement should be used. This option names a variable that specifies the order of measurements within subjects. Variables used in the WITHIN= option must also be listed in the CLASS statement. !	In SAS 9.1, you get an invalid reference level error if REF=?level? is used for two or more variables. The solution is to use REF=FIRST or REF=LAST for binary variables. This problem has been fixed in SAS 9.2. GEE Model of Wheezing among Children",CD,2728,"['example\tfit', 'gee', 'model', 'wheezing', 'data', 'specify', 'probability', 'wheezing', 'response', 'interest', 'unstructured', 'correlation_structure', 'reference', 'cell', 'coding', 'smoker', 'reference', 'cell', 'request', 'type', '3', 'score', 'statistic', 'final', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'also', 'compute', 'odds_ratio', 'comparing', 'smoker', 'nonsmoker', 'oneyear', 'decrease', 'age', '', 'c3demo13a', '', 'proc', 'genmod', 'datasasuserwheeze', 'desc', 'class', 'case', 'smokerparamref', 'refno', 'model', 'wheeze', '', 'smoker', 'age', '', 'distbin', 'type3', 'repeated', 'subject', '', 'case', '', 'corrw', 'modelse', 'typeunstr', 'estimate', 'smoking', 'smoker', '1', '', 'exp', 'estimate', 'age', 'age', '1', '', 'exp', 'title', 'gee', 'model', 'wheezing', 'among', 'child', 'run', 'selected', 'proc', 'genmod', 'statement', 'option', 'desc\treverses', 'sort', 'order', 'level', 'outcome', 'variable', 'selected', 'class', 'statement', 'option', 'param', '\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'default', 'paramglm', 'ref\tspecifies', 'reference', 'level', 'parameffect', 'paramref', 'orthogonalizations', 'individual', 'variable', 'specify', 'level', 'variable', 'use', 'reference', 'level', 'global', 'individual', 'variable', 'use', 'one', 'following', 'keywords', '\tfirst\tdesignates', 'first', 'ordered', 'level', 'reference', '\tlast\tdesignates', 'last', 'ordered', 'level', 'reference', 'default', 'selected', 'model_statement', 'option', 'dist', '\tspecifies', 'builtin', 'probability', 'distribution', 'use', 'model', 'default', 'link', 'function', 'binomial', 'distribution', 'logit', 'link', 'function', 'type3\trequests', 'type', '3', 'score', 'statistic', 'computed', 'effect', 'specified', 'model_statement', 'likelihood', 'ratio', 'statistic', 'produced', 'model', 'gee', 'model', 'selected', 'repeated', 'statement', 'option', 'corrw\tspecifies', 'final', 'working', 'correlation', 'matrix', 'printed', 'modelse\tdisplays', 'analysis', 'parameter_estimate', 'table', 'using', 'modelbased', 'standard_error', 'selected', 'estimate', 'statement', 'option', 'exp\trequests', 'exponentiated', 'contrast', 'standard_error', 'confidence', 'bound', 'computed', '\tif', 'repeated', 'measurement', 'proper', 'order', 'missing', 'time', 'point', 'subject', 'within', 'option', 'repeated', 'statement', 'used', 'option', 'name', 'variable', 'specifies', 'order', 'measurement', 'within', 'subject', 'variable', 'used', 'within', 'option', 'must', 'also', 'listed', 'class', 'statement', '\tin', 'sa', '91', 'get', 'invalid', 'reference', 'level', 'error', 'reflevel', 'used', 'two', 'variable', 'solution', 'use', 'reffirst', 'reflast', 'binary', 'variable', 'problem', 'ha', 'fixed', 'sa', '92', 'gee', 'model', 'wheezing', 'among', 'child']"
385,"Exploratory data analysis should be the first step in model building to identify any numerical problems and nonlinearity. Contingency table analysis of categorical predictors should also be performed so that you can compare the univariate effect and the multivariate effect of each predictor variable. You should be concerned about predictor variables whose coefficients have changed substantially in magnitude when other predictor variables are added to or eliminated from the model. This may identify one or more variables that were important in providing a needed adjustment of the effects of the variables that remained in the model. Finally, after a candidate model has been identified, you should assess the fit of the model and identify any outliers or influential observations that are contributing to a poor fitting model (Hosmer and Lemeshow 2000). 1.2	Exploratory Data Analysis",CD,888,"['exploratory', 'data', 'analysis', 'first', 'step', 'model', 'building', 'identify', 'numerical', 'problem', 'nonlinearity', 'contingency', 'table', 'analysis', 'categorical', 'predictor', 'also', 'performed', 'compare', 'univariate', 'effect', 'multivariate', 'effect', 'predictor_variable', 'concerned', 'predictor_variable', 'whose', 'coefficient', 'changed', 'substantially', 'magnitude', 'predictor_variable', 'added', 'eliminated', 'model', 'may', 'identify', 'one', 'variable', 'important', 'providing', 'needed', 'adjustment', 'effect', 'variable', 'remained', 'model', 'finally', 'candidate', 'model', 'ha', 'identified', 'ass', 'fit', 'model', 'identify', 'outlier', 'influential', 'observation', 'contributing', 'poor', 'fitting', 'model', 'hosmer', 'lemeshow', '2000', '12\texploratory', 'data', 'analysis']"
386,"Correlation Structure Unstructured Subject Effect case (537 levels) Number of Clusters 537 Correlation Matrix Dimension 4 Maximum Cluster Size 4 Minimum Cluster Size 4 Algorithm converged. The GEE Model Information table displays information about the model fit with GEEs. Because TYPE=UNSTR option is requested, the unstructured correlation structure is used. Furthermore, because there are 537 children, there are 537 clusters. Notice there are no missing data values. Working Correlation Matrix",CD,497,"['correlation_structure', 'unstructured', 'subject', 'effect', 'case', '537', 'level', 'number', 'cluster', '537', 'correlation', 'matrix', 'dimension', '4', 'maximum', 'cluster', 'size', '4', 'minimum', 'cluster', 'size', '4', 'algorithm', 'converged', 'gee', 'model', 'information', 'table', 'display', 'information', 'model', 'fit', 'gee', 'typeunstr', 'option', 'requested', 'unstructured', 'correlation_structure', 'used', 'furthermore', '537', 'child', '537', 'cluster', 'notice', 'missing', 'data', 'value', 'working', 'correlation', 'matrix']"
387,"You can also write a CONTRAST statement in PROC LOGISTIC to estimate the odds ratio for any effect along with the confidence bounds. The contrasts consist of the effects involved in the odds ratio along with the coefficients that measure the difference between the effects in the numerator and the effects in the denominator. The ESTIMATE=EXP option exponentiates the parameter estimate, which shows the odds ratio and the 95% confidence bounds. Estimating Odds Ratios in Interactions",CD,484,"['also', 'write', 'contrast', 'statement', 'proc_logistic', 'estimate', 'odds_ratio', 'effect', 'along', 'confidence', 'bound', 'contrast', 'consist', 'effect', 'involved', 'odds_ratio', 'along', 'coefficient', 'measure', 'difference', 'effect', 'numerator', 'effect', 'denominator', 'estimateexp', 'option', 'exponentiates', 'parameter_estimate', 'show', 'odds_ratio', '95', 'confidence', 'bound', 'estimating', 'odds_ratio', 'interaction']"
388,"Subject-matter knowledge does not always enable you to choose the best predictor variables and the structure for how the predictor variables appear in the model. Thus you are often forced to use the data to make these decisions (Harrell 1997). A common approach in variable selection is to use univariate associations to detect significant predictor variables. Each predictor variable is screened individually and only those with a p-value below an established cutoff (such as .05) are retained for the analysis. However, this approach has serious shortcomings. Because univariate screening does not account for partial associations (effect of one variable changes in the presence of another variable), some predictor variables may be erroneously omitted. Furthermore, the presence of interactions can give misleading univariate associations. A better approach is to consider a subset of variables jointly.",CD,906,"['subjectmatter', 'knowledge', 'doe', 'always', 'enable', 'choose', 'best', 'predictor_variable', 'structure', 'predictor_variable', 'appear', 'model', 'thus', 'often', 'forced', 'use', 'data', 'make', 'decision', 'harrell', '1997', 'common', 'approach', 'variable', 'selection', 'use', 'univariate', 'association', 'detect', 'significant', 'predictor_variable', 'predictor_variable', 'screened', 'individually', 'pvalue', 'established', 'cutoff', '05', 'retained', 'analysis', 'however', 'approach', 'ha', 'serious', 'shortcoming', 'univariate', 'screening', 'doe', 'account', 'partial', 'association', 'effect', 'one', 'variable', 'change', 'presence', 'another', 'variable', 'predictor_variable', 'may', 'erroneously', 'omitted', 'furthermore', 'presence', 'interaction', 'give', 'misleading', 'univariate', 'association', 'better', 'approach', 'consider', 'subset', 'variable', 'jointly']"
389,The logit plot can also show serious nonlinearities between the response variable and the predictor variable. The above graph reveals a quadratic relationship between the response and predictor variables. Adding a polynomial term or binning the predictor variable into three groups (because of the quadratic relationship) and treating it as a classification variable may improve the model fit.,CD,393,"['logit', 'plot', 'also', 'show', 'serious', 'nonlinearities', 'response_variable', 'predictor_variable', 'graph', 'reveals', 'quadratic', 'relationship', 'response', 'predictor_variable', 'adding', 'polynomial', 'term', 'binning', 'predictor_variable', 'three', 'group', 'quadratic', 'relationship', 'treating', 'classification', 'variable', 'may', 'improve', 'model', 'fit']"
390,"Exploratory data analysis should be the first step in model building to identify any numerical problems and nonlinearity. Contingency table analysis of categorical predictors should also be performed so that you can compare the univariate effect and the multivariate effect of each predictor variable. You should be concerned about predictor variables whose coefficients have changed substantially in magnitude when other predictor variables are added to or eliminated from the model. This may identify one or more variables that were important in providing a needed adjustment of the effects of the variables that remained in the model. Finally, after a candidate model has been identified, you should assess the fit of the model and identify any outliers or influential observations that are contributing to a poor fitting model (Hosmer and Lemeshow 2000). 1.2	Exploratory Data Analysis",CD,888,"['exploratory', 'data', 'analysis', 'first', 'step', 'model', 'building', 'identify', 'numerical', 'problem', 'nonlinearity', 'contingency', 'table', 'analysis', 'categorical', 'predictor', 'also', 'performed', 'compare', 'univariate', 'effect', 'multivariate', 'effect', 'predictor_variable', 'concerned', 'predictor_variable', 'whose', 'coefficient', 'changed', 'substantially', 'magnitude', 'predictor_variable', 'added', 'eliminated', 'model', 'may', 'identify', 'one', 'variable', 'important', 'providing', 'needed', 'adjustment', 'effect', 'variable', 'remained', 'model', 'finally', 'candidate', 'model', 'ha', 'identified', 'ass', 'fit', 'model', 'identify', 'outlier', 'influential', 'observation', 'contributing', 'poor', 'fitting', 'model', 'hosmer', 'lemeshow', '2000', '12\texploratory', 'data', 'analysis']"
391,"To test the null hypothesis that all regression coefficients of the model are 0, the likelihood ratio test statistic is computed. This statistic compares the log-likelihood values at the fitted parameter estimates (LogL1) to the log-likelihood values when the parameter estimates are 0 (LogL0). So that it follows a chi-square distribution, the statistic is computed by the formula ?2(LogL0?LogL1). In the above diagram, the likelihood ratio statistic is twice the vertical distance between the values of the log-likelihood function at LogL1 and at LogL0.",CD,555,"['test', 'null', 'hypothesis', 'regression', 'coefficient', 'model', '0', 'likelihood', 'ratio', 'test', 'statistic', 'computed', 'statistic', 'compare', 'loglikelihood', 'value', 'fitted', 'parameter_estimate', 'logl1', 'loglikelihood', 'value', 'parameter_estimate', '0', 'logl0', 'follows', 'chisquare', 'distribution', 'statistic', 'computed', 'formula', '2logl0logl1', 'diagram', 'likelihood', 'ratio', 'statistic', 'twice', 'vertical', 'distance', 'value', 'loglikelihood', 'function', 'logl1', 'logl0']"
392,"The LOGISTIC procedure fits logistic regression models for binary, ordinal, or nominal response data. Enhancements to PROC LOGISTIC in SAS?9 include the STRATA statement, which enables you to perform a conditional logistic regression on binary response data, and the SCORE statement, which enables you to score a data set using a previously fitted model. PROC LOGISTIC has options that control how to select effects (either variables or interactions) in and out of the model. When there are no interaction terms, a CLASS variable can enter or leave a model in a single step. When there are interaction terms, the selection process also depends on whether you want to preserve model hierarchy (which is explained later in the course). For example, you can specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. PROC LOGISTIC provides a CONTRAST statement for specifying customized hypothesis tests concerning the model parameters. The CONTRAST statement can also be used to obtain odds ratio estimates for various levels of the CLASS variables and confidence intervals around odds ratios for variables that are involved in an interaction. In the MODEL statement, the response variable can be specified in two ways. *	The events/trials syntax represents a ratio of variables where the event variable indicates the number of observations with the response of interest for a particular combination of predictor variable values and the trial variable indicates the number of observations in the same combination of predictor variable values. This response is useful when you have a summarized data set where each observation represents a unique combination of predictor variable values. *	The response variable can also be specified as a positive or negative response for each observation. In other words, each observation represents a single case. Selected PROC LOGISTIC statement options: NOPRINT	suppresses all displayed output. This option temporarily disables the Output Delivery System (ODS). NAMELEN=	specifies the length of effect names in tables and output data sets to be n characters, where n is a value between 20 and 200. Because the default length is 20 characters, you may have to increase the length for some interaction terms. Selected LOGISTIC procedure statements: CLASS	specifies the classification variables to be used in the analysis. The CLASS statement must precede the MODEL statement. MODEL	specifies the response variable (which can be binary, ordinal, or nominal) and the predictor variables (which can be character or numeric). The MODEL statement is required, and only one is allowed with each invocation of PROC LOGISTIC. CONTRAST	provides a mechanism for obtaining customized hypothesis tests. There is no limit to the number of CONTRAST statements that you can specify, but they must appear after the MODEL statement. EXACT	performs exact tests of the parameters for the specified effects and optionally estimates the parameters and outputs the exact conditional distributions. You can specify several EXACT statements, but they must follow the MODEL statement. SCORE	creates a data set that contains all the data in the DATA= data set together with posterior probabilities and, optionally, prediction confidence intervals. You can specify several SCORE statements. STRATA	names the variables that define strata or matched sets to use in a stratified conditional logistic regression of binary response data. The STRATA variables can be either character or numeric, and the formatted values of the STRATA variables determine the levels. You can use formats to group values into levels. UNITS	enables you to obtain an odds ratio estimate for a specified change in a predictor variable. The unit of change can be a number, standard deviation (SD) or a number times the standard deviation (2*SD). OUTPUT	creates an output data set containing all the variables from the input data set and the requested statistics.",CD,4045,"['logistic', 'procedure', 'fit', 'logistic_regression_model', 'binary', 'ordinal', 'nominal', 'response', 'data', 'enhancement', 'proc_logistic', 'sas9', 'include', 'stratum', 'statement', 'enables', 'perform', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'score', 'statement', 'enables', 'score', 'data_set', 'using', 'previously', 'fitted', 'model', 'proc_logistic', 'ha', 'option', 'control', 'select', 'effect', 'either', 'variable', 'interaction', 'model', 'interaction', 'term', 'class', 'variable', 'enter', 'leave', 'model', 'single', 'step', 'interaction', 'term', 'selection', 'process', 'also', 'depends', 'whether', 'want', 'preserve', 'model', 'hierarchy', 'explained', 'later', 'course', 'example', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'proc_logistic', 'provides', 'contrast', 'statement', 'specifying', 'customized', 'hypothesis', 'test', 'concerning', 'model', 'parameter', 'contrast', 'statement', 'also', 'used', 'obtain', 'odds_ratio', 'estimate', 'various', 'level', 'class', 'variable', 'confidence', 'interval', 'around', 'odds_ratio', 'variable', 'involved', 'interaction', 'model_statement', 'response_variable', 'specified', 'two', 'way', '\tthe', 'eventstrials', 'syntax', 'represents', 'ratio', 'variable', 'event', 'variable', 'indicates', 'number', 'observation', 'response', 'interest', 'particular', 'combination', 'predictor_variable', 'value', 'trial', 'variable', 'indicates', 'number', 'observation', 'combination', 'predictor_variable', 'value', 'response', 'useful', 'summarized', 'data_set', 'observation', 'represents', 'unique', 'combination', 'predictor_variable', 'value', '\tthe', 'response_variable', 'also', 'specified', 'positive', 'negative', 'response', 'observation', 'word', 'observation', 'represents', 'single', 'case', 'selected', 'proc_logistic', 'statement', 'option', 'noprint\tsuppresses', 'displayed', 'output', 'option', 'temporarily', 'disables', 'output', 'delivery', 'system', 'od', 'namelen\tspecifies', 'length', 'effect', 'name', 'table', 'output', 'data_set', 'n', 'character', 'n', 'value', '20', '200', 'default', 'length', '20', 'character', 'may', 'increase', 'length', 'interaction', 'term', 'selected', 'logistic', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'must', 'precede', 'model_statement', 'model\tspecifies', 'response_variable', 'binary', 'ordinal', 'nominal', 'predictor_variable', 'character', 'numeric', 'model_statement', 'required', 'one', 'allowed', 'invocation', 'proc_logistic', 'contrast\tprovides', 'mechanism', 'obtaining', 'customized', 'hypothesis', 'test', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'exact\tperforms', 'exact', 'test', 'parameter', 'specified', 'effect', 'optionally', 'estimate', 'parameter', 'output', 'exact', 'conditional', 'distribution', 'specify', 'several', 'exact', 'statement', 'must', 'follow', 'model_statement', 'score\tcreates', 'data_set', 'contains', 'data', 'data', 'data_set', 'together', 'posterior', 'probability', 'optionally', 'prediction', 'confidence', 'interval', 'specify', 'several', 'score', 'statement', 'strata\tnames', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'stratified', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'stratum', 'variable', 'either', 'character', 'numeric', 'formatted', 'value', 'stratum', 'variable', 'determine', 'level', 'use', 'format', 'group', 'value', 'level', 'units\tenables', 'obtain', 'odds_ratio', 'estimate', 'specified', 'change', 'predictor_variable', 'unit', 'change', 'number', 'standard', 'deviation', 'sd', 'number', 'time', 'standard', 'deviation', '2sd', 'output\tcreates', 'output', 'data_set', 'containing', 'variable', 'input', 'data_set', 'requested', 'statistic']"
393,"If the estimation of the regression coefficients is the primary objective of your study and there are a large number of clusters (approximately 200) and a small number of time points, then you should not spend much time choosing a correlation structure. If the mean model is correctly specified, the GEE method for the parameter estimates was designed to guarantee consistency of the parameter estimates under minimal assumptions about the time dependence (Diggle, Heagerty, Liang, and Zeger 2002). Furthermore, the loss of efficiency from an incorrect choice of the working correlation structure is inconsequential when the number of subjects is large (Davis 2002).",CD,666,"['estimation', 'regression', 'coefficient', 'primary', 'objective', 'study', 'large', 'number', 'cluster', 'approximately', '200', 'small', 'number', 'time', 'point', 'spend', 'much', 'time', 'choosing', 'correlation_structure', 'mean', 'model', 'correctly', 'specified', 'gee', 'method', 'parameter_estimate', 'wa', 'designed', 'guarantee', 'consistency', 'parameter_estimate', 'minimal', 'assumption', 'time', 'dependence', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'furthermore', 'loss', 'efficiency', 'incorrect', 'choice', 'working', 'correlation_structure', 'inconsequential', 'number', 'subject', 'large', 'davis', '2002']"
394,"Special methods of statistical analysis are needed for clustered data because the set of measurements on one subject tends to be correlated and measurements on the same subject close in time tend to be more highly correlated than measurements far apart in time. These potential patterns of correlation must be taken into account to draw valid statistical inferences. Therefore, models fit in PROC LOGISTIC might produce invalid results because the independence assumption might not be valid.",CD,491,"['special', 'method', 'statistical', 'analysis', 'needed', 'clustered', 'data_set', 'measurement', 'one', 'subject', 'tends', 'correlated', 'measurement', 'subject', 'close', 'time', 'tend', 'highly', 'correlated', 'measurement', 'far', 'apart', 'time', 'potential', 'pattern', 'correlation', 'must', 'taken', 'account', 'draw', 'valid', 'statistical', 'inference', 'therefore', 'model', 'fit', 'proc_logistic', 'might', 'produce', 'invalid', 'result', 'independence', 'assumption', 'might', 'valid']"
395,"For health-related studies, certain types of interactions have frequently been found to be significant. For example, the interaction between treatment and severity of disease sometimes shows that patients with mild severity have little opportunity to receive the treatment?s benefit. An example of an interaction between measurement and the state of the subject during a measurement is when the respiration rate measured during sleep has greater predictive value compared to the respiration rate measured during activity (Harrell 1997). Forward Selection",CD,554,"['healthrelated', 'study', 'certain', 'type', 'interaction', 'frequently', 'found', 'significant', 'example', 'interaction', 'treatment', 'severity', 'disease', 'sometimes', 'show', 'patient', 'mild', 'severity', 'little', 'opportunity', 'receive', 'treatment', 'benefit', 'example', 'interaction', 'measurement', 'state', 'subject', 'measurement', 'respiration', 'rate', 'measured', 'sleep', 'ha', 'greater', 'predictive', 'value', 'compared', 'respiration', 'rate', 'measured', 'activity', 'harrell', '1997', 'forward', 'selection']"
396,"For logistic regression, the sufficient statistics for the in the model are where j=1,?, number of predictor variables. Therefore, the sufficient statistics for the parameters of the predictor variables are the sum of the cross-products of the response value and the predictor variable values. The sufficient statistic for the intercept is the total number of events since the intercept variable is constant at 1.",CD,413,"['logistic_regression', 'sufficient', 'statistic', 'model', 'j1', 'number', 'predictor_variable', 'therefore', 'sufficient', 'statistic', 'parameter', 'predictor_variable', 'sum', 'crossproducts', 'response', 'value', 'predictor_variable', 'value', 'sufficient', 'statistic', 'intercept', 'total', 'number', 'event', 'since', 'intercept', 'variable', 'constant', '1']"
397,"In nominal logistic regression, the logit is now a generalized logit. If k is the number of categories for the outcome variable, then the number of generalized logits is k-1. The last category is the reference category or the denominator of each logit.",CD,252,"['nominal', 'logistic_regression', 'logit', 'generalized', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'generalized', 'logits', 'k1', 'last', 'category', 'reference', 'category', 'denominator', 'logit']"
398,"When fitting a GEE model in PROC GENMOD, you should decide what is a reasonable model for the correlation between measurements within subject. PROC GENMOD offers several common structures to use to model the working correlation matrix. The choice of the structure should be consistent with the empirical correlations. Liang and Zeger (1986) showed that there could be important gains in efficiency by correctly specifying the working correlation matrix. However, the loss of efficiency is inconsequential when the number of clusters is large (Davis 2002).",CD,555,"['fitting', 'gee', 'model', 'proc', 'genmod', 'decide', 'reasonable', 'model', 'correlation', 'measurement', 'within', 'subject', 'proc', 'genmod', 'offer', 'several', 'common', 'structure', 'use', 'model', 'working', 'correlation', 'matrix', 'choice', 'structure', 'consistent', 'empirical', 'correlation', 'liang', 'zeger', '1986', 'showed', 'could', 'important', 'gain', 'efficiency', 'correctly', 'specifying', 'working', 'correlation', 'matrix', 'however', 'loss', 'efficiency', 'inconsequential', 'number', 'cluster', 'large', 'davis', '2002']"
399,"The goal of conditional exact inference is to determine how likely the observed sequence of binary response values is with respect to all other sequences of binary response values having the same sufficient statistics for the nuisance parameters. All possible sequences of binary response values is referred to as the permutation distribution. To accomplish this goal, the conditional permutation distribution for the sufficient statistics of the parameters of interest needs to be generated. In other words, for every possible sequence of binary responses, the sufficient statistics for the parameters needs to be computed. A simple example illustrates the method. Suppose you had 5 observations in your data with a binary response variable and a dummy-coded predictor variable (values of 0 or 1). The observed data values are on the above slide. The sufficient statistic values are 1 for the intercept and 1 for the parameter for the dummy-coded predictor variable. The number of possible sequences of response values is 32 (25).",CD,1031,"['goal', 'conditional', 'exact', 'inference', 'determine', 'likely', 'observed', 'sequence', 'binary', 'response', 'value', 'respect', 'sequence', 'binary', 'response', 'value', 'sufficient', 'statistic', 'nuisance', 'parameter', 'possible', 'sequence', 'binary', 'response', 'value', 'referred', 'permutation', 'distribution', 'accomplish', 'goal', 'conditional', 'permutation', 'distribution', 'sufficient', 'statistic', 'parameter', 'interest', 'need', 'generated', 'word', 'every', 'possible', 'sequence', 'binary', 'response', 'sufficient', 'statistic', 'parameter', 'need', 'computed', 'simple', 'example', 'illustrates', 'method', 'suppose', '5', 'observation', 'data', 'binary', 'response_variable', 'dummycoded', 'predictor_variable', 'value', '0', '1', 'observed', 'data', 'value', 'slide', 'sufficient', 'statistic', 'value', '1', 'intercept', '1', 'parameter', 'dummycoded', 'predictor_variable', 'number', 'possible', 'sequence', 'response', 'value', '32', '25']"
400,"The first order autoregressive structure (TYPE=AR(1)) specifies that the correlations are raised to the power of the number of time points the measurements are apart. Therefore, if the measurements are three time points apart, the correlation is . The AR(1) model might be a good choice in a longitudinal model where measurements are taken repeatedly over time. One shortcoming is that the correlation decays very quickly as the spacing between measurements increases (Davis 2002).",CD,481,"['first', 'order', 'autoregressive', 'structure', 'typear1', 'specifies', 'correlation', 'raised', 'power', 'number', 'time', 'point', 'measurement', 'apart', 'therefore', 'measurement', 'three', 'time', 'point', 'apart', 'correlation', '', 'ar1', 'model', 'might', 'good', 'choice', 'longitudinal', 'model', 'measurement', 'taken', 'repeatedly', 'time', 'one', 'shortcoming', 'correlation', 'decay', 'quickly', 'spacing', 'measurement', 'increase', 'davis', '2002']"
401,"To document the strength of the association, the odds ratio could be used for the binary predictors. For the ordinal predictors, the Spearman correlation statistic (which correlates the ranks of the data) would be helpful. For nominal predictors, the uncertainty coefficient c|r (column given the row, which means the column variable is the outcome variable and the row variable is the predictor variable) could be used. The uncertainty coefficient is defined as the proportion of the entropy (or uncertainty) in the response variable that is explained by the predictor variable. This statistic is comparable to the R2 statistic used in regression analysis.",CD,657,"['document', 'strength', 'association', 'odds_ratio', 'could', 'used', 'binary', 'predictor', 'ordinal', 'predictor', 'spearman', 'correlation', 'statistic', 'correlate', 'rank', 'data', 'would', 'helpful', 'nominal', 'predictor', 'uncertainty', 'coefficient', 'cr', 'column', 'given', 'row', 'mean', 'column', 'variable', 'outcome', 'variable', 'row', 'variable', 'predictor_variable', 'could', 'used', 'uncertainty', 'coefficient', 'defined', 'proportion', 'entropy', 'uncertainty', 'response_variable', 'explained', 'predictor_variable', 'statistic', 'comparable', 'r2', 'statistic', 'used', 'regression', 'analysis']"
402,"Example:	Output the predicted probabilities and examine the distribution using the HISTOGRAM statement in PROC UNIVARIATE. Then create a classification table and a ROC curve for the final model. The sample is a stratified random sample, so specify a list of prior probabilities for low birth weight. /* c2demo10a */ options label;",CD,330,"['example\toutput', 'predicted', 'probability', 'examine', 'distribution', 'using', 'histogram', 'statement', 'proc', 'univariate', 'create', 'classification', 'table', 'roc', 'curve', 'final', 'model', 'sample', 'stratified', 'random', 'sample', 'specify', 'list', 'prior', 'probability', 'low', 'birth', 'weight', '', 'c2demo10a', '', 'option', 'label']"
403,"A useful way to explain significant interactions is to graph them. For example, to visualize the interaction between mother?s age and physician visit, first create a data set that contains the information about the fitted model. Then create a data set with plotting points, which include the median for each predictor variable not involved in the interaction and the 5th, 25th, 50th, 75th, and 95th percentiles of mother?s age and both values of physician visit. Then score the data set in PROC LOGISTIC with the SCORE statement. Finally, plot the predicted logits and the predicted probabilities by the plotting points for the two variables to illustrate how the slope for mother?s age differs by the level of physician visit. Illustrating Interactions",CD,753,"['useful', 'way', 'explain', 'significant', 'interaction', 'graph', 'example', 'visualize', 'interaction', 'mother', 'age', 'physician', 'visit', 'first', 'create', 'data_set', 'contains', 'information', 'fitted', 'model', 'create', 'data_set', 'plotting', 'point', 'include', 'median', 'predictor_variable', 'involved', 'interaction', '5th', '25th', '50th', '75th', '95th', 'percentile', 'mother', 'age', 'value', 'physician', 'visit', 'score', 'data_set', 'proc_logistic', 'score', 'statement', 'finally', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', 'two', 'variable', 'illustrate', 'slope', 'mother', 'age', 'differs', 'level', 'physician', 'visit', 'illustrating', 'interaction']"
404,"GEE regression models extend the generalized linear model, which is an extension of the traditional linear model. Generalized linear models extend the general linear model in several ways. 1.	The link function allows a wide variety of response variables to be modeled rather than just continuous response variables. For example, if the mean of the data is naturally restricted to a range of values such as a proportion, the appropriate link function ensures that the predicted values are within the appropriate range. 2.	The variance can be a specified function of the mean rather than just being constant. 3.	The distribution of error terms can come from a family of exponential distributions rather than just the normal distribution.",CD,735,"['gee', 'regression_model', 'extend', 'generalized', 'linear', 'model', 'extension', 'traditional', 'linear', 'model', 'generalized', 'linear', 'model', 'extend', 'general', 'linear', 'model', 'several', 'way', '1\tthe', 'link', 'function', 'allows', 'wide', 'variety', 'response_variable', 'modeled', 'rather', 'continuous', 'response_variable', 'example', 'mean', 'data', 'naturally', 'restricted', 'range', 'value', 'proportion', 'appropriate', 'link', 'function', 'ensures', 'predicted', 'value', 'within', 'appropriate', 'range', '2\tthe', 'variance', 'specified', 'function', 'mean', 'rather', 'constant', '3\tthe', 'distribution', 'error', 'term', 'come', 'family', 'exponential', 'distribution', 'rather', 'normal', 'distribution']"
405,"The modeling-building strategy for ordinal logistic regression is the same as for binary logistic regression. First, do an exploratory data analysis with contingency tables and logit plots. During this stage also look for confounders and interactions. Then try to find a subset of predictor variables that are associated with severity of back pain during pregnancy. In this example, there are 22 predictor variables. With so many variables, there is a good chance that many of them are collinear or redundant. A good strategy in this case is to reduce the number of redundant variables first before you try to build a model. One way to reduce the number of redundant variables is through variable clustering.",CD,708,"['modelingbuilding', 'strategy', 'ordinal', 'logistic_regression', 'binary', 'logistic_regression', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'stage', 'also', 'look', 'confounders', 'interaction', 'try', 'find', 'subset', 'predictor_variable', 'associated', 'severity', 'back', 'pain', 'pregnancy', 'example', '22', 'predictor_variable', 'many', 'variable', 'good', 'chance', 'many', 'collinear', 'redundant', 'good', 'strategy', 'case', 'reduce', 'number', 'redundant', 'variable', 'first', 'try', 'build', 'model', 'one', 'way', 'reduce', 'number', 'redundant', 'variable', 'variable', 'clustering']"
406,"Because the MODELSE option is used, the Analysis Of GEE Parameter Estimates table shows both the empirical standard error estimates and the model-based standard error estimates. The empirical standard error estimates are robust estimates that do not depend on the correctness of the structure imposed on the working correlation matrix. The model-based standard error estimates are based directly on the assumed correlation structure. The model-based standard errors are better estimates if the assumed model for the correlation structure is correct, but worse if the assumed model is incorrect (Allison 1999). Because the sample size is large and the number of repeated measurements is small, the robust standard errors are generally preferred. Notice that smoker is now not significant and age is even more significant. Because smoker is a time-independent variable, the standard error was underestimated (0.1235) in the initial parameter estimates where the standard errors are based on the assumption of independence. The empirical standard error estimate using GEEs is 0.1782, which makes smoker not significant (p-value of 0.1550). This illustrates how ignoring correlated observations can inflate the Type I error rate for time-independent predictor variables. The standard error for age, a time-dependent variable, is estimated at 0.0541 in the initial parameter estimates. The empirical standard error is 0.0442, which lowers the p-value of age (0.036 to 0.0094). This illustrates how ignoring correlated observations can inflate the Type II error rate for time-dependent predictor variables. Score Statistics For Type 3 GEE Analysis",CD,1641,"['modelse', 'option', 'used', 'analysis', 'gee', 'parameter_estimate', 'table', 'show', 'empirical', 'standard_error', 'estimate', 'modelbased', 'standard_error', 'estimate', 'empirical', 'standard_error', 'estimate', 'robust', 'estimate', 'depend', 'correctness', 'structure', 'imposed', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'estimate', 'based', 'directly', 'assumed', 'correlation_structure', 'modelbased', 'standard_error', 'better', 'estimate', 'assumed', 'model', 'correlation_structure', 'correct', 'worse', 'assumed', 'model', 'incorrect', 'allison', '1999', 'sample_size', 'large', 'number', 'repeated', 'measurement', 'small', 'robust', 'standard_error', 'generally', 'preferred', 'notice', 'smoker', 'significant', 'age', 'even', 'significant', 'smoker', 'timeindependent', 'variable', 'standard_error', 'wa', 'underestimated', '01235', 'initial', 'parameter_estimate', 'standard_error', 'based', 'assumption', 'independence', 'empirical', 'standard_error', 'estimate', 'using', 'gee', '01782', 'make', 'smoker', 'significant', 'pvalue', '01550', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'error', 'rate', 'timeindependent', 'predictor_variable', 'standard_error', 'age', 'timedependent', 'variable', 'estimated', '00541', 'initial', 'parameter_estimate', 'empirical', 'standard_error', '00442', 'lower', 'pvalue', 'age', '0036', '00094', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'ii', 'error', 'rate', 'timedependent', 'predictor_variable', 'score', 'statistic', 'type', '3', 'gee', 'analysis']"
407,"The odds ratio indicates that among women with no uterine irritability, those with previous preterm deliveries are 5.5 times more likely to have a low birth weight baby. The exact confidence limits are not needed because of the large sample size. Table 2 of prev_pretrm by low Controlling for uterine_irr=1",CD,306,"['odds_ratio', 'indicates', 'among', 'woman', 'uterine', 'irritability', 'previous', 'preterm', 'delivery', '55', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'exact', 'confidence', 'limit', 'needed', 'large', 'sample_size', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
408,WARNING: The maximum likelihood estimate may not exist. WARNING: The LOGISTIC procedure continues in spite of the above warning. Results shown are based on the last maximum likelihood iteration. Validity of the model fit is questionable.,CD,237,"['warning', 'maximum', 'likelihood', 'estimate', 'may', 'exist', 'warning', 'logistic', 'procedure', 'continues', 'spite', 'warning', 'result', 'shown', 'based', 'last', 'maximum', 'likelihood', 'iteration', 'validity', 'model', 'fit', 'questionable']"
409,"Special methods of statistical analysis are needed for clustered data because the set of measurements on one subject tends to be correlated and measurements on the same subject close in time tend to be more highly correlated than measurements far apart in time. These potential patterns of correlation must be taken into account to draw valid statistical inferences. Therefore, models fit in PROC LOGISTIC might produce invalid results because the independence assumption might not be valid.",CD,491,"['special', 'method', 'statistical', 'analysis', 'needed', 'clustered', 'data_set', 'measurement', 'one', 'subject', 'tends', 'correlated', 'measurement', 'subject', 'close', 'time', 'tend', 'highly', 'correlated', 'measurement', 'far', 'apart', 'time', 'potential', 'pattern', 'correlation', 'must', 'taken', 'account', 'draw', 'valid', 'statistical', 'inference', 'therefore', 'model', 'fit', 'proc_logistic', 'might', 'produce', 'invalid', 'result', 'independence', 'assumption', 'might', 'valid']"
410,"When building a model, it is critical that you assess the need to include interaction terms among the predictor variables. One recommendation is to assess only those interactions that are specified a priori based on subject-matter knowledge. To assess the significance of the interaction, compute a likelihood ratio test that compares the model with the interaction to the model with the main effects only. The degrees of freedom would be the difference in the number of variables. If the p-value is below a specified significance level, then you may want to include the interaction term in the final model. However, the final decision as to whether an interaction term should be included in a model should be based on statistical as well as practical considerations. In other words, the interaction term must make sense from a subject-matter point of view (Hosmer and Lemeshow 2000).",CD,884,"['building', 'model', 'critical', 'ass', 'need', 'include', 'interaction', 'term', 'among', 'predictor_variable', 'one', 'recommendation', 'ass', 'interaction', 'specified', 'priori', 'based', 'subjectmatter', 'knowledge', 'ass', 'significance', 'interaction', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'model', 'interaction', 'model', 'main_effect', 'degree', 'freedom', 'would', 'difference', 'number', 'variable', 'pvalue', 'specified', 'significance', 'level', 'may', 'want', 'include', 'interaction', 'term', 'final', 'model', 'however', 'final', 'decision', 'whether', 'interaction', 'term', 'included', 'model', 'based', 'statistical', 'well', 'practical', 'consideration', 'word', 'interaction', 'term', 'must', 'make', 'sense', 'subjectmatter', 'point', 'view', 'hosmer', 'lemeshow', '2000']"
411,"Because the MODELSE option is used, the Analysis Of GEE Parameter Estimates table shows both the empirical standard error estimates and the model-based standard error estimates. The empirical standard error estimates are robust estimates that do not depend on the correctness of the structure imposed on the working correlation matrix. The model-based standard error estimates are based directly on the assumed correlation structure. The model-based standard errors are better estimates if the assumed model for the correlation structure is correct, but worse if the assumed model is incorrect (Allison 1999). Because the sample size is large and the number of repeated measurements is small, the robust standard errors are generally preferred. Notice that smoker is now not significant and age is even more significant. Because smoker is a time-independent variable, the standard error was underestimated (0.1235) in the initial parameter estimates where the standard errors are based on the assumption of independence. The empirical standard error estimate using GEEs is 0.1782, which makes smoker not significant (p-value of 0.1550). This illustrates how ignoring correlated observations can inflate the Type I error rate for time-independent predictor variables. The standard error for age, a time-dependent variable, is estimated at 0.0541 in the initial parameter estimates. The empirical standard error is 0.0442, which lowers the p-value of age (0.036 to 0.0094). This illustrates how ignoring correlated observations can inflate the Type II error rate for time-dependent predictor variables. Score Statistics For Type 3 GEE Analysis",CD,1641,"['modelse', 'option', 'used', 'analysis', 'gee', 'parameter_estimate', 'table', 'show', 'empirical', 'standard_error', 'estimate', 'modelbased', 'standard_error', 'estimate', 'empirical', 'standard_error', 'estimate', 'robust', 'estimate', 'depend', 'correctness', 'structure', 'imposed', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'estimate', 'based', 'directly', 'assumed', 'correlation_structure', 'modelbased', 'standard_error', 'better', 'estimate', 'assumed', 'model', 'correlation_structure', 'correct', 'worse', 'assumed', 'model', 'incorrect', 'allison', '1999', 'sample_size', 'large', 'number', 'repeated', 'measurement', 'small', 'robust', 'standard_error', 'generally', 'preferred', 'notice', 'smoker', 'significant', 'age', 'even', 'significant', 'smoker', 'timeindependent', 'variable', 'standard_error', 'wa', 'underestimated', '01235', 'initial', 'parameter_estimate', 'standard_error', 'based', 'assumption', 'independence', 'empirical', 'standard_error', 'estimate', 'using', 'gee', '01782', 'make', 'smoker', 'significant', 'pvalue', '01550', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'error', 'rate', 'timeindependent', 'predictor_variable', 'standard_error', 'age', 'timedependent', 'variable', 'estimated', '00541', 'initial', 'parameter_estimate', 'empirical', 'standard_error', '00442', 'lower', 'pvalue', 'age', '0036', '00094', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'ii', 'error', 'rate', 'timedependent', 'predictor_variable', 'score', 'statistic', 'type', '3', 'gee', 'analysis']"
412,"For health-related studies, certain types of interactions have frequently been found to be significant. For example, the interaction between treatment and severity of disease sometimes shows that patients with mild severity have little opportunity to receive the treatment?s benefit. An example of an interaction between measurement and the state of the subject during a measurement is when the respiration rate measured during sleep has greater predictive value compared to the respiration rate measured during activity (Harrell 1997). Forward Selection",CD,554,"['healthrelated', 'study', 'certain', 'type', 'interaction', 'frequently', 'found', 'significant', 'example', 'interaction', 'treatment', 'severity', 'disease', 'sometimes', 'show', 'patient', 'mild', 'severity', 'little', 'opportunity', 'receive', 'treatment', 'benefit', 'example', 'interaction', 'measurement', 'state', 'subject', 'measurement', 'respiration', 'rate', 'measured', 'sleep', 'ha', 'greater', 'predictive', 'value', 'compared', 'respiration', 'rate', 'measured', 'activity', 'harrell', '1997', 'forward', 'selection']"
413,The Parameter Information table displays the names of the parameters. Notice PROC GENMOD shows which value of the response variable is being modeled. Criteria For Assessing Goodness Of Fit,CD,188,"['parameter', 'information', 'table', 'display', 'name', 'parameter', 'notice', 'proc', 'genmod', 'show', 'value', 'response_variable', 'modeled', 'criterion', 'assessing', 'goodness', 'fit']"
414,The forward selection procedure starts with no variables in the model. At each step the variable with the largest adjusted chi-square statistic is entered into the model if its p-value is lower than the specified significance level. The residual chi-square tests the significance of the variables not in the model. Step 1. Effect prev_pretrm entered: Model Convergence Status,CD,375,"['forward', 'selection', 'procedure', 'start', 'variable', 'model', 'step', 'variable', 'largest', 'adjusted', 'chisquare', 'statistic', 'entered', 'model', 'pvalue', 'lower', 'specified', 'significance', 'level', 'residual', 'chisquare', 'test', 'significance', 'variable', 'model', 'step', '1', 'effect', 'prevpretrm', 'entered', 'model', 'convergence', 'status']"
415,"Least squares estimators for the model parameters are not used in logistic regression because the variance of the outcome is not constant across the values of the predictor variable. Because of the nonconstant variance, least squares parameter estimates are not efficient (other estimation methods yield smaller standard errors) and the standard error estimates are not consistent (the estimated standard errors could be biased). Therefore, the method of maximum likelihood is used to produce estimators that are consistent, asymptotically efficient, and asymptotically normal. This method finds the parameter estimates that are most likely to occur, given the data, by maximizing the likelihood function, which expresses the probability of the observed data as a function of the unknown parameters.",CD,799,"['least', 'square', 'estimator', 'model', 'parameter', 'used', 'logistic_regression', 'variance', 'outcome', 'constant', 'across', 'value', 'predictor_variable', 'nonconstant', 'variance', 'least', 'square', 'parameter_estimate', 'efficient', 'estimation', 'method', 'yield', 'smaller', 'standard_error', 'standard_error', 'estimate', 'consistent', 'estimated', 'standard_error', 'could', 'biased', 'therefore', 'method', 'maximum', 'likelihood', 'used', 'produce', 'estimator', 'consistent', 'asymptotically', 'efficient', 'asymptotically', 'normal', 'method', 'find', 'parameter_estimate', 'likely', 'occur', 'given', 'data', 'maximizing', 'likelihood', 'function', 'express', 'probability', 'observed', 'data', 'function', 'unknown', 'parameter']"
416,"The first section of the output describes the data set, the response variable, the number of response levels, the type of model, the algorithm used to obtain the parameter estimates, and the number of observations read and used. The Response Profile table shows the response variable values listed according to their ordered values. By default, PROC LOGISTIC orders the response variable alphanumerically so that it bases the logistic regression model on the probability of the smallest value. Because you used the EVENT=option, in this example, the model is based on the probability of low birth weight (low=1). The Response Profile table also shows the value of the response variable and the frequency. The class level information shows that socio was dummy coded into two design variables. Because you used the PARAM=REF and REF='3' options, this table reflects your choice of socio=3 as the reference level. Model Fit Statistics",CD,932,"['first', 'section', 'output', 'describes', 'data_set', 'response_variable', 'number', 'response', 'level', 'type', 'model', 'algorithm', 'used', 'obtain', 'parameter_estimate', 'number', 'observation', 'read', 'used', 'response', 'profile', 'table', 'show', 'response_variable', 'value', 'listed', 'according', 'ordered', 'value', 'default', 'proc_logistic', 'order', 'response_variable', 'alphanumerically', 'base', 'logistic_regression_model', 'probability', 'smallest', 'value', 'used', 'eventoption', 'example', 'model', 'based', 'probability', 'low', 'birth', 'weight', 'low1', 'response', 'profile', 'table', 'also', 'show', 'value', 'response_variable', 'frequency', 'class', 'level', 'information', 'show', 'socio', 'wa', 'dummy', 'coded', 'two', 'design', 'variable', 'used', 'paramref', 'ref3', 'option', 'table', 'reflects', 'choice', 'socio3', 'reference', 'level', 'model', 'fit', 'statistic']"
417,"PROC FREQ was used to compute a crude odds ratio for each of the binary predictor variables while PROC LOGISTIC was used to compute a crude odds ratio for the continuous variables and an adjusted odds ratio for all the variables. A comparison of the crude odds ratios and the adjusted odds ratios show relatively large changes. Previous preterm deliveries showed a large decrease while uterine irritability went from a significant crude odds ratio to a nonsignificant adjusted odds ratio. History of hypertension showed a large increase in the odds ratio, but the large confidence interval indicates data sparseness.",CD,616,"['proc', 'freq', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'binary', 'predictor_variable', 'proc_logistic', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'continuous', 'variable', 'adjusted', 'odds_ratio', 'variable', 'comparison', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'show', 'relatively', 'large', 'change', 'previous', 'preterm', 'delivery', 'showed', 'large', 'decrease', 'uterine', 'irritability', 'went', 'significant', 'crude', 'odds_ratio', 'nonsignificant', 'adjusted', 'odds_ratio', 'history', 'hypertension', 'showed', 'large', 'increase', 'odds_ratio', 'large', 'confidence', 'interval', 'indicates', 'data', 'sparseness']"
418,"In this example the number of subjects is very large and the number of time points very small. Therefore, there should be little difference in the parameter estimates and the robust standard errors across the different correlation structures. The above slide illustrates the robustness of the GEE methods with regard to obtaining consistent parameter estimates and standard errors. Notice the standard errors increased for smoker and decreased for age when compared to the initial independent model. 3.2	Proportional Odds Model",CD,527,"['example', 'number', 'subject', 'large', 'number', 'time', 'point', 'small', 'therefore', 'little', 'difference', 'parameter_estimate', 'robust', 'standard_error', 'across', 'different', 'correlation_structure', 'slide', 'illustrates', 'robustness', 'gee', 'method', 'regard', 'obtaining', 'consistent', 'parameter_estimate', 'standard_error', 'notice', 'standard_error', 'increased', 'smoker', 'decreased', 'age', 'compared', 'initial', 'independent', 'model', '32\tproportional', 'odds', 'model']"
419,"In this example the number of subjects is very large and the number of time points very small. Therefore, there should be little difference in the parameter estimates and the robust standard errors across the different correlation structures. The above slide illustrates the robustness of the GEE methods with regard to obtaining consistent parameter estimates and standard errors. Notice the standard errors increased for smoker and decreased for age when compared to the initial independent model. 3.2	Proportional Odds Model",CD,527,"['example', 'number', 'subject', 'large', 'number', 'time', 'point', 'small', 'therefore', 'little', 'difference', 'parameter_estimate', 'robust', 'standard_error', 'across', 'different', 'correlation_structure', 'slide', 'illustrates', 'robustness', 'gee', 'method', 'regard', 'obtaining', 'consistent', 'parameter_estimate', 'standard_error', 'notice', 'standard_error', 'increased', 'smoker', 'decreased', 'age', 'compared', 'initial', 'independent', 'model', '32\tproportional', 'odds', 'model']"
420,"The modeling-building strategy for ordinal logistic regression is the same as for binary logistic regression. First, do an exploratory data analysis with contingency tables and logit plots. During this stage also look for confounders and interactions. Then try to find a subset of predictor variables that are associated with severity of back pain during pregnancy. In this example, there are 22 predictor variables. With so many variables, there is a good chance that many of them are collinear or redundant. A good strategy in this case is to reduce the number of redundant variables first before you try to build a model. One way to reduce the number of redundant variables is through variable clustering.",CD,708,"['modelingbuilding', 'strategy', 'ordinal', 'logistic_regression', 'binary', 'logistic_regression', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'stage', 'also', 'look', 'confounders', 'interaction', 'try', 'find', 'subset', 'predictor_variable', 'associated', 'severity', 'back', 'pain', 'pregnancy', 'example', '22', 'predictor_variable', 'many', 'variable', 'good', 'chance', 'many', 'collinear', 'redundant', 'good', 'strategy', 'case', 'reduce', 'number', 'redundant', 'variable', 'first', 'try', 'build', 'model', 'one', 'way', 'reduce', 'number', 'redundant', 'variable', 'variable', 'clustering']"
421,"For logistic regression, the sufficient statistics for the in the model are where j=1,?, number of predictor variables. Therefore, the sufficient statistics for the parameters of the predictor variables are the sum of the cross-products of the response value and the predictor variable values. The sufficient statistic for the intercept is the total number of events since the intercept variable is constant at 1.",CD,413,"['logistic_regression', 'sufficient', 'statistic', 'model', 'j1', 'number', 'predictor_variable', 'therefore', 'sufficient', 'statistic', 'parameter', 'predictor_variable', 'sum', 'crossproducts', 'response', 'value', 'predictor_variable', 'value', 'sufficient', 'statistic', 'intercept', 'total', 'number', 'event', 'since', 'intercept', 'variable', 'constant', '1']"
422,"Least squares estimators for the model parameters are not used in logistic regression because the variance of the outcome is not constant across the values of the predictor variable. Because of the nonconstant variance, least squares parameter estimates are not efficient (other estimation methods yield smaller standard errors) and the standard error estimates are not consistent (the estimated standard errors could be biased). Therefore, the method of maximum likelihood is used to produce estimators that are consistent, asymptotically efficient, and asymptotically normal. This method finds the parameter estimates that are most likely to occur, given the data, by maximizing the likelihood function, which expresses the probability of the observed data as a function of the unknown parameters.",CD,799,"['least', 'square', 'estimator', 'model', 'parameter', 'used', 'logistic_regression', 'variance', 'outcome', 'constant', 'across', 'value', 'predictor_variable', 'nonconstant', 'variance', 'least', 'square', 'parameter_estimate', 'efficient', 'estimation', 'method', 'yield', 'smaller', 'standard_error', 'standard_error', 'estimate', 'consistent', 'estimated', 'standard_error', 'could', 'biased', 'therefore', 'method', 'maximum', 'likelihood', 'used', 'produce', 'estimator', 'consistent', 'asymptotically', 'efficient', 'asymptotically', 'normal', 'method', 'find', 'parameter_estimate', 'likely', 'occur', 'given', 'data', 'maximizing', 'likelihood', 'function', 'express', 'probability', 'observed', 'data', 'function', 'unknown', 'parameter']"
423,"The graph shows that for mothers who did not visit the physician during the first trimester, the probability of a low birth weight baby increases with age. However, for mothers who did visit the physician during the first trimester, the probability of a low birth weight baby decreases with age.",CD,295,"['graph', 'show', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'increase', 'age', 'however', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'decrease', 'age']"
424,"The odds ratio indicates that among women with no uterine irritability, those with previous preterm deliveries are 5.5 times more likely to have a low birth weight baby. The exact confidence limits are not needed because of the large sample size. Table 2 of prev_pretrm by low Controlling for uterine_irr=1",CD,306,"['odds_ratio', 'indicates', 'among', 'woman', 'uterine', 'irritability', 'previous', 'preterm', 'delivery', '55', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'exact', 'confidence', 'limit', 'needed', 'large', 'sample_size', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
425,"Adjusted odds ratios provide a correct estimate of the effect of the predictor variable on the response only when the odds ratio is constant across the strata. Therefore, it is crucial to check for interactions among the predictor variables. For binary predictors, stratified data analysis can be used to detect interactions with the use of the Breslow-Day statistic. The Breslow-Day statistic *	tests the null hypothesis of homogeneity of the odds ratios *	has a chi-square distribution if the sample size is sufficiently large in each stratum and the null hypothesis is true *	requires a large sample size in each stratum. The sample size requirements are that at least 80% of the cells in all the tables have expected cell counts greater than 5. If the sample size is too small in any of the strata, then the p-value calculated from the chi-square distribution will not be accurate. The computation of the Breslow-Day statistic does not include any strata with zero rows or columns. If the Breslow-Day test is significant and valid, then the stratum-specific odds ratios should be displayed. It should be noted that the adjusted odds ratio may be misleading if the stratum-specific odds ratios vary widely across 1 (one stratum-specific odds ratio is less than 1 while the other is greater than 1). The computation of the Breslow-Day statistic includes the Mantel-Haenszel adjusted odds ratio. Tarone (1985) showed that because of the inefficiency of the Mantel-Haenszel adjusted odds ratio, you must adjust the Breslow-Day statistic for it to have a limiting chi-squared null distribution with degrees of freedom equal to the number of strata ? 1. This adjustment is usually minor. Frequency Table Analysis",CD,1710,"['adjusted', 'odds_ratio', 'provide', 'correct', 'estimate', 'effect', 'predictor_variable', 'response', 'odds_ratio', 'constant', 'across', 'stratum', 'therefore', 'crucial', 'check', 'interaction', 'among', 'predictor_variable', 'binary', 'predictor', 'stratified', 'data', 'analysis', 'used', 'detect', 'interaction', 'use', 'breslowday', 'statistic', 'breslowday', 'statistic', '\ttests', 'null', 'hypothesis', 'homogeneity', 'odds_ratio', '\thas', 'chisquare', 'distribution', 'sample_size', 'sufficiently', 'large', 'stratum', 'null', 'hypothesis', 'true', '\trequires', 'large', 'sample_size', 'stratum', 'sample_size', 'requirement', 'least', '80', 'cell', 'table', 'expected', 'cell', 'count', 'greater', '5', 'sample_size', 'small', 'stratum', 'pvalue', 'calculated', 'chisquare', 'distribution', 'accurate', 'computation', 'breslowday', 'statistic', 'doe', 'include', 'stratum', 'zero', 'row', 'column', 'breslowday', 'test', 'significant', 'valid', 'stratumspecific', 'odds_ratio', 'displayed', 'noted', 'adjusted', 'odds_ratio', 'may', 'misleading', 'stratumspecific', 'odds_ratio', 'vary', 'widely', 'across', '1', 'one', 'stratumspecific', 'odds_ratio', 'le', '1', 'greater', '1', 'computation', 'breslowday', 'statistic', 'includes', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'tarone', '1985', 'showed', 'inefficiency', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'must', 'adjust', 'breslowday', 'statistic', 'limiting', 'chisquared', 'null', 'distribution', 'degree', 'freedom', 'equal', 'number', 'stratum', '', '1', 'adjustment', 'usually', 'minor', 'frequency', 'table', 'analysis']"
426,"Because there is a common slope for each predictor variable, the odds ratio is constant for all the categories. The odds ratios can be interpreted as the effect of the predictor variable on the odds of being in a lower ordered value category rather than in a higher ordered value category, regardless of what cumulative logit you are examining. If you use the DESCENDING option in the PROC LOGISTIC statement, the odds ratio is the effect of the predictor variable on the odds of being in a higher rather than a lower category. For example, suppose the odds ratio for bending is 3.0 and you used the DESCENDING option (category=severe is the first ordered category and category=none is the last ordered category). You can interpret the odds ratio by stating the women who say that bending aggravates their back pain have 3 times the odds of being in a higher pain severity category compared to women who say that bending does not aggravate their back pain.",CD,956,"['common', 'slope', 'predictor_variable', 'odds_ratio', 'constant', 'category', 'odds_ratio', 'interpreted', 'effect', 'predictor_variable', 'odds', 'lower', 'ordered', 'value', 'category', 'rather', 'higher', 'ordered', 'value', 'category', 'regardless', 'cumulative', 'logit', 'examining', 'use', 'descending', 'option', 'proc_logistic', 'statement', 'odds_ratio', 'effect', 'predictor_variable', 'odds', 'higher', 'rather', 'lower', 'category', 'example', 'suppose', 'odds_ratio', 'bending', '30', 'used', 'descending', 'option', 'categorysevere', 'first', 'ordered', 'category', 'categorynone', 'last', 'ordered', 'category', 'interpret', 'odds_ratio', 'stating', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '3', 'time', 'odds', 'higher', 'pain', 'severity', 'category', 'compared', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain']"
427,"To assess the significance of the extra terms in the model, you can compute a likelihood ratio test that compares two models. One model would be the full model with all the terms, and the other model would be the reduced model with just a subset of the terms. The difference between the negative 2 log likelihood for the reduced model and the negative 2 log likelihood for the full model is the value of the test statistic for the likelihood ratio test. An alternative way to compute this test statistic is to take the difference between the likelihood ratio chi-square statistic reported for the model with the extra terms and the likelihood ratio chi-square statistic reported for the model without the extra terms. The degrees of freedom would be the difference in the number of terms between the two models. The test statistic along with the corresponding p-value can be computed using ODS. The test statistic for the likelihood ratio test follows a chi-square distribution if the reduced model is a subset of the full model. Therefore, the validity of the test would be compromised if you were comparing two entirely different models. An alternative way to compute likelihood-ratio tests is to use the GENMOD procedure with the TYPE3 option. PROC GENMOD will be shown in a later chapter. Likelihood Ratio Test Statistic",CD,1324,"['ass', 'significance', 'extra', 'term', 'model', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'two', 'model', 'one', 'model', 'would', 'full', 'model', 'term', 'model', 'would', 'reduced', 'model', 'subset', 'term', 'difference', 'negative', '2', 'log', 'likelihood', 'reduced', 'model', 'negative', '2', 'log', 'likelihood', 'full', 'model', 'value', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'alternative', 'way', 'compute', 'test', 'statistic', 'take', 'difference', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'extra', 'term', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'without', 'extra', 'term', 'degree', 'freedom', 'would', 'difference', 'number', 'term', 'two', 'model', 'test', 'statistic', 'along', 'corresponding', 'pvalue', 'computed', 'using', 'od', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'follows', 'chisquare', 'distribution', 'reduced', 'model', 'subset', 'full', 'model', 'therefore', 'validity', 'test', 'would', 'compromised', 'comparing', 'two', 'entirely', 'different', 'model', 'alternative', 'way', 'compute', 'likelihoodratio', 'test', 'use', 'genmod', 'procedure', 'type3', 'option', 'proc', 'genmod', 'shown', 'later', 'chapter', 'likelihood', 'ratio', 'test', 'statistic']"
428,"PROC LOGISTIC reports a score test for the proportional odds assumption. This tests the null hypothesis that the slope coefficients are equal across the cumulative logits for each predictor variable. Because the p-value is not significant at the 0.05 significance level, you do not reject the assumption of equal slopes and the proportional odds assumption is validated. Model Fit Statistics",CD,391,"['proc_logistic', 'report', 'score', 'test', 'proportional', 'odds', 'assumption', 'test', 'null', 'hypothesis', 'slope', 'coefficient', 'equal', 'across', 'cumulative', 'logits', 'predictor_variable', 'pvalue', 'significant', '005', 'significance', 'level', 'reject', 'assumption', 'equal', 'slope', 'proportional', 'odds', 'assumption', 'validated', 'model', 'fit', 'statistic']"
429,"Finally, the unstructured correlation structure (TYPE=UNSTR) is completely unspecified. Therefore, there are t(t?1)/2 parameters to be estimated (where t is the number of time points). Although the unstructured working correlation structure is the most efficient, it is useful only when there are very few observation times. If there were many time points, you would probably want to impose some structure to the correlation matrix by selecting one of the other correlation structures (Allison 1999). Furthermore, when there are missing values or a varying number of observations per subject, a nonpositive definite matrix may occur, which would stop the parameter estimation process (Stokes, Davis, and Koch 2000).",CD,715,"['finally', 'unstructured', 'correlation_structure', 'typeunstr', 'completely', 'unspecified', 'therefore', 'tt12', 'parameter', 'estimated', 'number', 'time', 'point', 'although', 'unstructured', 'working', 'correlation_structure', 'efficient', 'useful', 'observation', 'time', 'many', 'time', 'point', 'would', 'probably', 'want', 'impose', 'structure', 'correlation', 'matrix', 'selecting', 'one', 'correlation_structure', 'allison', '1999', 'furthermore', 'missing', 'value', 'varying', 'number', 'observation', 'per', 'subject', 'nonpositive', 'definite', 'matrix', 'may', 'occur', 'would', 'stop', 'parameter', 'estimation', 'process', 'stokes', 'davis', 'koch', '2000']"
430,Total Proportion Minimum Maximum Minimum Maximum Number Variation of Variation Proportion Second R-squared 1-R**2 Ratio of Explained Explained Explained Eigenvalue for a for a Clusters by Clusters by Clusters by a Cluster in a Cluster Variable Variable,CD,252,"['total', 'proportion', 'minimum', 'maximum', 'minimum', 'maximum', 'number', 'variation', 'variation', 'proportion', 'second', 'rsquared', '1r2', 'ratio', 'explained', 'explained', 'explained', 'eigenvalue', 'cluster', 'cluster', 'cluster', 'cluster', 'cluster', 'variable', 'variable']"
431,"Building a nominal logistic regression model employs the same strategy as building any other model. The first step is to examine the distribution of the predictor variables and take note of any missing values and unusual data values. Contingency table analysis should also be performed to examine the associations between the outcome variable and each of the ordinal predictor variables. You should carefully look for cells with no observations, because this may cause a problem in PROC LOGISTIC.",CD,496,"['building', 'nominal', 'logistic_regression_model', 'employ', 'strategy', 'building', 'model', 'first', 'step', 'examine', 'distribution', 'predictor_variable', 'take', 'note', 'missing', 'value', 'unusual', 'data', 'value', 'contingency', 'table', 'analysis', 'also', 'performed', 'examine', 'association', 'outcome', 'variable', 'ordinal', 'predictor_variable', 'carefully', 'look', 'cell', 'observation', 'may', 'cause', 'problem', 'proc_logistic']"
432,"Because the response variable has more than 2 levels, by default PROC LOGISTIC models cumulative logits. With the DESCENDING option, the probabilities modeled are cumulated by the jth category and higher. Score Test for the Proportional Odds Assumption",CD,252,"['response_variable', 'ha', '2', 'level', 'default', 'proc_logistic', 'model', 'cumulative', 'logits', 'descending', 'option', 'probability', 'modeled', 'cumulated', 'jth', 'category', 'higher', 'score', 'test', 'proportional', 'odds', 'assumption']"
433,"PROC LOGISTIC reports a score test for the proportional odds assumption. This tests the null hypothesis that the slope coefficients are equal across the cumulative logits for each predictor variable. Because the p-value is not significant at the 0.05 significance level, you do not reject the assumption of equal slopes and the proportional odds assumption is validated. Model Fit Statistics",CD,391,"['proc_logistic', 'report', 'score', 'test', 'proportional', 'odds', 'assumption', 'test', 'null', 'hypothesis', 'slope', 'coefficient', 'equal', 'across', 'cumulative', 'logits', 'predictor_variable', 'pvalue', 'significant', '005', 'significance', 'level', 'reject', 'assumption', 'equal', 'slope', 'proportional', 'odds', 'assumption', 'validated', 'model', 'fit', 'statistic']"
434,"NOTE: Reported test p-values are lower-bounds for the true p-values. Notice that the p-values are different for the score test and the probability test. It is recommended that the score test results be used. Also note that the reported test p-values are lower bounds for the true p-values. This occurs because when the exact distribution has ties, the Monte Carlo algorithm estimates the probabilities with error, and hence it cannot determine which values contribute to the reported p-values. If you need more precise values, you can specify the OUTDIST= option, determine appropriate cutoff values for the observed probability and score, and then construct the true p-value estimates from the OUTDIST= data set. See the SAS/STAT software online documentation under the LOGISTIC procedure for programming statements to accomplish this task. Exact Parameter Estimates",CD,867,"['note', 'reported', 'test', 'pvalues', 'lowerbounds', 'true', 'pvalues', 'notice', 'pvalues', 'different', 'score', 'test', 'probability', 'test', 'recommended', 'score', 'test', 'result', 'used', 'also', 'note', 'reported', 'test', 'pvalues', 'lower', 'bound', 'true', 'pvalues', 'occurs', 'exact', 'distribution', 'ha', 'tie', 'monte', 'carlo', 'algorithm', 'estimate', 'probability', 'error', 'hence', 'cannot', 'determine', 'value', 'contribute', 'reported', 'pvalues', 'need', 'precise', 'value', 'specify', 'outdist', 'option', 'determine', 'appropriate', 'cutoff', 'value', 'observed', 'probability', 'score', 'construct', 'true', 'pvalue', 'estimate', 'outdist', 'data_set', 'see', 'sasstat', 'software', 'online', 'documentation', 'logistic', 'procedure', 'programming', 'statement', 'accomplish', 'task', 'exact', 'parameter_estimate']"
435,Variables with the lowest 1 minus R-squared ratio are variables with a high correlation with their own cluster and with a low correlation with the other clusters. These variables may be good representative variables from each cluster.,CD,234,"['variable', 'lowest', '1', 'minus', 'rsquared', 'ratio', 'variable', 'high', 'correlation', 'cluster', 'low', 'correlation', 'cluster', 'variable', 'may', 'good', 'representative', 'variable', 'cluster']"
436,"In some estimation problems, you need to be able to summarize the information in the sample or find some function in the sample that tells you just as much about the parameter of interest as the sample itself. This function is sufficient for estimation purposes and therefore is called a sufficient statistic. In other words, a sufficient statistic condenses the data in such a way that no information is lost about the parameter. When a statistic loses no information, it contains all the information about the parameter that is contained in the sample. There can be more than one set of sufficient statistics. A minimal sufficient statistic is the most condensed summary of the data.",CD,685,"['estimation', 'problem', 'need', 'able', 'summarize', 'information', 'sample', 'find', 'function', 'sample', 'tell', 'much', 'parameter', 'interest', 'sample', 'function', 'sufficient', 'estimation', 'purpose', 'therefore', 'called', 'sufficient', 'statistic', 'word', 'sufficient', 'statistic', 'condenses', 'data', 'way', 'information', 'lost', 'parameter', 'statistic', 'loses', 'information', 'contains', 'information', 'parameter', 'contained', 'sample', 'one', 'set', 'sufficient', 'statistic', 'minimal', 'sufficient', 'statistic', 'condensed', 'summary', 'data']"
437,The chi-square test of association shows that there is strong evidence that an association exists between prev_pretrm and low. Fisher?s exact test is not needed because of the large sample size. Statistics for Table of prev_pretrm by low,CD,237,"['chisquare', 'test', 'association', 'show', 'strong', 'evidence', 'association', 'exists', 'prevpretrm', 'low', 'fisher', 'exact', 'test', 'needed', 'large', 'sample_size', 'statistic', 'table', 'prevpretrm', 'low']"
438,"The deviance and Pearson chi-squares are two goodness-of-fit statistics produced in PROC LOGISTIC. These statistics compare the fitted model to a saturated model. The saturated model, which has one parameter for every predicted probability, always fits the data better. However, if these statistics are not significant, then the difference in fit could be explained by chance. A significant chi-square means that there is a model that fits the data better than your model. With the AGGREGATE and SCALE=NONE options, PROC LOGISTIC computes the chi-squares by cross-classifying all the levels of the predictor variables. For each combination of levels, the observed and expected frequencies for each level of the outcome variable are then calculated based on the fitted model. The deviance chi-square is then calculated as where Oj and Ej are the observed and expected frequencies in cell j. The Pearson chi-square is calculated as , which is testing the same null hypothesis as the deviance chi-square test. A problem with these statistics is the sample size requirements. For these statistics to follow a chi- square distribution, there must be an average of at least 10 observations in each cell. Furthermore, at least 80% of the expected frequencies should be 5 or more and all other expected counts should be greater than 2. There should also be no empty cells (Stokes, Davis, Koch 2000).",CD,1391,"['deviance', 'pearson', 'chisquares', 'two', 'goodnessoffit', 'statistic', 'produced', 'proc_logistic', 'statistic', 'compare', 'fitted', 'model', 'saturated', 'model', 'saturated', 'model', 'ha', 'one', 'parameter', 'every', 'predicted', 'probability', 'always', 'fit', 'data', 'better', 'however', 'statistic', 'significant', 'difference', 'fit', 'could', 'explained', 'chance', 'significant', 'chisquare', 'mean', 'model', 'fit', 'data', 'better', 'model', 'aggregate', 'scalenone', 'option', 'proc_logistic', 'computes', 'chisquares', 'crossclassifying', 'level', 'predictor_variable', 'combination', 'level', 'observed', 'expected', 'frequency', 'level', 'outcome', 'variable', 'calculated', 'based', 'fitted', 'model', 'deviance', 'chisquare', 'calculated', 'oj', 'ej', 'observed', 'expected', 'frequency', 'cell', 'j', 'pearson', 'chisquare', 'calculated', '', 'testing', 'null', 'hypothesis', 'deviance', 'chisquare', 'test', 'problem', 'statistic', 'sample_size', 'requirement', 'statistic', 'follow', 'chi', 'square', 'distribution', 'must', 'average', 'least', '10', 'observation', 'cell', 'furthermore', 'least', '80', 'expected', 'frequency', '5', 'expected', 'count', 'greater', '2', 'also', 'empty', 'cell', 'stokes', 'davis', 'koch', '2000']"
439,"Exact inference on regression parameter estimates is based on the permutation distribution of their sufficient statistics. Inference on the parameters of the specified effects is performed by conditioning on the sufficient statistics of all other model parameters. Some of these other parameters might be regarded as nuisance parameters, which are in the model to adjust for relevant effects, but their values are not of special interest. For example, suppose you are interested in estimating the regression parameter for the predictor variable A, and regard the intercept as a nuisance parameter. You can eliminate the intercept by conditioning on the observed value of its sufficient statistic, which yields the conditional likelihood function. In other words, some of the sufficient statistics are fixed at their observed values and others are allowed to vary over their permissible ranges. This is different from an unconditional likelihood function used in the asymptotic methods, which estimates all the parameters in the model. To understand the methodology of exact logistic regression, three questions need to be addressed: What are sufficient statistics? What is a permutation distribution? What is a median unbiased estimate?",CD,1236,"['exact', 'inference', 'regression', 'parameter_estimate', 'based', 'permutation', 'distribution', 'sufficient', 'statistic', 'inference', 'parameter', 'specified', 'effect', 'performed', 'conditioning', 'sufficient', 'statistic', 'model', 'parameter', 'parameter', 'might', 'regarded', 'nuisance', 'parameter', 'model', 'adjust', 'relevant', 'effect', 'value', 'special', 'interest', 'example', 'suppose', 'interested', 'estimating', 'regression', 'parameter', 'predictor_variable', 'regard', 'intercept', 'nuisance', 'parameter', 'eliminate', 'intercept', 'conditioning', 'observed', 'value', 'sufficient', 'statistic', 'yield', 'conditional', 'likelihood', 'function', 'word', 'sufficient', 'statistic', 'fixed', 'observed', 'value', 'others', 'allowed', 'vary', 'permissible', 'range', 'different', 'unconditional', 'likelihood', 'function', 'used', 'asymptotic', 'method', 'estimate', 'parameter', 'model', 'understand', 'methodology', 'exact', 'logistic_regression', 'three', 'question', 'need', 'addressed', 'sufficient', 'statistic', 'permutation', 'distribution', 'median', 'unbiased', 'estimate']"
440,title 'Estimated Logit Plot of Socioeconomic Status'; run; Selected PROC MEANS statement option: NWAY	causes the output data set to have only one observation for each level of the class variable.,CD,195,"['title', 'estimated', 'logit', 'plot', 'socioeconomic', 'status', 'run', 'selected', 'proc', 'mean', 'statement', 'option', 'nway\tcauses', 'output', 'data_set', 'one', 'observation', 'level', 'class', 'variable']"
441,"Generalized linear models use the likelihood function in statistical inference. However, the distribution of the response variable must be specified. For discrete outcomes, it might be difficult to specify the appropriate theoretical probability distribution. Therefore, GEE regression models use the quasi-likelihood method of estimation. This estimation method only requires that you specify the relationships between the response mean and covariates and between the response mean and variance. Quasi-likelihood estimation possesses many of the advantages of maximum likelihood estimation without requiring full distributional assumptions. This is why the GEE approach is applicable to several types of response variables (Zeger and Liang 1986).",CD,747,"['generalized', 'linear', 'model', 'use', 'likelihood', 'function', 'statistical', 'inference', 'however', 'distribution', 'response_variable', 'must', 'specified', 'discrete', 'outcome', 'might', 'difficult', 'specify', 'appropriate', 'theoretical', 'probability', 'distribution', 'therefore', 'gee', 'regression_model', 'use', 'quasilikelihood', 'method', 'estimation', 'estimation', 'method', 'requires', 'specify', 'relationship', 'response', 'mean', 'covariates', 'response', 'mean', 'variance', 'quasilikelihood', 'estimation', 'posse', 'many', 'advantage', 'maximum', 'likelihood', 'estimation', 'without', 'requiring', 'full', 'distributional', 'assumption', 'gee', 'approach', 'applicable', 'several', 'type', 'response_variable', 'zeger', 'liang', '1986']"
442,"If you do not know which working correlation structure to choose, one recommendation is to compare the parameter estimates and standard errors from several different correlation structures. This might indicate whether there is sensitivity to the misspecification of the correlation structure. PROC GENMOD also enables you to choose a user-defined correlation matrix.",CD,366,"['know', 'working', 'correlation_structure', 'choose', 'one', 'recommendation', 'compare', 'parameter_estimate', 'standard_error', 'several', 'different', 'correlation_structure', 'might', 'indicate', 'whether', 'sensitivity', 'misspecification', 'correlation_structure', 'proc', 'genmod', 'also', 'enables', 'choose', 'userdefined', 'correlation', 'matrix']"
443,"The primary advantage for matching over random sampling without matching is that matching might lead to a more statistically efficient analysis (Rothman 1986, Kleinbaum 1991). For example, matching might lead to a tighter confidence interval around the odds ratio being estimated for the predictor variables of interest. The reason for the improved precision is that matching might reduce the number of uninformative strata in a stratified analysis. An uninformative stratum in a matched case-control analysis is one in which the predictor variable?s value is constant. For example, suppose the primary predictor variable of interest is an exposure variable (1=yes, 0=no). If the case and control both have the same value of the exposure variable, then it is an uninformative stratum with regards to the exposure effect. Matching might lead to fewer uninformative strata, which will improve the efficiency of the study. Matching is attractive when there is a high price of expanding the study size (Rothman 1986). For example, if the cost of obtaining information from the subjects is large, it is desirable to optimize the amount of information obtained per subject. In other words, it is worthwhile to pay the cost of matching to take full advantage of the information that is collected.",CD,1289,"['primary', 'advantage', 'matching', 'random', 'sampling', 'without', 'matching', 'matching', 'might', 'lead', 'statistically', 'efficient', 'analysis', 'rothman', '1986', 'kleinbaum', '1991', 'example', 'matching', 'might', 'lead', 'tighter', 'confidence', 'interval', 'around', 'odds_ratio', 'estimated', 'predictor_variable', 'interest', 'reason', 'improved', 'precision', 'matching', 'might', 'reduce', 'number', 'uninformative', 'stratum', 'stratified', 'analysis', 'uninformative', 'stratum', 'matched', 'casecontrol', 'analysis', 'one', 'predictor_variable', 'value', 'constant', 'example', 'suppose', 'primary', 'predictor_variable', 'interest', 'exposure', 'variable', '1yes', '0no', 'case', 'control', 'value', 'exposure', 'variable', 'uninformative', 'stratum', 'regard', 'exposure', 'effect', 'matching', 'might', 'lead', 'fewer', 'uninformative', 'stratum', 'improve', 'efficiency', 'study', 'matching', 'attractive', 'high', 'price', 'expanding', 'study', 'size', 'rothman', '1986', 'example', 'cost', 'obtaining', 'information', 'subject', 'large', 'desirable', 'optimize', 'amount', 'information', 'obtained', 'per', 'subject', 'word', 'worthwhile', 'pay', 'cost', 'matching', 'take', 'full', 'advantage', 'information', 'collected']"
444,"When building a model, it is critical that you assess the need to include interaction terms among the predictor variables. One recommendation is to assess only those interactions that are specified a priori based on subject-matter knowledge. To assess the significance of the interaction, compute a likelihood ratio test that compares the model with the interaction to the model with the main effects only. The degrees of freedom would be the difference in the number of variables. If the p-value is below a specified significance level, then you may want to include the interaction term in the final model. However, the final decision as to whether an interaction term should be included in a model should be based on statistical as well as practical considerations. In other words, the interaction term must make sense from a subject-matter point of view (Hosmer and Lemeshow 2000).",CD,884,"['building', 'model', 'critical', 'ass', 'need', 'include', 'interaction', 'term', 'among', 'predictor_variable', 'one', 'recommendation', 'ass', 'interaction', 'specified', 'priori', 'based', 'subjectmatter', 'knowledge', 'ass', 'significance', 'interaction', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'model', 'interaction', 'model', 'main_effect', 'degree', 'freedom', 'would', 'difference', 'number', 'variable', 'pvalue', 'specified', 'significance', 'level', 'may', 'want', 'include', 'interaction', 'term', 'final', 'model', 'however', 'final', 'decision', 'whether', 'interaction', 'term', 'included', 'model', 'based', 'statistical', 'well', 'practical', 'consideration', 'word', 'interaction', 'term', 'must', 'make', 'sense', 'subjectmatter', 'point', 'view', 'hosmer', 'lemeshow', '2000']"
445,"In a matched case-control study, the conditional likelihood allows the model to predict the odds for the event given the predictor variable values. This involves setting up the probabilities for having the observed predictor variable values given the event and then using Bayes? theorem to determine a relevant conditional probability concerning the event. The conditional likelihood is derived by computing the conditional probability of observing the predictor variable values given the outcome (event or not). A predictor variable that is constant within a stratum cancels out of the conditional likelihood. This is the reason why the conditional logistic models cannot estimate a between-cluster effect. Statistics providing information about the between-cluster effect use subject totals at different levels of the relevant predictor variable. However, those totals sum the sufficient statistics for the stratum- specific intercepts, so they themselves are fixed and have degenerate distributions after conditioning on the sufficient statistics (Agresti 2002). Note that the conditional likelihood for the 1:1 matched case-control data is the unconditional likelihood for a logistic regression model where the response is always equal to 1, the predictor variable values are equal to the differences between the values for the case and the control, and there is no intercept. Before SAS?9, you could use PROC LOGISTIC by configuring your data appropriately and eliminating the intercept term. However, you would have to use PROC PHREG for 1:m and m:n matching.",CD,1565,"['matched', 'casecontrol', 'study', 'conditional', 'likelihood', 'allows', 'model', 'predict', 'odds', 'event', 'given', 'predictor_variable', 'value', 'involves', 'setting', 'probability', 'observed', 'predictor_variable', 'value', 'given', 'event', 'using', 'bayes', 'theorem', 'determine', 'relevant', 'conditional', 'probability', 'concerning', 'event', 'conditional', 'likelihood', 'derived', 'computing', 'conditional', 'probability', 'observing', 'predictor_variable', 'value', 'given', 'outcome', 'event', 'predictor_variable', 'constant', 'within', 'stratum', 'cancel', 'conditional', 'likelihood', 'reason', 'conditional', 'logistic', 'model', 'cannot', 'estimate', 'betweencluster', 'effect', 'statistic', 'providing', 'information', 'betweencluster', 'effect', 'use', 'subject', 'total', 'different', 'level', 'relevant', 'predictor_variable', 'however', 'total', 'sum', 'sufficient', 'statistic', 'stratum', 'specific', 'intercept', 'fixed', 'degenerate', 'distribution', 'conditioning', 'sufficient', 'statistic', 'agresti', '2002', 'note', 'conditional', 'likelihood', '11', 'matched', 'casecontrol', 'data', 'unconditional', 'likelihood', 'logistic_regression_model', 'response', 'always', 'equal', '1', 'predictor_variable', 'value', 'equal', 'difference', 'value', 'case', 'control', 'intercept', 'sas9', 'could', 'use', 'proc_logistic', 'configuring', 'data', 'appropriately', 'eliminating', 'intercept', 'term', 'however', 'would', 'use', 'proc', 'phreg', '1m', 'mn', 'matching']"
446,The odds ratio indicates that women with previous preterm deliveries are 4.3 times more likely to have a low birth weight baby than women without previous preterm deliveries. The confidence interval is not symmetric around the estimate because distributions of ratios are asymmetric. The exact confidence interval is not needed because of the large sample size. Summary Statistics for prev_pretrm by low,CD,403,"['odds_ratio', 'indicates', 'woman', 'previous', 'preterm', 'delivery', '43', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'woman', 'without', 'previous', 'preterm', 'delivery', 'confidence', 'interval', 'symmetric', 'around', 'estimate', 'distribution', 'ratio', 'asymmetric', 'exact', 'confidence', 'interval', 'needed', 'large', 'sample_size', 'summary', 'statistic', 'prevpretrm', 'low']"
447,"Because there are 16 predictor variables, it would be wise to reduce the number of redundant variables before building a model in PROC LOGISTIC. One approach to variable reduction is variable clustering. Variable clustering finds groups of variables that are as correlated as possible among themselves and as uncorrelated as possible with variables in other clusters. A common strategy is to pick one variable from each cluster based on subject-matter knowledge.",CD,462,"['16', 'predictor_variable', 'would', 'wise', 'reduce', 'number', 'redundant', 'variable', 'building', 'model', 'proc_logistic', 'one', 'approach', 'variable', 'reduction', 'variable', 'clustering', 'variable', 'clustering', 'find', 'group', 'variable', 'correlated', 'possible', 'among', 'uncorrelated', 'possible', 'variable', 'cluster', 'common', 'strategy', 'pick', 'one', 'variable', 'cluster', 'based', 'subjectmatter', 'knowledge']"
448,"Two types of adjusted odds ratio estimates are computed by PROC FREQ. One type is the Mantel- Haenszel (MH) estimator, which is obtained as a weighted average of the stratum specific odds ratios. Another type is the logit-based estimator, which is obtained from a weighted average of the stratum-specific log-odds ratios. However, zero frequencies pose a computational problem, so one- half is added to each cell of any table that contains a zero frequency. Therefore, a common recommendation is to use the MH estimators when you have a small sample size because it is less sensitive to small numbers than the logit-based estimator. It should be noted that the MH estimator and the logit-based estimator are similar when the data is not too sparse within the strata.",CD,766,"['two', 'type', 'adjusted', 'odds_ratio', 'estimate', 'computed', 'proc', 'freq', 'one', 'type', 'mantel', 'haenszel', 'mh', 'estimator', 'obtained', 'weighted', 'average', 'stratum', 'specific', 'odds_ratio', 'another', 'type', 'logitbased', 'estimator', 'obtained', 'weighted', 'average', 'stratumspecific', 'logodds', 'ratio', 'however', 'zero', 'frequency', 'pose', 'computational', 'problem', 'one', 'half', 'added', 'cell', 'table', 'contains', 'zero', 'frequency', 'therefore', 'common', 'recommendation', 'use', 'mh', 'estimator', 'small', 'sample_size', 'le', 'sensitive', 'small', 'number', 'logitbased', 'estimator', 'noted', 'mh', 'estimator', 'logitbased', 'estimator', 'similar', 'data', 'sparse', 'within', 'stratum']"
449,"Example:	Fit a conditional logistic regression model to the sasuser.matched data set. Specify low as the response variable and use all of the predictor variables. Use the EVENT= option to model the probability of low birth weight. Use the UNITS statement to obtain an odds ratio estimate for a 10-unit change in Mother_wt. Also specify socio as a CLASS variable, reference cell coding, 3 as the reference level, standardized estimates, and Wald confidence intervals for the odds ratios. /* c3demo20a */ proc logistic data=sasuser.matched; strata Pair; class Socio (param=ref ref='3'); model Low(event='1') = Mother_age Mother_wt Socio Smoke Prev_pretrm Uterine_irr Hist_hyp / stb clodds=wald; units Mother_wt=10; title 'Conditional Model for Matched Case-Control Study'; run; Selected STRATA statement options: MISSING	treats missing values as valid STRATA variable values. NOSUMMARY	suppresses the display of the ?Strata Summary? table. INFO	displays the ?Strata Information? table, which includes the stratum number, levels of the STRATA variables that define the stratum, the number of events, the number of nonevents, and the total frequency for each stratum. The STRATA statement names the variables that define strata or matched sets to use in a conditional logistic regression model. Observations having the same variable levels are in the same matched set. At least one variable must be specified to invoke the stratified analysis, and the usual unconditional asymptotic analysis is not performed. STRATA variables can also be specified in the MODEL statement as classification or continuous variables. However, the effects are nondegenerate only when crossed with a non-stratification variable. The SCORE and WEIGHT statements are not available with a STRATA statement. The following MODEL options are also not supported with a STRATA statement: CLPARM=PL, CLODDS=PL, CTABLE, LACKFIT, LINK=, NOFIT, OUTMODEL=, OUTROC=, and SCALE=. Conditional Model for Matched Case-Control Study",CD,1988,"['example\tfit', 'conditional', 'logistic_regression_model', 'sasusermatched', 'data_set', 'specify', 'low', 'response_variable', 'use', 'predictor_variable', 'use', 'event', 'option', 'model', 'probability', 'low', 'birth', 'weight', 'use', 'unit', 'statement', 'obtain', 'odds_ratio', 'estimate', '10unit', 'change', 'motherwt', 'also', 'specify', 'socio', 'class', 'variable', 'reference', 'cell', 'coding', '3', 'reference', 'level', 'standardized', 'estimate', 'wald', 'confidence', 'interval', 'odds_ratio', '', 'c3demo20a', '', 'proc_logistic', 'datasasusermatched', 'stratum', 'pair', 'class', 'socio', 'paramref', 'ref3', 'model', 'lowevent1', '', 'motherage', 'motherwt', 'socio', 'smoke', 'prevpretrm', 'uterineirr', 'histhyp', '', 'stb', 'cloddswald', 'unit', 'motherwt10', 'title', 'conditional', 'model', 'matched', 'casecontrol', 'study', 'run', 'selected', 'stratum', 'statement', 'option', 'missing\ttreats', 'missing', 'value', 'valid', 'stratum', 'variable', 'value', 'nosummary\tsuppresses', 'display', 'stratum', 'summary', 'table', 'info\tdisplays', 'stratum', 'information', 'table', 'includes', 'stratum', 'number', 'level', 'stratum', 'variable', 'define', 'stratum', 'number', 'event', 'number', 'nonevent', 'total', 'frequency', 'stratum', 'stratum', 'statement', 'name', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'conditional', 'logistic_regression_model', 'observation', 'variable', 'level', 'matched', 'set', 'least', 'one', 'variable', 'must', 'specified', 'invoke', 'stratified', 'analysis', 'usual', 'unconditional', 'asymptotic', 'analysis', 'performed', 'stratum', 'variable', 'also', 'specified', 'model_statement', 'classification', 'continuous', 'variable', 'however', 'effect', 'nondegenerate', 'crossed', 'nonstratification', 'variable', 'score', 'weight', 'statement', 'available', 'stratum', 'statement', 'following', 'model', 'option', 'also', 'supported', 'stratum', 'statement', 'clparmpl', 'cloddspl', 'ctable', 'lackfit', 'link', 'nofit', 'outmodel', 'outroc', 'scale', 'conditional', 'model', 'matched', 'casecontrol', 'study']"
450,"The first order autoregressive structure (TYPE=AR(1)) specifies that the correlations are raised to the power of the number of time points the measurements are apart. Therefore, if the measurements are three time points apart, the correlation is . The AR(1) model might be a good choice in a longitudinal model where measurements are taken repeatedly over time. One shortcoming is that the correlation decays very quickly as the spacing between measurements increases (Davis 2002).",CD,481,"['first', 'order', 'autoregressive', 'structure', 'typear1', 'specifies', 'correlation', 'raised', 'power', 'number', 'time', 'point', 'measurement', 'apart', 'therefore', 'measurement', 'three', 'time', 'point', 'apart', 'correlation', '', 'ar1', 'model', 'might', 'good', 'choice', 'longitudinal', 'model', 'measurement', 'taken', 'repeatedly', 'time', 'one', 'shortcoming', 'correlation', 'decay', 'quickly', 'spacing', 'measurement', 'increase', 'davis', '2002']"
451,"Example:	To assess the significance of the interaction mother_age*phy_visit, run a model with the interaction and one with no interaction. Use ODS to calculate the likelihood ratio test statistics between the main effects model and the interaction model. Use the GLOBALTESTS output object, which contains the likelihood ratio chi-square statistic. /* c1demo06a */ ods listing close;",CD,382,"['example\tto', 'ass', 'significance', 'interaction', 'motheragephyvisit', 'run', 'model', 'interaction', 'one', 'interaction', 'use', 'od', 'calculate', 'likelihood', 'ratio', 'test', 'statistic', 'main_effect', 'model', 'interaction', 'model', 'use', 'globaltests', 'output', 'object', 'contains', 'likelihood', 'ratio', 'chisquare', 'statistic', '', 'c1demo06a', '', 'od', 'listing', 'close']"
452,"Example:	Fit a GEE model on the wheezing data and specify the probability of wheezing as the response of interest, the unstructured correlation structure, reference cell coding for smoker with No as the reference cell, and request the Type 3 score statistics, the final working correlation matrix, and the model-based standard errors. Also compute the odds ratio comparing smokers to non-smokers and a one-year decrease in age. /* c3demo13a */ proc genmod data=sasuser.wheeze desc; class case smoker(param=ref ref='No'); model wheeze = smoker age / dist=bin type3; repeated subject = case / corrw modelse type=unstr; estimate 'smoking' smoker 1 / exp; estimate 'age' age -1 / exp; title 'GEE Model of Wheezing among Children'; run; Selected PROC GENMOD statement option: DESC	reverses the sort order for the levels of the outcome variable. Selected CLASS statement options: PARAM= 	specifies the parameterization method for the classification variable or variables. The default is PARAM=GLM. REF=	specifies the reference level for PARAM=EFFECT, PARAM=REF, and their orthogonalizations. For an individual variable, you can specify the level of the variable to use as the reference level. For a global or individual variable, you can use one of the following keywords: 	FIRST	designates the first ordered level as the reference. 	LAST	designates the last ordered level as the reference. This is the default. Selected MODEL statement options: DIST= 	specifies the built-in probability distribution to use in the model. The default link function for the binomial distribution is the logit link function. TYPE3	requests that Type 3 score statistics be computed for each effect that is specified in the MODEL statement. Likelihood ratio statistics are produced for models that are not GEE models. Selected REPEATED statement options: CORRW	specifies that the final working correlation matrix be printed. MODELSE	displays an analysis of parameter estimates table using model-based standard errors. Selected ESTIMATE statement option: EXP	requests that the exponentiated contrast, its standard error, and the confidence bounds be computed. ?	If the repeated measurements are not in the proper order or if there are missing time points for some subjects, then the WITHIN= option in the REPEATED statement should be used. This option names a variable that specifies the order of measurements within subjects. Variables used in the WITHIN= option must also be listed in the CLASS statement. !	In SAS 9.1, you get an invalid reference level error if REF=?level? is used for two or more variables. The solution is to use REF=FIRST or REF=LAST for binary variables. This problem has been fixed in SAS 9.2. GEE Model of Wheezing among Children",CD,2728,"['example\tfit', 'gee', 'model', 'wheezing', 'data', 'specify', 'probability', 'wheezing', 'response', 'interest', 'unstructured', 'correlation_structure', 'reference', 'cell', 'coding', 'smoker', 'reference', 'cell', 'request', 'type', '3', 'score', 'statistic', 'final', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'also', 'compute', 'odds_ratio', 'comparing', 'smoker', 'nonsmoker', 'oneyear', 'decrease', 'age', '', 'c3demo13a', '', 'proc', 'genmod', 'datasasuserwheeze', 'desc', 'class', 'case', 'smokerparamref', 'refno', 'model', 'wheeze', '', 'smoker', 'age', '', 'distbin', 'type3', 'repeated', 'subject', '', 'case', '', 'corrw', 'modelse', 'typeunstr', 'estimate', 'smoking', 'smoker', '1', '', 'exp', 'estimate', 'age', 'age', '1', '', 'exp', 'title', 'gee', 'model', 'wheezing', 'among', 'child', 'run', 'selected', 'proc', 'genmod', 'statement', 'option', 'desc\treverses', 'sort', 'order', 'level', 'outcome', 'variable', 'selected', 'class', 'statement', 'option', 'param', '\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'default', 'paramglm', 'ref\tspecifies', 'reference', 'level', 'parameffect', 'paramref', 'orthogonalizations', 'individual', 'variable', 'specify', 'level', 'variable', 'use', 'reference', 'level', 'global', 'individual', 'variable', 'use', 'one', 'following', 'keywords', '\tfirst\tdesignates', 'first', 'ordered', 'level', 'reference', '\tlast\tdesignates', 'last', 'ordered', 'level', 'reference', 'default', 'selected', 'model_statement', 'option', 'dist', '\tspecifies', 'builtin', 'probability', 'distribution', 'use', 'model', 'default', 'link', 'function', 'binomial', 'distribution', 'logit', 'link', 'function', 'type3\trequests', 'type', '3', 'score', 'statistic', 'computed', 'effect', 'specified', 'model_statement', 'likelihood', 'ratio', 'statistic', 'produced', 'model', 'gee', 'model', 'selected', 'repeated', 'statement', 'option', 'corrw\tspecifies', 'final', 'working', 'correlation', 'matrix', 'printed', 'modelse\tdisplays', 'analysis', 'parameter_estimate', 'table', 'using', 'modelbased', 'standard_error', 'selected', 'estimate', 'statement', 'option', 'exp\trequests', 'exponentiated', 'contrast', 'standard_error', 'confidence', 'bound', 'computed', '\tif', 'repeated', 'measurement', 'proper', 'order', 'missing', 'time', 'point', 'subject', 'within', 'option', 'repeated', 'statement', 'used', 'option', 'name', 'variable', 'specifies', 'order', 'measurement', 'within', 'subject', 'variable', 'used', 'within', 'option', 'must', 'also', 'listed', 'class', 'statement', '\tin', 'sa', '91', 'get', 'invalid', 'reference', 'level', 'error', 'reflevel', 'used', 'two', 'variable', 'solution', 'use', 'reffirst', 'reflast', 'binary', 'variable', 'problem', 'ha', 'fixed', 'sa', '92', 'gee', 'model', 'wheezing', 'among', 'child']"
453,"The conditional logistic model takes into account the dependence of the matched pairs with the stratum-specific intercepts. Ignoring the strata will bias the inferences just like ignoring the clusters in the GEE models. However, dummy-coding the strata is not satisfactory either, unless there is a small number of clusters and a large number of observations per cluster. In the asymptotic theory of maximum likelihood estimation, it is assumed that as the number of observations gets large the number of parameters remains constant. In a matched 1:1 case-control study, you would have to estimate n-1 intercepts (n equaling the number of strata). This leads to the incidental parameters problem where the number of parameters increases as the number of observations increases (Kalbfleisch and Sprott 1970). This will lead to very substantial bias in the parameter estimates because you need a large sample size relative to the number of parameters.",CD,949,"['conditional', 'logistic', 'model', 'take', 'account', 'dependence', 'matched', 'pair', 'stratumspecific', 'intercept', 'ignoring', 'stratum', 'bias', 'inference', 'like', 'ignoring', 'cluster', 'gee', 'model', 'however', 'dummycoding', 'stratum', 'satisfactory', 'either', 'unless', 'small', 'number', 'cluster', 'large', 'number', 'observation', 'per', 'cluster', 'asymptotic', 'theory', 'maximum', 'likelihood', 'estimation', 'assumed', 'number', 'observation', 'get', 'large', 'number', 'parameter', 'remains', 'constant', 'matched', '11', 'casecontrol', 'study', 'would', 'estimate', 'n1', 'intercept', 'n', 'equaling', 'number', 'stratum', 'lead', 'incidental', 'parameter', 'problem', 'number', 'parameter', 'increase', 'number', 'observation', 'increase', 'kalbfleisch', 'sprott', '1970', 'lead', 'substantial', 'bias', 'parameter_estimate', 'need', 'large', 'sample_size', 'relative', 'number', 'parameter']"
454,"CMH statistics have low power (probability of correctly rejecting the null hypothesis) for detecting associations where the pattern of association in some of the strata is in the opposite direction of the pattern displayed by other strata (there is an interaction between the stratum variable and the predictor variable). Generally, this is not a problem because if there is an association, it is usually in the same direction across the set of tables, albeit in varying degrees. However, you should always examine the individual tables even if you fail to reject the null hypothesis (Stokes, Davis, and Koch 2000).",CD,615,"['cmh', 'statistic', 'low', 'power', 'probability', 'correctly', 'rejecting', 'null', 'hypothesis', 'detecting', 'association', 'pattern', 'association', 'stratum', 'opposite', 'direction', 'pattern', 'displayed', 'stratum', 'interaction', 'stratum', 'variable', 'predictor_variable', 'generally', 'problem', 'association', 'usually', 'direction', 'across', 'set', 'table', 'albeit', 'varying', 'degree', 'however', 'always', 'examine', 'individual', 'table', 'even', 'fail', 'reject', 'null', 'hypothesis', 'stokes', 'davis', 'koch', '2000']"
455,"Convergence problems are also caused by complete separation. This occurs when some linear combination of the predictor variables perfectly predicts the response variable. The net result is infinite parameter estimates. In order to have finite maximum likelihood estimates, there must be some overlap in the distribution of the predictor variables in the model. The diagram above shows that the continuous predictor age perfectly separates the response. Thus age is a perfect predictor of the response.",CD,501,"['convergence', 'problem', 'also', 'caused', 'complete', 'separation', 'occurs', 'linear', 'combination', 'predictor_variable', 'perfectly', 'predicts', 'response_variable', 'net', 'result', 'infinite', 'parameter_estimate', 'order', 'finite', 'maximum', 'likelihood', 'estimate', 'must', 'overlap', 'distribution', 'predictor_variable', 'model', 'diagram', 'show', 'continuous', 'predictor', 'age', 'perfectly', 'separate', 'response', 'thus', 'age', 'perfect', 'predictor', 'response']"
456,"Because the response variable (painseverity) is an ordinal variable, you should analyze it as an ordinal variable. Do not dichotomize the outcome variable because that would lower the power of your hypothesis tests, especially the Wald tests for the parameter estimates of your predictor variables (Allison 1999). In some situations with a continuous outcome, there is a restricted range of values because of the limitations of the measuring techniques. This is a common feature in bioassay analyses. With restricted ranges, there is usually a lower limit of quantification (LOQ) and an upper limit of quantification. For example, suppose that the response variable had a lower LOQ of 300 and the upper LOQ of 900. Analyzing the response variable as continuous might not be optimal given the truncated nature of the distribution. An alternative way to analyze a continuous variable with a restricted range is to create ordered categories and fit an ordinal logistic regression model.",CD,983,"['response_variable', 'painseverity', 'ordinal', 'variable', 'analyze', 'ordinal', 'variable', 'dichotomize', 'outcome', 'variable', 'would', 'lower', 'power', 'hypothesis', 'test', 'especially', 'wald', 'test', 'parameter_estimate', 'predictor_variable', 'allison', '1999', 'situation', 'continuous', 'outcome', 'restricted', 'range', 'value', 'limitation', 'measuring', 'technique', 'common', 'feature', 'bioassay', 'analysis', 'restricted', 'range', 'usually', 'lower', 'limit', 'quantification', 'loq', 'upper', 'limit', 'quantification', 'example', 'suppose', 'response_variable', 'lower', 'loq', '300', 'upper', 'loq', '900', 'analyzing', 'response_variable', 'continuous', 'might', 'optimal', 'given', 'truncated', 'nature', 'distribution', 'alternative', 'way', 'analyze', 'continuous', 'variable', 'restricted', 'range', 'create', 'ordered', 'category', 'fit', 'ordinal', 'logistic_regression_model']"
457,"To test the null hypothesis that all regression coefficients of the model are 0, the likelihood ratio test statistic is computed. This statistic compares the log-likelihood values at the fitted parameter estimates (LogL1) to the log-likelihood values when the parameter estimates are 0 (LogL0). So that it follows a chi-square distribution, the statistic is computed by the formula ?2(LogL0?LogL1). In the above diagram, the likelihood ratio statistic is twice the vertical distance between the values of the log-likelihood function at LogL1 and at LogL0.",CD,555,"['test', 'null', 'hypothesis', 'regression', 'coefficient', 'model', '0', 'likelihood', 'ratio', 'test', 'statistic', 'computed', 'statistic', 'compare', 'loglikelihood', 'value', 'fitted', 'parameter_estimate', 'logl1', 'loglikelihood', 'value', 'parameter_estimate', '0', 'logl0', 'follows', 'chisquare', 'distribution', 'statistic', 'computed', 'formula', '2logl0logl1', 'diagram', 'likelihood', 'ratio', 'statistic', 'twice', 'vertical', 'distance', 'value', 'loglikelihood', 'function', 'logl1', 'logl0']"
458,"The likelihood ratio test is not significant, which means adding an extra degree of freedom to socio did not improve the model. Unless treating socio as a classification variable has subject- matter importance, the model with a continuous socio would be the model of choice.",CD,274,"['likelihood', 'ratio', 'test', 'significant', 'mean', 'adding', 'extra', 'degree', 'freedom', 'socio', 'improve', 'model', 'unless', 'treating', 'socio', 'classification', 'variable', 'ha', 'subject', 'matter', 'importance', 'model', 'continuous', 'socio', 'would', 'model', 'choice']"
459,"Generalized estimating equations (GEE) were developed to accommodate correlated observations within subjects. An estimating equation is simply the equation you solve to calculate the parameter estimates. The extra term generalized distinguishes the GEE as the estimating equations that accommodate the correlation structure of the repeated measurements. GEE are marginal models where the marginal expectation (average response for observations sharing the same covariates) is modeled as a function of the predictor variables. The parameters in marginal models can be interpreted as the influence of the covariates on the population-averaged response. These models are appropriate when the scientific objectives are to characterize and contrast populations of subjects. A useful feature of the GEE is that the parameter estimates along with the covariance matrix are consistently estimated (as the sample size increases, the estimates converge to the true values) even if the correlation structure within subject is not known. Therefore, the variances along with the inferences regarding the parameter estimates are asymptotically correct (Zeger and Liang 1986). It is also not necessary that the observations for all subjects have the same correlation structure.",CD,1262,"['generalized', 'estimating', 'equation', 'gee', 'developed', 'accommodate', 'correlated', 'observation', 'within', 'subject', 'estimating', 'equation', 'simply', 'equation', 'solve', 'calculate', 'parameter_estimate', 'extra', 'term', 'generalized', 'distinguishes', 'gee', 'estimating', 'equation', 'accommodate', 'correlation_structure', 'repeated', 'measurement', 'gee', 'marginal', 'model', 'marginal', 'expectation', 'average', 'response', 'observation', 'sharing', 'covariates', 'modeled', 'function', 'predictor_variable', 'parameter', 'marginal', 'model', 'interpreted', 'influence', 'covariates', 'populationaveraged', 'response', 'model', 'appropriate', 'scientific', 'objective', 'characterize', 'contrast', 'population', 'subject', 'useful', 'feature', 'gee', 'parameter_estimate', 'along', 'covariance', 'matrix', 'consistently', 'estimated', 'sample_size', 'increase', 'estimate', 'converge', 'true', 'value', 'even', 'correlation_structure', 'within', 'subject', 'known', 'therefore', 'variance', 'along', 'inference', 'regarding', 'parameter_estimate', 'asymptotically', 'correct', 'zeger', 'liang', '1986', 'also', 'necessary', 'observation', 'subject', 'correlation_structure']"
460,"The LOGISTIC procedure has five variable selection methods with the use of the SELECTION= option. The default is SELECTION=NONE, in which PROC LOGISTIC fits the complete model as specified in the MODEL statement. The other four methods are FORWARD for forward selection, BACKWARD for backward elimination, STEPWISE for stepwise selection, and SCORE for best subsets selection. Best subsets selection finds a specified number of models with the highest likelihood score (chi- square) statistic for all possible model sizes (1-, 2-, 3-variable models, and so on, up to the single model containing all predictor variables). The method requires only that the full model be fit because the results are then manipulated to calculate the likelihood score statistic for each possible combination of predictor variables. Because the method uses a branch and bound algorithm to search the many combinations of variables, the best subsets selection is relatively efficient for a relatively small number of variables. However, the performance acutely deteriorates when the model has over approximately 50 effects (predictor variables and their interactions) (Potts and Patetta 1999).",CD,1171,"['logistic', 'procedure', 'ha', 'five', 'variable', 'selection', 'method', 'use', 'selection', 'option', 'default', 'selectionnone', 'proc_logistic', 'fit', 'complete', 'model', 'specified', 'model_statement', 'four', 'method', 'forward', 'forward', 'selection', 'backward', 'backward', 'elimination', 'stepwise', 'stepwise', 'selection', 'score', 'best', 'subset', 'selection', 'best', 'subset', 'selection', 'find', 'specified', 'number', 'model', 'highest', 'likelihood', 'score', 'chi', 'square', 'statistic', 'possible', 'model', 'size', '1', '2', '3variable', 'model', 'single', 'model', 'containing', 'predictor_variable', 'method', 'requires', 'full', 'model', 'fit', 'result', 'manipulated', 'calculate', 'likelihood', 'score', 'statistic', 'possible', 'combination', 'predictor_variable', 'method', 'us', 'branch', 'bound', 'algorithm', 'search', 'many', 'combination', 'variable', 'best', 'subset', 'selection', 'relatively', 'efficient', 'relatively', 'small', 'number', 'variable', 'however', 'performance', 'acutely', 'deteriorates', 'model', 'ha', 'approximately', '50', 'effect', 'predictor_variable', 'interaction', 'potts', 'patetta', '1999']"
461,"In GEE regression models, the number of observations is not the number of subjects, but rather the number of measurements taken on all the subjects. The variance-covariance matrix is now a block- diagonal matrix in which the observations within each block (the block corresponds to a subject) are assumed to be correlated and the observations outside of the blocks are assumed to be independent. In other words, the subjects are still assumed to be independent of each other and the measurements within each subject are assumed to be correlated.",CD,545,"['gee', 'regression_model', 'number', 'observation', 'number', 'subject', 'rather', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'block', 'corresponds', 'subject', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'word', 'subject', 'still', 'assumed', 'independent', 'measurement', 'within', 'subject', 'assumed', 'correlated']"
462,"Example:	Examine the relationships between prev_pretrm and low, and prev_pretrm and low, controlling for uterine_irr. Request a Breslow-Day test for homogeneity of odds ratios with a Tarone?s adjustment, exact confidence limits for the crude odds ratios and the adjusted odds ratios, and the number of variable levels. /* c1demo02a */ proc freq data=sasuser.birth nlevels; tables prev_pretrm*low uterine_irr*prev_pretrm*low / all bdt; exact or comor; title 'Contingency Table Analysis Assessing PREV_PRETRM' ' and UTERINE_IRR'; run; PROC FREQ statement option: NLEVELS	displays a table that provides the number of levels for each variable in the TABLES statement. Selected TABLES statement options: CHISQ	produces the chi-square test of association and the measures of association based upon the chi-square statistic. MEASURES	requests several measures of association. CL 	produces confidence bounds for the MEASURES statistics. CMH	requests Cochran-Mantel-Haenszel statistics, which test for association between the row and column variables after adjusting for the remaining variables in a multiway table. ALL	requests the CHISQ, MEASURES, and CMH options. Provides all the test statistics and measures for each table along with the summary CMH statistics. BDT	request Tarone's adjustment for the Breslow-Day test. Selected EXACT statement options: OR	requests exact confidence limits for the odds ratio for 2*2 tables. COMOR	requests exact confidence limits for the adjusted odds ratio. An exact test that the adjusted odds ratio equals 1 is also computed. MAXTIME=	specifies the maximum clock time (in seconds) that PROC FREQ can use to compute an exact p-value. MC	requests Monte Carlo estimation of exact p-values instead of direct exact p-value computation.",CD,1763,"['example\texamine', 'relationship', 'prevpretrm', 'low', 'prevpretrm', 'low', 'controlling', 'uterineirr', 'request', 'breslowday', 'test', 'homogeneity', 'odds_ratio', 'tarones', 'adjustment', 'exact', 'confidence', 'limit', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'number', 'variable', 'level', '', 'c1demo02a', '', 'proc', 'freq', 'datasasuserbirth', 'nlevels', 'table', 'prevpretrmlow', 'uterineirrprevpretrmlow', '', 'bdt', 'exact', 'comor', 'title', 'contingency', 'table', 'analysis', 'assessing', 'prevpretrm', '', 'uterineirr', 'run', 'proc', 'freq', 'statement', 'option', 'nlevels\tdisplays', 'table', 'provides', 'number', 'level', 'variable', 'table', 'statement', 'selected', 'table', 'statement', 'option', 'chisq\tproduces', 'chisquare', 'test', 'association', 'measure', 'association', 'based', 'upon', 'chisquare', 'statistic', 'measures\trequests', 'several', 'measure', 'association', 'cl', '\tproduces', 'confidence', 'bound', 'measure', 'statistic', 'cmh\trequests', 'cochranmantelhaenszel', 'statistic', 'test', 'association', 'row', 'column', 'variable', 'adjusting', 'remaining', 'variable', 'multiway', 'table', 'all\trequests', 'chisq', 'measure', 'cmh', 'option', 'provides', 'test', 'statistic', 'measure', 'table', 'along', 'summary', 'cmh', 'statistic', 'bdt\trequest', 'tarones', 'adjustment', 'breslowday', 'test', 'selected', 'exact', 'statement', 'option', 'or\trequests', 'exact', 'confidence', 'limit', 'odds_ratio', '22', 'table', 'comor\trequests', 'exact', 'confidence', 'limit', 'adjusted', 'odds_ratio', 'exact', 'test', 'adjusted', 'odds_ratio', 'equal', '1', 'also', 'computed', 'maxtime\tspecifies', 'maximum', 'clock', 'time', 'second', 'proc', 'freq', 'use', 'compute', 'exact', 'pvalue', 'mc\trequests', 'monte', 'carlo', 'estimation', 'exact', 'pvalues', 'instead', 'direct', 'exact', 'pvalue', 'computation']"
463,"The Strata Summary table displays the number of strata, which have a specific number of events and nonevents. Strata containing only events or only nonevents are reported in this table, but such strata are uninformative and are not used in the analysis. NOTE: The following parameters have been set to 0, since the variables are a linear combination of other variables as shown. Mother_age = 0",CD,393,"['stratum', 'summary', 'table', 'display', 'number', 'stratum', 'specific', 'number', 'event', 'nonevent', 'stratum', 'containing', 'event', 'nonevent', 'reported', 'table', 'stratum', 'uninformative', 'used', 'analysis', 'note', 'following', 'parameter', 'set', '0', 'since', 'variable', 'linear', 'combination', 'variable', 'shown', 'motherage', '', '0']"
464,title 'Nominal Logistic Regression Model on Alligator Food Data'; run; Selected MODEL statement options: REF=	specifies the reference group for the nominal and binary response model. You can specify the reference category in quotes or the keyword FIRST (designates the first ordered category as the reference) or the keyword LAST (designates the last ordered category as the reference). The default is REF=LAST. LINK=	specifies the function linking the response probabilities to the linear predictors. The keyword GLOGIT requests the generalized logit function. The default is LINK=LOGIT (the log odds function). Nominal Logistic Regression Model on Alligator Food Data,CD,669,"['title', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data', 'run', 'selected', 'model_statement', 'option', 'ref\tspecifies', 'reference', 'group', 'nominal', 'binary', 'response', 'model', 'specify', 'reference', 'category', 'quote', 'keyword', 'first', 'designates', 'first', 'ordered', 'category', 'reference', 'keyword', 'last', 'designates', 'last', 'ordered', 'category', 'reference', 'default', 'reflast', 'link\tspecifies', 'function', 'linking', 'response', 'probability', 'linear', 'predictor', 'keyword', 'glogit', 'request', 'generalized', 'logit', 'function', 'default', 'linklogit', 'log', 'odds', 'function', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data']"
465,"PROC FREQ was used to compute a crude odds ratio for each of the binary predictor variables while PROC LOGISTIC was used to compute a crude odds ratio for the continuous variables and an adjusted odds ratio for all the variables. A comparison of the crude odds ratios and the adjusted odds ratios show relatively large changes. Previous preterm deliveries showed a large decrease while uterine irritability went from a significant crude odds ratio to a nonsignificant adjusted odds ratio. History of hypertension showed a large increase in the odds ratio, but the large confidence interval indicates data sparseness.",CD,616,"['proc', 'freq', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'binary', 'predictor_variable', 'proc_logistic', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'continuous', 'variable', 'adjusted', 'odds_ratio', 'variable', 'comparison', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'show', 'relatively', 'large', 'change', 'previous', 'preterm', 'delivery', 'showed', 'large', 'decrease', 'uterine', 'irritability', 'went', 'significant', 'crude', 'odds_ratio', 'nonsignificant', 'adjusted', 'odds_ratio', 'history', 'hypertension', 'showed', 'large', 'increase', 'odds_ratio', 'large', 'confidence', 'interval', 'indicates', 'data', 'sparseness']"
466,"In ordinal logistic regression, the logit is now a cumulative logit. If k is the number of categories for the outcome variable, then the number of cumulative logits is k-1. The model generates cumulative probabilities, which is the probability that an individual is in the jth ordered category or lower. If you use the DESCENDING option in PROC LOGISTIC, then the model generates probabilities that an individual is in the jth category or higher.",CD,446,"['ordinal', 'logistic_regression', 'logit', 'cumulative', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'cumulative', 'logits', 'k1', 'model', 'generates', 'cumulative', 'probability', 'probability', 'individual', 'jth', 'ordered', 'category', 'lower', 'use', 'descending', 'option', 'proc_logistic', 'model', 'generates', 'probability', 'individual', 'jth', 'category', 'higher']"
467,"For continuous predictor variables with a large number of unique values, binning the data (collapsing data values into groups) is necessary to compute the logit. The bin size should have an adequate number of observations to reduce the sample variability of the logits. If the standard logistic regression model adequately fits the data, the logit plots should be fairly linear. The above graph shows a predictor variable that meets the assumption of linearity in the logit.",CD,474,"['continuous', 'predictor_variable', 'large', 'number', 'unique', 'value', 'binning', 'data', 'collapsing', 'data', 'value', 'group', 'necessary', 'compute', 'logit', 'bin', 'size', 'adequate', 'number', 'observation', 'reduce', 'sample', 'variability', 'logits', 'standard', 'logistic_regression_model', 'adequately', 'fit', 'data', 'logit', 'plot', 'fairly', 'linear', 'graph', 'show', 'predictor_variable', 'meet', 'assumption', 'linearity', 'logit']"
468,The logistic regression model with the two main effects in the model shows no problems with quasi-complete separation. The parameter estimates and their associated standard errors are all reasonable.,CD,199,"['logistic_regression_model', 'two', 'main_effect', 'model', 'show', 'problem', 'quasicomplete', 'separation', 'parameter_estimate', 'associated', 'standard_error', 'reasonable']"
469,"The primary advantage for matching over random sampling without matching is that matching might lead to a more statistically efficient analysis (Rothman 1986, Kleinbaum 1991). For example, matching might lead to a tighter confidence interval around the odds ratio being estimated for the predictor variables of interest. The reason for the improved precision is that matching might reduce the number of uninformative strata in a stratified analysis. An uninformative stratum in a matched case-control analysis is one in which the predictor variable?s value is constant. For example, suppose the primary predictor variable of interest is an exposure variable (1=yes, 0=no). If the case and control both have the same value of the exposure variable, then it is an uninformative stratum with regards to the exposure effect. Matching might lead to fewer uninformative strata, which will improve the efficiency of the study. Matching is attractive when there is a high price of expanding the study size (Rothman 1986). For example, if the cost of obtaining information from the subjects is large, it is desirable to optimize the amount of information obtained per subject. In other words, it is worthwhile to pay the cost of matching to take full advantage of the information that is collected.",CD,1289,"['primary', 'advantage', 'matching', 'random', 'sampling', 'without', 'matching', 'matching', 'might', 'lead', 'statistically', 'efficient', 'analysis', 'rothman', '1986', 'kleinbaum', '1991', 'example', 'matching', 'might', 'lead', 'tighter', 'confidence', 'interval', 'around', 'odds_ratio', 'estimated', 'predictor_variable', 'interest', 'reason', 'improved', 'precision', 'matching', 'might', 'reduce', 'number', 'uninformative', 'stratum', 'stratified', 'analysis', 'uninformative', 'stratum', 'matched', 'casecontrol', 'analysis', 'one', 'predictor_variable', 'value', 'constant', 'example', 'suppose', 'primary', 'predictor_variable', 'interest', 'exposure', 'variable', '1yes', '0no', 'case', 'control', 'value', 'exposure', 'variable', 'uninformative', 'stratum', 'regard', 'exposure', 'effect', 'matching', 'might', 'lead', 'fewer', 'uninformative', 'stratum', 'improve', 'efficiency', 'study', 'matching', 'attractive', 'high', 'price', 'expanding', 'study', 'size', 'rothman', '1986', 'example', 'cost', 'obtaining', 'information', 'subject', 'large', 'desirable', 'optimize', 'amount', 'information', 'obtained', 'per', 'subject', 'word', 'worthwhile', 'pay', 'cost', 'matching', 'take', 'full', 'advantage', 'information', 'collected']"
470,"Example:	To assess the significance of the interaction mother_age*phy_visit, run a model with the interaction and one with no interaction. Use ODS to calculate the likelihood ratio test statistics between the main effects model and the interaction model. Use the GLOBALTESTS output object, which contains the likelihood ratio chi-square statistic. /* c1demo06a */ ods listing close;",CD,382,"['example\tto', 'ass', 'significance', 'interaction', 'motheragephyvisit', 'run', 'model', 'interaction', 'one', 'interaction', 'use', 'od', 'calculate', 'likelihood', 'ratio', 'test', 'statistic', 'main_effect', 'model', 'interaction', 'model', 'use', 'globaltests', 'output', 'object', 'contains', 'likelihood', 'ratio', 'chisquare', 'statistic', '', 'c1demo06a', '', 'od', 'listing', 'close']"
471,"Hosmer and Lemeshow (2000) also recommend plotting the diagnostic statistics by the predicted probabilities where the size of the plotting symbol is proportional to the effect of each covariate pattern on the value of the estimated parameters. The GPLOT procedure can accomplish this with the use of a bubble plot. In the bubble plot above, the size of the bubbles is proportional to the c diagnostic statistic. In general, the largest values of the c diagnostic statistic are likely to occur when the change in the Pearson chi-square is large or when the leverage is large (the diagonal of the hat matrix). The position of the bubbles in the graph can give a general idea which statistic contributed to the high c diagnostic statistic. For example, if the large bubbles occur in the upper-right or upper-left corner, then the change in the Pearson chi-square contributed the most to the high c diagnostic statistic because leverage values tend to be low when the estimated probabilities are below .10 or above .90. However, if the bubbles fall in the bottom of the cup defined by the two quadratic curves, then the leverage values contributed the most to the high c diagnostic statistic. The points in the plot that are of greatest concern are those with large circles falling within the cup. These correspond to covariate patterns that are not fit very well and have high leverage values (Hosmer and Lemeshow 2000). The formula for the c diagnostic is:",CD,1454,"['hosmer', 'lemeshow', '2000', 'also', 'recommend', 'plotting', 'diagnostic', 'statistic', 'predicted', 'probability', 'size', 'plotting', 'symbol', 'proportional', 'effect', 'covariate', 'pattern', 'value', 'estimated', 'parameter', 'gplot', 'procedure', 'accomplish', 'use', 'bubble', 'plot', 'bubble', 'plot', 'size', 'bubble', 'proportional', 'c', 'diagnostic', 'statistic', 'general', 'largest', 'value', 'c', 'diagnostic', 'statistic', 'likely', 'occur', 'change', 'pearson', 'chisquare', 'large', 'leverage', 'large', 'diagonal', 'hat', 'matrix', 'position', 'bubble', 'graph', 'give', 'general', 'idea', 'statistic', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'example', 'large', 'bubble', 'occur', 'upperright', 'upperleft', 'corner', 'change', 'pearson', 'chisquare', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'leverage', 'value', 'tend', 'low', 'estimated', 'probability', '10', '90', 'however', 'bubble', 'fall', 'bottom', 'cup', 'defined', 'two', 'quadratic', 'curve', 'leverage', 'value', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'point', 'plot', 'greatest', 'concern', 'large', 'circle', 'falling', 'within', 'cup', 'correspond', 'covariate', 'pattern', 'fit', 'well', 'high', 'leverage', 'value', 'hosmer', 'lemeshow', '2000', 'formula', 'c', 'diagnostic']"
472,"The TRACE statement produces a trace record of each output object, including the name and label. The LISTING option writes this information, interleaved with the procedure output, to the SAS listing. Partial Output Low Birth Weight Model",CD,237,"['trace', 'statement', 'produce', 'trace', 'record', 'output', 'object', 'including', 'name', 'label', 'listing', 'option', 'writes', 'information', 'interleaved', 'procedure', 'output', 'sa', 'listing', 'partial', 'output', 'low', 'birth', 'weight', 'model']"
473,"Because repeated measurements are taken on each subject, a GEE model should be fit. However, the model building strategy is similar to the one used on the binary logistic regression model with independent observations. First, do an exploratory data analysis with contingency tables and logit plots. A useful contingency table would be the subject?s identification number by the response variable. Then fit a GEE model using various correlation structures based on subject-matter knowledge. The choice of correlation structure is irrelevant if the primary objective of the study is to estimate regression coefficients and there are a large number of subjects. Exploratory Data Analysis Using Logit Plots",CD,702,"['repeated', 'measurement', 'taken', 'subject', 'gee', 'model', 'fit', 'however', 'model', 'building', 'strategy', 'similar', 'one', 'used', 'binary', 'logistic_regression_model', 'independent', 'observation', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'useful', 'contingency', 'table', 'would', 'subject', 'identification', 'number', 'response_variable', 'fit', 'gee', 'model', 'using', 'various', 'correlation_structure', 'based', 'subjectmatter', 'knowledge', 'choice', 'correlation_structure', 'irrelevant', 'primary', 'objective', 'study', 'estimate', 'regression', 'coefficient', 'large', 'number', 'subject', 'exploratory', 'data', 'analysis', 'using', 'logit', 'plot']"
474,"Forward selection starts with an empty model. The method computes an adjusted chi-square statistic for each predictor variable not in the model and examines the largest of these statistics. If it is significant at a specified significance level (specified by the SLENTRY= option), the corresponding variable is added to the model. After a variable is entered in the model, it is never removed from the model. The process is repeated until none of the remaining variables meet the specified level for entry. By default, SLENTRY=0.05. The forward selection method may be useful in assessing interactions. You start with the main effects only model (using the INCLUDE= option) and then let the forward selection method search for any significant interactions. The significance level should be relatively low (.01 or less) because you only want to include relatively strong interactions in your final model.",CD,903,"['forward', 'selection', 'start', 'empty', 'model', 'method', 'computes', 'adjusted', 'chisquare', 'statistic', 'predictor_variable', 'model', 'examines', 'largest', 'statistic', 'significant', 'specified', 'significance', 'level', 'specified', 'slentry', 'option', 'corresponding', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'never', 'removed', 'model', 'process', 'repeated', 'none', 'remaining', 'variable', 'meet', 'specified', 'level', 'entry', 'default', 'slentry005', 'forward', 'selection', 'method', 'may', 'useful', 'assessing', 'interaction', 'start', 'main_effect', 'model', 'using', 'include', 'option', 'let', 'forward', 'selection', 'method', 'search', 'significant', 'interaction', 'significance', 'level', 'relatively', 'low', '01', 'le', 'want', 'include', 'relatively', 'strong', 'interaction', 'final', 'model']"
475,The overlay plot of the ROC curves clearly shows that the model with the interaction is the superior model with regard to predictive accuracy. 2.2	Logistic Regression Diagnostics,CD,178,"['overlay', 'plot', 'roc', 'curve', 'clearly', 'show', 'model', 'interaction', 'superior', 'model', 'regard', 'predictive', 'accuracy', '22\tlogistic', 'regression', 'diagnostics']"
476,"The odds ratio for bending indicates that women who say that bending aggravates their back pain have 2.4 times the odds to be in a higher severity level of back pain than women who say that bending does not aggravate their back pain. Because the confidence bounds do not include 1.0, the odds ratio is significant at the 0.05 significance level. Association of Predicted Probabilities and Observed Responses",CD,407,"['odds_ratio', 'bending', 'indicates', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '24', 'time', 'odds', 'higher', 'severity', 'level', 'back', 'pain', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain', 'confidence', 'bound', 'include', '10', 'odds_ratio', 'significant', '005', 'significance', 'level', 'association', 'predicted', 'probability', 'observed', 'response']"
477,"The LOGISTIC procedure has five variable selection methods with the use of the SELECTION= option. The default is SELECTION=NONE, in which PROC LOGISTIC fits the complete model as specified in the MODEL statement. The other four methods are FORWARD for forward selection, BACKWARD for backward elimination, STEPWISE for stepwise selection, and SCORE for best subsets selection. Best subsets selection finds a specified number of models with the highest likelihood score (chi- square) statistic for all possible model sizes (1-, 2-, 3-variable models, and so on, up to the single model containing all predictor variables). The method requires only that the full model be fit because the results are then manipulated to calculate the likelihood score statistic for each possible combination of predictor variables. Because the method uses a branch and bound algorithm to search the many combinations of variables, the best subsets selection is relatively efficient for a relatively small number of variables. However, the performance acutely deteriorates when the model has over approximately 50 effects (predictor variables and their interactions) (Potts and Patetta 1999).",CD,1171,"['logistic', 'procedure', 'ha', 'five', 'variable', 'selection', 'method', 'use', 'selection', 'option', 'default', 'selectionnone', 'proc_logistic', 'fit', 'complete', 'model', 'specified', 'model_statement', 'four', 'method', 'forward', 'forward', 'selection', 'backward', 'backward', 'elimination', 'stepwise', 'stepwise', 'selection', 'score', 'best', 'subset', 'selection', 'best', 'subset', 'selection', 'find', 'specified', 'number', 'model', 'highest', 'likelihood', 'score', 'chi', 'square', 'statistic', 'possible', 'model', 'size', '1', '2', '3variable', 'model', 'single', 'model', 'containing', 'predictor_variable', 'method', 'requires', 'full', 'model', 'fit', 'result', 'manipulated', 'calculate', 'likelihood', 'score', 'statistic', 'possible', 'combination', 'predictor_variable', 'method', 'us', 'branch', 'bound', 'algorithm', 'search', 'many', 'combination', 'variable', 'best', 'subset', 'selection', 'relatively', 'efficient', 'relatively', 'small', 'number', 'variable', 'however', 'performance', 'acutely', 'deteriorates', 'model', 'ha', 'approximately', '50', 'effect', 'predictor_variable', 'interaction', 'potts', 'patetta', '1999']"
478,Example: 	Illustrate the mother?s age by physician visit interaction. First create a data set with the plotting points for the interaction. Score the data set with the plotting points and plot the predicted logits and predicted probabilities by the plotting points. /* c1demo07a */ proc univariate data=sasuser.birth; var mother_age; run; Partial Output Quantile Estimate,CD,371,"['example', '\tillustrate', 'mother', 'age', 'physician', 'visit', 'interaction', 'first', 'create', 'data_set', 'plotting', 'point', 'interaction', 'score', 'data_set', 'plotting', 'point', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', '', 'c1demo07a', '', 'proc', 'univariate', 'datasasuserbirth', 'var', 'motherage', 'run', 'partial', 'output', 'quantile', 'estimate']"
479,"Because repeated measurements are taken on each subject, a GEE model should be fit. However, the model building strategy is similar to the one used on the binary logistic regression model with independent observations. First, do an exploratory data analysis with contingency tables and logit plots. A useful contingency table would be the subject?s identification number by the response variable. Then fit a GEE model using various correlation structures based on subject-matter knowledge. The choice of correlation structure is irrelevant if the primary objective of the study is to estimate regression coefficients and there are a large number of subjects. Exploratory Data Analysis Using Logit Plots",CD,702,"['repeated', 'measurement', 'taken', 'subject', 'gee', 'model', 'fit', 'however', 'model', 'building', 'strategy', 'similar', 'one', 'used', 'binary', 'logistic_regression_model', 'independent', 'observation', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'useful', 'contingency', 'table', 'would', 'subject', 'identification', 'number', 'response_variable', 'fit', 'gee', 'model', 'using', 'various', 'correlation_structure', 'based', 'subjectmatter', 'knowledge', 'choice', 'correlation_structure', 'irrelevant', 'primary', 'objective', 'study', 'estimate', 'regression', 'coefficient', 'large', 'number', 'subject', 'exploratory', 'data', 'analysis', 'using', 'logit', 'plot']"
480,"The common effect of the predictor variable for different cumulative logits in the proportional odds model can be motivated by assuming that a regression model holds when the response is measured more finely (Anderson and Phillips 1981). For example, suppose there is an underlying continuous response variable with ordered categories that are produced via cutoff points. The relationship between the predictor variable and the response should not depend on the cutoff points. In other words, the effect parameters are invariant to the choice of categories for the response variable. Only the intercepts are affected by the cutoff points. The proportional odds model is therefore invariant to the choice of the outcome categories. There is some loss of efficiency when you collapse the ordinal categories, but when the observations are evenly spread among the categories the efficiency loss is minor. However, the efficiency loss is large when you collapse the ordinal categories to a binary response (Agresti 1996). Allison (1999) recommends that you need at least 10 observations for each category of the response variable. As the number of categories increases, ordinary least squares might be appropriate. However, Hastie et al. (1989) showed that ordinary least squares methods could give misleading results with up to 13 categories of the response variable. The proportional odds model also makes no assumptions about the distances between the categories. Therefore, how you code the ordinal outcome variable has no effect on the odds ratios. Fitting Simple Ordinal Logistic Regression Models",CD,1598,"['common', 'effect', 'predictor_variable', 'different', 'cumulative', 'logits', 'proportional', 'odds', 'model', 'motivated', 'assuming', 'regression_model', 'hold', 'response', 'measured', 'finely', 'anderson', 'phillips', '1981', 'example', 'suppose', 'underlying', 'continuous', 'response_variable', 'ordered', 'category', 'produced', 'via', 'cutoff', 'point', 'relationship', 'predictor_variable', 'response', 'depend', 'cutoff', 'point', 'word', 'effect', 'parameter', 'invariant', 'choice', 'category', 'response_variable', 'intercept', 'affected', 'cutoff', 'point', 'proportional', 'odds', 'model', 'therefore', 'invariant', 'choice', 'outcome', 'category', 'loss', 'efficiency', 'collapse', 'ordinal', 'category', 'observation', 'evenly', 'spread', 'among', 'category', 'efficiency', 'loss', 'minor', 'however', 'efficiency', 'loss', 'large', 'collapse', 'ordinal', 'category', 'binary', 'response', 'agresti', '1996', 'allison', '1999', 'recommends', 'need', 'least', '10', 'observation', 'category', 'response_variable', 'number', 'category', 'increase', 'ordinary', 'least', 'square', 'might', 'appropriate', 'however', 'hastie', 'et', 'al', '1989', 'showed', 'ordinary', 'least', 'square', 'method', 'could', 'give', 'misleading', 'result', '13', 'category', 'response_variable', 'proportional', 'odds', 'model', 'also', 'make', 'assumption', 'distance', 'category', 'therefore', 'code', 'ordinal', 'outcome', 'variable', 'ha', 'effect', 'odds_ratio', 'fitting', 'simple', 'ordinal', 'logistic_regression_model']"
481,The Parameter Information table displays the names of the parameters. Notice PROC GENMOD shows which value of the response variable is being modeled. Criteria For Assessing Goodness Of Fit,CD,188,"['parameter', 'information', 'table', 'display', 'name', 'parameter', 'notice', 'proc', 'genmod', 'show', 'value', 'response_variable', 'modeled', 'criterion', 'assessing', 'goodness', 'fit']"
482,"PROC FREQ was used to compute a crude odds ratio for each of the binary predictor variables while PROC LOGISTIC was used to compute a crude odds ratio for the continuous variables and an adjusted odds ratio for all the variables. A comparison of the crude odds ratios and the adjusted odds ratios show relatively large changes. Previous preterm deliveries showed a large decrease while uterine irritability went from a significant crude odds ratio to a nonsignificant adjusted odds ratio. History of hypertension showed a large increase in the odds ratio, but the large confidence interval indicates data sparseness.",CD,616,"['proc', 'freq', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'binary', 'predictor_variable', 'proc_logistic', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'continuous', 'variable', 'adjusted', 'odds_ratio', 'variable', 'comparison', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'show', 'relatively', 'large', 'change', 'previous', 'preterm', 'delivery', 'showed', 'large', 'decrease', 'uterine', 'irritability', 'went', 'significant', 'crude', 'odds_ratio', 'nonsignificant', 'adjusted', 'odds_ratio', 'history', 'hypertension', 'showed', 'large', 'increase', 'odds_ratio', 'large', 'confidence', 'interval', 'indicates', 'data', 'sparseness']"
483,"Backward elimination starts off with the full model. Results of the Wald test for individual parameter estimates are examined, and the least significant variable that falls above the specified significance level (specified by the SLSTAY= option) is removed. After a variable is removed from the model, it remains excluded. The process is repeated until no other variable in the model meets the specified significance level for removal. By default, SLSTAY=0.05. When using backward elimination, you could use the FAST option to increase efficiency. This method only requires passing through the data matrix once to get the initial full model fit. Then the method uses an algorithm to manipulate the full model fit to approximate the parameter estimates for the reduced models. This eliminates the need to refit the model every time a variable is removed. Simulations examining variable selection techniques found that backward elimination methods usually performed better than the forward stepwise methods, especially when collinearity is present among the predictor variables. However, a relatively large number of predictor variables increases the risk of complete separation (Hosmer and Lemeshow 2000). Furthermore, sparseness in the data causes unstable parameter estimates that negatively impact the performance of the backward elimination method (Harrell 1997).",CD,1366,"['backward', 'elimination', 'start', 'full', 'model', 'result', 'wald', 'test', 'individual', 'parameter_estimate', 'examined', 'least', 'significant', 'variable', 'fall', 'specified', 'significance', 'level', 'specified', 'slstay', 'option', 'removed', 'variable', 'removed', 'model', 'remains', 'excluded', 'process', 'repeated', 'variable', 'model', 'meet', 'specified', 'significance', 'level', 'removal', 'default', 'slstay005', 'using', 'backward', 'elimination', 'could', 'use', 'fast', 'option', 'increase', 'efficiency', 'method', 'requires', 'passing', 'data', 'matrix', 'get', 'initial', 'full', 'model', 'fit', 'method', 'us', 'algorithm', 'manipulate', 'full', 'model', 'fit', 'approximate', 'parameter_estimate', 'reduced', 'model', 'eliminates', 'need', 'refit', 'model', 'every', 'time', 'variable', 'removed', 'simulation', 'examining', 'variable', 'selection', 'technique', 'found', 'backward', 'elimination', 'method', 'usually', 'performed', 'better', 'forward', 'stepwise', 'method', 'especially', 'collinearity', 'present', 'among', 'predictor_variable', 'however', 'relatively', 'large', 'number', 'predictor_variable', 'increase', 'risk', 'complete', 'separation', 'hosmer', 'lemeshow', '2000', 'furthermore', 'sparseness', 'data', 'cause', 'unstable', 'parameter_estimate', 'negatively', 'impact', 'performance', 'backward', 'elimination', 'method', 'harrell', '1997']"
484,"A model using the same data and ignoring the matched pairs was run for illustrative purposes. The standard errors (in parentheses) are all lower for the unconditional parameter estimates compared to the conditional parameter estimates. The reason for the difference is that ignoring the matched pairs and treating the observations as though they are independent produces standard errors that are underestimated. The conditional parameter estimates are also quite different from the unconditional parameter estimates. The reason for this difference is that the conditional parameter estimates are stratum-specific because they are defined at the stratum level. The unconditional parameter estimates are population-averaged, rather than based on individual stratum. 3.5	Nominal Logistic Regression",CD,795,"['model', 'using', 'data', 'ignoring', 'matched', 'pair', 'wa', 'run', 'illustrative', 'purpose', 'standard_error', 'parenthesis', 'lower', 'unconditional', 'parameter_estimate', 'compared', 'conditional', 'parameter_estimate', 'reason', 'difference', 'ignoring', 'matched', 'pair', 'treating', 'observation', 'though', 'independent', 'produce', 'standard_error', 'underestimated', 'conditional', 'parameter_estimate', 'also', 'quite', 'different', 'unconditional', 'parameter_estimate', 'reason', 'difference', 'conditional', 'parameter_estimate', 'stratumspecific', 'defined', 'stratum', 'level', 'unconditional', 'parameter_estimate', 'populationaveraged', 'rather', 'based', 'individual', 'stratum', '35\tnominal', 'logistic_regression']"
485,"In the CLASS statement in PROC LOGISTIC, you can specify the coding scheme for the design variables created from the CLASS variable. For effect coding (also called deviation from the mean coding), the number of design variables created is the number of levels of the CLASS variable minus 1. For example, because the variable socio has three levels, only two design variables are created. For the last level of the CLASS variable, all the design variables have a value of ?1. Parameter estimates of the CLASS main effects using this coding scheme estimate the difference between the effect of each level and the average effect over all levels. Effect coding is the default in PROC LOGISTIC.",CD,689,"['class', 'statement', 'proc_logistic', 'specify', 'coding', 'scheme', 'design', 'variable', 'created', 'class', 'variable', 'effect', 'coding', 'also', 'called', 'deviation', 'mean', 'coding', 'number', 'design', 'variable', 'created', 'number', 'level', 'class', 'variable', 'minus', '1', 'example', 'variable', 'socio', 'ha', 'three', 'level', 'two', 'design', 'variable', 'created', 'last', 'level', 'class', 'variable', 'design', 'variable', 'value', '1', 'parameter_estimate', 'class', 'main_effect', 'using', 'coding', 'scheme', 'estimate', 'difference', 'effect', 'level', 'average', 'effect', 'level', 'effect', 'coding', 'default', 'proc_logistic']"
486,"The process of fitting a GEE model can be summarized in a series of steps. First, a regression model is fitted that assumes independence and the Pearson standardized residuals are computed. These residuals are then used to estimate the parameters of the correlation matrix, which characterizes the correlation of the observations within subject. The correlation parameters are then incorporated into the GEE estimating equations, which generates new values for the regression coefficients and new Pearson residuals. These residuals are then used to re-estimate the correlation parameters. The cyclical process continues until the parameter estimates stabilize and model convergence is achieved. !	For more information, see the SAS online documentation.",CD,752,"['process', 'fitting', 'gee', 'model', 'summarized', 'series', 'step', 'first', 'regression_model', 'fitted', 'assumes', 'independence', 'pearson', 'standardized', 'residual', 'computed', 'residual', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'characterizes', 'correlation', 'observation', 'within', 'subject', 'correlation', 'parameter', 'incorporated', 'gee', 'estimating', 'equation', 'generates', 'new', 'value', 'regression', 'coefficient', 'new', 'pearson', 'residual', 'residual', 'used', 'reestimate', 'correlation', 'parameter', 'cyclical', 'process', 'continues', 'parameter_estimate', 'stabilize', 'model', 'convergence', 'achieved', '\tfor', 'information', 'see', 'sa', 'online', 'documentation']"
487,"The likelihood ratio test is not significant, which means adding an extra degree of freedom to socio did not improve the model. Unless treating socio as a classification variable has subject- matter importance, the model with a continuous socio would be the model of choice.",CD,274,"['likelihood', 'ratio', 'test', 'significant', 'mean', 'adding', 'extra', 'degree', 'freedom', 'socio', 'improve', 'model', 'unless', 'treating', 'socio', 'classification', 'variable', 'ha', 'subject', 'matter', 'importance', 'model', 'continuous', 'socio', 'would', 'model', 'choice']"
488,title 'Estimated Logit Plot of Socioeconomic Status'; run; Selected PROC MEANS statement option: NWAY	causes the output data set to have only one observation for each level of the class variable.,CD,195,"['title', 'estimated', 'logit', 'plot', 'socioeconomic', 'status', 'run', 'selected', 'proc', 'mean', 'statement', 'option', 'nway\tcauses', 'output', 'data_set', 'one', 'observation', 'level', 'class', 'variable']"
489,proc varclus data=sasuser.backache maxeigen=.70 short; var bending lifting age numberchd height weightend trimester weightbaby weightgain sitting fatigue standing makingbeds ironing walking; title 'Variable Clustering of the Backache Example'; run; Partial Output Variable Clustering of the Backache Example,CD,307,"['proc', 'varclus', 'datasasuserbackache', 'maxeigen70', 'short', 'var', 'bending', 'lifting', 'age', 'numberchd', 'height', 'weightend', 'trimester', 'weightbaby', 'weightgain', 'sitting', 'fatigue', 'standing', 'makingbeds', 'ironing', 'walking', 'title', 'variable', 'clustering', 'backache', 'example', 'run', 'partial', 'output', 'variable', 'clustering', 'backache', 'example']"
490,"CMH statistics have low power (probability of correctly rejecting the null hypothesis) for detecting associations where the pattern of association in some of the strata is in the opposite direction of the pattern displayed by other strata (there is an interaction between the stratum variable and the predictor variable). Generally, this is not a problem because if there is an association, it is usually in the same direction across the set of tables, albeit in varying degrees. However, you should always examine the individual tables even if you fail to reject the null hypothesis (Stokes, Davis, and Koch 2000).",CD,615,"['cmh', 'statistic', 'low', 'power', 'probability', 'correctly', 'rejecting', 'null', 'hypothesis', 'detecting', 'association', 'pattern', 'association', 'stratum', 'opposite', 'direction', 'pattern', 'displayed', 'stratum', 'interaction', 'stratum', 'variable', 'predictor_variable', 'generally', 'problem', 'association', 'usually', 'direction', 'across', 'set', 'table', 'albeit', 'varying', 'degree', 'however', 'always', 'examine', 'individual', 'table', 'even', 'fail', 'reject', 'null', 'hypothesis', 'stokes', 'davis', 'koch', '2000']"
491,"The deviance and Pearson chi-squares are two goodness-of-fit statistics produced in PROC LOGISTIC. These statistics compare the fitted model to a saturated model. The saturated model, which has one parameter for every predicted probability, always fits the data better. However, if these statistics are not significant, then the difference in fit could be explained by chance. A significant chi-square means that there is a model that fits the data better than your model. With the AGGREGATE and SCALE=NONE options, PROC LOGISTIC computes the chi-squares by cross-classifying all the levels of the predictor variables. For each combination of levels, the observed and expected frequencies for each level of the outcome variable are then calculated based on the fitted model. The deviance chi-square is then calculated as where Oj and Ej are the observed and expected frequencies in cell j. The Pearson chi-square is calculated as , which is testing the same null hypothesis as the deviance chi-square test. A problem with these statistics is the sample size requirements. For these statistics to follow a chi- square distribution, there must be an average of at least 10 observations in each cell. Furthermore, at least 80% of the expected frequencies should be 5 or more and all other expected counts should be greater than 2. There should also be no empty cells (Stokes, Davis, Koch 2000).",CD,1391,"['deviance', 'pearson', 'chisquares', 'two', 'goodnessoffit', 'statistic', 'produced', 'proc_logistic', 'statistic', 'compare', 'fitted', 'model', 'saturated', 'model', 'saturated', 'model', 'ha', 'one', 'parameter', 'every', 'predicted', 'probability', 'always', 'fit', 'data', 'better', 'however', 'statistic', 'significant', 'difference', 'fit', 'could', 'explained', 'chance', 'significant', 'chisquare', 'mean', 'model', 'fit', 'data', 'better', 'model', 'aggregate', 'scalenone', 'option', 'proc_logistic', 'computes', 'chisquares', 'crossclassifying', 'level', 'predictor_variable', 'combination', 'level', 'observed', 'expected', 'frequency', 'level', 'outcome', 'variable', 'calculated', 'based', 'fitted', 'model', 'deviance', 'chisquare', 'calculated', 'oj', 'ej', 'observed', 'expected', 'frequency', 'cell', 'j', 'pearson', 'chisquare', 'calculated', '', 'testing', 'null', 'hypothesis', 'deviance', 'chisquare', 'test', 'problem', 'statistic', 'sample_size', 'requirement', 'statistic', 'follow', 'chi', 'square', 'distribution', 'must', 'average', 'least', '10', 'observation', 'cell', 'furthermore', 'least', '80', 'expected', 'frequency', '5', 'expected', 'count', 'greater', '2', 'also', 'empty', 'cell', 'stokes', 'davis', 'koch', '2000']"
492,"Example:	An insurance company wants to relate the safety of vehicles to several other variables. A score has been given to each vehicle model, using the frequency of insurance claims as a basis. The data is in the sasuser.safety data set. The variables in the data set are safety	safety score (1=Below Average, 0=Average or Above) type	type of vehicle (Sports, Small, Medium, Large, and Sport/Utility) region	manufacturing region (Asia, N America) weight	weight of the vehicle in thousands of pounds. Recall from the exercises that the logistic model for the car safety data detected quasi-complete separation of data. This occurred because none of the large cars had below average safety records. The parameter estimate and standard error for the large effect were deemed unreliable. Fitting Exact Logistic Regression Models with the Hybrid Network ? Monte Carlo Algorithm Example:	Fit an exact logistic regression model using the Monte Carlo algorithm with safety as the response variable and type, region, and weight as the predictor variables. Model the probability of below average safety scores and request that the individual parameters and the odds ratios be estimated. Specify type and region as classification variables using reference cell coding. Specify Small as the reference level for type and Asia as the reference level for region. Also, add the observed sufficient statistic to the sampled exact distribution, specify that 100,000 Monte Carlo samples be taken, and set the seed at 27514. /* c3demo19a */ proc logistic data=sasuser.safety exactoptions(method=networkmc addtobs n=100000 seed=27514); class type (param=ref ref='Small') region (param=ref ref='Asia'); model safety = type region weight; exact type weight region / estimate=both; title 'Car Safety Model'; run; PROC LOGISTIC statement options: EXACTOPTIONS(options)	specifies options that apply to every EXACT statement in the program. Selected EXACTOPTIONS options: ADDTOBS	adds the observed sufficient statistic to the sampled exact distribution if the statistic was not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified and the ESTIMATE option is specified in the EXACT statement. If the observed statistic has not been sampled, then the parameter estimate does not exist: by specifying this option, you can produce (biased) estimates. METHOD=	specifies which exact conditional algorithm to use for every EXACT statement specified. The keywords are DIRECT (invokes the multivariate shift algorithm), NETWORK (invokes a network algorithm) and NETWORKMC (invokes the hybrid network and Monte Carlo algorithm). N=	specifies the number of Monte Carlo samples to take when METHOD=NETWORKMC. By default n=10,000. SEED=	specifies the initial seed for the random number generator used to take the Monte Carlo samples for METHOD=NETWORKMC. The value of the SEED= option must be an integer. If you do not specify a seed, or if you specify a value less than or equal to zero, then PROC LOGISTIC uses the time of day from the computer?s clock to generate the initial seed. Car Safety Model",CD,3092,"['example\tan', 'insurance', 'company', 'want', 'relate', 'safety', 'vehicle', 'several', 'variable', 'score', 'ha', 'given', 'vehicle', 'model', 'using', 'frequency', 'insurance', 'claim', 'basis', 'data', 'sasusersafety', 'data_set', 'variable', 'data_set', 'safety\tsafety', 'score', '1below', 'average', '0average', 'type\ttype', 'vehicle', 'sport', 'small', 'medium', 'large', 'sportutility', 'region\tmanufacturing', 'region', 'asia', 'n', 'america', 'weight\tweight', 'vehicle', 'thousand', 'pound', 'recall', 'exercise', 'logistic', 'model', 'car', 'safety', 'data', 'detected', 'quasicomplete', 'separation', 'data', 'occurred', 'none', 'large', 'car', 'average', 'safety', 'record', 'parameter_estimate', 'standard_error', 'large', 'effect', 'deemed', 'unreliable', 'fitting', 'exact', 'logistic_regression_model', 'hybrid', 'network', '', 'monte', 'carlo', 'algorithm', 'example\tfit', 'exact', 'logistic_regression_model', 'using', 'monte', 'carlo', 'algorithm', 'safety', 'response_variable', 'type', 'region', 'weight', 'predictor_variable', 'model', 'probability', 'average', 'safety', 'score', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'specify', 'type', 'region', 'classification', 'variable', 'using', 'reference', 'cell', 'coding', 'specify', 'small', 'reference', 'level', 'type', 'asia', 'reference', 'level', 'region', 'also', 'add', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'specify', '100000', 'monte', 'carlo', 'sample', 'taken', 'set', 'seed', '27514', '', 'c3demo19a', '', 'proc_logistic', 'datasasusersafety', 'exactoptionsmethodnetworkmc', 'addtobs', 'n100000', 'seed27514', 'class', 'type', 'paramref', 'refsmall', 'region', 'paramref', 'refasia', 'model', 'safety', '', 'type', 'region', 'weight', 'exact', 'type', 'weight', 'region', '', 'estimateboth', 'title', 'car', 'safety', 'model', 'run', 'proc_logistic', 'statement', 'option', 'exactoptionsoptions\tspecifies', 'option', 'apply', 'every', 'exact', 'statement', 'program', 'selected', 'exactoptions', 'option', 'addtobs\tadds', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'statistic', 'wa', 'sampled', 'option', 'ha', 'effect', 'unless', 'methodnetworkmc', 'option', 'specified', 'estimate', 'option', 'specified', 'exact', 'statement', 'observed', 'statistic', 'ha', 'sampled', 'parameter_estimate', 'doe', 'exist', 'specifying', 'option', 'produce', 'biased', 'estimate', 'method\tspecifies', 'exact', 'conditional', 'algorithm', 'use', 'every', 'exact', 'statement', 'specified', 'keywords', 'direct', 'invokes', 'multivariate', 'shift', 'algorithm', 'network', 'invokes', 'network', 'algorithm', 'networkmc', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'algorithm', 'n\tspecifies', 'number', 'monte', 'carlo', 'sample', 'take', 'methodnetworkmc', 'default', 'n10000', 'seed\tspecifies', 'initial', 'seed', 'random', 'number', 'generator', 'used', 'take', 'monte', 'carlo', 'sample', 'methodnetworkmc', 'value', 'seed', 'option', 'must', 'integer', 'specify', 'seed', 'specify', 'value', 'le', 'equal', 'zero', 'proc_logistic', 'us', 'time', 'day', 'computer', 'clock', 'generate', 'initial', 'seed', 'car', 'safety', 'model']"
493,"TABLES	requests one-way to n-way frequency and crosstabulation tables and statistics for those tables. You can use multiple TABLES statements in the PROC FREQ step. EXACT	requests exact tests or confidence limits for the specified statistics. PROC FREQ also computes Monte Carlo estimates of the exact p-values. The statistic options specify the statistics for which to provide exact tests or confidence limits. The computation options specify options for the computation of exact statistics. TEST	requests asymptotic tests for the specified measures of association and measures of agreement. You must use a TABLES statement with the TEST statement. For each measure of association or agreement that you specify, the TEST statement provides an asymptotic test that the measure equals zero. OUTPUT	creates a SAS data set containing statistics computed by PROC FREQ. Only one OUTPUT statement is allowed for each execution of PROC FREQ. You must specify a TABLES statement with the OUTPUT statement. ?	Exact tests are appropriate when a data set is small, sparse, skewed, or heavily tied. For some large problems, computation of exact tests may require a large amount of time and memory. Consider using asymptotic tests for such problems. Alternatively, when asymptotic methods may not be sufficient for such large problems, consider using Monte Carlo estimation of exact p-values.",CD,1379,"['tables\trequests', 'oneway', 'nway', 'frequency', 'crosstabulation', 'table', 'statistic', 'table', 'use', 'multiple', 'table', 'statement', 'proc', 'freq', 'step', 'exact\trequests', 'exact', 'test', 'confidence', 'limit', 'specified', 'statistic', 'proc', 'freq', 'also', 'computes', 'monte', 'carlo', 'estimate', 'exact', 'pvalues', 'statistic', 'option', 'specify', 'statistic', 'provide', 'exact', 'test', 'confidence', 'limit', 'computation', 'option', 'specify', 'option', 'computation', 'exact', 'statistic', 'test\trequests', 'asymptotic', 'test', 'specified', 'measure', 'association', 'measure', 'agreement', 'must', 'use', 'table', 'statement', 'test', 'statement', 'measure', 'association', 'agreement', 'specify', 'test', 'statement', 'provides', 'asymptotic', 'test', 'measure', 'equal', 'zero', 'output\tcreates', 'sa', 'data_set', 'containing', 'statistic', 'computed', 'proc', 'freq', 'one', 'output', 'statement', 'allowed', 'execution', 'proc', 'freq', 'must', 'specify', 'table', 'statement', 'output', 'statement', '\texact', 'test', 'appropriate', 'data_set', 'small', 'sparse', 'skewed', 'heavily', 'tied', 'large', 'problem', 'computation', 'exact', 'test', 'may', 'require', 'large', 'amount', 'time', 'memory', 'consider', 'using', 'asymptotic', 'test', 'problem', 'alternatively', 'asymptotic', 'method', 'may', 'sufficient', 'large', 'problem', 'consider', 'using', 'monte', 'carlo', 'estimation', 'exact', 'pvalues']"
494,"Unfortunately, the distributions of the diagnostic statistics are not known, so cutoff values cannot be given for determining when the values are large (Pregibon 1981). Therefore, you have to rely on visual inspection of these statistics. Hosmer and Lemeshow (2000) recommend plotting the influence statistics such as the change in the Pearson chi-square against the predicted values. Graphing these influence statistics may enable you to identify those covariate patterns (subjects) that are poorly fit by the model. Examination of these patterns may indicate that important variables are missing from the model or that some of the variables in the model have not been entered in the correct scale. These patterns may also identify erroneous data values. The plot above is a plot of the change in the Pearson chi-square statistic by the predicted probabilities. The points on the curve going from the upper-left to the lower-right corner correspond to the covariate patterns with a response value of 1. The points on the curve going from the upper- right to the lower-left corners correspond to the covariate patterns with a response value of 0. Covariate patterns that are poorly fit by the model will lie in the upper-right and left corners of the plot. Hosmer and Lemeshow (2000) suggest that values of the change in the Pearson chi-square statistic above 4 are potential outliers. ?	Another graph that can be used to identify influential observations and outliers in relatively small data sets is the index plot. In an index plot, the diagnostic statistic is plotted against the observation number. This enables visual inspection and comparison of the values across observations. If the model is correctly specified and fits all observations well, then no extreme points should appear. The IPLOTS option in the MODEL statement requests an index plot for each regression diagnostic statistic.",CD,1896,"['unfortunately', 'distribution', 'diagnostic', 'statistic', 'known', 'cutoff', 'value', 'cannot', 'given', 'determining', 'value', 'large', 'pregibon', '1981', 'therefore', 'rely', 'visual', 'inspection', 'statistic', 'hosmer', 'lemeshow', '2000', 'recommend', 'plotting', 'influence', 'statistic', 'change', 'pearson', 'chisquare', 'predicted', 'value', 'graphing', 'influence', 'statistic', 'may', 'enable', 'identify', 'covariate', 'pattern', 'subject', 'poorly', 'fit', 'model', 'examination', 'pattern', 'may', 'indicate', 'important', 'variable', 'missing', 'model', 'variable', 'model', 'entered', 'correct', 'scale', 'pattern', 'may', 'also', 'identify', 'erroneous', 'data', 'value', 'plot', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'point', 'curve', 'going', 'upperleft', 'lowerright', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '1', 'point', 'curve', 'going', 'upper', 'right', 'lowerleft', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '0', 'covariate', 'pattern', 'poorly', 'fit', 'model', 'lie', 'upperright', 'left', 'corner', 'plot', 'hosmer', 'lemeshow', '2000', 'suggest', 'value', 'change', 'pearson', 'chisquare', 'statistic', '4', 'potential', 'outlier', '\tanother', 'graph', 'used', 'identify', 'influential', 'observation', 'outlier', 'relatively', 'small', 'data_set', 'index', 'plot', 'index', 'plot', 'diagnostic', 'statistic', 'plotted', 'observation', 'number', 'enables', 'visual', 'inspection', 'comparison', 'value', 'across', 'observation', 'model', 'correctly', 'specified', 'fit', 'observation', 'well', 'extreme', 'point', 'appear', 'iplots', 'option', 'model_statement', 'request', 'index', 'plot', 'regression', 'diagnostic', 'statistic']"
495,Example:	Fit a simple ordinal logistic regression model to the backache data set. Specify painseverity as the response variable and bending as the predictor variable. Also specify the DESCENDING option to reverse the sort order of the response variable. /* c3demo14a */ proc logistic data=sasuser.backache desc; model painseverity=bending; title 'Ordinal Logistic Regression Model for the Backache ' 'Example'; run; PROC LOGISTIC statement option: DESC	reverses the sorting order for the levels of the response variable. This option has the same effect as the response variable option DESCENDING in the MODEL statement. Ordinal Logistic Regression Model for the Backache Example,CD,678,"['example\tfit', 'simple', 'ordinal', 'logistic_regression_model', 'backache', 'data_set', 'specify', 'painseverity', 'response_variable', 'bending', 'predictor_variable', 'also', 'specify', 'descending', 'option', 'reverse', 'sort', 'order', 'response_variable', '', 'c3demo14a', '', 'proc_logistic', 'datasasuserbackache', 'desc', 'model', 'painseveritybending', 'title', 'ordinal', 'logistic_regression_model', 'backache', '', 'example', 'run', 'proc_logistic', 'statement', 'option', 'desc\treverses', 'sorting', 'order', 'level', 'response_variable', 'option', 'ha', 'effect', 'response_variable', 'option', 'descending', 'model_statement', 'ordinal', 'logistic_regression_model', 'backache', 'example']"
496,"When you statistically adjust for age, you are comparing the two groups at some common value of age. If there is no interaction, then any common value of age could be used, because it would yield the same difference between the two groups. In the logistic regression model with age and gender as predictor variables, the coefficient for gender would be the log odds ratio expected from a univariate comparison if the two groups had the same distribution of age. Age is a confounder in the relationship between gender and the response because it distorts the effect of gender on the response. The distribution of age is not the same in the two groups, and age is related to the response. For variables with few unique values, a stratified contingency table analysis may help identify confounders. For continuous variables, fitting the logistic model with and without the possible confounder and documenting any changes in the coefficient of the other predictor variable will be necessary.",CD,987,"['statistically', 'adjust', 'age', 'comparing', 'two', 'group', 'common', 'value', 'age', 'interaction', 'common', 'value', 'age', 'could', 'used', 'would', 'yield', 'difference', 'two', 'group', 'logistic_regression_model', 'age', 'gender', 'predictor_variable', 'coefficient', 'gender', 'would', 'log', 'odds_ratio', 'expected', 'univariate', 'comparison', 'two', 'group', 'distribution', 'age', 'age', 'confounder', 'relationship', 'gender', 'response', 'distorts', 'effect', 'gender', 'response', 'distribution', 'age', 'two', 'group', 'age', 'related', 'response_variable', 'unique', 'value', 'stratified', 'contingency', 'table', 'analysis', 'may', 'help', 'identify', 'confounders', 'continuous', 'variable', 'fitting', 'logistic', 'model', 'without', 'possible', 'confounder', 'documenting', 'change', 'coefficient', 'predictor_variable', 'necessary']"
497,"Backward elimination starts off with the full model. Results of the Wald test for individual parameter estimates are examined, and the least significant variable that falls above the specified significance level (specified by the SLSTAY= option) is removed. After a variable is removed from the model, it remains excluded. The process is repeated until no other variable in the model meets the specified significance level for removal. By default, SLSTAY=0.05. When using backward elimination, you could use the FAST option to increase efficiency. This method only requires passing through the data matrix once to get the initial full model fit. Then the method uses an algorithm to manipulate the full model fit to approximate the parameter estimates for the reduced models. This eliminates the need to refit the model every time a variable is removed. Simulations examining variable selection techniques found that backward elimination methods usually performed better than the forward stepwise methods, especially when collinearity is present among the predictor variables. However, a relatively large number of predictor variables increases the risk of complete separation (Hosmer and Lemeshow 2000). Furthermore, sparseness in the data causes unstable parameter estimates that negatively impact the performance of the backward elimination method (Harrell 1997).",CD,1366,"['backward', 'elimination', 'start', 'full', 'model', 'result', 'wald', 'test', 'individual', 'parameter_estimate', 'examined', 'least', 'significant', 'variable', 'fall', 'specified', 'significance', 'level', 'specified', 'slstay', 'option', 'removed', 'variable', 'removed', 'model', 'remains', 'excluded', 'process', 'repeated', 'variable', 'model', 'meet', 'specified', 'significance', 'level', 'removal', 'default', 'slstay005', 'using', 'backward', 'elimination', 'could', 'use', 'fast', 'option', 'increase', 'efficiency', 'method', 'requires', 'passing', 'data', 'matrix', 'get', 'initial', 'full', 'model', 'fit', 'method', 'us', 'algorithm', 'manipulate', 'full', 'model', 'fit', 'approximate', 'parameter_estimate', 'reduced', 'model', 'eliminates', 'need', 'refit', 'model', 'every', 'time', 'variable', 'removed', 'simulation', 'examining', 'variable', 'selection', 'technique', 'found', 'backward', 'elimination', 'method', 'usually', 'performed', 'better', 'forward', 'stepwise', 'method', 'especially', 'collinearity', 'present', 'among', 'predictor_variable', 'however', 'relatively', 'large', 'number', 'predictor_variable', 'increase', 'risk', 'complete', 'separation', 'hosmer', 'lemeshow', '2000', 'furthermore', 'sparseness', 'data', 'cause', 'unstable', 'parameter_estimate', 'negatively', 'impact', 'performance', 'backward', 'elimination', 'method', 'harrell', '1997']"
498,"Variable clustering is based on principal components. Principal components are weighted linear combinations of the predictor variables where the weights are chosen to account for the largest amount of variation in the data; total variation in this case is the sum of the sample variances of the predictor variables. The principal components are numbered according to how much variation in the data is accounted for (first principal component accounts for the largest, second principal component accounts for the second largest, and so on) and each principal component accounts for a unique portion of the variation in the data. In other words, they are not correlated.",CD,668,"['variable', 'clustering', 'based', 'principal', 'component', 'principal', 'component', 'weighted', 'linear', 'combination', 'predictor_variable', 'weight', 'chosen', 'account', 'largest', 'amount', 'variation', 'data', 'total', 'variation', 'case', 'sum', 'sample', 'variance', 'predictor_variable', 'principal', 'component', 'numbered', 'according', 'much', 'variation', 'data', 'accounted', 'first', 'principal', 'component', 'account', 'largest', 'second', 'principal', 'component', 'account', 'second', 'largest', 'principal', 'component', 'account', 'unique', 'portion', 'variation', 'data', 'word', 'correlated']"
499,"Stepwise selection is similar to forward selection in that it starts with an empty model and incrementally builds a model one variable at a time. However, the method differs from forward selection in that variables already in the model do not necessarily remain. The backward component of the method removes variables from the model that do not meet the significance criteria specified in the SLSTAY= option. The stepwise selection process terminates if no further variable can be added to the model or if the variable just entered into the model is the only variable removed in the subsequent backward elimination. Stepwise selection in PROC LOGISTIC is not an efficient method to select variables. In fact, its performance acutely deteriorates if the full model has over approximately 60 effects (Potts and Patetta 1999). Stepwise selection has some serious shortcomings. Simulation studies (Derksen and Keselman 1992) evaluating variable selection techniques found the following: 1.	The degree of collinearity among the predictor variables affected the frequency with which authentic predictor variables found their way into the final model. 2.	The number of candidate predictor variables affected the number of noise variables that gained entry to the model. 3.	The size of the sample was of little practical importance in determining the number of authentic variables contained in the final model. One recommendation is to use the variable selection methods to create several candidate models, and then use subject-matter knowledge to select the variables that result in the best model within the scientific or business context of the problem. Therefore, you are simply using these methods as a useful tool in the model-building process (Hosmer and Lemeshow 2000).",CD,1769,"['stepwise', 'selection', 'similar', 'forward', 'selection', 'start', 'empty', 'model', 'incrementally', 'build', 'model', 'one', 'variable', 'time', 'however', 'method', 'differs', 'forward', 'selection', 'variable', 'already', 'model', 'necessarily', 'remain', 'backward', 'component', 'method', 'remove', 'variable', 'model', 'meet', 'significance', 'criterion', 'specified', 'slstay', 'option', 'stepwise', 'selection', 'process', 'terminates', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'variable', 'removed', 'subsequent', 'backward', 'elimination', 'stepwise', 'selection', 'proc_logistic', 'efficient', 'method', 'select', 'variable', 'fact', 'performance', 'acutely', 'deteriorates', 'full', 'model', 'ha', 'approximately', '60', 'effect', 'potts', 'patetta', '1999', 'stepwise', 'selection', 'ha', 'serious', 'shortcoming', 'simulation', 'study', 'derksen', 'keselman', '1992', 'evaluating', 'variable', 'selection', 'technique', 'found', 'following', '1\tthe', 'degree', 'collinearity', 'among', 'predictor_variable', 'affected', 'frequency', 'authentic', 'predictor_variable', 'found', 'way', 'final', 'model', '2\tthe', 'number', 'candidate', 'predictor_variable', 'affected', 'number', 'noise', 'variable', 'gained', 'entry', 'model', '3\tthe', 'size', 'sample', 'wa', 'little', 'practical', 'importance', 'determining', 'number', 'authentic', 'variable', 'contained', 'final', 'model', 'one', 'recommendation', 'use', 'variable', 'selection', 'method', 'create', 'several', 'candidate', 'model', 'use', 'subjectmatter', 'knowledge', 'select', 'variable', 'result', 'best', 'model', 'within', 'scientific', 'business', 'context', 'problem', 'therefore', 'simply', 'using', 'method', 'useful', 'tool', 'modelbuilding', 'process', 'hosmer', 'lemeshow', '2000']"
500,"The distribution of predicted probabilities is slightly skewed, but each bar has an adequate percentage of observations. Therefore, create a classification table where the cutoffs range from .1 to .9 by .1.",CD,206,"['distribution', 'predicted', 'probability', 'slightly', 'skewed', 'bar', 'ha', 'adequate', 'percentage', 'observation', 'therefore', 'create', 'classification', 'table', 'cutoff', 'range', '1', '9', '1']"
501,"Example:	Fit a conditional logistic regression model to the sasuser.matched data set. Specify low as the response variable and use all of the predictor variables. Use the EVENT= option to model the probability of low birth weight. Use the UNITS statement to obtain an odds ratio estimate for a 10-unit change in Mother_wt. Also specify socio as a CLASS variable, reference cell coding, 3 as the reference level, standardized estimates, and Wald confidence intervals for the odds ratios. /* c3demo20a */ proc logistic data=sasuser.matched; strata Pair; class Socio (param=ref ref='3'); model Low(event='1') = Mother_age Mother_wt Socio Smoke Prev_pretrm Uterine_irr Hist_hyp / stb clodds=wald; units Mother_wt=10; title 'Conditional Model for Matched Case-Control Study'; run; Selected STRATA statement options: MISSING	treats missing values as valid STRATA variable values. NOSUMMARY	suppresses the display of the ?Strata Summary? table. INFO	displays the ?Strata Information? table, which includes the stratum number, levels of the STRATA variables that define the stratum, the number of events, the number of nonevents, and the total frequency for each stratum. The STRATA statement names the variables that define strata or matched sets to use in a conditional logistic regression model. Observations having the same variable levels are in the same matched set. At least one variable must be specified to invoke the stratified analysis, and the usual unconditional asymptotic analysis is not performed. STRATA variables can also be specified in the MODEL statement as classification or continuous variables. However, the effects are nondegenerate only when crossed with a non-stratification variable. The SCORE and WEIGHT statements are not available with a STRATA statement. The following MODEL options are also not supported with a STRATA statement: CLPARM=PL, CLODDS=PL, CTABLE, LACKFIT, LINK=, NOFIT, OUTMODEL=, OUTROC=, and SCALE=. Conditional Model for Matched Case-Control Study",CD,1988,"['example\tfit', 'conditional', 'logistic_regression_model', 'sasusermatched', 'data_set', 'specify', 'low', 'response_variable', 'use', 'predictor_variable', 'use', 'event', 'option', 'model', 'probability', 'low', 'birth', 'weight', 'use', 'unit', 'statement', 'obtain', 'odds_ratio', 'estimate', '10unit', 'change', 'motherwt', 'also', 'specify', 'socio', 'class', 'variable', 'reference', 'cell', 'coding', '3', 'reference', 'level', 'standardized', 'estimate', 'wald', 'confidence', 'interval', 'odds_ratio', '', 'c3demo20a', '', 'proc_logistic', 'datasasusermatched', 'stratum', 'pair', 'class', 'socio', 'paramref', 'ref3', 'model', 'lowevent1', '', 'motherage', 'motherwt', 'socio', 'smoke', 'prevpretrm', 'uterineirr', 'histhyp', '', 'stb', 'cloddswald', 'unit', 'motherwt10', 'title', 'conditional', 'model', 'matched', 'casecontrol', 'study', 'run', 'selected', 'stratum', 'statement', 'option', 'missing\ttreats', 'missing', 'value', 'valid', 'stratum', 'variable', 'value', 'nosummary\tsuppresses', 'display', 'stratum', 'summary', 'table', 'info\tdisplays', 'stratum', 'information', 'table', 'includes', 'stratum', 'number', 'level', 'stratum', 'variable', 'define', 'stratum', 'number', 'event', 'number', 'nonevent', 'total', 'frequency', 'stratum', 'stratum', 'statement', 'name', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'conditional', 'logistic_regression_model', 'observation', 'variable', 'level', 'matched', 'set', 'least', 'one', 'variable', 'must', 'specified', 'invoke', 'stratified', 'analysis', 'usual', 'unconditional', 'asymptotic', 'analysis', 'performed', 'stratum', 'variable', 'also', 'specified', 'model_statement', 'classification', 'continuous', 'variable', 'however', 'effect', 'nondegenerate', 'crossed', 'nonstratification', 'variable', 'score', 'weight', 'statement', 'available', 'stratum', 'statement', 'following', 'model', 'option', 'also', 'supported', 'stratum', 'statement', 'clparmpl', 'cloddspl', 'ctable', 'lackfit', 'link', 'nofit', 'outmodel', 'outroc', 'scale', 'conditional', 'model', 'matched', 'casecontrol', 'study']"
502,"The Type III Analysis of Effects table shows that the variable size is significant in the model. This means that for at least one of the generalized logits, size has a significant effect. Analysis of Maximum Likelihood Estimates",CD,228,"['type', 'iii', 'analysis', 'effect', 'table', 'show', 'variable', 'size', 'significant', 'model', 'mean', 'least', 'one', 'generalized', 'logits', 'size', 'ha', 'significant', 'effect', 'analysis', 'maximum', 'likelihood', 'estimate']"
503,"Example:	Output the predicted probabilities and examine the distribution using the HISTOGRAM statement in PROC UNIVARIATE. Then create a classification table and a ROC curve for the final model. The sample is a stratified random sample, so specify a list of prior probabilities for low birth weight. /* c2demo10a */ options label;",CD,330,"['example\toutput', 'predicted', 'probability', 'examine', 'distribution', 'using', 'histogram', 'statement', 'proc', 'univariate', 'create', 'classification', 'table', 'roc', 'curve', 'final', 'model', 'sample', 'stratified', 'random', 'sample', 'specify', 'list', 'prior', 'probability', 'low', 'birth', 'weight', '', 'c2demo10a', '', 'option', 'label']"
504,"Building a nominal logistic regression model employs the same strategy as building any other model. The first step is to examine the distribution of the predictor variables and take note of any missing values and unusual data values. Contingency table analysis should also be performed to examine the associations between the outcome variable and each of the ordinal predictor variables. You should carefully look for cells with no observations, because this may cause a problem in PROC LOGISTIC.",CD,496,"['building', 'nominal', 'logistic_regression_model', 'employ', 'strategy', 'building', 'model', 'first', 'step', 'examine', 'distribution', 'predictor_variable', 'take', 'note', 'missing', 'value', 'unusual', 'data', 'value', 'contingency', 'table', 'analysis', 'also', 'performed', 'examine', 'association', 'outcome', 'variable', 'ordinal', 'predictor_variable', 'carefully', 'look', 'cell', 'observation', 'may', 'cause', 'problem', 'proc_logistic']"
505,"Variable clustering is based on principal components. Principal components are weighted linear combinations of the predictor variables where the weights are chosen to account for the largest amount of variation in the data; total variation in this case is the sum of the sample variances of the predictor variables. The principal components are numbered according to how much variation in the data is accounted for (first principal component accounts for the largest, second principal component accounts for the second largest, and so on) and each principal component accounts for a unique portion of the variation in the data. In other words, they are not correlated.",CD,668,"['variable', 'clustering', 'based', 'principal', 'component', 'principal', 'component', 'weighted', 'linear', 'combination', 'predictor_variable', 'weight', 'chosen', 'account', 'largest', 'amount', 'variation', 'data', 'total', 'variation', 'case', 'sum', 'sample', 'variance', 'predictor_variable', 'principal', 'component', 'numbered', 'according', 'much', 'variation', 'data', 'accounted', 'first', 'principal', 'component', 'account', 'largest', 'second', 'principal', 'component', 'account', 'second', 'largest', 'principal', 'component', 'account', 'unique', 'portion', 'variation', 'data', 'word', 'correlated']"
506,"For the 2-dependent correlation structure (TYPE=MDEP(2)), measurements are correlated if they are two or less time periods apart. Measurements that are one time period apart have different correlations than measurements that are two time periods apart. These last two correlation structures are generally called m-dependent correlation structures. The m represents how many time periods apart the measurements are still correlated. Therefore, a 5- dependent correlation structure would indicate that measurements are correlated if they are five or fewer time periods apart.",CD,573,"['2dependent', 'correlation_structure', 'typemdep2', 'measurement', 'correlated', 'two', 'le', 'time', 'period', 'apart', 'measurement', 'one', 'time', 'period', 'apart', 'different', 'correlation', 'measurement', 'two', 'time', 'period', 'apart', 'last', 'two', 'correlation_structure', 'generally', 'called', 'mdependent', 'correlation_structure', 'represents', 'many', 'time', 'period', 'apart', 'measurement', 'still', 'correlated', 'therefore', '5', 'dependent', 'correlation_structure', 'would', 'indicate', 'measurement', 'correlated', 'five', 'fewer', 'time', 'period', 'apart']"
507,Matching is carried out in the design phase of the study where you want to balance two or more groups with respect to one or more risk factors that are either known or thought to be associated with the outcome.,CD,210,"['matching', 'carried', 'design', 'phase', 'study', 'want', 'balance', 'two', 'group', 'respect', 'one', 'risk', 'factor', 'either', 'known', 'thought', 'associated', 'outcome']"
508,Example:	Generate the regression diagnostic statistics for each observation. /* c2demo11a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / influence; title 'Logistic Regression Diagnostic Statistics'; run; Selected MODEL statement options: INFLUENCE	displays diagnostic measures for identifying influential observations in the case of the binary outcome model. Partial Output Logistic Regression Diagnostic Statistics,CD,527,"['example\tgenerate', 'regression', 'diagnostic', 'statistic', 'observation', '', 'c2demo11a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'influence', 'title', 'logistic_regression', 'diagnostic', 'statistic', 'run', 'selected', 'model_statement', 'option', 'influence\tdisplays', 'diagnostic', 'measure', 'identifying', 'influential', 'observation', 'case', 'binary', 'outcome', 'model', 'partial', 'output', 'logistic_regression', 'diagnostic', 'statistic']"
509,"In the univariate analysis of the data, it is important to document, for each predictor variable, whether an association exists with the response variable and the strength of the association. For binary predictor variables, the confidence bounds around the odds ratio would indicate whether an association exists. If the confidence interval does not include 1, then there is evidence that there is an association. For ordinal predictors, the Mantel-Haenszel chi-square could be used. For nominal predictors, the mean score statistic would be helpful (Stokes, Davis, and Koch 2000). ?	Binary variables can be considered ordinal variables.",CD,637,"['univariate', 'analysis', 'data', 'important', 'document', 'predictor_variable', 'whether', 'association', 'exists', 'response_variable', 'strength', 'association', 'binary', 'predictor_variable', 'confidence', 'bound', 'around', 'odds_ratio', 'would', 'indicate', 'whether', 'association', 'exists', 'confidence', 'interval', 'doe', 'include', '1', 'evidence', 'association', 'ordinal', 'predictor', 'mantelhaenszel', 'chisquare', 'could', 'used', 'nominal', 'predictor', 'mean', 'score', 'statistic', 'would', 'helpful', 'stokes', 'davis', 'koch', '2000', '\tbinary', 'variable', 'considered', 'ordinal', 'variable']"
510,title 'Nominal Logistic Regression Model on Alligator Food Data'; run; Selected MODEL statement options: REF=	specifies the reference group for the nominal and binary response model. You can specify the reference category in quotes or the keyword FIRST (designates the first ordered category as the reference) or the keyword LAST (designates the last ordered category as the reference). The default is REF=LAST. LINK=	specifies the function linking the response probabilities to the linear predictors. The keyword GLOGIT requests the generalized logit function. The default is LINK=LOGIT (the log odds function). Nominal Logistic Regression Model on Alligator Food Data,CD,669,"['title', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data', 'run', 'selected', 'model_statement', 'option', 'ref\tspecifies', 'reference', 'group', 'nominal', 'binary', 'response', 'model', 'specify', 'reference', 'category', 'quote', 'keyword', 'first', 'designates', 'first', 'ordered', 'category', 'reference', 'keyword', 'last', 'designates', 'last', 'ordered', 'category', 'reference', 'default', 'reflast', 'link\tspecifies', 'function', 'linking', 'response', 'probability', 'linear', 'predictor', 'keyword', 'glogit', 'request', 'generalized', 'logit', 'function', 'default', 'linklogit', 'log', 'odds', 'function', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data']"
511,"Logits modeled use food='Fish' as the reference category. The first part of the output is similar to the output for the binary logit model. Because the MODEL statement option REF='Fish', the response category Fish is used as the reference category. Class Level Information",CD,272,"['logits', 'modeled', 'use', 'foodfish', 'reference', 'category', 'first', 'part', 'output', 'similar', 'output', 'binary', 'logit', 'model', 'model_statement', 'option', 'reffish', 'response', 'category', 'fish', 'used', 'reference', 'category', 'class', 'level', 'information']"
512,"The DIFDEV and DIFCHISQ are diagnostics for detecting which observations contribute heavily to the disagreement between the data and the predicted values of the fitted model. The range of DIFCHISQ is much greater then DIFDEV. DFBETAS are diagnostics that can be used to assess the effect of an individual observation on each estimated parameter of the fitted model. These statistics are useful in detecting observations that are causing instability in the selected parameter estimates. Instead of re-estimating the parameter each time an observation is deleted, PROC LOGISTIC uses the one-step estimate. C and CBAR are confidence interval displacement diagnostics. These statistics are based on the same idea as the Cook distance in linear regression. PROC LOGISTIC also computes these using the one-step estimate. H is the hat matrix diagonal. The diagonal elements of the hat matrix are useful in detecting extreme points in the design space. However, if the estimated probability is extreme (less than 0.1 and greater than 0.9), then the hat diagonal may be greatly reduced in value. Consequently, when an observation has a very large or very small estimated probability, its hat diagonal value is not a good indicator of the observation?s distance from the design space (Hosmer and Lemeshow 2000). The deviance residuals (contribution of each observation to the deviance chi-square) and Pearson residuals (contribution of each observation to the Pearson chi-square) can also be used to determine which observations are poorly fit by the model.",CD,1547,"['difdev', 'difchisq', 'diagnostics', 'detecting', 'observation', 'contribute', 'heavily', 'disagreement', 'data', 'predicted', 'value', 'fitted', 'model', 'range', 'difchisq', 'much', 'greater', 'difdev', 'dfbetas', 'diagnostics', 'used', 'ass', 'effect', 'individual', 'observation', 'estimated', 'parameter', 'fitted', 'model', 'statistic', 'useful', 'detecting', 'observation', 'causing', 'instability', 'selected', 'parameter_estimate', 'instead', 'reestimating', 'parameter', 'time', 'observation', 'deleted', 'proc_logistic', 'us', 'onestep', 'estimate', 'c', 'cbar', 'confidence', 'interval', 'displacement', 'diagnostics', 'statistic', 'based', 'idea', 'cook', 'distance', 'linear', 'regression', 'proc_logistic', 'also', 'computes', 'using', 'onestep', 'estimate', 'h', 'hat', 'matrix', 'diagonal', 'diagonal', 'element', 'hat', 'matrix', 'useful', 'detecting', 'extreme', 'point', 'design', 'space', 'however', 'estimated', 'probability', 'extreme', 'le', '01', 'greater', '09', 'hat', 'diagonal', 'may', 'greatly', 'reduced', 'value', 'consequently', 'observation', 'ha', 'large', 'small', 'estimated', 'probability', 'hat', 'diagonal', 'value', 'good', 'indicator', 'observation', 'distance', 'design', 'space', 'hosmer', 'lemeshow', '2000', 'deviance', 'residual', 'contribution', 'observation', 'deviance', 'chisquare', 'pearson', 'residual', 'contribution', 'observation', 'pearson', 'chisquare', 'also', 'used', 'determine', 'observation', 'poorly', 'fit', 'model']"
513,"Building a nominal logistic regression model employs the same strategy as building any other model. The first step is to examine the distribution of the predictor variables and take note of any missing values and unusual data values. Contingency table analysis should also be performed to examine the associations between the outcome variable and each of the ordinal predictor variables. You should carefully look for cells with no observations, because this may cause a problem in PROC LOGISTIC.",CD,496,"['building', 'nominal', 'logistic_regression_model', 'employ', 'strategy', 'building', 'model', 'first', 'step', 'examine', 'distribution', 'predictor_variable', 'take', 'note', 'missing', 'value', 'unusual', 'data', 'value', 'contingency', 'table', 'analysis', 'also', 'performed', 'examine', 'association', 'outcome', 'variable', 'ordinal', 'predictor_variable', 'carefully', 'look', 'cell', 'observation', 'may', 'cause', 'problem', 'proc_logistic']"
514,"For reference cell coding, parameter estimates of the CLASS main effects estimate the difference between the effect of each level and the last level. For example, the effect for the low level would estimate the difference between low and high. You can choose the reference level with the REF= option.",CD,300,"['reference', 'cell', 'coding', 'parameter_estimate', 'class', 'main_effect', 'estimate', 'difference', 'effect', 'level', 'last', 'level', 'example', 'effect', 'low', 'level', 'would', 'estimate', 'difference', 'low', 'high', 'choose', 'reference', 'level', 'ref', 'option']"
515,"For logistic regression, the sufficient statistics for the in the model are where j=1,?, number of predictor variables. Therefore, the sufficient statistics for the parameters of the predictor variables are the sum of the cross-products of the response value and the predictor variable values. The sufficient statistic for the intercept is the total number of events since the intercept variable is constant at 1.",CD,413,"['logistic_regression', 'sufficient', 'statistic', 'model', 'j1', 'number', 'predictor_variable', 'therefore', 'sufficient', 'statistic', 'parameter', 'predictor_variable', 'sum', 'crossproducts', 'response', 'value', 'predictor_variable', 'value', 'sufficient', 'statistic', 'intercept', 'total', 'number', 'event', 'since', 'intercept', 'variable', 'constant', '1']"
516,"Generating the exact conditional distribution becomes unfeasible with a large number of observations. For example, if you had 30 observations you would have to scan 230 or more than a billion different sequences of the binary response values. However, PROC LOGISTIC has several numerical algorithms that use faster methods of generating and counting the response value vectors for larger problems. The multivariate shift algorithm developed by Hirji, Mehta, and Patel (1987) is invoked using the METHOD=DIRECT option. This method uses a number of shortcuts in a brand and bound algorithm to build the exact distribution, but it may require an excessive amount of memory in its intermediate stages. The METHOD=NETWORK option invokes a method (described in Mehta, Patel, and Senchaudhuri (1992)) that is faster and requires less memory than the DIRECT method. The NETWORK method is invoked by default for most analyses. Finally, the METHOD=NETWORKMC option invokes a hybrid network and a Monte Carlo sampling algorithm (described in Mehta, Patel, and Senchaudhuri (2000)) that samples from the combined network to estimate the exact distribution. This method is most useful for producing parameter estimates for problems that are too large for the DIRECT and NETWORK methods to handle and for which the asymptotic methods are invalid (sparse data on a large grid). ?	Monte Carlo simulation is performed using random sampling from the probability density functions. This is different than a bootstrapped sample where you sample with replacement from a given data set, compute statistics, and repeat many times. With bootstrapping, you are basically creating a distribution for a target statistic. The Monte Carlo algorithm starts with a network where every path through the network corresponds to a sequence with the correct sufficient statistics. Then the algorithm does a weighted random traversal of the network to sample a binary sequence to create a sampled distribution.",CD,1973,"['generating', 'exact', 'conditional', 'distribution', 'becomes', 'unfeasible', 'large', 'number', 'observation', 'example', '30', 'observation', 'would', 'scan', '230', 'billion', 'different', 'sequence', 'binary', 'response', 'value', 'however', 'proc_logistic', 'ha', 'several', 'numerical', 'algorithm', 'use', 'faster', 'method', 'generating', 'counting', 'response', 'value', 'vector', 'larger', 'problem', 'multivariate', 'shift', 'algorithm', 'developed', 'hirji', 'mehta', 'patel', '1987', 'invoked', 'using', 'methoddirect', 'option', 'method', 'us', 'number', 'shortcut', 'brand', 'bound', 'algorithm', 'build', 'exact', 'distribution', 'may', 'require', 'excessive', 'amount', 'memory', 'intermediate', 'stage', 'methodnetwork', 'option', 'invokes', 'method', 'described', 'mehta', 'patel', 'senchaudhuri', '1992', 'faster', 'requires', 'le', 'memory', 'direct', 'method', 'network', 'method', 'invoked', 'default', 'analysis', 'finally', 'methodnetworkmc', 'option', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'sampling', 'algorithm', 'described', 'mehta', 'patel', 'senchaudhuri', '2000', 'sample', 'combined', 'network', 'estimate', 'exact', 'distribution', 'method', 'useful', 'producing', 'parameter_estimate', 'problem', 'large', 'direct', 'network', 'method', 'handle', 'asymptotic', 'method', 'invalid', 'sparse', 'data', 'large', 'grid', '\tmonte', 'carlo', 'simulation', 'performed', 'using', 'random', 'sampling', 'probability', 'density', 'function', 'different', 'bootstrapped', 'sample', 'sample', 'replacement', 'given', 'data_set', 'compute', 'statistic', 'repeat', 'many', 'time', 'bootstrapping', 'basically', 'creating', 'distribution', 'target', 'statistic', 'monte', 'carlo', 'algorithm', 'start', 'network', 'every', 'path', 'network', 'corresponds', 'sequence', 'correct', 'sufficient', 'statistic', 'algorithm', 'doe', 'weighted', 'random', 'traversal', 'network', 'sample', 'binary', 'sequence', 'create', 'sampled', 'distribution']"
517,The plot of the change in the deviance by predicted probabilities shows several observations that need to be examined. The points in the upper-left corner represent women who had low birth weight babies with very favorable covariate patterns. The points in the upper-right corner represent women who had normal weight babies with very unfavorable covariate patterns. Careful examination of these observations may lead to strategies to improve the fit of the model (Hosmer and Lemeshow 2000). Example:	Generate a bubble plot of the change in the Pearson chi-square statistic by predicted probabilities with the plotting symbol proportional to the c diagnostic statistic. Create an ActiveX graph in HTML output. /* c2demo11c */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difchisq=difchisq c=c; run;,CD,942,"['plot', 'change', 'deviance', 'predicted', 'probability', 'show', 'several', 'observation', 'need', 'examined', 'point', 'upperleft', 'corner', 'represent', 'woman', 'low', 'birth', 'weight', 'baby', 'favorable', 'covariate', 'pattern', 'point', 'upperright', 'corner', 'represent', 'woman', 'normal', 'weight', 'baby', 'unfavorable', 'covariate', 'pattern', 'careful', 'examination', 'observation', 'may', 'lead', 'strategy', 'improve', 'fit', 'model', 'hosmer', 'lemeshow', '2000', 'example\tgenerate', 'bubble', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'plotting', 'symbol', 'proportional', 'c', 'diagnostic', 'statistic', 'create', 'activex', 'graph', 'html', 'output', '', 'c2demo11c', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difchisqdifchisq', 'cc', 'run']"
518,Complete separation can cause severe bias in the estimates of the odds ratios and poor chi-squared approximations for the goodness-of-fit statistics. You should be concerned about your model when the three goodness-of-fit tests reported in PROC LOGISTIC vary widely. Complete separation should be detected in the univariate analysis of the predictor variables. It should be noted that the modeling strategy that includes all the predictor variables in the model is particularly sensitive to complete separation (Allison 1999).,CD,526,"['complete', 'separation', 'cause', 'severe', 'bias', 'estimate', 'odds_ratio', 'poor', 'chisquared', 'approximation', 'goodnessoffit', 'statistic', 'concerned', 'model', 'three', 'goodnessoffit', 'test', 'reported', 'proc_logistic', 'vary', 'widely', 'complete', 'separation', 'detected', 'univariate', 'analysis', 'predictor_variable', 'noted', 'modeling', 'strategy', 'includes', 'predictor_variable', 'model', 'particularly', 'sensitive', 'complete', 'separation', 'allison', '1999']"
519,Cases are allocated to classes based on cutoff values of the predicted probability. The steps include the following: 1.	Estimate the predicted probability of class 1 for each case by the logistic regression model. 2.	Choose a cutoff probability. 3.	Assign cases to class 1 if their estimated predicted probability exceeds the cutoff; otherwise assign the case to class 0.,CD,371,"['case', 'allocated', 'class', 'based', 'cutoff', 'value', 'predicted', 'probability', 'step', 'include', 'following', '1\testimate', 'predicted', 'probability', 'class', '1', 'case', 'logistic_regression_model', '2\tchoose', 'cutoff', 'probability', '3\tassign', 'case', 'class', '1', 'estimated', 'predicted', 'probability', 'exceeds', 'cutoff', 'otherwise', 'assign', 'case', 'class', '0']"
520,"Example:	Output the predicted probabilities and examine the distribution using the HISTOGRAM statement in PROC UNIVARIATE. Then create a classification table and a ROC curve for the final model. The sample is a stratified random sample, so specify a list of prior probabilities for low birth weight. /* c2demo10a */ options label;",CD,330,"['example\toutput', 'predicted', 'probability', 'examine', 'distribution', 'using', 'histogram', 'statement', 'proc', 'univariate', 'create', 'classification', 'table', 'roc', 'curve', 'final', 'model', 'sample', 'stratified', 'random', 'sample', 'specify', 'list', 'prior', 'probability', 'low', 'birth', 'weight', '', 'c2demo10a', '', 'option', 'label']"
521,The plot of the change in the deviance by predicted probabilities shows several observations that need to be examined. The points in the upper-left corner represent women who had low birth weight babies with very favorable covariate patterns. The points in the upper-right corner represent women who had normal weight babies with very unfavorable covariate patterns. Careful examination of these observations may lead to strategies to improve the fit of the model (Hosmer and Lemeshow 2000). Example:	Generate a bubble plot of the change in the Pearson chi-square statistic by predicted probabilities with the plotting symbol proportional to the c diagnostic statistic. Create an ActiveX graph in HTML output. /* c2demo11c */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difchisq=difchisq c=c; run;,CD,942,"['plot', 'change', 'deviance', 'predicted', 'probability', 'show', 'several', 'observation', 'need', 'examined', 'point', 'upperleft', 'corner', 'represent', 'woman', 'low', 'birth', 'weight', 'baby', 'favorable', 'covariate', 'pattern', 'point', 'upperright', 'corner', 'represent', 'woman', 'normal', 'weight', 'baby', 'unfavorable', 'covariate', 'pattern', 'careful', 'examination', 'observation', 'may', 'lead', 'strategy', 'improve', 'fit', 'model', 'hosmer', 'lemeshow', '2000', 'example\tgenerate', 'bubble', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'plotting', 'symbol', 'proportional', 'c', 'diagnostic', 'statistic', 'create', 'activex', 'graph', 'html', 'output', '', 'c2demo11c', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difchisqdifchisq', 'cc', 'run']"
522,"From the classification table you can compute sensitivity, which is the proportion of event observations (in this example low birth weight babies) that were predicted to have an event response. The formula is (true positives) / (total actual positives).",CD,253,"['classification', 'table', 'compute', 'sensitivity', 'proportion', 'event', 'observation', 'example', 'low', 'birth', 'weight', 'baby', 'predicted', 'event', 'response', 'formula', 'true', 'positive', '', 'total', 'actual', 'positive']"
523,"The graph shows that for mothers who did not visit the physician during the first trimester, the probability of a low birth weight baby increases with age. However, for mothers who did visit the physician during the first trimester, the probability of a low birth weight baby decreases with age.",CD,295,"['graph', 'show', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'increase', 'age', 'however', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'decrease', 'age']"
524,"PROC LOGISTIC estimates a separate intercept for each cumulative logit. However, PROC LOGISTIC does not estimate a separate slope for each cumulative logit, but rather a common slope across the cumulative logits for each predictor variable. This common slope is a weighted average across the logits. Therefore, a parallel-lines regression model is fitted in which each curve that describes the cumulative probabilities has the same shape. The only difference in the curves is the difference between the values of the intercept parameters. This model is called a proportional odds model.",CD,586,"['proc_logistic', 'estimate', 'separate', 'intercept', 'cumulative', 'logit', 'however', 'proc_logistic', 'doe', 'estimate', 'separate', 'slope', 'cumulative', 'logit', 'rather', 'common', 'slope', 'across', 'cumulative', 'logits', 'predictor_variable', 'common', 'slope', 'weighted', 'average', 'across', 'logits', 'therefore', 'parallellines', 'regression_model', 'fitted', 'curve', 'describes', 'cumulative', 'probability', 'ha', 'shape', 'difference', 'curve', 'difference', 'value', 'intercept', 'parameter', 'model', 'called', 'proportional', 'odds', 'model']"
525,"After the model fit has been assessed using summary statistics, it is important to identify which observations are poorly fit and which observations have a great deal of influence on the values of the estimated parameters. The LOGISTIC procedure produces a number of statistics that are designed to detect outliers and influential observations. Most of these statistics measure how much some aspect of the model changes when a particular observation is deleted. After identifying these observations, you can begin to address the role they play in the analysis.",CD,560,"['model', 'fit', 'ha', 'assessed', 'using', 'summary', 'statistic', 'important', 'identify', 'observation', 'poorly', 'fit', 'observation', 'great', 'deal', 'influence', 'value', 'estimated', 'parameter', 'logistic', 'procedure', 'produce', 'number', 'statistic', 'designed', 'detect', 'outlier', 'influential', 'observation', 'statistic', 'measure', 'much', 'aspect', 'model', 'change', 'particular', 'observation', 'deleted', 'identifying', 'observation', 'begin', 'address', 'role', 'play', 'analysis']"
526,"If the estimation of the regression coefficients is the primary objective of your study and there are a large number of clusters (approximately 200) and a small number of time points, then you should not spend much time choosing a correlation structure. If the mean model is correctly specified, the GEE method for the parameter estimates was designed to guarantee consistency of the parameter estimates under minimal assumptions about the time dependence (Diggle, Heagerty, Liang, and Zeger 2002). Furthermore, the loss of efficiency from an incorrect choice of the working correlation structure is inconsequential when the number of subjects is large (Davis 2002).",CD,666,"['estimation', 'regression', 'coefficient', 'primary', 'objective', 'study', 'large', 'number', 'cluster', 'approximately', '200', 'small', 'number', 'time', 'point', 'spend', 'much', 'time', 'choosing', 'correlation_structure', 'mean', 'model', 'correctly', 'specified', 'gee', 'method', 'parameter_estimate', 'wa', 'designed', 'guarantee', 'consistency', 'parameter_estimate', 'minimal', 'assumption', 'time', 'dependence', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'furthermore', 'loss', 'efficiency', 'incorrect', 'choice', 'working', 'correlation_structure', 'inconsequential', 'number', 'subject', 'large', 'davis', '2002']"
527,"The estimated logit plot shows no apparent pattern. Therefore, mother_age may be entered into the model as a continuous variable because creating several groups will probably not improve the fit of the model. Although it seems mother_age is not an important predictor for low birth weight, the estimated logit plot is a univariate plot that can be misleading in the presence of partial associations and interactions. A model with two-factor interactions and main effects should be evaluated before mother_age is eliminated. Estimated logit plots should never be used to eliminate variables.",CD,590,"['estimated', 'logit', 'plot', 'show', 'apparent', 'pattern', 'therefore', 'motherage', 'may', 'entered', 'model', 'continuous', 'variable', 'creating', 'several', 'group', 'probably', 'improve', 'fit', 'model', 'although', 'seems', 'motherage', 'important', 'predictor', 'low', 'birth', 'weight', 'estimated', 'logit', 'plot', 'univariate', 'plot', 'misleading', 'presence', 'partial', 'association', 'interaction', 'model', 'twofactor', 'interaction', 'main_effect', 'evaluated', 'motherage', 'eliminated', 'estimated', 'logit', 'plot', 'never', 'used', 'eliminate', 'variable']"
528,The logit plot can also show serious nonlinearities between the response variable and the predictor variable. The above graph reveals a quadratic relationship between the response and predictor variables. Adding a polynomial term or binning the predictor variable into three groups (because of the quadratic relationship) and treating it as a classification variable may improve the model fit.,CD,393,"['logit', 'plot', 'also', 'show', 'serious', 'nonlinearities', 'response_variable', 'predictor_variable', 'graph', 'reveals', 'quadratic', 'relationship', 'response', 'predictor_variable', 'adding', 'polynomial', 'term', 'binning', 'predictor_variable', 'three', 'group', 'quadratic', 'relationship', 'treating', 'classification', 'variable', 'may', 'improve', 'model', 'fit']"
529,"An estimator of a parameter is said to be median unbiased if 	 and	 The formula shows that if the probability is greater than or equal to .50 on both sides of beta, then the estimated beta is median unbiased. The median unbiased estimators (MUE) of the parameters of a logistic model can be computed from the distribution of sufficient statistics for the parameters. A Newton-Raphson-type algorithm is used to perform the search for the MUE that corresponds to the median of the conditional distribution of the sufficient statistics for the parameters. Hirji, Tsiatis, and Mehta (1989) compared the accuracy of the MUE with that of the maximum likelihood estimator (MLE) for a logistic regression model with two binary covariates. The MUE was shown to be uniformly more accurate than MLE for small to moderately large sample sizes and a broad range of parameter values. The authors recommend that median unbiased estimation be used as an alternative to maximum likelihood estimation when the data structure is sparse.",CD,1017,"['estimator', 'parameter', 'said', 'median', 'unbiased', '\t', 'and\t', 'formula', 'show', 'probability', 'greater', 'equal', '50', 'side', 'beta', 'estimated', 'beta', 'median', 'unbiased', 'median', 'unbiased', 'estimator', 'mue', 'parameter', 'logistic', 'model', 'computed', 'distribution', 'sufficient', 'statistic', 'parameter', 'newtonraphsontype', 'algorithm', 'used', 'perform', 'search', 'mue', 'corresponds', 'median', 'conditional', 'distribution', 'sufficient', 'statistic', 'parameter', 'hirji', 'tsiatis', 'mehta', '1989', 'compared', 'accuracy', 'mue', 'maximum', 'likelihood', 'estimator', 'mle', 'logistic_regression_model', 'two', 'binary', 'covariates', 'mue', 'wa', 'shown', 'uniformly', 'accurate', 'mle', 'small', 'moderately', 'large', 'sample_size', 'broad', 'range', 'parameter', 'value', 'author', 'recommend', 'median', 'unbiased', 'estimation', 'used', 'alternative', 'maximum', 'likelihood', 'estimation', 'data', 'structure', 'sparse']"
530,where is the diagonal elements of the hat matrix and is the change in the Pearson chi- square due to the deleted observation. The formula illustrates that the c diagnostic statistic can be large due to either lack-of-fit (large difchisq) or high leverage (large hat diagonal). Regression Diagnostics,CD,299,"['diagonal', 'element', 'hat', 'matrix', 'change', 'pearson', 'chi', 'square', 'due', 'deleted', 'observation', 'formula', 'illustrates', 'c', 'diagnostic', 'statistic', 'large', 'due', 'either', 'lackoffit', 'large', 'difchisq', 'high', 'leverage', 'large', 'hat', 'diagonal', 'regression', 'diagnostics']"
531,"In the univariate analysis of the data, it is important to document, for each predictor variable, whether an association exists with the response variable and the strength of the association. For binary predictor variables, the confidence bounds around the odds ratio would indicate whether an association exists. If the confidence interval does not include 1, then there is evidence that there is an association. For ordinal predictors, the Mantel-Haenszel chi-square could be used. For nominal predictors, the mean score statistic would be helpful (Stokes, Davis, and Koch 2000). ?	Binary variables can be considered ordinal variables.",CD,637,"['univariate', 'analysis', 'data', 'important', 'document', 'predictor_variable', 'whether', 'association', 'exists', 'response_variable', 'strength', 'association', 'binary', 'predictor_variable', 'confidence', 'bound', 'around', 'odds_ratio', 'would', 'indicate', 'whether', 'association', 'exists', 'confidence', 'interval', 'doe', 'include', '1', 'evidence', 'association', 'ordinal', 'predictor', 'mantelhaenszel', 'chisquare', 'could', 'used', 'nominal', 'predictor', 'mean', 'score', 'statistic', 'would', 'helpful', 'stokes', 'davis', 'koch', '2000', '\tbinary', 'variable', 'considered', 'ordinal', 'variable']"
532,"The variables that are significant at the 0.05 significance level are smoking status, previous preterm delivery, presence of uterine irritability, and history of hypertension. Analysis of Maximum Likelihood Estimates",CD,216,"['variable', 'significant', '005', 'significance', 'level', 'smoking', 'status', 'previous', 'preterm', 'delivery', 'presence', 'uterine', 'irritability', 'history', 'hypertension', 'analysis', 'maximum', 'likelihood', 'estimate']"
533,"One solution to the incidental parameters problem is to use conditional maximum likelihood estimation. This approach eliminates the stratum-specific intercepts from the likelihood by conditioning on their sufficient statistics (just like the approach in exact logistic regression). Recall that a sufficient statistic for the intercept is simply the sum of the events. By deriving a conditional likelihood that is conditional on the sufficient statistics of the stratum-specific intercepts, you are factoring out the intercepts from the likelihood equation. In other words, you are taking the stratification into account by conditioning out (and not estimating) the stratum-specific intercepts. You are essentially modeling a meaningful conditional probability, and the model has a reduced number of parameters that can be estimated without bias. A conditional likelihood is just like an ordinary likelihood. Conditional maximum likelihood estimates are those values that maximize the conditional likelihood function. The estimates are consistent and asymptotically normal. The optimization techniques used to obtain the maximum likelihood estimates are Newton-Raphson with ridging when the number of parameters is less than 40, quasi-Newton when the number of parameters is 40-399, and conjugate gradient when the number of parameters is 400 or greater. Sometimes the log likelihood converges but the estimates diverge. This condition is flagged by having inordinately large standard errors for some of your parameter estimates. It may be possible to circumvent this problem by standardizing the predictor variables before fitting the model.",CD,1641,"['one', 'solution', 'incidental', 'parameter', 'problem', 'use', 'conditional', 'maximum', 'likelihood', 'estimation', 'approach', 'eliminates', 'stratumspecific', 'intercept', 'likelihood', 'conditioning', 'sufficient', 'statistic', 'like', 'approach', 'exact', 'logistic_regression', 'recall', 'sufficient', 'statistic', 'intercept', 'simply', 'sum', 'event', 'deriving', 'conditional', 'likelihood', 'conditional', 'sufficient', 'statistic', 'stratumspecific', 'intercept', 'factoring', 'intercept', 'likelihood', 'equation', 'word', 'taking', 'stratification', 'account', 'conditioning', 'estimating', 'stratumspecific', 'intercept', 'essentially', 'modeling', 'meaningful', 'conditional', 'probability', 'model', 'ha', 'reduced', 'number', 'parameter', 'estimated', 'without', 'bias', 'conditional', 'likelihood', 'like', 'ordinary', 'likelihood', 'conditional', 'maximum', 'likelihood', 'estimate', 'value', 'maximize', 'conditional', 'likelihood', 'function', 'estimate', 'consistent', 'asymptotically', 'normal', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'estimate', 'newtonraphson', 'ridging', 'number', 'parameter', 'le', '40', 'quasinewton', 'number', 'parameter', '40399', 'conjugate', 'gradient', 'number', 'parameter', '400', 'greater', 'sometimes', 'log', 'likelihood', 'converges', 'estimate', 'diverge', 'condition', 'flagged', 'inordinately', 'large', 'standard_error', 'parameter_estimate', 'may', 'possible', 'circumvent', 'problem', 'standardizing', 'predictor_variable', 'fitting', 'model']"
534,"TABLES	requests one-way to n-way frequency and crosstabulation tables and statistics for those tables. You can use multiple TABLES statements in the PROC FREQ step. EXACT	requests exact tests or confidence limits for the specified statistics. PROC FREQ also computes Monte Carlo estimates of the exact p-values. The statistic options specify the statistics for which to provide exact tests or confidence limits. The computation options specify options for the computation of exact statistics. TEST	requests asymptotic tests for the specified measures of association and measures of agreement. You must use a TABLES statement with the TEST statement. For each measure of association or agreement that you specify, the TEST statement provides an asymptotic test that the measure equals zero. OUTPUT	creates a SAS data set containing statistics computed by PROC FREQ. Only one OUTPUT statement is allowed for each execution of PROC FREQ. You must specify a TABLES statement with the OUTPUT statement. ?	Exact tests are appropriate when a data set is small, sparse, skewed, or heavily tied. For some large problems, computation of exact tests may require a large amount of time and memory. Consider using asymptotic tests for such problems. Alternatively, when asymptotic methods may not be sufficient for such large problems, consider using Monte Carlo estimation of exact p-values.",CD,1379,"['tables\trequests', 'oneway', 'nway', 'frequency', 'crosstabulation', 'table', 'statistic', 'table', 'use', 'multiple', 'table', 'statement', 'proc', 'freq', 'step', 'exact\trequests', 'exact', 'test', 'confidence', 'limit', 'specified', 'statistic', 'proc', 'freq', 'also', 'computes', 'monte', 'carlo', 'estimate', 'exact', 'pvalues', 'statistic', 'option', 'specify', 'statistic', 'provide', 'exact', 'test', 'confidence', 'limit', 'computation', 'option', 'specify', 'option', 'computation', 'exact', 'statistic', 'test\trequests', 'asymptotic', 'test', 'specified', 'measure', 'association', 'measure', 'agreement', 'must', 'use', 'table', 'statement', 'test', 'statement', 'measure', 'association', 'agreement', 'specify', 'test', 'statement', 'provides', 'asymptotic', 'test', 'measure', 'equal', 'zero', 'output\tcreates', 'sa', 'data_set', 'containing', 'statistic', 'computed', 'proc', 'freq', 'one', 'output', 'statement', 'allowed', 'execution', 'proc', 'freq', 'must', 'specify', 'table', 'statement', 'output', 'statement', '\texact', 'test', 'appropriate', 'data_set', 'small', 'sparse', 'skewed', 'heavily', 'tied', 'large', 'problem', 'computation', 'exact', 'test', 'may', 'require', 'large', 'amount', 'time', 'memory', 'consider', 'using', 'asymptotic', 'test', 'problem', 'alternatively', 'asymptotic', 'method', 'may', 'sufficient', 'large', 'problem', 'consider', 'using', 'monte', 'carlo', 'estimation', 'exact', 'pvalues']"
535,"The odds ratio for bending indicates that women who say that bending aggravates their back pain have 2.4 times the odds to be in a higher severity level of back pain than women who say that bending does not aggravate their back pain. Because the confidence bounds do not include 1.0, the odds ratio is significant at the 0.05 significance level. Association of Predicted Probabilities and Observed Responses",CD,407,"['odds_ratio', 'bending', 'indicates', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '24', 'time', 'odds', 'higher', 'severity', 'level', 'back', 'pain', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain', 'confidence', 'bound', 'include', '10', 'odds_ratio', 'significant', '005', 'significance', 'level', 'association', 'predicted', 'probability', 'observed', 'response']"
536,"Convergence problems are also caused by complete separation. This occurs when some linear combination of the predictor variables perfectly predicts the response variable. The net result is infinite parameter estimates. In order to have finite maximum likelihood estimates, there must be some overlap in the distribution of the predictor variables in the model. The diagram above shows that the continuous predictor age perfectly separates the response. Thus age is a perfect predictor of the response.",CD,501,"['convergence', 'problem', 'also', 'caused', 'complete', 'separation', 'occurs', 'linear', 'combination', 'predictor_variable', 'perfectly', 'predicts', 'response_variable', 'net', 'result', 'infinite', 'parameter_estimate', 'order', 'finite', 'maximum', 'likelihood', 'estimate', 'must', 'overlap', 'distribution', 'predictor_variable', 'model', 'diagram', 'show', 'continuous', 'predictor', 'age', 'perfectly', 'separate', 'response', 'thus', 'age', 'perfect', 'predictor', 'response']"
537,"The first section of the output describes the data set, the response variable, the number of response levels, the type of model, the algorithm used to obtain the parameter estimates, and the number of observations read and used. The Response Profile table shows the response variable values listed according to their ordered values. By default, PROC LOGISTIC orders the response variable alphanumerically so that it bases the logistic regression model on the probability of the smallest value. Because you used the EVENT=option, in this example, the model is based on the probability of low birth weight (low=1). The Response Profile table also shows the value of the response variable and the frequency. The class level information shows that socio was dummy coded into two design variables. Because you used the PARAM=REF and REF='3' options, this table reflects your choice of socio=3 as the reference level. Model Fit Statistics",CD,932,"['first', 'section', 'output', 'describes', 'data_set', 'response_variable', 'number', 'response', 'level', 'type', 'model', 'algorithm', 'used', 'obtain', 'parameter_estimate', 'number', 'observation', 'read', 'used', 'response', 'profile', 'table', 'show', 'response_variable', 'value', 'listed', 'according', 'ordered', 'value', 'default', 'proc_logistic', 'order', 'response_variable', 'alphanumerically', 'base', 'logistic_regression_model', 'probability', 'smallest', 'value', 'used', 'eventoption', 'example', 'model', 'based', 'probability', 'low', 'birth', 'weight', 'low1', 'response', 'profile', 'table', 'also', 'show', 'value', 'response_variable', 'frequency', 'class', 'level', 'information', 'show', 'socio', 'wa', 'dummy', 'coded', 'two', 'design', 'variable', 'used', 'paramref', 'ref3', 'option', 'table', 'reflects', 'choice', 'socio3', 'reference', 'level', 'model', 'fit', 'statistic']"
538,"Correlation Structure Unstructured Subject Effect case (537 levels) Number of Clusters 537 Correlation Matrix Dimension 4 Maximum Cluster Size 4 Minimum Cluster Size 4 Algorithm converged. The GEE Model Information table displays information about the model fit with GEEs. Because TYPE=UNSTR option is requested, the unstructured correlation structure is used. Furthermore, because there are 537 children, there are 537 clusters. Notice there are no missing data values. Working Correlation Matrix",CD,497,"['correlation_structure', 'unstructured', 'subject', 'effect', 'case', '537', 'level', 'number', 'cluster', '537', 'correlation', 'matrix', 'dimension', '4', 'maximum', 'cluster', 'size', '4', 'minimum', 'cluster', 'size', '4', 'algorithm', 'converged', 'gee', 'model', 'information', 'table', 'display', 'information', 'model', 'fit', 'gee', 'typeunstr', 'option', 'requested', 'unstructured', 'correlation_structure', 'used', 'furthermore', '537', 'child', '537', 'cluster', 'notice', 'missing', 'data', 'value', 'working', 'correlation', 'matrix']"
539,"After you have formulated the final model, you need to assess how well it fits the data. In other words, you need to assess how close the model-predicted values are to the corresponding observed values. Test statistics that assess the fit of the model are called goodness-of-fit statistics. If departures of the predicted values from the observed values are essentially random, then the goodness-of-fit statistics are not statistically significant. Some of the problems that can cause the goodness-of-fit statistics to be statistically significant are having outliers in the data, omitting important terms in the model such as interactions, needing to transform some predictor variables, having a nonlinear relationship between the logits and a predictor variable, and having a model that has greater variability than predicted by the random component of the model. This latter problem is also known as overdispersion, and it occurs when the assumption of binomial variability may not be valid. These problems should be examined before proceeding to use methods to correct for overdispersion (SAS Institute Inc. 1995). Another problem with logistic regression, as in linear regression, is multicollinearity. This occurs when there are strong linear dependencies among the predictor variables. Although multicollinearity does not bias the parameter estimates, it does increase their variances, which results in less precise estimates of the parameters (Allison 1999). There are no multicollinearity diagnostics in the LOGISTIC procedure. However, you can use the diagnostics in the REG procedure because multicollinearity only deals with the predictor variables, not the outcome variable. Some of the options in the MODEL statement in PROC REG include TOL, VIF, COLLIN, and COLLINOINT. In most cases, serious multicollinearity will be detected. In rare instances you may fail to detect the problem because the linear combinations should actually be adjusted by the weight matrix used in the maximum likelihood algorithm (Allison 1999).",CD,2034,"['formulated', 'final', 'model', 'need', 'ass', 'well', 'fit', 'data', 'word', 'need', 'ass', 'close', 'modelpredicted', 'value', 'corresponding', 'observed', 'value', 'test', 'statistic', 'ass', 'fit', 'model', 'called', 'goodnessoffit', 'statistic', 'departure', 'predicted', 'value', 'observed', 'value', 'essentially', 'random', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'problem', 'cause', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'outlier', 'data', 'omitting', 'important', 'term', 'model', 'interaction', 'needing', 'transform', 'predictor_variable', 'nonlinear', 'relationship', 'logits', 'predictor_variable', 'model', 'ha', 'greater', 'variability', 'predicted', 'random', 'component', 'model', 'latter', 'problem', 'also', 'known', 'overdispersion', 'occurs', 'assumption', 'binomial', 'variability', 'may', 'valid', 'problem', 'examined', 'proceeding', 'use', 'method', 'correct', 'overdispersion', 'sa', 'institute', 'inc', '1995', 'another', 'problem', 'logistic_regression', 'linear', 'regression', 'multicollinearity', 'occurs', 'strong', 'linear', 'dependency', 'among', 'predictor_variable', 'although', 'multicollinearity', 'doe', 'bias', 'parameter_estimate', 'doe', 'increase', 'variance', 'result', 'le', 'precise', 'estimate', 'parameter', 'allison', '1999', 'multicollinearity', 'diagnostics', 'logistic', 'procedure', 'however', 'use', 'diagnostics', 'reg', 'procedure', 'multicollinearity', 'deal', 'predictor_variable', 'outcome', 'variable', 'option', 'model_statement', 'proc', 'reg', 'include', 'tol', 'vif', 'collin', 'collinoint', 'case', 'serious', 'multicollinearity', 'detected', 'rare', 'instance', 'may', 'fail', 'detect', 'problem', 'linear', 'combination', 'actually', 'adjusted', 'weight', 'matrix', 'used', 'maximum', 'likelihood', 'algorithm', 'allison', '1999']"
540,"The routine use of matching is seldom justified (Rothman 1986). For example, if matching does not improve study efficiency, then the effort expended in finding matched subjects would have been better spent in gathering information for a greater number of unmatched subjects. Furthermore, matching does not prevent confounding but rather introduces confounding. Therefore, it is recommended to use an analysis that removes the confounding by the matching factors since matching might cause confounding even when none existed. Finally, matching might lead to overmatching which will increase the number of uninformative strata and decrease study efficiency. For example, matching on a variable that has a strong correlation with an important exposure variable and that has no relation to the outcome might lead to overmatching because it will lead to relatively few informative strata with no offsetting gain (Rothman 1986). Kleinbaum (1991) recommends that the safest strategy is to match only on strong risk factors expected to cause confounding in the data.",CD,1058,"['routine', 'use', 'matching', 'seldom', 'justified', 'rothman', '1986', 'example', 'matching', 'doe', 'improve', 'study', 'efficiency', 'effort', 'expended', 'finding', 'matched', 'subject', 'would', 'better', 'spent', 'gathering', 'information', 'greater', 'number', 'unmatched', 'subject', 'furthermore', 'matching', 'doe', 'prevent', 'confounding', 'rather', 'introduces', 'confounding', 'therefore', 'recommended', 'use', 'analysis', 'remove', 'confounding', 'matching', 'factor', 'since', 'matching', 'might', 'cause', 'confounding', 'even', 'none', 'existed', 'finally', 'matching', 'might', 'lead', 'overmatching', 'increase', 'number', 'uninformative', 'stratum', 'decrease', 'study', 'efficiency', 'example', 'matching', 'variable', 'ha', 'strong', 'correlation', 'important', 'exposure', 'variable', 'ha', 'relation', 'outcome', 'might', 'lead', 'overmatching', 'lead', 'relatively', 'informative', 'stratum', 'offsetting', 'gain', 'rothman', '1986', 'kleinbaum', '1991', 'recommends', 'safest', 'strategy', 'match', 'strong', 'risk', 'factor', 'expected', 'cause', 'confounding', 'data']"
541,"The problem of biasing the inferences can be avoided by prespecifying the model. When you have a large number of variables, however, prespecifying the model is not feasible. Therefore, analysts use the results of the model selection techniques (usually the p-values for the predictor variables) to select a model. However, the p-values calculated in the model selection techniques are not p-values in the traditional hypothesis-testing context. Instead, they should be viewed as indicators of relative importance among variables (Hosmer and Lemeshow 2000). Because the biased p-values overstate the significance of the predictor variables, the traditional cutoff of .05 is not very useful unless the sample size is small (30-50). For large sample sizes, much smaller p-values are required to imply that the data provide evidence for the effect of interest. The slide above provides approximate two-sided p-values corresponding to different grades of evidence for tests involving one additional parameter (one degree of freedom). Significance levels for tests involving more than one degree of freedom would even be lower, especially for the larger sample sizes (Raftery 1994).",CD,1176,"['problem', 'biasing', 'inference', 'avoided', 'prespecifying', 'model', 'large', 'number', 'variable', 'however', 'prespecifying', 'model', 'feasible', 'therefore', 'analyst', 'use', 'result', 'model', 'selection', 'technique', 'usually', 'pvalues', 'predictor_variable', 'select', 'model', 'however', 'pvalues', 'calculated', 'model', 'selection', 'technique', 'pvalues', 'traditional', 'hypothesistesting', 'context', 'instead', 'viewed', 'indicator', 'relative', 'importance', 'among', 'variable', 'hosmer', 'lemeshow', '2000', 'biased', 'pvalues', 'overstate', 'significance', 'predictor_variable', 'traditional', 'cutoff', '05', 'useful', 'unless', 'sample_size', 'small', '3050', 'large', 'sample_size', 'much', 'smaller', 'pvalues', 'required', 'imply', 'data', 'provide', 'evidence', 'effect', 'interest', 'slide', 'provides', 'approximate', 'twosided', 'pvalues', 'corresponding', 'different', 'grade', 'evidence', 'test', 'involving', 'one', 'additional', 'parameter', 'one', 'degree', 'freedom', 'significance', 'level', 'test', 'involving', 'one', 'degree', 'freedom', 'would', 'even', 'lower', 'especially', 'larger', 'sample_size', 'raftery', '1994']"
542,The chi-square test of association indicates that there is strong evidence of an association between previous preterm deliveries and low birth weight for women with no uterine irritability. Statistics for Table 1 of prev_pretrm by low Controlling for uterine_irr=0,CD,264,"['chisquare', 'test', 'association', 'indicates', 'strong', 'evidence', 'association', 'previous', 'preterm', 'delivery', 'low', 'birth', 'weight', 'woman', 'uterine', 'irritability', 'statistic', 'table', '1', 'prevpretrm', 'low', 'controlling', 'uterineirr0']"
543,"For time-dependent predictor variables (variables whose values change within cluster or across time) ignoring positive correlation leads to variance estimates that are too large. In other words, the Type II error rates (failing to reject the null hypothesis when it is false, also know as, a false negative) are inflated for these variables (Dunlop 1994). Because the variances of the group effects will be underestimated and the variance of the time effects will be overestimated if positive correlation is ignored, it is evident that correlated outcomes must be addressed to obtain valid analyses.",CD,599,"['timedependent', 'predictor_variable', 'variable', 'whose', 'value', 'change', 'within', 'cluster', 'across', 'time', 'ignoring', 'positive', 'correlation', 'lead', 'variance', 'estimate', 'large', 'word', 'type', 'ii', 'error', 'rate', 'failing', 'reject', 'null', 'hypothesis', 'false', 'also', 'know', 'false', 'negative', 'inflated', 'variable', 'dunlop', '1994', 'variance', 'group', 'effect', 'underestimated', 'variance', 'time', 'effect', 'overestimated', 'positive', 'correlation', 'ignored', 'evident', 'correlated', 'outcome', 'must', 'addressed', 'obtain', 'valid', 'analysis']"
544,"Before building a multivariate model, the analyst should perform an exploratory data analysis with contingency tables and logit plots. Contingency table analysis may detect confounders and interactions. Confounders are variables that are associated with both the response variable and a primary predictor variable. When confounding is present, the estimate of the effect of the primary predictor variable to the response is distorted because it is mixed with the effect of the confounder or extraneous variable. Identifying confounders may help the analyst gain an understanding of the relationships among the variables and may help the analyst build a better multivariate model (Rothman 1986). The next two graphs illustrate the concept of confounding. It can be seen that there is a large difference in the log odds of the response between males (Y1) and females (Y2). However, a large portion of this difference may be due to differences in the age of the groups. Therefore, it may not be possible to determine the effect of gender without first eliminating the discrepancy in age.",CD,1084,"['building', 'multivariate', 'model', 'analyst', 'perform', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'contingency', 'table', 'analysis', 'may', 'detect', 'confounders', 'interaction', 'confounders', 'variable', 'associated', 'response_variable', 'primary', 'predictor_variable', 'confounding', 'present', 'estimate', 'effect', 'primary', 'predictor_variable', 'response', 'distorted', 'mixed', 'effect', 'confounder', 'extraneous', 'variable', 'identifying', 'confounders', 'may', 'help', 'analyst', 'gain', 'understanding', 'relationship', 'among', 'variable', 'may', 'help', 'analyst', 'build', 'better', 'multivariate', 'model', 'rothman', '1986', 'next', 'two', 'graph', 'illustrate', 'concept', 'confounding', 'seen', 'large', 'difference', 'log', 'odds', 'response', 'male', 'y1', 'female', 'y2', 'however', 'large', 'portion', 'difference', 'may', 'due', 'difference', 'age', 'group', 'therefore', 'may', 'possible', 'determine', 'effect', 'gender', 'without', 'first', 'eliminating', 'discrepancy', 'age']"
545,The logit plot can also show serious nonlinearities between the response variable and the predictor variable. The above graph reveals a quadratic relationship between the response and predictor variables. Adding a polynomial term or binning the predictor variable into three groups (because of the quadratic relationship) and treating it as a classification variable may improve the model fit.,CD,393,"['logit', 'plot', 'also', 'show', 'serious', 'nonlinearities', 'response_variable', 'predictor_variable', 'graph', 'reveals', 'quadratic', 'relationship', 'response', 'predictor_variable', 'adding', 'polynomial', 'term', 'binning', 'predictor_variable', 'three', 'group', 'quadratic', 'relationship', 'treating', 'classification', 'variable', 'may', 'improve', 'model', 'fit']"
546,"After an extensive univariate and stratified data analysis, the above variables were identified as potential confounders. The criterion was a big difference between the crude odds ratio of the main effect and the adjusted odds ratio. For example, the crude odds ratio for history of hypertension is 3.365 and the odds ratio adjusted for mother?s weight is 6.435. Therefore, to obtain an accurate, unconfounded effect of history of hypertension, mother?s weight should be in the model.",CD,484,"['extensive', 'univariate', 'stratified', 'data', 'analysis', 'variable', 'identified', 'potential', 'confounders', 'criterion', 'wa', 'big', 'difference', 'crude', 'odds_ratio', 'main_effect', 'adjusted', 'odds_ratio', 'example', 'crude', 'odds_ratio', 'history', 'hypertension', '3365', 'odds_ratio', 'adjusted', 'mother', 'weight', '6435', 'therefore', 'obtain', 'accurate', 'unconfounded', 'effect', 'history', 'hypertension', 'mother', 'weight', 'model']"
547,"The independent correlation structure (TYPE=IND) forces the off-diagonals to be 0. Therefore, no working correlation structure is estimated in this case. Under this constraint, the coefficients and model-based standard errors (requested by the MODELSE option in the REPEATED statement) are the same as those reported in the LOGISTIC procedure. However, PROC GENMOD, by default, computes robust standard error estimates. These estimates take into account the correlations among the repeated measurements and usually are different from the model-based standard errors assuming independence. The independent correlation structure might be a good choice when you have a large number of subjects with few measurements per subject. The correlation influence is often small enough to have little impact on the regression coefficients, but the robust standard errors will give the correct inferences. This model gives consistent estimates of the parameters and standard errors when the mean model is correctly specified (Davis 2002).",CD,1025,"['independent', 'correlation_structure', 'typeind', 'force', 'offdiagonals', '0', 'therefore', 'working', 'correlation_structure', 'estimated', 'case', 'constraint', 'coefficient', 'modelbased', 'standard_error', 'requested', 'modelse', 'option', 'repeated', 'statement', 'reported', 'logistic', 'procedure', 'however', 'proc', 'genmod', 'default', 'computes', 'robust', 'standard_error', 'estimate', 'estimate', 'take', 'account', 'correlation', 'among', 'repeated', 'measurement', 'usually', 'different', 'modelbased', 'standard_error', 'assuming', 'independence', 'independent', 'correlation_structure', 'might', 'good', 'choice', 'large', 'number', 'subject', 'measurement', 'per', 'subject', 'correlation', 'influence', 'often', 'small', 'enough', 'little', 'impact', 'regression', 'coefficient', 'robust', 'standard_error', 'give', 'correct', 'inference', 'model', 'give', 'consistent', 'estimate', 'parameter', 'standard_error', 'mean', 'model', 'correctly', 'specified', 'davis', '2002']"
548,"Because the response variable (painseverity) is an ordinal variable, you should analyze it as an ordinal variable. Do not dichotomize the outcome variable because that would lower the power of your hypothesis tests, especially the Wald tests for the parameter estimates of your predictor variables (Allison 1999). In some situations with a continuous outcome, there is a restricted range of values because of the limitations of the measuring techniques. This is a common feature in bioassay analyses. With restricted ranges, there is usually a lower limit of quantification (LOQ) and an upper limit of quantification. For example, suppose that the response variable had a lower LOQ of 300 and the upper LOQ of 900. Analyzing the response variable as continuous might not be optimal given the truncated nature of the distribution. An alternative way to analyze a continuous variable with a restricted range is to create ordered categories and fit an ordinal logistic regression model.",CD,983,"['response_variable', 'painseverity', 'ordinal', 'variable', 'analyze', 'ordinal', 'variable', 'dichotomize', 'outcome', 'variable', 'would', 'lower', 'power', 'hypothesis', 'test', 'especially', 'wald', 'test', 'parameter_estimate', 'predictor_variable', 'allison', '1999', 'situation', 'continuous', 'outcome', 'restricted', 'range', 'value', 'limitation', 'measuring', 'technique', 'common', 'feature', 'bioassay', 'analysis', 'restricted', 'range', 'usually', 'lower', 'limit', 'quantification', 'loq', 'upper', 'limit', 'quantification', 'example', 'suppose', 'response_variable', 'lower', 'loq', '300', 'upper', 'loq', '900', 'analyzing', 'response_variable', 'continuous', 'might', 'optimal', 'given', 'truncated', 'nature', 'distribution', 'alternative', 'way', 'analyze', 'continuous', 'variable', 'restricted', 'range', 'create', 'ordered', 'category', 'fit', 'ordinal', 'logistic_regression_model']"
549,"Example:	Fit a GEE model on the wheezing data and specify the probability of wheezing as the response of interest, the unstructured correlation structure, reference cell coding for smoker with No as the reference cell, and request the Type 3 score statistics, the final working correlation matrix, and the model-based standard errors. Also compute the odds ratio comparing smokers to non-smokers and a one-year decrease in age. /* c3demo13a */ proc genmod data=sasuser.wheeze desc; class case smoker(param=ref ref='No'); model wheeze = smoker age / dist=bin type3; repeated subject = case / corrw modelse type=unstr; estimate 'smoking' smoker 1 / exp; estimate 'age' age -1 / exp; title 'GEE Model of Wheezing among Children'; run; Selected PROC GENMOD statement option: DESC	reverses the sort order for the levels of the outcome variable. Selected CLASS statement options: PARAM= 	specifies the parameterization method for the classification variable or variables. The default is PARAM=GLM. REF=	specifies the reference level for PARAM=EFFECT, PARAM=REF, and their orthogonalizations. For an individual variable, you can specify the level of the variable to use as the reference level. For a global or individual variable, you can use one of the following keywords: 	FIRST	designates the first ordered level as the reference. 	LAST	designates the last ordered level as the reference. This is the default. Selected MODEL statement options: DIST= 	specifies the built-in probability distribution to use in the model. The default link function for the binomial distribution is the logit link function. TYPE3	requests that Type 3 score statistics be computed for each effect that is specified in the MODEL statement. Likelihood ratio statistics are produced for models that are not GEE models. Selected REPEATED statement options: CORRW	specifies that the final working correlation matrix be printed. MODELSE	displays an analysis of parameter estimates table using model-based standard errors. Selected ESTIMATE statement option: EXP	requests that the exponentiated contrast, its standard error, and the confidence bounds be computed. ?	If the repeated measurements are not in the proper order or if there are missing time points for some subjects, then the WITHIN= option in the REPEATED statement should be used. This option names a variable that specifies the order of measurements within subjects. Variables used in the WITHIN= option must also be listed in the CLASS statement. !	In SAS 9.1, you get an invalid reference level error if REF=?level? is used for two or more variables. The solution is to use REF=FIRST or REF=LAST for binary variables. This problem has been fixed in SAS 9.2. GEE Model of Wheezing among Children",CD,2728,"['example\tfit', 'gee', 'model', 'wheezing', 'data', 'specify', 'probability', 'wheezing', 'response', 'interest', 'unstructured', 'correlation_structure', 'reference', 'cell', 'coding', 'smoker', 'reference', 'cell', 'request', 'type', '3', 'score', 'statistic', 'final', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'also', 'compute', 'odds_ratio', 'comparing', 'smoker', 'nonsmoker', 'oneyear', 'decrease', 'age', '', 'c3demo13a', '', 'proc', 'genmod', 'datasasuserwheeze', 'desc', 'class', 'case', 'smokerparamref', 'refno', 'model', 'wheeze', '', 'smoker', 'age', '', 'distbin', 'type3', 'repeated', 'subject', '', 'case', '', 'corrw', 'modelse', 'typeunstr', 'estimate', 'smoking', 'smoker', '1', '', 'exp', 'estimate', 'age', 'age', '1', '', 'exp', 'title', 'gee', 'model', 'wheezing', 'among', 'child', 'run', 'selected', 'proc', 'genmod', 'statement', 'option', 'desc\treverses', 'sort', 'order', 'level', 'outcome', 'variable', 'selected', 'class', 'statement', 'option', 'param', '\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'default', 'paramglm', 'ref\tspecifies', 'reference', 'level', 'parameffect', 'paramref', 'orthogonalizations', 'individual', 'variable', 'specify', 'level', 'variable', 'use', 'reference', 'level', 'global', 'individual', 'variable', 'use', 'one', 'following', 'keywords', '\tfirst\tdesignates', 'first', 'ordered', 'level', 'reference', '\tlast\tdesignates', 'last', 'ordered', 'level', 'reference', 'default', 'selected', 'model_statement', 'option', 'dist', '\tspecifies', 'builtin', 'probability', 'distribution', 'use', 'model', 'default', 'link', 'function', 'binomial', 'distribution', 'logit', 'link', 'function', 'type3\trequests', 'type', '3', 'score', 'statistic', 'computed', 'effect', 'specified', 'model_statement', 'likelihood', 'ratio', 'statistic', 'produced', 'model', 'gee', 'model', 'selected', 'repeated', 'statement', 'option', 'corrw\tspecifies', 'final', 'working', 'correlation', 'matrix', 'printed', 'modelse\tdisplays', 'analysis', 'parameter_estimate', 'table', 'using', 'modelbased', 'standard_error', 'selected', 'estimate', 'statement', 'option', 'exp\trequests', 'exponentiated', 'contrast', 'standard_error', 'confidence', 'bound', 'computed', '\tif', 'repeated', 'measurement', 'proper', 'order', 'missing', 'time', 'point', 'subject', 'within', 'option', 'repeated', 'statement', 'used', 'option', 'name', 'variable', 'specifies', 'order', 'measurement', 'within', 'subject', 'variable', 'used', 'within', 'option', 'must', 'also', 'listed', 'class', 'statement', '\tin', 'sa', '91', 'get', 'invalid', 'reference', 'level', 'error', 'reflevel', 'used', 'two', 'variable', 'solution', 'use', 'reffirst', 'reflast', 'binary', 'variable', 'problem', 'ha', 'fixed', 'sa', '92', 'gee', 'model', 'wheezing', 'among', 'child']"
550,Example:	Fit a simple ordinal logistic regression model to the backache data set. Specify painseverity as the response variable and bending as the predictor variable. Also specify the DESCENDING option to reverse the sort order of the response variable. /* c3demo14a */ proc logistic data=sasuser.backache desc; model painseverity=bending; title 'Ordinal Logistic Regression Model for the Backache ' 'Example'; run; PROC LOGISTIC statement option: DESC	reverses the sorting order for the levels of the response variable. This option has the same effect as the response variable option DESCENDING in the MODEL statement. Ordinal Logistic Regression Model for the Backache Example,CD,678,"['example\tfit', 'simple', 'ordinal', 'logistic_regression_model', 'backache', 'data_set', 'specify', 'painseverity', 'response_variable', 'bending', 'predictor_variable', 'also', 'specify', 'descending', 'option', 'reverse', 'sort', 'order', 'response_variable', '', 'c3demo14a', '', 'proc_logistic', 'datasasuserbackache', 'desc', 'model', 'painseveritybending', 'title', 'ordinal', 'logistic_regression_model', 'backache', '', 'example', 'run', 'proc_logistic', 'statement', 'option', 'desc\treverses', 'sorting', 'order', 'level', 'response_variable', 'option', 'ha', 'effect', 'response_variable', 'option', 'descending', 'model_statement', 'ordinal', 'logistic_regression_model', 'backache', 'example']"
551,"In Chapter 1, you saw how the quasi-complete separation of data points leads to convergence problems in logistic regression. In the example above, level B is a perfect predictor of the outcome. In this situation, the log-likelihood function cannot be maximized but approaches a finite upper bound as the parameter estimate for B goes to negative infinity. You cannot evaluate the first and second derivatives of the log-likelihood at the maximum likelihood estimates, and it is not possible to estimate the parameter estimate for the contrast of level B to C or its confidence interval by conventional maximum likelihood methods. However, exact inference is possible and can provide valid inferences in this situation. Notice that the contrast of level B to C had a p-value approaching 1 with the asymptotic methods but is statistically significant with the exact methods. Note that the exact tests do not produce standard errors for the estimates. Furthermore, the parameter estimate for the contrast of level B to C is a median unbiased estimate, which will be discussed later. ?	In SAS 9.2 PROC LOGISTIC will compute standard errors for the exact estimates.",CD,1160,"['chapter', '1', 'saw', 'quasicomplete', 'separation', 'data', 'point', 'lead', 'convergence', 'problem', 'logistic_regression', 'example', 'level', 'b', 'perfect', 'predictor', 'outcome', 'situation', 'loglikelihood', 'function', 'cannot', 'maximized', 'approach', 'finite', 'upper', 'bound', 'parameter_estimate', 'b', 'go', 'negative', 'infinity', 'cannot', 'evaluate', 'first', 'second', 'derivative', 'loglikelihood', 'maximum', 'likelihood', 'estimate', 'possible', 'estimate', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'confidence', 'interval', 'conventional', 'maximum', 'likelihood', 'method', 'however', 'exact', 'inference', 'possible', 'provide', 'valid', 'inference', 'situation', 'notice', 'contrast', 'level', 'b', 'c', 'pvalue', 'approaching', '1', 'asymptotic', 'method', 'statistically', 'significant', 'exact', 'method', 'note', 'exact', 'test', 'produce', 'standard_error', 'estimate', 'furthermore', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'median', 'unbiased', 'estimate', 'discussed', 'later', '\tin', 'sa', '92', 'proc_logistic', 'compute', 'standard_error', 'exact', 'estimate']"
552,"Forward selection starts with an empty model. The method computes an adjusted chi-square statistic for each predictor variable not in the model and examines the largest of these statistics. If it is significant at a specified significance level (specified by the SLENTRY= option), the corresponding variable is added to the model. After a variable is entered in the model, it is never removed from the model. The process is repeated until none of the remaining variables meet the specified level for entry. By default, SLENTRY=0.05. The forward selection method may be useful in assessing interactions. You start with the main effects only model (using the INCLUDE= option) and then let the forward selection method search for any significant interactions. The significance level should be relatively low (.01 or less) because you only want to include relatively strong interactions in your final model.",CD,903,"['forward', 'selection', 'start', 'empty', 'model', 'method', 'computes', 'adjusted', 'chisquare', 'statistic', 'predictor_variable', 'model', 'examines', 'largest', 'statistic', 'significant', 'specified', 'significance', 'level', 'specified', 'slentry', 'option', 'corresponding', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'never', 'removed', 'model', 'process', 'repeated', 'none', 'remaining', 'variable', 'meet', 'specified', 'level', 'entry', 'default', 'slentry005', 'forward', 'selection', 'method', 'may', 'useful', 'assessing', 'interaction', 'start', 'main_effect', 'model', 'using', 'include', 'option', 'let', 'forward', 'selection', 'method', 'search', 'significant', 'interaction', 'significance', 'level', 'relatively', 'low', '01', 'le', 'want', 'include', 'relatively', 'strong', 'interaction', 'final', 'model']"
553,proc varclus data=sasuser.backache maxeigen=.70 short; var bending lifting age numberchd height weightend trimester weightbaby weightgain sitting fatigue standing makingbeds ironing walking; title 'Variable Clustering of the Backache Example'; run; Partial Output Variable Clustering of the Backache Example,CD,307,"['proc', 'varclus', 'datasasuserbackache', 'maxeigen70', 'short', 'var', 'bending', 'lifting', 'age', 'numberchd', 'height', 'weightend', 'trimester', 'weightbaby', 'weightgain', 'sitting', 'fatigue', 'standing', 'makingbeds', 'ironing', 'walking', 'title', 'variable', 'clustering', 'backache', 'example', 'run', 'partial', 'output', 'variable', 'clustering', 'backache', 'example']"
554,"Because repeated measurements are taken on each subject, a GEE model should be fit. However, the model building strategy is similar to the one used on the binary logistic regression model with independent observations. First, do an exploratory data analysis with contingency tables and logit plots. A useful contingency table would be the subject?s identification number by the response variable. Then fit a GEE model using various correlation structures based on subject-matter knowledge. The choice of correlation structure is irrelevant if the primary objective of the study is to estimate regression coefficients and there are a large number of subjects. Exploratory Data Analysis Using Logit Plots",CD,702,"['repeated', 'measurement', 'taken', 'subject', 'gee', 'model', 'fit', 'however', 'model', 'building', 'strategy', 'similar', 'one', 'used', 'binary', 'logistic_regression_model', 'independent', 'observation', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'useful', 'contingency', 'table', 'would', 'subject', 'identification', 'number', 'response_variable', 'fit', 'gee', 'model', 'using', 'various', 'correlation_structure', 'based', 'subjectmatter', 'knowledge', 'choice', 'correlation_structure', 'irrelevant', 'primary', 'objective', 'study', 'estimate', 'regression', 'coefficient', 'large', 'number', 'subject', 'exploratory', 'data', 'analysis', 'using', 'logit', 'plot']"
555,"Example: 	Select a subset of variables using the forward selection method. In the MODEL statement specify all the main effects and two-factor interactions. Examine the differences in which variables were selected when you use HIERARCHY=SINGLE and when you include all the main effects in the model to assess interactions. /* c1demo04a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age|phy_visit|alcohol|hist_hyp| mother_wt|prev_pretrm|socio|uterine_irr @2 / selection=forward slentry=.05 hierarchy=single; title 'Low Birth Weight Model'; run; Selected MODEL statement options: SELECTION= 	specifies the method used to select the variables in the model. SLENTRY=	specifies the significance level for entry into the model. HIERARCHY=	specifies how model hierarchy is to be applied. Available methods are NONE, SINGLE, MULTIPLE, SINGLECLASS (same as HIERACHY=SINGLE except only class variables are subject to the hierarchy requirement), and MULTIPLECLASS (same as HIERACHY=MULTIPLE except only the class variables are subject to the hierarchy requirement). ?	The bar notation with @2 constructs a model with all the main effects and the two-factor interactions. If you increased it to @3, then you would construct a model with all of the main effects, the two-factor interactions, and the three factor interactions. Low Birth Weight Model",CD,1354,"['example', '\tselect', 'subset', 'variable', 'using', 'forward', 'selection', 'method', 'model_statement', 'specify', 'main_effect', 'twofactor', 'interaction', 'examine', 'difference', 'variable', 'selected', 'use', 'hierarchysingle', 'include', 'main_effect', 'model', 'ass', 'interaction', '', 'c1demo04a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motheragephyvisitalcoholhisthyp', 'motherwtprevpretrmsociouterineirr', '2', '', 'selectionforward', 'slentry05', 'hierarchysingle', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'selection', '\tspecifies', 'method', 'used', 'select', 'variable', 'model', 'slentry\tspecifies', 'significance', 'level', 'entry', 'model', 'hierarchy\tspecifies', 'model', 'hierarchy', 'applied', 'available', 'method', 'none', 'single', 'multiple', 'singleclass', 'hierachysingle', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', 'multipleclass', 'hierachymultiple', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', '\tthe', 'bar', 'notation', '2', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'increased', '3', 'would', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'three', 'factor', 'interaction', 'low', 'birth', 'weight', 'model']"
556,"GEE regression models extend the generalized linear model, which is an extension of the traditional linear model. Generalized linear models extend the general linear model in several ways. 1.	The link function allows a wide variety of response variables to be modeled rather than just continuous response variables. For example, if the mean of the data is naturally restricted to a range of values such as a proportion, the appropriate link function ensures that the predicted values are within the appropriate range. 2.	The variance can be a specified function of the mean rather than just being constant. 3.	The distribution of error terms can come from a family of exponential distributions rather than just the normal distribution.",CD,735,"['gee', 'regression_model', 'extend', 'generalized', 'linear', 'model', 'extension', 'traditional', 'linear', 'model', 'generalized', 'linear', 'model', 'extend', 'general', 'linear', 'model', 'several', 'way', '1\tthe', 'link', 'function', 'allows', 'wide', 'variety', 'response_variable', 'modeled', 'rather', 'continuous', 'response_variable', 'example', 'mean', 'data', 'naturally', 'restricted', 'range', 'value', 'proportion', 'appropriate', 'link', 'function', 'ensures', 'predicted', 'value', 'within', 'appropriate', 'range', '2\tthe', 'variance', 'specified', 'function', 'mean', 'rather', 'constant', '3\tthe', 'distribution', 'error', 'term', 'come', 'family', 'exponential', 'distribution', 'rather', 'normal', 'distribution']"
557,"The Type III Analysis of Effects table shows that the variable size is significant in the model. This means that for at least one of the generalized logits, size has a significant effect. Analysis of Maximum Likelihood Estimates",CD,228,"['type', 'iii', 'analysis', 'effect', 'table', 'show', 'variable', 'size', 'significant', 'model', 'mean', 'least', 'one', 'generalized', 'logits', 'size', 'ha', 'significant', 'effect', 'analysis', 'maximum', 'likelihood', 'estimate']"
558,proc varclus data=sasuser.backache maxeigen=.70 short; var bending lifting age numberchd height weightend trimester weightbaby weightgain sitting fatigue standing makingbeds ironing walking; title 'Variable Clustering of the Backache Example'; run; Partial Output Variable Clustering of the Backache Example,CD,307,"['proc', 'varclus', 'datasasuserbackache', 'maxeigen70', 'short', 'var', 'bending', 'lifting', 'age', 'numberchd', 'height', 'weightend', 'trimester', 'weightbaby', 'weightgain', 'sitting', 'fatigue', 'standing', 'makingbeds', 'ironing', 'walking', 'title', 'variable', 'clustering', 'backache', 'example', 'run', 'partial', 'output', 'variable', 'clustering', 'backache', 'example']"
559,"To test the null hypothesis that all regression coefficients of the model are 0, the likelihood ratio test statistic is computed. This statistic compares the log-likelihood values at the fitted parameter estimates (LogL1) to the log-likelihood values when the parameter estimates are 0 (LogL0). So that it follows a chi-square distribution, the statistic is computed by the formula ?2(LogL0?LogL1). In the above diagram, the likelihood ratio statistic is twice the vertical distance between the values of the log-likelihood function at LogL1 and at LogL0.",CD,555,"['test', 'null', 'hypothesis', 'regression', 'coefficient', 'model', '0', 'likelihood', 'ratio', 'test', 'statistic', 'computed', 'statistic', 'compare', 'loglikelihood', 'value', 'fitted', 'parameter_estimate', 'logl1', 'loglikelihood', 'value', 'parameter_estimate', '0', 'logl0', 'follows', 'chisquare', 'distribution', 'statistic', 'computed', 'formula', '2logl0logl1', 'diagram', 'likelihood', 'ratio', 'statistic', 'twice', 'vertical', 'distance', 'value', 'loglikelihood', 'function', 'logl1', 'logl0']"
560,The logistic regression model with the two main effects in the model shows no problems with quasi-complete separation. The parameter estimates and their associated standard errors are all reasonable.,CD,199,"['logistic_regression_model', 'two', 'main_effect', 'model', 'show', 'problem', 'quasicomplete', 'separation', 'parameter_estimate', 'associated', 'standard_error', 'reasonable']"
561,"The Criteria For Assessing Goodness Of Fit table displays the scaled deviance and scaled Pearson chi-squares, which both measure the goodness-of-fit of the model. However, the model being evaluated is the independence-only model, not the GEE model. Notice also that the log likelihood is based on the independence model and should not be used to construct a likelihood-ratio test comparing GEE models. Because the GEE method is quasi-likelihood based, there is no reported log likelihood for the GEE model. Analysis Of Initial Parameter Estimates",CD,546,"['criterion', 'assessing', 'goodness', 'fit', 'table', 'display', 'scaled', 'deviance', 'scaled', 'pearson', 'chisquares', 'measure', 'goodnessoffit', 'model', 'however', 'model', 'evaluated', 'independenceonly', 'model', 'gee', 'model', 'notice', 'also', 'log', 'likelihood', 'based', 'independence', 'model', 'used', 'construct', 'likelihoodratio', 'test', 'comparing', 'gee', 'model', 'gee', 'method', 'quasilikelihood', 'based', 'reported', 'log', 'likelihood', 'gee', 'model', 'analysis', 'initial', 'parameter_estimate']"
562,"The LOGISTIC procedure enables you to specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. Model hierarchy refers to the requirement that for any effect in the model, all effects it contains must also be in the model. For example, in order for the interaction A*B to enter the model, the main effects A and B must be in the model. Model hierarchy is desirable because models that are hierarchically well formulated have inferences that are invariant to the coding you choose for your predictor variables (Kleinbaum, Kupper, and Muller 1988). If the model is not hierarchically well formulated, then the tests for the lower order terms will depend on the coding (reference versus effect coding for categorical variables). The HIERARCHY= option specifies whether hierarchy is maintained and whether a single effect or multiple effects are allowed to enter or leave the model in one step for SELECTION=FORWARD, SELECTION=BACKWARD, and SELECTION=STEPWISE. For HIERARCHY=SINGLE, only one effect can enter or leave the model at one time, subject to model hierarchy. For example, suppose that you specify the main effects A and B and the interaction of A*B in the model. For backward elimination, the interaction A*B must first be removed before the main effects are removed. For forward selection, the main effects must enter the model before the interaction. For HIERARCHY=MULTIPLE, more than one effect can enter or leave the model at one time, subject to model hierarchy. For forward selection, a single main effect can enter the model or an interaction can enter the model together with all the effects that are contained in the interaction. Backward selection can remove an interaction itself or the interaction together with all the effects that the interaction contains. If you do not want to have model hierarchy, specify HIERARCHY=NONE. In that case, any single effect can enter or leave the model at any given step of the selection process. The default is HIERARCHY=SINGLE.",CD,2087,"['logistic', 'procedure', 'enables', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'model', 'hierarchy', 'refers', 'requirement', 'effect', 'model', 'effect', 'contains', 'must', 'also', 'model', 'example', 'order', 'interaction', 'ab', 'enter', 'model', 'main_effect', 'b', 'must', 'model', 'model', 'hierarchy', 'desirable', 'model', 'hierarchically', 'well', 'formulated', 'inference', 'invariant', 'coding', 'choose', 'predictor_variable', 'kleinbaum', 'kupper', 'muller', '1988', 'model', 'hierarchically', 'well', 'formulated', 'test', 'lower', 'order', 'term', 'depend', 'coding', 'reference', 'versus', 'effect', 'coding', 'categorical', 'variable', 'hierarchy', 'option', 'specifies', 'whether', 'hierarchy', 'maintained', 'whether', 'single', 'effect', 'multiple', 'effect', 'allowed', 'enter', 'leave', 'model', 'one', 'step', 'selectionforward', 'selectionbackward', 'selectionstepwise', 'hierarchysingle', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'example', 'suppose', 'specify', 'main_effect', 'b', 'interaction', 'ab', 'model', 'backward', 'elimination', 'interaction', 'ab', 'must', 'first', 'removed', 'main_effect', 'removed', 'forward', 'selection', 'main_effect', 'must', 'enter', 'model', 'interaction', 'hierarchymultiple', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'forward', 'selection', 'single', 'main_effect', 'enter', 'model', 'interaction', 'enter', 'model', 'together', 'effect', 'contained', 'interaction', 'backward', 'selection', 'remove', 'interaction', 'interaction', 'together', 'effect', 'interaction', 'contains', 'want', 'model', 'hierarchy', 'specify', 'hierarchynone', 'case', 'single', 'effect', 'enter', 'leave', 'model', 'given', 'step', 'selection', 'process', 'default', 'hierarchysingle']"
563,"PROC FREQ computes three different types of CMH statistics: TYPE 1	is the correlation statistic, which is sensitive only to linear associations. This statistic is appropriate only when both the row and the column variable are ordinally scaled. TYPE 2	is the mean score statistic, which is sensitive to different means among the levels or groups of the nominal predictor. This statistic requires that the column variable be ordinally scaled. TYPE 3	is a generalization of the Pearson chi-square, which is sensitive to general patterns of association. This statistic is always interpretable because it does not require an ordinal scale for either variable.",CD,654,"['proc', 'freq', 'computes', 'three', 'different', 'type', 'cmh', 'statistic', 'type', '1\tis', 'correlation', 'statistic', 'sensitive', 'linear', 'association', 'statistic', 'appropriate', 'row', 'column', 'variable', 'ordinally', 'scaled', 'type', '2\tis', 'mean', 'score', 'statistic', 'sensitive', 'different', 'mean', 'among', 'level', 'group', 'nominal', 'predictor', 'statistic', 'requires', 'column', 'variable', 'ordinally', 'scaled', 'type', '3\tis', 'generalization', 'pearson', 'chisquare', 'sensitive', 'general', 'pattern', 'association', 'statistic', 'always', 'interpretable', 'doe', 'require', 'ordinal', 'scale', 'either', 'variable']"
564,"Stratified data analysis is the process of analyzing contingency tables from two or more strata or groups. The objective of stratified data analysis is to statistically control for a third variable when examining the relationship between the predictor variable and the response variable. When you stratify by a third variable, you examine the relationship between the predictor variable and the response variable within homogenous categories of the third variable, which removes the unequal distribution across the levels of the third variable. The Cochran-Mantel-Haenszel statistic (CMH) combines the results of the stratum-specific comparisons into a single overall estimate. It is formed by a weighted average of the stratum effects where each weight is based on the precision of the effect and the size of the stratum. The null hypothesis for the CMH test is that there is no association between the row and the column variable controlling for a third variable. The alternative hypothesis is that there is an association between the row and column variable controlling for a third variable.",CD,1094,"['stratified', 'data', 'analysis', 'process', 'analyzing', 'contingency', 'table', 'two', 'stratum', 'group', 'objective', 'stratified', 'data', 'analysis', 'statistically', 'control', 'third', 'variable', 'examining', 'relationship', 'predictor_variable', 'response_variable', 'stratify', 'third', 'variable', 'examine', 'relationship', 'predictor_variable', 'response_variable', 'within', 'homogenous', 'category', 'third', 'variable', 'remove', 'unequal', 'distribution', 'across', 'level', 'third', 'variable', 'cochranmantelhaenszel', 'statistic', 'cmh', 'combine', 'result', 'stratumspecific', 'comparison', 'single', 'overall', 'estimate', 'formed', 'weighted', 'average', 'stratum', 'effect', 'weight', 'based', 'precision', 'effect', 'size', 'stratum', 'null', 'hypothesis', 'cmh', 'test', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable', 'alternative', 'hypothesis', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable']"
565,"TABLES	requests one-way to n-way frequency and crosstabulation tables and statistics for those tables. You can use multiple TABLES statements in the PROC FREQ step. EXACT	requests exact tests or confidence limits for the specified statistics. PROC FREQ also computes Monte Carlo estimates of the exact p-values. The statistic options specify the statistics for which to provide exact tests or confidence limits. The computation options specify options for the computation of exact statistics. TEST	requests asymptotic tests for the specified measures of association and measures of agreement. You must use a TABLES statement with the TEST statement. For each measure of association or agreement that you specify, the TEST statement provides an asymptotic test that the measure equals zero. OUTPUT	creates a SAS data set containing statistics computed by PROC FREQ. Only one OUTPUT statement is allowed for each execution of PROC FREQ. You must specify a TABLES statement with the OUTPUT statement. ?	Exact tests are appropriate when a data set is small, sparse, skewed, or heavily tied. For some large problems, computation of exact tests may require a large amount of time and memory. Consider using asymptotic tests for such problems. Alternatively, when asymptotic methods may not be sufficient for such large problems, consider using Monte Carlo estimation of exact p-values.",CD,1379,"['tables\trequests', 'oneway', 'nway', 'frequency', 'crosstabulation', 'table', 'statistic', 'table', 'use', 'multiple', 'table', 'statement', 'proc', 'freq', 'step', 'exact\trequests', 'exact', 'test', 'confidence', 'limit', 'specified', 'statistic', 'proc', 'freq', 'also', 'computes', 'monte', 'carlo', 'estimate', 'exact', 'pvalues', 'statistic', 'option', 'specify', 'statistic', 'provide', 'exact', 'test', 'confidence', 'limit', 'computation', 'option', 'specify', 'option', 'computation', 'exact', 'statistic', 'test\trequests', 'asymptotic', 'test', 'specified', 'measure', 'association', 'measure', 'agreement', 'must', 'use', 'table', 'statement', 'test', 'statement', 'measure', 'association', 'agreement', 'specify', 'test', 'statement', 'provides', 'asymptotic', 'test', 'measure', 'equal', 'zero', 'output\tcreates', 'sa', 'data_set', 'containing', 'statistic', 'computed', 'proc', 'freq', 'one', 'output', 'statement', 'allowed', 'execution', 'proc', 'freq', 'must', 'specify', 'table', 'statement', 'output', 'statement', '\texact', 'test', 'appropriate', 'data_set', 'small', 'sparse', 'skewed', 'heavily', 'tied', 'large', 'problem', 'computation', 'exact', 'test', 'may', 'require', 'large', 'amount', 'time', 'memory', 'consider', 'using', 'asymptotic', 'test', 'problem', 'alternatively', 'asymptotic', 'method', 'may', 'sufficient', 'large', 'problem', 'consider', 'using', 'monte', 'carlo', 'estimation', 'exact', 'pvalues']"
566,"For reference cell coding, parameter estimates of the CLASS main effects estimate the difference between the effect of each level and the last level. For example, the effect for the low level would estimate the difference between low and high. You can choose the reference level with the REF= option.",CD,300,"['reference', 'cell', 'coding', 'parameter_estimate', 'class', 'main_effect', 'estimate', 'difference', 'effect', 'level', 'last', 'level', 'example', 'effect', 'low', 'level', 'would', 'estimate', 'difference', 'low', 'high', 'choose', 'reference', 'level', 'ref', 'option']"
567,"The Type III Analysis of Effects table shows that the variable size is significant in the model. This means that for at least one of the generalized logits, size has a significant effect. Analysis of Maximum Likelihood Estimates",CD,228,"['type', 'iii', 'analysis', 'effect', 'table', 'show', 'variable', 'size', 'significant', 'model', 'mean', 'least', 'one', 'generalized', 'logits', 'size', 'ha', 'significant', 'effect', 'analysis', 'maximum', 'likelihood', 'estimate']"
568,"The common effect of the predictor variable for different cumulative logits in the proportional odds model can be motivated by assuming that a regression model holds when the response is measured more finely (Anderson and Phillips 1981). For example, suppose there is an underlying continuous response variable with ordered categories that are produced via cutoff points. The relationship between the predictor variable and the response should not depend on the cutoff points. In other words, the effect parameters are invariant to the choice of categories for the response variable. Only the intercepts are affected by the cutoff points. The proportional odds model is therefore invariant to the choice of the outcome categories. There is some loss of efficiency when you collapse the ordinal categories, but when the observations are evenly spread among the categories the efficiency loss is minor. However, the efficiency loss is large when you collapse the ordinal categories to a binary response (Agresti 1996). Allison (1999) recommends that you need at least 10 observations for each category of the response variable. As the number of categories increases, ordinary least squares might be appropriate. However, Hastie et al. (1989) showed that ordinary least squares methods could give misleading results with up to 13 categories of the response variable. The proportional odds model also makes no assumptions about the distances between the categories. Therefore, how you code the ordinal outcome variable has no effect on the odds ratios. Fitting Simple Ordinal Logistic Regression Models",CD,1598,"['common', 'effect', 'predictor_variable', 'different', 'cumulative', 'logits', 'proportional', 'odds', 'model', 'motivated', 'assuming', 'regression_model', 'hold', 'response', 'measured', 'finely', 'anderson', 'phillips', '1981', 'example', 'suppose', 'underlying', 'continuous', 'response_variable', 'ordered', 'category', 'produced', 'via', 'cutoff', 'point', 'relationship', 'predictor_variable', 'response', 'depend', 'cutoff', 'point', 'word', 'effect', 'parameter', 'invariant', 'choice', 'category', 'response_variable', 'intercept', 'affected', 'cutoff', 'point', 'proportional', 'odds', 'model', 'therefore', 'invariant', 'choice', 'outcome', 'category', 'loss', 'efficiency', 'collapse', 'ordinal', 'category', 'observation', 'evenly', 'spread', 'among', 'category', 'efficiency', 'loss', 'minor', 'however', 'efficiency', 'loss', 'large', 'collapse', 'ordinal', 'category', 'binary', 'response', 'agresti', '1996', 'allison', '1999', 'recommends', 'need', 'least', '10', 'observation', 'category', 'response_variable', 'number', 'category', 'increase', 'ordinary', 'least', 'square', 'might', 'appropriate', 'however', 'hastie', 'et', 'al', '1989', 'showed', 'ordinary', 'least', 'square', 'method', 'could', 'give', 'misleading', 'result', '13', 'category', 'response_variable', 'proportional', 'odds', 'model', 'also', 'make', 'assumption', 'distance', 'category', 'therefore', 'code', 'ordinal', 'outcome', 'variable', 'ha', 'effect', 'odds_ratio', 'fitting', 'simple', 'ordinal', 'logistic_regression_model']"
569,"In a matched case-control study, the conditional likelihood allows the model to predict the odds for the event given the predictor variable values. This involves setting up the probabilities for having the observed predictor variable values given the event and then using Bayes? theorem to determine a relevant conditional probability concerning the event. The conditional likelihood is derived by computing the conditional probability of observing the predictor variable values given the outcome (event or not). A predictor variable that is constant within a stratum cancels out of the conditional likelihood. This is the reason why the conditional logistic models cannot estimate a between-cluster effect. Statistics providing information about the between-cluster effect use subject totals at different levels of the relevant predictor variable. However, those totals sum the sufficient statistics for the stratum- specific intercepts, so they themselves are fixed and have degenerate distributions after conditioning on the sufficient statistics (Agresti 2002). Note that the conditional likelihood for the 1:1 matched case-control data is the unconditional likelihood for a logistic regression model where the response is always equal to 1, the predictor variable values are equal to the differences between the values for the case and the control, and there is no intercept. Before SAS?9, you could use PROC LOGISTIC by configuring your data appropriately and eliminating the intercept term. However, you would have to use PROC PHREG for 1:m and m:n matching.",CD,1565,"['matched', 'casecontrol', 'study', 'conditional', 'likelihood', 'allows', 'model', 'predict', 'odds', 'event', 'given', 'predictor_variable', 'value', 'involves', 'setting', 'probability', 'observed', 'predictor_variable', 'value', 'given', 'event', 'using', 'bayes', 'theorem', 'determine', 'relevant', 'conditional', 'probability', 'concerning', 'event', 'conditional', 'likelihood', 'derived', 'computing', 'conditional', 'probability', 'observing', 'predictor_variable', 'value', 'given', 'outcome', 'event', 'predictor_variable', 'constant', 'within', 'stratum', 'cancel', 'conditional', 'likelihood', 'reason', 'conditional', 'logistic', 'model', 'cannot', 'estimate', 'betweencluster', 'effect', 'statistic', 'providing', 'information', 'betweencluster', 'effect', 'use', 'subject', 'total', 'different', 'level', 'relevant', 'predictor_variable', 'however', 'total', 'sum', 'sufficient', 'statistic', 'stratum', 'specific', 'intercept', 'fixed', 'degenerate', 'distribution', 'conditioning', 'sufficient', 'statistic', 'agresti', '2002', 'note', 'conditional', 'likelihood', '11', 'matched', 'casecontrol', 'data', 'unconditional', 'likelihood', 'logistic_regression_model', 'response', 'always', 'equal', '1', 'predictor_variable', 'value', 'equal', 'difference', 'value', 'case', 'control', 'intercept', 'sas9', 'could', 'use', 'proc_logistic', 'configuring', 'data', 'appropriately', 'eliminating', 'intercept', 'term', 'however', 'would', 'use', 'proc', 'phreg', '1m', 'mn', 'matching']"
570,"When fitting a GEE model in PROC GENMOD, you should decide what is a reasonable model for the correlation between measurements within subject. PROC GENMOD offers several common structures to use to model the working correlation matrix. The choice of the structure should be consistent with the empirical correlations. Liang and Zeger (1986) showed that there could be important gains in efficiency by correctly specifying the working correlation matrix. However, the loss of efficiency is inconsequential when the number of clusters is large (Davis 2002).",CD,555,"['fitting', 'gee', 'model', 'proc', 'genmod', 'decide', 'reasonable', 'model', 'correlation', 'measurement', 'within', 'subject', 'proc', 'genmod', 'offer', 'several', 'common', 'structure', 'use', 'model', 'working', 'correlation', 'matrix', 'choice', 'structure', 'consistent', 'empirical', 'correlation', 'liang', 'zeger', '1986', 'showed', 'could', 'important', 'gain', 'efficiency', 'correctly', 'specifying', 'working', 'correlation', 'matrix', 'however', 'loss', 'efficiency', 'inconsequential', 'number', 'cluster', 'large', 'davis', '2002']"
571,title 'Estimated Logit Plot of Socioeconomic Status'; run; Selected PROC MEANS statement option: NWAY	causes the output data set to have only one observation for each level of the class variable.,CD,195,"['title', 'estimated', 'logit', 'plot', 'socioeconomic', 'status', 'run', 'selected', 'proc', 'mean', 'statement', 'option', 'nway\tcauses', 'output', 'data_set', 'one', 'observation', 'level', 'class', 'variable']"
572,"Convergence problems are also caused by complete separation. This occurs when some linear combination of the predictor variables perfectly predicts the response variable. The net result is infinite parameter estimates. In order to have finite maximum likelihood estimates, there must be some overlap in the distribution of the predictor variables in the model. The diagram above shows that the continuous predictor age perfectly separates the response. Thus age is a perfect predictor of the response.",CD,501,"['convergence', 'problem', 'also', 'caused', 'complete', 'separation', 'occurs', 'linear', 'combination', 'predictor_variable', 'perfectly', 'predicts', 'response_variable', 'net', 'result', 'infinite', 'parameter_estimate', 'order', 'finite', 'maximum', 'likelihood', 'estimate', 'must', 'overlap', 'distribution', 'predictor_variable', 'model', 'diagram', 'show', 'continuous', 'predictor', 'age', 'perfectly', 'separate', 'response', 'thus', 'age', 'perfect', 'predictor', 'response']"
573,"Stratified data analysis is the process of analyzing contingency tables from two or more strata or groups. The objective of stratified data analysis is to statistically control for a third variable when examining the relationship between the predictor variable and the response variable. When you stratify by a third variable, you examine the relationship between the predictor variable and the response variable within homogenous categories of the third variable, which removes the unequal distribution across the levels of the third variable. The Cochran-Mantel-Haenszel statistic (CMH) combines the results of the stratum-specific comparisons into a single overall estimate. It is formed by a weighted average of the stratum effects where each weight is based on the precision of the effect and the size of the stratum. The null hypothesis for the CMH test is that there is no association between the row and the column variable controlling for a third variable. The alternative hypothesis is that there is an association between the row and column variable controlling for a third variable.",CD,1094,"['stratified', 'data', 'analysis', 'process', 'analyzing', 'contingency', 'table', 'two', 'stratum', 'group', 'objective', 'stratified', 'data', 'analysis', 'statistically', 'control', 'third', 'variable', 'examining', 'relationship', 'predictor_variable', 'response_variable', 'stratify', 'third', 'variable', 'examine', 'relationship', 'predictor_variable', 'response_variable', 'within', 'homogenous', 'category', 'third', 'variable', 'remove', 'unequal', 'distribution', 'across', 'level', 'third', 'variable', 'cochranmantelhaenszel', 'statistic', 'cmh', 'combine', 'result', 'stratumspecific', 'comparison', 'single', 'overall', 'estimate', 'formed', 'weighted', 'average', 'stratum', 'effect', 'weight', 'based', 'precision', 'effect', 'size', 'stratum', 'null', 'hypothesis', 'cmh', 'test', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable', 'alternative', 'hypothesis', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable']"
574,"For continuous predictor variables with a large number of unique values, binning the data (collapsing data values into groups) is necessary to compute the logit. The bin size should have an adequate number of observations to reduce the sample variability of the logits. If the standard logistic regression model adequately fits the data, the logit plots should be fairly linear. The above graph shows a predictor variable that meets the assumption of linearity in the logit.",CD,474,"['continuous', 'predictor_variable', 'large', 'number', 'unique', 'value', 'binning', 'data', 'collapsing', 'data', 'value', 'group', 'necessary', 'compute', 'logit', 'bin', 'size', 'adequate', 'number', 'observation', 'reduce', 'sample', 'variability', 'logits', 'standard', 'logistic_regression_model', 'adequately', 'fit', 'data', 'logit', 'plot', 'fairly', 'linear', 'graph', 'show', 'predictor_variable', 'meet', 'assumption', 'linearity', 'logit']"
575,"After an extensive univariate and stratified data analysis, the above variables were identified as potential confounders. The criterion was a big difference between the crude odds ratio of the main effect and the adjusted odds ratio. For example, the crude odds ratio for history of hypertension is 3.365 and the odds ratio adjusted for mother?s weight is 6.435. Therefore, to obtain an accurate, unconfounded effect of history of hypertension, mother?s weight should be in the model.",CD,484,"['extensive', 'univariate', 'stratified', 'data', 'analysis', 'variable', 'identified', 'potential', 'confounders', 'criterion', 'wa', 'big', 'difference', 'crude', 'odds_ratio', 'main_effect', 'adjusted', 'odds_ratio', 'example', 'crude', 'odds_ratio', 'history', 'hypertension', '3365', 'odds_ratio', 'adjusted', 'mother', 'weight', '6435', 'therefore', 'obtain', 'accurate', 'unconfounded', 'effect', 'history', 'hypertension', 'mother', 'weight', 'model']"
576,PROC GENMOD is modeling the probability that wheeze='1'. The Class Level Information table displays the levels of the class variables while the response profile table displays the levels of the response variable. Parameter Information,CD,234,"['proc', 'genmod', 'modeling', 'probability', 'wheeze1', 'class', 'level', 'information', 'table', 'display', 'level', 'class', 'variable', 'response', 'profile', 'table', 'display', 'level', 'response_variable', 'parameter', 'information']"
577,"One solution to the incidental parameters problem is to use conditional maximum likelihood estimation. This approach eliminates the stratum-specific intercepts from the likelihood by conditioning on their sufficient statistics (just like the approach in exact logistic regression). Recall that a sufficient statistic for the intercept is simply the sum of the events. By deriving a conditional likelihood that is conditional on the sufficient statistics of the stratum-specific intercepts, you are factoring out the intercepts from the likelihood equation. In other words, you are taking the stratification into account by conditioning out (and not estimating) the stratum-specific intercepts. You are essentially modeling a meaningful conditional probability, and the model has a reduced number of parameters that can be estimated without bias. A conditional likelihood is just like an ordinary likelihood. Conditional maximum likelihood estimates are those values that maximize the conditional likelihood function. The estimates are consistent and asymptotically normal. The optimization techniques used to obtain the maximum likelihood estimates are Newton-Raphson with ridging when the number of parameters is less than 40, quasi-Newton when the number of parameters is 40-399, and conjugate gradient when the number of parameters is 400 or greater. Sometimes the log likelihood converges but the estimates diverge. This condition is flagged by having inordinately large standard errors for some of your parameter estimates. It may be possible to circumvent this problem by standardizing the predictor variables before fitting the model.",CD,1641,"['one', 'solution', 'incidental', 'parameter', 'problem', 'use', 'conditional', 'maximum', 'likelihood', 'estimation', 'approach', 'eliminates', 'stratumspecific', 'intercept', 'likelihood', 'conditioning', 'sufficient', 'statistic', 'like', 'approach', 'exact', 'logistic_regression', 'recall', 'sufficient', 'statistic', 'intercept', 'simply', 'sum', 'event', 'deriving', 'conditional', 'likelihood', 'conditional', 'sufficient', 'statistic', 'stratumspecific', 'intercept', 'factoring', 'intercept', 'likelihood', 'equation', 'word', 'taking', 'stratification', 'account', 'conditioning', 'estimating', 'stratumspecific', 'intercept', 'essentially', 'modeling', 'meaningful', 'conditional', 'probability', 'model', 'ha', 'reduced', 'number', 'parameter', 'estimated', 'without', 'bias', 'conditional', 'likelihood', 'like', 'ordinary', 'likelihood', 'conditional', 'maximum', 'likelihood', 'estimate', 'value', 'maximize', 'conditional', 'likelihood', 'function', 'estimate', 'consistent', 'asymptotically', 'normal', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'estimate', 'newtonraphson', 'ridging', 'number', 'parameter', 'le', '40', 'quasinewton', 'number', 'parameter', '40399', 'conjugate', 'gradient', 'number', 'parameter', '400', 'greater', 'sometimes', 'log', 'likelihood', 'converges', 'estimate', 'diverge', 'condition', 'flagged', 'inordinately', 'large', 'standard_error', 'parameter_estimate', 'may', 'possible', 'circumvent', 'problem', 'standardizing', 'predictor_variable', 'fitting', 'model']"
578,"The graph shows that for mothers who did not visit the physician during the first trimester, the probability of a low birth weight baby increases with age. However, for mothers who did visit the physician during the first trimester, the probability of a low birth weight baby decreases with age.",CD,295,"['graph', 'show', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'increase', 'age', 'however', 'mother', 'visit', 'physician', 'first', 'trimester', 'probability', 'low', 'birth', 'weight', 'baby', 'decrease', 'age']"
579,"PROC LOGISTIC reports a score test for the proportional odds assumption. This tests the null hypothesis that the slope coefficients are equal across the cumulative logits for each predictor variable. Because the p-value is not significant at the 0.05 significance level, you do not reject the assumption of equal slopes and the proportional odds assumption is validated. Model Fit Statistics",CD,391,"['proc_logistic', 'report', 'score', 'test', 'proportional', 'odds', 'assumption', 'test', 'null', 'hypothesis', 'slope', 'coefficient', 'equal', 'across', 'cumulative', 'logits', 'predictor_variable', 'pvalue', 'significant', '005', 'significance', 'level', 'reject', 'assumption', 'equal', 'slope', 'proportional', 'odds', 'assumption', 'validated', 'model', 'fit', 'statistic']"
580,The chi-square test of association indicates that there is strong evidence of an association between previous preterm deliveries and low birth weight for women with no uterine irritability. Statistics for Table 1 of prev_pretrm by low Controlling for uterine_irr=0,CD,264,"['chisquare', 'test', 'association', 'indicates', 'strong', 'evidence', 'association', 'previous', 'preterm', 'delivery', 'low', 'birth', 'weight', 'woman', 'uterine', 'irritability', 'statistic', 'table', '1', 'prevpretrm', 'low', 'controlling', 'uterineirr0']"
581,"The Strata Summary table displays the number of strata, which have a specific number of events and nonevents. Strata containing only events or only nonevents are reported in this table, but such strata are uninformative and are not used in the analysis. NOTE: The following parameters have been set to 0, since the variables are a linear combination of other variables as shown. Mother_age = 0",CD,393,"['stratum', 'summary', 'table', 'display', 'number', 'stratum', 'specific', 'number', 'event', 'nonevent', 'stratum', 'containing', 'event', 'nonevent', 'reported', 'table', 'stratum', 'uninformative', 'used', 'analysis', 'note', 'following', 'parameter', 'set', '0', 'since', 'variable', 'linear', 'combination', 'variable', 'shown', 'motherage', '', '0']"
582,"The odds ratio for bending indicates that women who say that bending aggravates their back pain have 2.4 times the odds to be in a higher severity level of back pain than women who say that bending does not aggravate their back pain. Because the confidence bounds do not include 1.0, the odds ratio is significant at the 0.05 significance level. Association of Predicted Probabilities and Observed Responses",CD,407,"['odds_ratio', 'bending', 'indicates', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '24', 'time', 'odds', 'higher', 'severity', 'level', 'back', 'pain', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain', 'confidence', 'bound', 'include', '10', 'odds_ratio', 'significant', '005', 'significance', 'level', 'association', 'predicted', 'probability', 'observed', 'response']"
583,"Because the mother_age*phy_visit interaction is significant, you need to compute two odds ratios for mother?s age. One odds ratio is for mothers who did visit the physician during the first trimester; the other is for mothers who did not visit the physician during the first trimester. These odds ratios can be computed using the coefficients in the model. To compute the odds ratio of interest, write out the equation for the odds ratio. Solve the expression algebraically and exponentiate the final estimate. The example above shows that among women who went to a physician during the first trimester, women who are 10 years younger are 4.95 times more likely to have a low birth weight baby.",CD,694,"['motheragephyvisit', 'interaction', 'significant', 'need', 'compute', 'two', 'odds_ratio', 'mother', 'age', 'one', 'odds_ratio', 'mother', 'visit', 'physician', 'first', 'trimester', 'mother', 'visit', 'physician', 'first', 'trimester', 'odds_ratio', 'computed', 'using', 'coefficient', 'model', 'compute', 'odds_ratio', 'interest', 'write', 'equation', 'odds_ratio', 'solve', 'expression', 'algebraically', 'exponentiate', 'final', 'estimate', 'example', 'show', 'among', 'woman', 'went', 'physician', 'first', 'trimester', 'woman', '10', 'year', 'younger', '495', 'time', 'likely', 'low', 'birth', 'weight', 'baby']"
584,"Conditional logistic regression is a useful technique when you have paired observations. One example is the matched case-control studies. In the past, the PHREG procedure was usually used to fit a conditional logistic regression model. However, in SAS?9 the STRATA statement in PROC LOGISTIC can be used to fit conditional logistic regression models. An important feature of the conditional logistic model is that the model requires the matched data to be considered in strata. The strata represent the matched sets (paired observations). These models also allow the probabilities to vary by observation within strata. Therefore, the models permit the strata to have their own probability distributions and they account for the dependence of the matched pairs. These models are known as the conditional models because the parameter estimate ? is defined conditional on the subject. The effect is subject-specific, because it is defined at the subject level. This is in contrast to the GEE models which were marginal models. The effects in those models are population-averaged because they refer to averaging over the entire population rather than to individual subjects. For example, in a matched case-control study the probabilities modeled refer to the distribution of Y given X. Although the model permits stratum-specific distributions, it assumes a common effect ?. The parameter ? compares the response distributions. It follows that the conditional model is restricted to estimating ? that are within stratum effects. Thus only the predictor variables that vary within stratum contribute to the likelihood. Conditional models do not estimate a between-stratum effect. Therefore, a predictor variable that is constant within stratum contributes nothing to the likelihood. This is why a coefficient is not estimated for the matching variables. However, the stratum-constant variables are still being controlled for in the model. It should be noted that when there are several observations per stratum, then the GEE models can be used. For 1:1 matched case-control studies, the estimated values in the working correlation matrix are ?1 and the GEE method breaks down. Therefore, the conditional model is the only way to go for case-control matching. A good discussion about the differences between GEE models and conditional logistic models can be found in Allison (1999).",CD,2376,"['conditional', 'logistic_regression', 'useful', 'technique', 'paired', 'observation', 'one', 'example', 'matched', 'casecontrol', 'study', 'past', 'phreg', 'procedure', 'wa', 'usually', 'used', 'fit', 'conditional', 'logistic_regression_model', 'however', 'sas9', 'stratum', 'statement', 'proc_logistic', 'used', 'fit', 'conditional', 'logistic_regression_model', 'important', 'feature', 'conditional', 'logistic', 'model', 'model', 'requires', 'matched', 'data', 'considered', 'stratum', 'stratum', 'represent', 'matched', 'set', 'paired', 'observation', 'model', 'also', 'allow', 'probability', 'vary', 'observation', 'within', 'stratum', 'therefore', 'model', 'permit', 'stratum', 'probability', 'distribution', 'account', 'dependence', 'matched', 'pair', 'model', 'known', 'conditional', 'model', 'parameter_estimate', '', 'defined', 'conditional', 'subject', 'effect', 'subjectspecific', 'defined', 'subject', 'level', 'contrast', 'gee', 'model', 'marginal', 'model', 'effect', 'model', 'populationaveraged', 'refer', 'averaging', 'entire', 'population', 'rather', 'individual', 'subject', 'example', 'matched', 'casecontrol', 'study', 'probability', 'modeled', 'refer', 'distribution', 'given', 'x', 'although', 'model', 'permit', 'stratumspecific', 'distribution', 'assumes', 'common', 'effect', '', 'parameter', '', 'compare', 'response', 'distribution', 'follows', 'conditional', 'model', 'restricted', 'estimating', '', 'within', 'stratum', 'effect', 'thus', 'predictor_variable', 'vary', 'within', 'stratum', 'contribute', 'likelihood', 'conditional', 'model', 'estimate', 'betweenstratum', 'effect', 'therefore', 'predictor_variable', 'constant', 'within', 'stratum', 'contributes', 'nothing', 'likelihood', 'coefficient', 'estimated', 'matching', 'variable', 'however', 'stratumconstant', 'variable', 'still', 'controlled', 'model', 'noted', 'several', 'observation', 'per', 'stratum', 'gee', 'model', 'used', '11', 'matched', 'casecontrol', 'study', 'estimated', 'value', 'working', 'correlation', 'matrix', '1', 'gee', 'method', 'break', 'therefore', 'conditional', 'model', 'way', 'go', 'casecontrol', 'matching', 'good', 'discussion', 'difference', 'gee', 'model', 'conditional', 'logistic', 'model', 'found', 'allison', '1999']"
585,"The logit transformation is the log of the odds, which is the ratio of the probability of the outcome to the probability of no outcome. To create a linear model, the logit transformation is applied to the probability. Unlike a probability, the logit is unbounded because transforming the probability to odds removes the upper bound, whereas taking the natural logarithm of the odds removes the lower bound. The model (also called the logistic regression model) is now linear because the logit is linear in its parameters. Furthermore, the model gives estimated probabilities that are between 0 and 1.",CD,600,"['logit', 'transformation', 'log', 'odds_ratio', 'probability', 'outcome', 'probability', 'outcome', 'create', 'linear', 'model', 'logit', 'transformation', 'applied', 'probability', 'unlike', 'probability', 'logit', 'unbounded', 'transforming', 'probability', 'odds', 'remove', 'upper', 'bound', 'whereas', 'taking', 'natural', 'logarithm', 'odds', 'remove', 'lower', 'bound', 'model', 'also', 'called', 'logistic_regression_model', 'linear', 'logit', 'linear', 'parameter', 'furthermore', 'model', 'give', 'estimated', 'probability', '0', '1']"
586,"In nominal logistic regression, the logit is now a generalized logit. If k is the number of categories for the outcome variable, then the number of generalized logits is k-1. The last category is the reference category or the denominator of each logit.",CD,252,"['nominal', 'logistic_regression', 'logit', 'generalized', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'generalized', 'logits', 'k1', 'last', 'category', 'reference', 'category', 'denominator', 'logit']"
587,"The LOGISTIC procedure has five variable selection methods with the use of the SELECTION= option. The default is SELECTION=NONE, in which PROC LOGISTIC fits the complete model as specified in the MODEL statement. The other four methods are FORWARD for forward selection, BACKWARD for backward elimination, STEPWISE for stepwise selection, and SCORE for best subsets selection. Best subsets selection finds a specified number of models with the highest likelihood score (chi- square) statistic for all possible model sizes (1-, 2-, 3-variable models, and so on, up to the single model containing all predictor variables). The method requires only that the full model be fit because the results are then manipulated to calculate the likelihood score statistic for each possible combination of predictor variables. Because the method uses a branch and bound algorithm to search the many combinations of variables, the best subsets selection is relatively efficient for a relatively small number of variables. However, the performance acutely deteriorates when the model has over approximately 50 effects (predictor variables and their interactions) (Potts and Patetta 1999).",CD,1171,"['logistic', 'procedure', 'ha', 'five', 'variable', 'selection', 'method', 'use', 'selection', 'option', 'default', 'selectionnone', 'proc_logistic', 'fit', 'complete', 'model', 'specified', 'model_statement', 'four', 'method', 'forward', 'forward', 'selection', 'backward', 'backward', 'elimination', 'stepwise', 'stepwise', 'selection', 'score', 'best', 'subset', 'selection', 'best', 'subset', 'selection', 'find', 'specified', 'number', 'model', 'highest', 'likelihood', 'score', 'chi', 'square', 'statistic', 'possible', 'model', 'size', '1', '2', '3variable', 'model', 'single', 'model', 'containing', 'predictor_variable', 'method', 'requires', 'full', 'model', 'fit', 'result', 'manipulated', 'calculate', 'likelihood', 'score', 'statistic', 'possible', 'combination', 'predictor_variable', 'method', 'us', 'branch', 'bound', 'algorithm', 'search', 'many', 'combination', 'variable', 'best', 'subset', 'selection', 'relatively', 'efficient', 'relatively', 'small', 'number', 'variable', 'however', 'performance', 'acutely', 'deteriorates', 'model', 'ha', 'approximately', '50', 'effect', 'predictor_variable', 'interaction', 'potts', 'patetta', '1999']"
588,"You can also write a CONTRAST statement in PROC LOGISTIC to estimate the odds ratio for any effect along with the confidence bounds. The contrasts consist of the effects involved in the odds ratio along with the coefficients that measure the difference between the effects in the numerator and the effects in the denominator. The ESTIMATE=EXP option exponentiates the parameter estimate, which shows the odds ratio and the 95% confidence bounds. Estimating Odds Ratios in Interactions",CD,484,"['also', 'write', 'contrast', 'statement', 'proc_logistic', 'estimate', 'odds_ratio', 'effect', 'along', 'confidence', 'bound', 'contrast', 'consist', 'effect', 'involved', 'odds_ratio', 'along', 'coefficient', 'measure', 'difference', 'effect', 'numerator', 'effect', 'denominator', 'estimateexp', 'option', 'exponentiates', 'parameter_estimate', 'show', 'odds_ratio', '95', 'confidence', 'bound', 'estimating', 'odds_ratio', 'interaction']"
589,"Unlike the binary and ordinal logistic models, the nominal logistic model has separate intercept parameters and separate slope parameters for each generalized logit. Therefore, there are multiple sets of parameters for both the intercept terms and the predictor variables. When building nominal models, you should consider whether the sample size is large enough to support the number of generalized logits you are modeling. Because you are estimating many parameters, you may encounter parameter estimation problems with small sample sizes. As a general rule you need each possible outcome to have at least five observations per explanatory variable in the model for valid estimation to proceed (Stokes, Davis, and Koch 2000). If you have a small sample size, one solution is to use the EXACT statement to fit an exact logistic regression model.",CD,846,"['unlike', 'binary', 'ordinal', 'logistic', 'model', 'nominal', 'logistic', 'model', 'ha', 'separate', 'intercept', 'parameter', 'separate', 'slope', 'parameter', 'generalized', 'logit', 'therefore', 'multiple', 'set', 'parameter', 'intercept', 'term', 'predictor_variable', 'building', 'nominal', 'model', 'consider', 'whether', 'sample_size', 'large', 'enough', 'support', 'number', 'generalized', 'logits', 'modeling', 'estimating', 'many', 'parameter', 'may', 'encounter', 'parameter', 'estimation', 'problem', 'small', 'sample_size', 'general', 'rule', 'need', 'possible', 'outcome', 'least', 'five', 'observation', 'per', 'explanatory', 'variable', 'model', 'valid', 'estimation', 'proceed', 'stokes', 'davis', 'koch', '2000', 'small', 'sample_size', 'one', 'solution', 'use', 'exact', 'statement', 'fit', 'exact', 'logistic_regression_model']"
590,"For backward elimination, the model selected when you allow multiple effects to leave the model at one time is the same as the model selected when you allow single effects to leave the model at one time. This is because only one main effect, not involved in a significant interaction, was itself not significant. Therefore, the method did not have the chance to eliminate the interaction along with its main effects in one step. When you include all the main effects in the model, the backward elimination method finds one significant interaction (mother_age*phy_visit). This is the same model as the one selected in forward selection including all the main effects. This model also has the highest c statistic (.793).",CD,718,"['backward', 'elimination', 'model', 'selected', 'allow', 'multiple', 'effect', 'leave', 'model', 'one', 'time', 'model', 'selected', 'allow', 'single', 'effect', 'leave', 'model', 'one', 'time', 'one', 'main_effect', 'involved', 'significant', 'interaction', 'wa', 'significant', 'therefore', 'method', 'chance', 'eliminate', 'interaction', 'along', 'main_effect', 'one', 'step', 'include', 'main_effect', 'model', 'backward', 'elimination', 'method', 'find', 'one', 'significant', 'interaction', 'motheragephyvisit', 'model', 'one', 'selected', 'forward', 'selection', 'including', 'main_effect', 'model', 'also', 'ha', 'highest', 'c', 'statistic', '793']"
591,Complete separation can cause severe bias in the estimates of the odds ratios and poor chi-squared approximations for the goodness-of-fit statistics. You should be concerned about your model when the three goodness-of-fit tests reported in PROC LOGISTIC vary widely. Complete separation should be detected in the univariate analysis of the predictor variables. It should be noted that the modeling strategy that includes all the predictor variables in the model is particularly sensitive to complete separation (Allison 1999).,CD,526,"['complete', 'separation', 'cause', 'severe', 'bias', 'estimate', 'odds_ratio', 'poor', 'chisquared', 'approximation', 'goodnessoffit', 'statistic', 'concerned', 'model', 'three', 'goodnessoffit', 'test', 'reported', 'proc_logistic', 'vary', 'widely', 'complete', 'separation', 'detected', 'univariate', 'analysis', 'predictor_variable', 'noted', 'modeling', 'strategy', 'includes', 'predictor_variable', 'model', 'particularly', 'sensitive', 'complete', 'separation', 'allison', '1999']"
592,"To assess the significance of the extra terms in the model, you can compute a likelihood ratio test that compares two models. One model would be the full model with all the terms, and the other model would be the reduced model with just a subset of the terms. The difference between the negative 2 log likelihood for the reduced model and the negative 2 log likelihood for the full model is the value of the test statistic for the likelihood ratio test. An alternative way to compute this test statistic is to take the difference between the likelihood ratio chi-square statistic reported for the model with the extra terms and the likelihood ratio chi-square statistic reported for the model without the extra terms. The degrees of freedom would be the difference in the number of terms between the two models. The test statistic along with the corresponding p-value can be computed using ODS. The test statistic for the likelihood ratio test follows a chi-square distribution if the reduced model is a subset of the full model. Therefore, the validity of the test would be compromised if you were comparing two entirely different models. An alternative way to compute likelihood-ratio tests is to use the GENMOD procedure with the TYPE3 option. PROC GENMOD will be shown in a later chapter. Likelihood Ratio Test Statistic",CD,1324,"['ass', 'significance', 'extra', 'term', 'model', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'two', 'model', 'one', 'model', 'would', 'full', 'model', 'term', 'model', 'would', 'reduced', 'model', 'subset', 'term', 'difference', 'negative', '2', 'log', 'likelihood', 'reduced', 'model', 'negative', '2', 'log', 'likelihood', 'full', 'model', 'value', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'alternative', 'way', 'compute', 'test', 'statistic', 'take', 'difference', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'extra', 'term', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'without', 'extra', 'term', 'degree', 'freedom', 'would', 'difference', 'number', 'term', 'two', 'model', 'test', 'statistic', 'along', 'corresponding', 'pvalue', 'computed', 'using', 'od', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'follows', 'chisquare', 'distribution', 'reduced', 'model', 'subset', 'full', 'model', 'therefore', 'validity', 'test', 'would', 'compromised', 'comparing', 'two', 'entirely', 'different', 'model', 'alternative', 'way', 'compute', 'likelihoodratio', 'test', 'use', 'genmod', 'procedure', 'type3', 'option', 'proc', 'genmod', 'shown', 'later', 'chapter', 'likelihood', 'ratio', 'test', 'statistic']"
593,"Subject-matter knowledge does not always enable you to choose the best predictor variables and the structure for how the predictor variables appear in the model. Thus you are often forced to use the data to make these decisions (Harrell 1997). A common approach in variable selection is to use univariate associations to detect significant predictor variables. Each predictor variable is screened individually and only those with a p-value below an established cutoff (such as .05) are retained for the analysis. However, this approach has serious shortcomings. Because univariate screening does not account for partial associations (effect of one variable changes in the presence of another variable), some predictor variables may be erroneously omitted. Furthermore, the presence of interactions can give misleading univariate associations. A better approach is to consider a subset of variables jointly.",CD,906,"['subjectmatter', 'knowledge', 'doe', 'always', 'enable', 'choose', 'best', 'predictor_variable', 'structure', 'predictor_variable', 'appear', 'model', 'thus', 'often', 'forced', 'use', 'data', 'make', 'decision', 'harrell', '1997', 'common', 'approach', 'variable', 'selection', 'use', 'univariate', 'association', 'detect', 'significant', 'predictor_variable', 'predictor_variable', 'screened', 'individually', 'pvalue', 'established', 'cutoff', '05', 'retained', 'analysis', 'however', 'approach', 'ha', 'serious', 'shortcoming', 'univariate', 'screening', 'doe', 'account', 'partial', 'association', 'effect', 'one', 'variable', 'change', 'presence', 'another', 'variable', 'predictor_variable', 'may', 'erroneously', 'omitted', 'furthermore', 'presence', 'interaction', 'give', 'misleading', 'univariate', 'association', 'better', 'approach', 'consider', 'subset', 'variable', 'jointly']"
594,"Because the mother_age*phy_visit interaction is significant, you need to compute two odds ratios for mother?s age. One odds ratio is for mothers who did visit the physician during the first trimester; the other is for mothers who did not visit the physician during the first trimester. These odds ratios can be computed using the coefficients in the model. To compute the odds ratio of interest, write out the equation for the odds ratio. Solve the expression algebraically and exponentiate the final estimate. The example above shows that among women who went to a physician during the first trimester, women who are 10 years younger are 4.95 times more likely to have a low birth weight baby.",CD,694,"['motheragephyvisit', 'interaction', 'significant', 'need', 'compute', 'two', 'odds_ratio', 'mother', 'age', 'one', 'odds_ratio', 'mother', 'visit', 'physician', 'first', 'trimester', 'mother', 'visit', 'physician', 'first', 'trimester', 'odds_ratio', 'computed', 'using', 'coefficient', 'model', 'compute', 'odds_ratio', 'interest', 'write', 'equation', 'odds_ratio', 'solve', 'expression', 'algebraically', 'exponentiate', 'final', 'estimate', 'example', 'show', 'among', 'woman', 'went', 'physician', 'first', 'trimester', 'woman', '10', 'year', 'younger', '495', 'time', 'likely', 'low', 'birth', 'weight', 'baby']"
595,"Conditional logistic regression is a useful technique when you have paired observations. One example is the matched case-control studies. In the past, the PHREG procedure was usually used to fit a conditional logistic regression model. However, in SAS?9 the STRATA statement in PROC LOGISTIC can be used to fit conditional logistic regression models. An important feature of the conditional logistic model is that the model requires the matched data to be considered in strata. The strata represent the matched sets (paired observations). These models also allow the probabilities to vary by observation within strata. Therefore, the models permit the strata to have their own probability distributions and they account for the dependence of the matched pairs. These models are known as the conditional models because the parameter estimate ? is defined conditional on the subject. The effect is subject-specific, because it is defined at the subject level. This is in contrast to the GEE models which were marginal models. The effects in those models are population-averaged because they refer to averaging over the entire population rather than to individual subjects. For example, in a matched case-control study the probabilities modeled refer to the distribution of Y given X. Although the model permits stratum-specific distributions, it assumes a common effect ?. The parameter ? compares the response distributions. It follows that the conditional model is restricted to estimating ? that are within stratum effects. Thus only the predictor variables that vary within stratum contribute to the likelihood. Conditional models do not estimate a between-stratum effect. Therefore, a predictor variable that is constant within stratum contributes nothing to the likelihood. This is why a coefficient is not estimated for the matching variables. However, the stratum-constant variables are still being controlled for in the model. It should be noted that when there are several observations per stratum, then the GEE models can be used. For 1:1 matched case-control studies, the estimated values in the working correlation matrix are ?1 and the GEE method breaks down. Therefore, the conditional model is the only way to go for case-control matching. A good discussion about the differences between GEE models and conditional logistic models can be found in Allison (1999).",CD,2376,"['conditional', 'logistic_regression', 'useful', 'technique', 'paired', 'observation', 'one', 'example', 'matched', 'casecontrol', 'study', 'past', 'phreg', 'procedure', 'wa', 'usually', 'used', 'fit', 'conditional', 'logistic_regression_model', 'however', 'sas9', 'stratum', 'statement', 'proc_logistic', 'used', 'fit', 'conditional', 'logistic_regression_model', 'important', 'feature', 'conditional', 'logistic', 'model', 'model', 'requires', 'matched', 'data', 'considered', 'stratum', 'stratum', 'represent', 'matched', 'set', 'paired', 'observation', 'model', 'also', 'allow', 'probability', 'vary', 'observation', 'within', 'stratum', 'therefore', 'model', 'permit', 'stratum', 'probability', 'distribution', 'account', 'dependence', 'matched', 'pair', 'model', 'known', 'conditional', 'model', 'parameter_estimate', '', 'defined', 'conditional', 'subject', 'effect', 'subjectspecific', 'defined', 'subject', 'level', 'contrast', 'gee', 'model', 'marginal', 'model', 'effect', 'model', 'populationaveraged', 'refer', 'averaging', 'entire', 'population', 'rather', 'individual', 'subject', 'example', 'matched', 'casecontrol', 'study', 'probability', 'modeled', 'refer', 'distribution', 'given', 'x', 'although', 'model', 'permit', 'stratumspecific', 'distribution', 'assumes', 'common', 'effect', '', 'parameter', '', 'compare', 'response', 'distribution', 'follows', 'conditional', 'model', 'restricted', 'estimating', '', 'within', 'stratum', 'effect', 'thus', 'predictor_variable', 'vary', 'within', 'stratum', 'contribute', 'likelihood', 'conditional', 'model', 'estimate', 'betweenstratum', 'effect', 'therefore', 'predictor_variable', 'constant', 'within', 'stratum', 'contributes', 'nothing', 'likelihood', 'coefficient', 'estimated', 'matching', 'variable', 'however', 'stratumconstant', 'variable', 'still', 'controlled', 'model', 'noted', 'several', 'observation', 'per', 'stratum', 'gee', 'model', 'used', '11', 'matched', 'casecontrol', 'study', 'estimated', 'value', 'working', 'correlation', 'matrix', '1', 'gee', 'method', 'break', 'therefore', 'conditional', 'model', 'way', 'go', 'casecontrol', 'matching', 'good', 'discussion', 'difference', 'gee', 'model', 'conditional', 'logistic', 'model', 'found', 'allison', '1999']"
596,"MAXEIGEN=n	specifies the largest permissible value of the second eigenvalue in each cluster. SHORT	suppresses printing of the cluster structure, scoring coefficient, and intercluster correlation matrices. Selected VARCLUS procedure statement: VAR	specifies the variables to be clustered. If you do not specify the VAR statement, all numeric variables not listed in other statements are processed. Variable Clustering",CD,416,"['maxeigenn\tspecifies', 'largest', 'permissible', 'value', 'second', 'eigenvalue', 'cluster', 'short\tsuppresses', 'printing', 'cluster', 'structure', 'scoring', 'coefficient', 'intercluster', 'correlation', 'matrix', 'selected', 'varclus', 'procedure', 'statement', 'var\tspecifies', 'variable', 'clustered', 'specify', 'var', 'statement', 'numeric', 'variable', 'listed', 'statement', 'processed', 'variable', 'clustering']"
597,"The score test for the proportional odds assumption tends to reject the null hypothesis more often than is warranted. If there are many predictor variables and if the sample size is large, the test usually produces p-values below 0.05 (Allison 1999). Given such a liberal test, it may be useful to graph the cumulative logits to visually inspect the proportional odds assumption. Cumulative logit plots are graphs of cumulative logits for each predictor variable. If the proportional odds assumption is true, then the slopes of the logits should be parallel. If the plotted lines diverge greatly from parallelism, then you should consider a different modeling approach such as modeling generalized logits. Agresti (2002) also recommends trying a link function for which the response curve is nonsymmetric (in other words, complementary log-log), adding additional parameters such as interactions, and adding dispersion parameters. Cumulative Logit Plots",CD,953,"['score', 'test', 'proportional', 'odds', 'assumption', 'tends', 'reject', 'null', 'hypothesis', 'often', 'warranted', 'many', 'predictor_variable', 'sample_size', 'large', 'test', 'usually', 'produce', 'pvalues', '005', 'allison', '1999', 'given', 'liberal', 'test', 'may', 'useful', 'graph', 'cumulative', 'logits', 'visually', 'inspect', 'proportional', 'odds', 'assumption', 'cumulative', 'logit', 'plot', 'graph', 'cumulative', 'logits', 'predictor_variable', 'proportional', 'odds', 'assumption', 'true', 'slope', 'logits', 'parallel', 'plotted', 'line', 'diverge', 'greatly', 'parallelism', 'consider', 'different', 'modeling', 'approach', 'modeling', 'generalized', 'logits', 'agresti', '2002', 'also', 'recommends', 'trying', 'link', 'function', 'response', 'curve', 'nonsymmetric', 'word', 'complementary', 'loglog', 'adding', 'additional', 'parameter', 'interaction', 'adding', 'dispersion', 'parameter', 'cumulative', 'logit', 'plot']"
598,"The modeling-building strategy for ordinal logistic regression is the same as for binary logistic regression. First, do an exploratory data analysis with contingency tables and logit plots. During this stage also look for confounders and interactions. Then try to find a subset of predictor variables that are associated with severity of back pain during pregnancy. In this example, there are 22 predictor variables. With so many variables, there is a good chance that many of them are collinear or redundant. A good strategy in this case is to reduce the number of redundant variables first before you try to build a model. One way to reduce the number of redundant variables is through variable clustering.",CD,708,"['modelingbuilding', 'strategy', 'ordinal', 'logistic_regression', 'binary', 'logistic_regression', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'stage', 'also', 'look', 'confounders', 'interaction', 'try', 'find', 'subset', 'predictor_variable', 'associated', 'severity', 'back', 'pain', 'pregnancy', 'example', '22', 'predictor_variable', 'many', 'variable', 'good', 'chance', 'many', 'collinear', 'redundant', 'good', 'strategy', 'case', 'reduce', 'number', 'redundant', 'variable', 'first', 'try', 'build', 'model', 'one', 'way', 'reduce', 'number', 'redundant', 'variable', 'variable', 'clustering']"
599,"Stepwise selection is similar to forward selection in that it starts with an empty model and incrementally builds a model one variable at a time. However, the method differs from forward selection in that variables already in the model do not necessarily remain. The backward component of the method removes variables from the model that do not meet the significance criteria specified in the SLSTAY= option. The stepwise selection process terminates if no further variable can be added to the model or if the variable just entered into the model is the only variable removed in the subsequent backward elimination. Stepwise selection in PROC LOGISTIC is not an efficient method to select variables. In fact, its performance acutely deteriorates if the full model has over approximately 60 effects (Potts and Patetta 1999). Stepwise selection has some serious shortcomings. Simulation studies (Derksen and Keselman 1992) evaluating variable selection techniques found the following: 1.	The degree of collinearity among the predictor variables affected the frequency with which authentic predictor variables found their way into the final model. 2.	The number of candidate predictor variables affected the number of noise variables that gained entry to the model. 3.	The size of the sample was of little practical importance in determining the number of authentic variables contained in the final model. One recommendation is to use the variable selection methods to create several candidate models, and then use subject-matter knowledge to select the variables that result in the best model within the scientific or business context of the problem. Therefore, you are simply using these methods as a useful tool in the model-building process (Hosmer and Lemeshow 2000).",CD,1769,"['stepwise', 'selection', 'similar', 'forward', 'selection', 'start', 'empty', 'model', 'incrementally', 'build', 'model', 'one', 'variable', 'time', 'however', 'method', 'differs', 'forward', 'selection', 'variable', 'already', 'model', 'necessarily', 'remain', 'backward', 'component', 'method', 'remove', 'variable', 'model', 'meet', 'significance', 'criterion', 'specified', 'slstay', 'option', 'stepwise', 'selection', 'process', 'terminates', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'variable', 'removed', 'subsequent', 'backward', 'elimination', 'stepwise', 'selection', 'proc_logistic', 'efficient', 'method', 'select', 'variable', 'fact', 'performance', 'acutely', 'deteriorates', 'full', 'model', 'ha', 'approximately', '60', 'effect', 'potts', 'patetta', '1999', 'stepwise', 'selection', 'ha', 'serious', 'shortcoming', 'simulation', 'study', 'derksen', 'keselman', '1992', 'evaluating', 'variable', 'selection', 'technique', 'found', 'following', '1\tthe', 'degree', 'collinearity', 'among', 'predictor_variable', 'affected', 'frequency', 'authentic', 'predictor_variable', 'found', 'way', 'final', 'model', '2\tthe', 'number', 'candidate', 'predictor_variable', 'affected', 'number', 'noise', 'variable', 'gained', 'entry', 'model', '3\tthe', 'size', 'sample', 'wa', 'little', 'practical', 'importance', 'determining', 'number', 'authentic', 'variable', 'contained', 'final', 'model', 'one', 'recommendation', 'use', 'variable', 'selection', 'method', 'create', 'several', 'candidate', 'model', 'use', 'subjectmatter', 'knowledge', 'select', 'variable', 'result', 'best', 'model', 'within', 'scientific', 'business', 'context', 'problem', 'therefore', 'simply', 'using', 'method', 'useful', 'tool', 'modelbuilding', 'process', 'hosmer', 'lemeshow', '2000']"
600,title 'Nominal Logistic Regression Model on Alligator Food Data'; run; Selected MODEL statement options: REF=	specifies the reference group for the nominal and binary response model. You can specify the reference category in quotes or the keyword FIRST (designates the first ordered category as the reference) or the keyword LAST (designates the last ordered category as the reference). The default is REF=LAST. LINK=	specifies the function linking the response probabilities to the linear predictors. The keyword GLOGIT requests the generalized logit function. The default is LINK=LOGIT (the log odds function). Nominal Logistic Regression Model on Alligator Food Data,CD,669,"['title', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data', 'run', 'selected', 'model_statement', 'option', 'ref\tspecifies', 'reference', 'group', 'nominal', 'binary', 'response', 'model', 'specify', 'reference', 'category', 'quote', 'keyword', 'first', 'designates', 'first', 'ordered', 'category', 'reference', 'keyword', 'last', 'designates', 'last', 'ordered', 'category', 'reference', 'default', 'reflast', 'link\tspecifies', 'function', 'linking', 'response', 'probability', 'linear', 'predictor', 'keyword', 'glogit', 'request', 'generalized', 'logit', 'function', 'default', 'linklogit', 'log', 'odds', 'function', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data']"
601,"Example:	Compute the deviance and Pearson chi-square statistics, the Hosmer-Lemeshow test, and the generalized R2 statistic on the model with all of the main effects and the mother_age*phy_visit interaction. /* c2demo09a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / aggregate scale=none lackfit rsq; title 'Low Birth Weight Model'; run; Selected MODEL statement options: AGGREGATE	requests that PROC LOGISTIC treat each unique combination of the predictor variable values as a distinct group in computing the goodness-of-fit statistics. SCALE=	specifies the value of the dispersion parameter or the method for estimating the dispersion parameter. This option is normally used to correct for overdispersion or underdispersion, but in this case it is required to display the goodness-of-fit statistics. LACKFIT	performs the Hosmer and Lemeshow goodness-of-fit test for the case of a binary outcome model. RSQ	requests a generalized R2 for the fitted model. Partial Output Deviance and Pearson Goodness-of-Fit Statistics",CD,1131,"['example\tcompute', 'deviance', 'pearson', 'chisquare', 'statistic', 'hosmerlemeshow', 'test', 'generalized', 'r2', 'statistic', 'model', 'main_effect', 'motheragephyvisit', 'interaction', '', 'c2demo09a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'aggregate', 'scalenone', 'lackfit', 'rsq', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'aggregate\trequests', 'proc_logistic', 'treat', 'unique', 'combination', 'predictor_variable', 'value', 'distinct', 'group', 'computing', 'goodnessoffit', 'statistic', 'scale\tspecifies', 'value', 'dispersion', 'parameter', 'method', 'estimating', 'dispersion', 'parameter', 'option', 'normally', 'used', 'correct', 'overdispersion', 'underdispersion', 'case', 'required', 'display', 'goodnessoffit', 'statistic', 'lackfit\tperforms', 'hosmer', 'lemeshow', 'goodnessoffit', 'test', 'case', 'binary', 'outcome', 'model', 'rsq\trequests', 'generalized', 'r2', 'fitted', 'model', 'partial', 'output', 'deviance', 'pearson', 'goodnessoffit', 'statistic']"
602,"The likelihood ratio test is not significant, which means adding an extra degree of freedom to socio did not improve the model. Unless treating socio as a classification variable has subject- matter importance, the model with a continuous socio would be the model of choice.",CD,274,"['likelihood', 'ratio', 'test', 'significant', 'mean', 'adding', 'extra', 'degree', 'freedom', 'socio', 'improve', 'model', 'unless', 'treating', 'socio', 'classification', 'variable', 'ha', 'subject', 'matter', 'importance', 'model', 'continuous', 'socio', 'would', 'model', 'choice']"
603,"The equation for the logistic regression model that refers directly to the probability of the outcome is shown above. This equation has the desired property that the predicted probabilities will always be between 0 and 1. This model is nonlinear because the parameter estimates do not enter the model equation linearly. Furthermore, the model permits the rate of change of the probabilities to vary as the predictor variable values vary.",CD,437,"['equation', 'logistic_regression_model', 'refers', 'directly', 'probability', 'outcome', 'shown', 'equation', 'ha', 'desired', 'property', 'predicted', 'probability', 'always', '0', '1', 'model', 'nonlinear', 'parameter_estimate', 'enter', 'model', 'equation', 'linearly', 'furthermore', 'model', 'permit', 'rate', 'change', 'probability', 'vary', 'predictor_variable', 'value', 'vary']"
604,"Least squares estimators for the model parameters are not used in logistic regression because the variance of the outcome is not constant across the values of the predictor variable. Because of the nonconstant variance, least squares parameter estimates are not efficient (other estimation methods yield smaller standard errors) and the standard error estimates are not consistent (the estimated standard errors could be biased). Therefore, the method of maximum likelihood is used to produce estimators that are consistent, asymptotically efficient, and asymptotically normal. This method finds the parameter estimates that are most likely to occur, given the data, by maximizing the likelihood function, which expresses the probability of the observed data as a function of the unknown parameters.",CD,799,"['least', 'square', 'estimator', 'model', 'parameter', 'used', 'logistic_regression', 'variance', 'outcome', 'constant', 'across', 'value', 'predictor_variable', 'nonconstant', 'variance', 'least', 'square', 'parameter_estimate', 'efficient', 'estimation', 'method', 'yield', 'smaller', 'standard_error', 'standard_error', 'estimate', 'consistent', 'estimated', 'standard_error', 'could', 'biased', 'therefore', 'method', 'maximum', 'likelihood', 'used', 'produce', 'estimator', 'consistent', 'asymptotically', 'efficient', 'asymptotically', 'normal', 'method', 'find', 'parameter_estimate', 'likely', 'occur', 'given', 'data', 'maximizing', 'likelihood', 'function', 'express', 'probability', 'observed', 'data', 'function', 'unknown', 'parameter']"
605,"In conclusion, careful exploratory data analysis may help you identify scientifically relevant variables to include in your candidate model. Exploratory data analysis may also help you build a model that better depicts the relationships you are studying. Relying on the variable selection techniques in PROC LOGISTIC is no substitute for this stage in the modeling process. 1.3	Subsets Selection Methods",CD,403,"['conclusion', 'careful', 'exploratory', 'data', 'analysis', 'may', 'help', 'identify', 'scientifically', 'relevant', 'variable', 'include', 'candidate', 'model', 'exploratory', 'data', 'analysis', 'may', 'also', 'help', 'build', 'model', 'better', 'depicts', 'relationship', 'studying', 'relying', 'variable', 'selection', 'technique', 'proc_logistic', 'substitute', 'stage', 'modeling', 'process', '13\tsubsets', 'selection', 'method']"
606,"Because there is a common slope for each predictor variable, the odds ratio is constant for all the categories. The odds ratios can be interpreted as the effect of the predictor variable on the odds of being in a lower ordered value category rather than in a higher ordered value category, regardless of what cumulative logit you are examining. If you use the DESCENDING option in the PROC LOGISTIC statement, the odds ratio is the effect of the predictor variable on the odds of being in a higher rather than a lower category. For example, suppose the odds ratio for bending is 3.0 and you used the DESCENDING option (category=severe is the first ordered category and category=none is the last ordered category). You can interpret the odds ratio by stating the women who say that bending aggravates their back pain have 3 times the odds of being in a higher pain severity category compared to women who say that bending does not aggravate their back pain.",CD,956,"['common', 'slope', 'predictor_variable', 'odds_ratio', 'constant', 'category', 'odds_ratio', 'interpreted', 'effect', 'predictor_variable', 'odds', 'lower', 'ordered', 'value', 'category', 'rather', 'higher', 'ordered', 'value', 'category', 'regardless', 'cumulative', 'logit', 'examining', 'use', 'descending', 'option', 'proc_logistic', 'statement', 'odds_ratio', 'effect', 'predictor_variable', 'odds', 'higher', 'rather', 'lower', 'category', 'example', 'suppose', 'odds_ratio', 'bending', '30', 'used', 'descending', 'option', 'categorysevere', 'first', 'ordered', 'category', 'categorynone', 'last', 'ordered', 'category', 'interpret', 'odds_ratio', 'stating', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '3', 'time', 'odds', 'higher', 'pain', 'severity', 'category', 'compared', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain']"
607,"Example:	To assess the significance of the interaction mother_age*phy_visit, run a model with the interaction and one with no interaction. Use ODS to calculate the likelihood ratio test statistics between the main effects model and the interaction model. Use the GLOBALTESTS output object, which contains the likelihood ratio chi-square statistic. /* c1demo06a */ ods listing close;",CD,382,"['example\tto', 'ass', 'significance', 'interaction', 'motheragephyvisit', 'run', 'model', 'interaction', 'one', 'interaction', 'use', 'od', 'calculate', 'likelihood', 'ratio', 'test', 'statistic', 'main_effect', 'model', 'interaction', 'model', 'use', 'globaltests', 'output', 'object', 'contains', 'likelihood', 'ratio', 'chisquare', 'statistic', '', 'c1demo06a', '', 'od', 'listing', 'close']"
608,"The goal of conditional exact inference is to determine how likely the observed sequence of binary response values is with respect to all other sequences of binary response values having the same sufficient statistics for the nuisance parameters. All possible sequences of binary response values is referred to as the permutation distribution. To accomplish this goal, the conditional permutation distribution for the sufficient statistics of the parameters of interest needs to be generated. In other words, for every possible sequence of binary responses, the sufficient statistics for the parameters needs to be computed. A simple example illustrates the method. Suppose you had 5 observations in your data with a binary response variable and a dummy-coded predictor variable (values of 0 or 1). The observed data values are on the above slide. The sufficient statistic values are 1 for the intercept and 1 for the parameter for the dummy-coded predictor variable. The number of possible sequences of response values is 32 (25).",CD,1031,"['goal', 'conditional', 'exact', 'inference', 'determine', 'likely', 'observed', 'sequence', 'binary', 'response', 'value', 'respect', 'sequence', 'binary', 'response', 'value', 'sufficient', 'statistic', 'nuisance', 'parameter', 'possible', 'sequence', 'binary', 'response', 'value', 'referred', 'permutation', 'distribution', 'accomplish', 'goal', 'conditional', 'permutation', 'distribution', 'sufficient', 'statistic', 'parameter', 'interest', 'need', 'generated', 'word', 'every', 'possible', 'sequence', 'binary', 'response', 'sufficient', 'statistic', 'parameter', 'need', 'computed', 'simple', 'example', 'illustrates', 'method', 'suppose', '5', 'observation', 'data', 'binary', 'response_variable', 'dummycoded', 'predictor_variable', 'value', '0', '1', 'observed', 'data', 'value', 'slide', 'sufficient', 'statistic', 'value', '1', 'intercept', '1', 'parameter', 'dummycoded', 'predictor_variable', 'number', 'possible', 'sequence', 'response', 'value', '32', '25']"
609,"Because the response variable has more than 2 levels, by default PROC LOGISTIC models cumulative logits. With the DESCENDING option, the probabilities modeled are cumulated by the jth category and higher. Score Test for the Proportional Odds Assumption",CD,252,"['response_variable', 'ha', '2', 'level', 'default', 'proc_logistic', 'model', 'cumulative', 'logits', 'descending', 'option', 'probability', 'modeled', 'cumulated', 'jth', 'category', 'higher', 'score', 'test', 'proportional', 'odds', 'assumption']"
610,The plot of the change in the deviance by predicted probabilities shows several observations that need to be examined. The points in the upper-left corner represent women who had low birth weight babies with very favorable covariate patterns. The points in the upper-right corner represent women who had normal weight babies with very unfavorable covariate patterns. Careful examination of these observations may lead to strategies to improve the fit of the model (Hosmer and Lemeshow 2000). Example:	Generate a bubble plot of the change in the Pearson chi-square statistic by predicted probabilities with the plotting symbol proportional to the c diagnostic statistic. Create an ActiveX graph in HTML output. /* c2demo11c */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difchisq=difchisq c=c; run;,CD,942,"['plot', 'change', 'deviance', 'predicted', 'probability', 'show', 'several', 'observation', 'need', 'examined', 'point', 'upperleft', 'corner', 'represent', 'woman', 'low', 'birth', 'weight', 'baby', 'favorable', 'covariate', 'pattern', 'point', 'upperright', 'corner', 'represent', 'woman', 'normal', 'weight', 'baby', 'unfavorable', 'covariate', 'pattern', 'careful', 'examination', 'observation', 'may', 'lead', 'strategy', 'improve', 'fit', 'model', 'hosmer', 'lemeshow', '2000', 'example\tgenerate', 'bubble', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'plotting', 'symbol', 'proportional', 'c', 'diagnostic', 'statistic', 'create', 'activex', 'graph', 'html', 'output', '', 'c2demo11c', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difchisqdifchisq', 'cc', 'run']"
611,"The algorithm for variable clustering starts off with all the variables in one cluster. A principal components analysis is then done on the variables and the algorithm examines the eigenvalues computed for each principal component. Eigenvalues measure how much variability is explained by the principal components. They are scaled so that the sum of the eigenvalues is equal to the number of variables. When the predictor variables are uncorrelated, then all of the eigenvalues equal 1. If there is only one group of variables that is related to each other, then the first eigenvalue (corresponding to the first principal component) is large and the others are all close to 0. However, if there are several groups of related variables, then several eigenvalues are much larger than 1. The algorithm examines the second eigenvalue because that determines whether there is more than one dominant dimension in the variable cluster. If the second eigenvalue is greater than a specified threshold, then the variable cluster is split into 2 groups. The process is repeated until the second eigenvalue drops below the threshold. Larger thresholds for the second eigenvalue give fewer clusters and less variation is explained among the predictor variables. Smaller thresholds give more clusters and more variation is explained. The default threshold is 1 because it represents the average size of the eigenvalues (if the correlation matrix is analyzed). To account for sampling variability, smaller values such as .70 have been suggested (Jackson 1991). However, the threshold should be chosen based on the results of variable clustering.",CD,1630,"['algorithm', 'variable', 'clustering', 'start', 'variable', 'one', 'cluster', 'principal', 'component', 'analysis', 'done', 'variable', 'algorithm', 'examines', 'eigenvalue', 'computed', 'principal', 'component', 'eigenvalue', 'measure', 'much', 'variability', 'explained', 'principal', 'component', 'scaled', 'sum', 'eigenvalue', 'equal', 'number', 'variable', 'predictor_variable', 'uncorrelated', 'eigenvalue', 'equal', '1', 'one', 'group', 'variable', 'related', 'first', 'eigenvalue', 'corresponding', 'first', 'principal', 'component', 'large', 'others', 'close', '0', 'however', 'several', 'group', 'related', 'variable', 'several', 'eigenvalue', 'much', 'larger', '1', 'algorithm', 'examines', 'second', 'eigenvalue', 'determines', 'whether', 'one', 'dominant', 'dimension', 'variable', 'cluster', 'second', 'eigenvalue', 'greater', 'specified', 'threshold', 'variable', 'cluster', 'split', '2', 'group', 'process', 'repeated', 'second', 'eigenvalue', 'drop', 'threshold', 'larger', 'threshold', 'second', 'eigenvalue', 'give', 'fewer', 'cluster', 'le', 'variation', 'explained', 'among', 'predictor_variable', 'smaller', 'threshold', 'give', 'cluster', 'variation', 'explained', 'default', 'threshold', '1', 'represents', 'average', 'size', 'eigenvalue', 'correlation', 'matrix', 'analyzed', 'account', 'sampling', 'variability', 'smaller', 'value', '70', 'suggested', 'jackson', '1991', 'however', 'threshold', 'chosen', 'based', 'result', 'variable', 'clustering']"
612,"For the 2-dependent correlation structure (TYPE=MDEP(2)), measurements are correlated if they are two or less time periods apart. Measurements that are one time period apart have different correlations than measurements that are two time periods apart. These last two correlation structures are generally called m-dependent correlation structures. The m represents how many time periods apart the measurements are still correlated. Therefore, a 5- dependent correlation structure would indicate that measurements are correlated if they are five or fewer time periods apart.",CD,573,"['2dependent', 'correlation_structure', 'typemdep2', 'measurement', 'correlated', 'two', 'le', 'time', 'period', 'apart', 'measurement', 'one', 'time', 'period', 'apart', 'different', 'correlation', 'measurement', 'two', 'time', 'period', 'apart', 'last', 'two', 'correlation_structure', 'generally', 'called', 'mdependent', 'correlation_structure', 'represents', 'many', 'time', 'period', 'apart', 'measurement', 'still', 'correlated', 'therefore', '5', 'dependent', 'correlation_structure', 'would', 'indicate', 'measurement', 'correlated', 'five', 'fewer', 'time', 'period', 'apart']"
613,"The likelihood ratio statistic that compares the main effects model to the interaction model is clearly significant at the 0.05 level. Therefore, a candidate final model should include the mother_age*phy_visit interaction and the main effects. Example:	Compute a likelihood ratio test comparing a model treating socio as a continuous variable and a model treating socio as a classification variable. /* c1demo06e */ ods listing close;",CD,434,"['likelihood', 'ratio', 'statistic', 'compare', 'main_effect', 'model', 'interaction', 'model', 'clearly', 'significant', '005', 'level', 'therefore', 'candidate', 'final', 'model', 'include', 'motheragephyvisit', 'interaction', 'main_effect', 'example\tcompute', 'likelihood', 'ratio', 'test', 'comparing', 'model', 'treating', 'socio', 'continuous', 'variable', 'model', 'treating', 'socio', 'classification', 'variable', '', 'c1demo06e', '', 'od', 'listing', 'close']"
614,"random component	identifies the response variable and its probability distribution. systematic component	specifies the predictor variables used in a linear predictor. link function	specifies the function of E(Y) that the model equates to the systematic component. For the general linear model, the link function is the identity link (modeling the mean), the response variable is normally distributed, and the variance is constant. For logistic regression, the link function is the logit link ( ) and the response variable follows a binomial distribution (a common distribution for binary outcomes). For Poisson regression, the link function is the natural log and the response variable follows the Poisson distribution. The link function that transforms the mean to the natural location parameter is called the canonical link. For example, in the normal distribution the natural location parameter is the mean. Models with canonical links usually make the best sense on scientific grounds, but you can choose other link functions besides the canonical links. ?	The reason for restricting the distribution of the response variable to the family of exponential distributions is that the same algorithm to compute maximum likelihood parameter estimates applies to this entire family for any choice of link function.",CD,1312,"['random', 'component\tidentifies', 'response_variable', 'probability', 'distribution', 'systematic', 'component\tspecifies', 'predictor_variable', 'used', 'linear', 'predictor', 'link', 'function\tspecifies', 'function', 'ey', 'model', 'equates', 'systematic', 'component', 'general', 'linear', 'model', 'link', 'function', 'identity', 'link', 'modeling', 'mean', 'response_variable', 'normally', 'distributed', 'variance', 'constant', 'logistic_regression', 'link', 'function', 'logit', 'link', '', '', 'response_variable', 'follows', 'binomial', 'distribution', 'common', 'distribution', 'binary', 'outcome', 'poisson', 'regression', 'link', 'function', 'natural', 'log', 'response_variable', 'follows', 'poisson', 'distribution', 'link', 'function', 'transforms', 'mean', 'natural', 'location', 'parameter', 'called', 'canonical', 'link', 'example', 'normal', 'distribution', 'natural', 'location', 'parameter', 'mean', 'model', 'canonical', 'link', 'usually', 'make', 'best', 'sense', 'scientific', 'ground', 'choose', 'link', 'function', 'besides', 'canonical', 'link', '\tthe', 'reason', 'restricting', 'distribution', 'response_variable', 'family', 'exponential', 'distribution', 'algorithm', 'compute', 'maximum', 'likelihood', 'parameter_estimate', 'applies', 'entire', 'family', 'choice', 'link', 'function']"
615,"random component	identifies the response variable and its probability distribution. systematic component	specifies the predictor variables used in a linear predictor. link function	specifies the function of E(Y) that the model equates to the systematic component. For the general linear model, the link function is the identity link (modeling the mean), the response variable is normally distributed, and the variance is constant. For logistic regression, the link function is the logit link ( ) and the response variable follows a binomial distribution (a common distribution for binary outcomes). For Poisson regression, the link function is the natural log and the response variable follows the Poisson distribution. The link function that transforms the mean to the natural location parameter is called the canonical link. For example, in the normal distribution the natural location parameter is the mean. Models with canonical links usually make the best sense on scientific grounds, but you can choose other link functions besides the canonical links. ?	The reason for restricting the distribution of the response variable to the family of exponential distributions is that the same algorithm to compute maximum likelihood parameter estimates applies to this entire family for any choice of link function.",CD,1312,"['random', 'component\tidentifies', 'response_variable', 'probability', 'distribution', 'systematic', 'component\tspecifies', 'predictor_variable', 'used', 'linear', 'predictor', 'link', 'function\tspecifies', 'function', 'ey', 'model', 'equates', 'systematic', 'component', 'general', 'linear', 'model', 'link', 'function', 'identity', 'link', 'modeling', 'mean', 'response_variable', 'normally', 'distributed', 'variance', 'constant', 'logistic_regression', 'link', 'function', 'logit', 'link', '', '', 'response_variable', 'follows', 'binomial', 'distribution', 'common', 'distribution', 'binary', 'outcome', 'poisson', 'regression', 'link', 'function', 'natural', 'log', 'response_variable', 'follows', 'poisson', 'distribution', 'link', 'function', 'transforms', 'mean', 'natural', 'location', 'parameter', 'called', 'canonical', 'link', 'example', 'normal', 'distribution', 'natural', 'location', 'parameter', 'mean', 'model', 'canonical', 'link', 'usually', 'make', 'best', 'sense', 'scientific', 'ground', 'choose', 'link', 'function', 'besides', 'canonical', 'link', '\tthe', 'reason', 'restricting', 'distribution', 'response_variable', 'family', 'exponential', 'distribution', 'algorithm', 'compute', 'maximum', 'likelihood', 'parameter_estimate', 'applies', 'entire', 'family', 'choice', 'link', 'function']"
616,The overlay plot of the ROC curves clearly shows that the model with the interaction is the superior model with regard to predictive accuracy. 2.2	Logistic Regression Diagnostics,CD,178,"['overlay', 'plot', 'roc', 'curve', 'clearly', 'show', 'model', 'interaction', 'superior', 'model', 'regard', 'predictive', 'accuracy', '22\tlogistic', 'regression', 'diagnostics']"
617,WARNING: The maximum likelihood estimate may not exist. WARNING: The LOGISTIC procedure continues in spite of the above warning. Results shown are based on the last maximum likelihood iteration. Validity of the model fit is questionable.,CD,237,"['warning', 'maximum', 'likelihood', 'estimate', 'may', 'exist', 'warning', 'logistic', 'procedure', 'continues', 'spite', 'warning', 'result', 'shown', 'based', 'last', 'maximum', 'likelihood', 'iteration', 'validity', 'model', 'fit', 'questionable']"
618,"PROC FREQ was used to compute a crude odds ratio for each of the binary predictor variables while PROC LOGISTIC was used to compute a crude odds ratio for the continuous variables and an adjusted odds ratio for all the variables. A comparison of the crude odds ratios and the adjusted odds ratios show relatively large changes. Previous preterm deliveries showed a large decrease while uterine irritability went from a significant crude odds ratio to a nonsignificant adjusted odds ratio. History of hypertension showed a large increase in the odds ratio, but the large confidence interval indicates data sparseness.",CD,616,"['proc', 'freq', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'binary', 'predictor_variable', 'proc_logistic', 'wa', 'used', 'compute', 'crude', 'odds_ratio', 'continuous', 'variable', 'adjusted', 'odds_ratio', 'variable', 'comparison', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'show', 'relatively', 'large', 'change', 'previous', 'preterm', 'delivery', 'showed', 'large', 'decrease', 'uterine', 'irritability', 'went', 'significant', 'crude', 'odds_ratio', 'nonsignificant', 'adjusted', 'odds_ratio', 'history', 'hypertension', 'showed', 'large', 'increase', 'odds_ratio', 'large', 'confidence', 'interval', 'indicates', 'data', 'sparseness']"
619,"Example: 	Select a subset of variables using the forward selection method. In the MODEL statement specify all the main effects and two-factor interactions. Examine the differences in which variables were selected when you use HIERARCHY=SINGLE and when you include all the main effects in the model to assess interactions. /* c1demo04a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age|phy_visit|alcohol|hist_hyp| mother_wt|prev_pretrm|socio|uterine_irr @2 / selection=forward slentry=.05 hierarchy=single; title 'Low Birth Weight Model'; run; Selected MODEL statement options: SELECTION= 	specifies the method used to select the variables in the model. SLENTRY=	specifies the significance level for entry into the model. HIERARCHY=	specifies how model hierarchy is to be applied. Available methods are NONE, SINGLE, MULTIPLE, SINGLECLASS (same as HIERACHY=SINGLE except only class variables are subject to the hierarchy requirement), and MULTIPLECLASS (same as HIERACHY=MULTIPLE except only the class variables are subject to the hierarchy requirement). ?	The bar notation with @2 constructs a model with all the main effects and the two-factor interactions. If you increased it to @3, then you would construct a model with all of the main effects, the two-factor interactions, and the three factor interactions. Low Birth Weight Model",CD,1354,"['example', '\tselect', 'subset', 'variable', 'using', 'forward', 'selection', 'method', 'model_statement', 'specify', 'main_effect', 'twofactor', 'interaction', 'examine', 'difference', 'variable', 'selected', 'use', 'hierarchysingle', 'include', 'main_effect', 'model', 'ass', 'interaction', '', 'c1demo04a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motheragephyvisitalcoholhisthyp', 'motherwtprevpretrmsociouterineirr', '2', '', 'selectionforward', 'slentry05', 'hierarchysingle', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'selection', '\tspecifies', 'method', 'used', 'select', 'variable', 'model', 'slentry\tspecifies', 'significance', 'level', 'entry', 'model', 'hierarchy\tspecifies', 'model', 'hierarchy', 'applied', 'available', 'method', 'none', 'single', 'multiple', 'singleclass', 'hierachysingle', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', 'multipleclass', 'hierachymultiple', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', '\tthe', 'bar', 'notation', '2', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'increased', '3', 'would', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'three', 'factor', 'interaction', 'low', 'birth', 'weight', 'model']"
620,The forward selection procedure starts with no variables in the model. At each step the variable with the largest adjusted chi-square statistic is entered into the model if its p-value is lower than the specified significance level. The residual chi-square tests the significance of the variables not in the model. Step 1. Effect prev_pretrm entered: Model Convergence Status,CD,375,"['forward', 'selection', 'procedure', 'start', 'variable', 'model', 'step', 'variable', 'largest', 'adjusted', 'chisquare', 'statistic', 'entered', 'model', 'pvalue', 'lower', 'specified', 'significance', 'level', 'residual', 'chisquare', 'test', 'significance', 'variable', 'model', 'step', '1', 'effect', 'prevpretrm', 'entered', 'model', 'convergence', 'status']"
621,"Hosmer and Lemeshow (2000) also recommend plotting the diagnostic statistics by the predicted probabilities where the size of the plotting symbol is proportional to the effect of each covariate pattern on the value of the estimated parameters. The GPLOT procedure can accomplish this with the use of a bubble plot. In the bubble plot above, the size of the bubbles is proportional to the c diagnostic statistic. In general, the largest values of the c diagnostic statistic are likely to occur when the change in the Pearson chi-square is large or when the leverage is large (the diagonal of the hat matrix). The position of the bubbles in the graph can give a general idea which statistic contributed to the high c diagnostic statistic. For example, if the large bubbles occur in the upper-right or upper-left corner, then the change in the Pearson chi-square contributed the most to the high c diagnostic statistic because leverage values tend to be low when the estimated probabilities are below .10 or above .90. However, if the bubbles fall in the bottom of the cup defined by the two quadratic curves, then the leverage values contributed the most to the high c diagnostic statistic. The points in the plot that are of greatest concern are those with large circles falling within the cup. These correspond to covariate patterns that are not fit very well and have high leverage values (Hosmer and Lemeshow 2000). The formula for the c diagnostic is:",CD,1454,"['hosmer', 'lemeshow', '2000', 'also', 'recommend', 'plotting', 'diagnostic', 'statistic', 'predicted', 'probability', 'size', 'plotting', 'symbol', 'proportional', 'effect', 'covariate', 'pattern', 'value', 'estimated', 'parameter', 'gplot', 'procedure', 'accomplish', 'use', 'bubble', 'plot', 'bubble', 'plot', 'size', 'bubble', 'proportional', 'c', 'diagnostic', 'statistic', 'general', 'largest', 'value', 'c', 'diagnostic', 'statistic', 'likely', 'occur', 'change', 'pearson', 'chisquare', 'large', 'leverage', 'large', 'diagonal', 'hat', 'matrix', 'position', 'bubble', 'graph', 'give', 'general', 'idea', 'statistic', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'example', 'large', 'bubble', 'occur', 'upperright', 'upperleft', 'corner', 'change', 'pearson', 'chisquare', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'leverage', 'value', 'tend', 'low', 'estimated', 'probability', '10', '90', 'however', 'bubble', 'fall', 'bottom', 'cup', 'defined', 'two', 'quadratic', 'curve', 'leverage', 'value', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'point', 'plot', 'greatest', 'concern', 'large', 'circle', 'falling', 'within', 'cup', 'correspond', 'covariate', 'pattern', 'fit', 'well', 'high', 'leverage', 'value', 'hosmer', 'lemeshow', '2000', 'formula', 'c', 'diagnostic']"
622,"Example:	Fit a GEE model on the wheezing data and specify the probability of wheezing as the response of interest, the unstructured correlation structure, reference cell coding for smoker with No as the reference cell, and request the Type 3 score statistics, the final working correlation matrix, and the model-based standard errors. Also compute the odds ratio comparing smokers to non-smokers and a one-year decrease in age. /* c3demo13a */ proc genmod data=sasuser.wheeze desc; class case smoker(param=ref ref='No'); model wheeze = smoker age / dist=bin type3; repeated subject = case / corrw modelse type=unstr; estimate 'smoking' smoker 1 / exp; estimate 'age' age -1 / exp; title 'GEE Model of Wheezing among Children'; run; Selected PROC GENMOD statement option: DESC	reverses the sort order for the levels of the outcome variable. Selected CLASS statement options: PARAM= 	specifies the parameterization method for the classification variable or variables. The default is PARAM=GLM. REF=	specifies the reference level for PARAM=EFFECT, PARAM=REF, and their orthogonalizations. For an individual variable, you can specify the level of the variable to use as the reference level. For a global or individual variable, you can use one of the following keywords: 	FIRST	designates the first ordered level as the reference. 	LAST	designates the last ordered level as the reference. This is the default. Selected MODEL statement options: DIST= 	specifies the built-in probability distribution to use in the model. The default link function for the binomial distribution is the logit link function. TYPE3	requests that Type 3 score statistics be computed for each effect that is specified in the MODEL statement. Likelihood ratio statistics are produced for models that are not GEE models. Selected REPEATED statement options: CORRW	specifies that the final working correlation matrix be printed. MODELSE	displays an analysis of parameter estimates table using model-based standard errors. Selected ESTIMATE statement option: EXP	requests that the exponentiated contrast, its standard error, and the confidence bounds be computed. ?	If the repeated measurements are not in the proper order or if there are missing time points for some subjects, then the WITHIN= option in the REPEATED statement should be used. This option names a variable that specifies the order of measurements within subjects. Variables used in the WITHIN= option must also be listed in the CLASS statement. !	In SAS 9.1, you get an invalid reference level error if REF=?level? is used for two or more variables. The solution is to use REF=FIRST or REF=LAST for binary variables. This problem has been fixed in SAS 9.2. GEE Model of Wheezing among Children",CD,2728,"['example\tfit', 'gee', 'model', 'wheezing', 'data', 'specify', 'probability', 'wheezing', 'response', 'interest', 'unstructured', 'correlation_structure', 'reference', 'cell', 'coding', 'smoker', 'reference', 'cell', 'request', 'type', '3', 'score', 'statistic', 'final', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'also', 'compute', 'odds_ratio', 'comparing', 'smoker', 'nonsmoker', 'oneyear', 'decrease', 'age', '', 'c3demo13a', '', 'proc', 'genmod', 'datasasuserwheeze', 'desc', 'class', 'case', 'smokerparamref', 'refno', 'model', 'wheeze', '', 'smoker', 'age', '', 'distbin', 'type3', 'repeated', 'subject', '', 'case', '', 'corrw', 'modelse', 'typeunstr', 'estimate', 'smoking', 'smoker', '1', '', 'exp', 'estimate', 'age', 'age', '1', '', 'exp', 'title', 'gee', 'model', 'wheezing', 'among', 'child', 'run', 'selected', 'proc', 'genmod', 'statement', 'option', 'desc\treverses', 'sort', 'order', 'level', 'outcome', 'variable', 'selected', 'class', 'statement', 'option', 'param', '\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'default', 'paramglm', 'ref\tspecifies', 'reference', 'level', 'parameffect', 'paramref', 'orthogonalizations', 'individual', 'variable', 'specify', 'level', 'variable', 'use', 'reference', 'level', 'global', 'individual', 'variable', 'use', 'one', 'following', 'keywords', '\tfirst\tdesignates', 'first', 'ordered', 'level', 'reference', '\tlast\tdesignates', 'last', 'ordered', 'level', 'reference', 'default', 'selected', 'model_statement', 'option', 'dist', '\tspecifies', 'builtin', 'probability', 'distribution', 'use', 'model', 'default', 'link', 'function', 'binomial', 'distribution', 'logit', 'link', 'function', 'type3\trequests', 'type', '3', 'score', 'statistic', 'computed', 'effect', 'specified', 'model_statement', 'likelihood', 'ratio', 'statistic', 'produced', 'model', 'gee', 'model', 'selected', 'repeated', 'statement', 'option', 'corrw\tspecifies', 'final', 'working', 'correlation', 'matrix', 'printed', 'modelse\tdisplays', 'analysis', 'parameter_estimate', 'table', 'using', 'modelbased', 'standard_error', 'selected', 'estimate', 'statement', 'option', 'exp\trequests', 'exponentiated', 'contrast', 'standard_error', 'confidence', 'bound', 'computed', '\tif', 'repeated', 'measurement', 'proper', 'order', 'missing', 'time', 'point', 'subject', 'within', 'option', 'repeated', 'statement', 'used', 'option', 'name', 'variable', 'specifies', 'order', 'measurement', 'within', 'subject', 'variable', 'used', 'within', 'option', 'must', 'also', 'listed', 'class', 'statement', '\tin', 'sa', '91', 'get', 'invalid', 'reference', 'level', 'error', 'reflevel', 'used', 'two', 'variable', 'solution', 'use', 'reffirst', 'reflast', 'binary', 'variable', 'problem', 'ha', 'fixed', 'sa', '92', 'gee', 'model', 'wheezing', 'among', 'child']"
623,"The analyst should be aware that after the predictor variables have been chosen based on subject- matter knowledge, refitting many submodels in terms of an optimum fit to the data distorts the significance levels of conventional statistical tests. Basically, you are using the data to make decisions about the form of the model. After a model is developed, the entire modeling process is routinely forgotten, and statistical quantities such as standard errors, confidence limits, p-values, and R-squared are computed as if the resulting model was entirely prespecified. These inferences are inaccurate, tending to err on the side of overstating the significance of predictors and making predictions with overly optimistic confidence. This problem is very evident when there are many iterative stages in model building. When there are many variables and you use stepwise selection to find a small subset of variables, inferences become less accurate (Chatfield 1995, Raftery 1994, Freedman 1983). One solution to this problem is to split your data. One part could be used for finding the regression model and the other part could be used for inference. However, if your data set is small, the loss of efficiency can be prohibitive (Faraway 1992). Another solution is to use bootstrapping methods to obtain the correct standard errors and p-values. Bootstrapping is a resampling method that tries to approximate the distribution of the parameter estimates to estimate the standard error. Unfortunately, bootstrapping is not part of PROC LOGISTIC and the computer programming is beyond the scope of this course.",CD,1608,"['analyst', 'aware', 'predictor_variable', 'chosen', 'based', 'subject', 'matter', 'knowledge', 'refitting', 'many', 'submodels', 'term', 'optimum', 'fit', 'data', 'distorts', 'significance', 'level', 'conventional', 'statistical', 'test', 'basically', 'using', 'data', 'make', 'decision', 'form', 'model', 'model', 'developed', 'entire', 'modeling', 'process', 'routinely', 'forgotten', 'statistical', 'quantity', 'standard_error', 'confidence', 'limit', 'pvalues', 'rsquared', 'computed', 'resulting', 'model', 'wa', 'entirely', 'prespecified', 'inference', 'inaccurate', 'tending', 'err', 'side', 'overstating', 'significance', 'predictor', 'making', 'prediction', 'overly', 'optimistic', 'confidence', 'problem', 'evident', 'many', 'iterative', 'stage', 'model', 'building', 'many', 'variable', 'use', 'stepwise', 'selection', 'find', 'small', 'subset', 'variable', 'inference', 'become', 'le', 'accurate', 'chatfield', '1995', 'raftery', '1994', 'freedman', '1983', 'one', 'solution', 'problem', 'split', 'data', 'one', 'part', 'could', 'used', 'finding', 'regression_model', 'part', 'could', 'used', 'inference', 'however', 'data_set', 'small', 'loss', 'efficiency', 'prohibitive', 'faraway', '1992', 'another', 'solution', 'use', 'bootstrapping', 'method', 'obtain', 'correct', 'standard_error', 'pvalues', 'bootstrapping', 'resampling', 'method', 'try', 'approximate', 'distribution', 'parameter_estimate', 'estimate', 'standard_error', 'unfortunately', 'bootstrapping', 'part', 'proc_logistic', 'computer', 'programming', 'beyond', 'scope', 'course']"
624,"In some estimation problems, you need to be able to summarize the information in the sample or find some function in the sample that tells you just as much about the parameter of interest as the sample itself. This function is sufficient for estimation purposes and therefore is called a sufficient statistic. In other words, a sufficient statistic condenses the data in such a way that no information is lost about the parameter. When a statistic loses no information, it contains all the information about the parameter that is contained in the sample. There can be more than one set of sufficient statistics. A minimal sufficient statistic is the most condensed summary of the data.",CD,685,"['estimation', 'problem', 'need', 'able', 'summarize', 'information', 'sample', 'find', 'function', 'sample', 'tell', 'much', 'parameter', 'interest', 'sample', 'function', 'sufficient', 'estimation', 'purpose', 'therefore', 'called', 'sufficient', 'statistic', 'word', 'sufficient', 'statistic', 'condenses', 'data', 'way', 'information', 'lost', 'parameter', 'statistic', 'loses', 'information', 'contains', 'information', 'parameter', 'contained', 'sample', 'one', 'set', 'sufficient', 'statistic', 'minimal', 'sufficient', 'statistic', 'condensed', 'summary', 'data']"
625,"The variables that are significant at the 0.05 significance level are smoking status, previous preterm delivery, presence of uterine irritability, and history of hypertension. Analysis of Maximum Likelihood Estimates",CD,216,"['variable', 'significant', '005', 'significance', 'level', 'smoking', 'status', 'previous', 'preterm', 'delivery', 'presence', 'uterine', 'irritability', 'history', 'hypertension', 'analysis', 'maximum', 'likelihood', 'estimate']"
626,"PROC LOGISTIC also produces statistics that measure predictive power. These statistics are not the same as the goodness-of-fit statistics because models with high predictive power do not necessarily have a good fit to the data (and vice versa). One statistic that measures predictive power is the generalized R2. It is based on the likelihood ratio chi-square for testing the null hypothesis that all of the slope parameters are 0. However, it uses the likelihood values (L1 and L0) rather than the log- likelihood values and it is adjusted by the sample size n. It can be interpreted in the same way as the rank correlation statistics in PROC LOGISTIC. The higher the statistic, the more predictive power your model has. However, it cannot be interpreted as the proportion of variance explained by the predictor variables. Therefore, it is inappropriate to compare the generalized R2 to the linear model?s R2 (Allison 1999). Goodness-of-Fit Statistics and Predictive Power",CD,973,"['proc_logistic', 'also', 'produce', 'statistic', 'measure', 'predictive', 'power', 'statistic', 'goodnessoffit', 'statistic', 'model', 'high', 'predictive', 'power', 'necessarily', 'good', 'fit', 'data', 'vice', 'versa', 'one', 'statistic', 'measure', 'predictive', 'power', 'generalized', 'r2', 'based', 'likelihood', 'ratio', 'chisquare', 'testing', 'null', 'hypothesis', 'slope', 'parameter', '0', 'however', 'us', 'likelihood', 'value', 'l1', 'l0', 'rather', 'log', 'likelihood', 'value', 'adjusted', 'sample_size', 'n', 'interpreted', 'way', 'rank', 'correlation', 'statistic', 'proc_logistic', 'higher', 'statistic', 'predictive', 'power', 'model', 'ha', 'however', 'cannot', 'interpreted', 'proportion', 'variance', 'explained', 'predictor_variable', 'therefore', 'inappropriate', 'compare', 'generalized', 'r2', 'linear', 'model', 'r2', 'allison', '1999', 'goodnessoffit', 'statistic', 'predictive', 'power']"
627,"CMH statistics have low power (probability of correctly rejecting the null hypothesis) for detecting associations where the pattern of association in some of the strata is in the opposite direction of the pattern displayed by other strata (there is an interaction between the stratum variable and the predictor variable). Generally, this is not a problem because if there is an association, it is usually in the same direction across the set of tables, albeit in varying degrees. However, you should always examine the individual tables even if you fail to reject the null hypothesis (Stokes, Davis, and Koch 2000).",CD,615,"['cmh', 'statistic', 'low', 'power', 'probability', 'correctly', 'rejecting', 'null', 'hypothesis', 'detecting', 'association', 'pattern', 'association', 'stratum', 'opposite', 'direction', 'pattern', 'displayed', 'stratum', 'interaction', 'stratum', 'variable', 'predictor_variable', 'generally', 'problem', 'association', 'usually', 'direction', 'across', 'set', 'table', 'albeit', 'varying', 'degree', 'however', 'always', 'examine', 'individual', 'table', 'even', 'fail', 'reject', 'null', 'hypothesis', 'stokes', 'davis', 'koch', '2000']"
628,"Interaction occurs when the relationship between a predictor variable and the response differs by the level of another predictor variable. For example, the graph above shows that the relationship between gender and the response differs by the level of age. Therefore, age modifies the effect of gender and the age*gender interaction should be included in the model. Furthermore, any estimate of the odds ratio for gender should be made with respect to a specific age. It should be noted that when a predictor variable is involved in an interaction, assessing it for confounding is inappropriate. The reason is that when you statistically adjust for the potential confounder, you are assuming that the effect of the predictor variable on the response is the same regardless of the level of the confounder. When interaction is present, that assumption is violated. For binary predictor variables or predictor variables with few unique values, you can assess interactions through stratified data analysis. For continuous predictor variables, you can assess interactions by including them in a multivariate model.",CD,1109,"['interaction', 'occurs', 'relationship', 'predictor_variable', 'response', 'differs', 'level', 'another', 'predictor_variable', 'example', 'graph', 'show', 'relationship', 'gender', 'response', 'differs', 'level', 'age', 'therefore', 'age', 'modifies', 'effect', 'gender', 'agegender', 'interaction', 'included', 'model', 'furthermore', 'estimate', 'odds_ratio', 'gender', 'made', 'respect', 'specific', 'age', 'noted', 'predictor_variable', 'involved', 'interaction', 'assessing', 'confounding', 'inappropriate', 'reason', 'statistically', 'adjust', 'potential', 'confounder', 'assuming', 'effect', 'predictor_variable', 'response', 'regardless', 'level', 'confounder', 'interaction', 'present', 'assumption', 'violated', 'binary', 'predictor_variable', 'predictor_variable', 'unique', 'value', 'ass', 'interaction', 'stratified', 'data', 'analysis', 'continuous', 'predictor_variable', 'ass', 'interaction', 'including', 'multivariate', 'model']"
629,"The contingency table analysis revealed that several variables had very small numbers in their levels (the details of the analysis were omitted to save time and space). Therefore, several variables had levels collapsed and several predictor variables were eliminated from the analysis. For example, there was only one woman whose bowel action aggravated her back pain. Therefore, a total of 16 predictor variables were selected for the analysis.",CD,445,"['contingency', 'table', 'analysis', 'revealed', 'several', 'variable', 'small', 'number', 'level', 'detail', 'analysis', 'omitted', 'save', 'time', 'space', 'therefore', 'several', 'variable', 'level', 'collapsed', 'several', 'predictor_variable', 'eliminated', 'analysis', 'example', 'wa', 'one', 'woman', 'whose', 'bowel', 'action', 'aggravated', 'back', 'pain', 'therefore', 'total', '16', 'predictor_variable', 'selected', 'analysis']"
630,"Stratified data analysis is the process of analyzing contingency tables from two or more strata or groups. The objective of stratified data analysis is to statistically control for a third variable when examining the relationship between the predictor variable and the response variable. When you stratify by a third variable, you examine the relationship between the predictor variable and the response variable within homogenous categories of the third variable, which removes the unequal distribution across the levels of the third variable. The Cochran-Mantel-Haenszel statistic (CMH) combines the results of the stratum-specific comparisons into a single overall estimate. It is formed by a weighted average of the stratum effects where each weight is based on the precision of the effect and the size of the stratum. The null hypothesis for the CMH test is that there is no association between the row and the column variable controlling for a third variable. The alternative hypothesis is that there is an association between the row and column variable controlling for a third variable.",CD,1094,"['stratified', 'data', 'analysis', 'process', 'analyzing', 'contingency', 'table', 'two', 'stratum', 'group', 'objective', 'stratified', 'data', 'analysis', 'statistically', 'control', 'third', 'variable', 'examining', 'relationship', 'predictor_variable', 'response_variable', 'stratify', 'third', 'variable', 'examine', 'relationship', 'predictor_variable', 'response_variable', 'within', 'homogenous', 'category', 'third', 'variable', 'remove', 'unequal', 'distribution', 'across', 'level', 'third', 'variable', 'cochranmantelhaenszel', 'statistic', 'cmh', 'combine', 'result', 'stratumspecific', 'comparison', 'single', 'overall', 'estimate', 'formed', 'weighted', 'average', 'stratum', 'effect', 'weight', 'based', 'precision', 'effect', 'size', 'stratum', 'null', 'hypothesis', 'cmh', 'test', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable', 'alternative', 'hypothesis', 'association', 'row', 'column', 'variable', 'controlling', 'third', 'variable']"
631,"For continuous predictor variables with a large number of unique values, binning the data (collapsing data values into groups) is necessary to compute the logit. The bin size should have an adequate number of observations to reduce the sample variability of the logits. If the standard logistic regression model adequately fits the data, the logit plots should be fairly linear. The above graph shows a predictor variable that meets the assumption of linearity in the logit.",CD,474,"['continuous', 'predictor_variable', 'large', 'number', 'unique', 'value', 'binning', 'data', 'collapsing', 'data', 'value', 'group', 'necessary', 'compute', 'logit', 'bin', 'size', 'adequate', 'number', 'observation', 'reduce', 'sample', 'variability', 'logits', 'standard', 'logistic_regression_model', 'adequately', 'fit', 'data', 'logit', 'plot', 'fairly', 'linear', 'graph', 'show', 'predictor_variable', 'meet', 'assumption', 'linearity', 'logit']"
632,"The first order autoregressive structure (TYPE=AR(1)) specifies that the correlations are raised to the power of the number of time points the measurements are apart. Therefore, if the measurements are three time points apart, the correlation is . The AR(1) model might be a good choice in a longitudinal model where measurements are taken repeatedly over time. One shortcoming is that the correlation decays very quickly as the spacing between measurements increases (Davis 2002).",CD,481,"['first', 'order', 'autoregressive', 'structure', 'typear1', 'specifies', 'correlation', 'raised', 'power', 'number', 'time', 'point', 'measurement', 'apart', 'therefore', 'measurement', 'three', 'time', 'point', 'apart', 'correlation', '', 'ar1', 'model', 'might', 'good', 'choice', 'longitudinal', 'model', 'measurement', 'taken', 'repeatedly', 'time', 'one', 'shortcoming', 'correlation', 'decay', 'quickly', 'spacing', 'measurement', 'increase', 'davis', '2002']"
633,"However, when the model is fit with the main effects and the interaction term, the parameter estimates for the stratification variable and the interaction term along with their associated standard errors increase dramatically. The reason for the model instability is the presence of the 0 cell count when you stratify on the predictor variable. This problem should be detected during the stratified analysis of the predictor variables.",CD,435,"['however', 'model', 'fit', 'main_effect', 'interaction', 'term', 'parameter_estimate', 'stratification', 'variable', 'interaction', 'term', 'along', 'associated', 'standard_error', 'increase', 'dramatically', 'reason', 'model', 'instability', 'presence', '0', 'cell', 'count', 'stratify', 'predictor_variable', 'problem', 'detected', 'stratified', 'analysis', 'predictor_variable']"
634,"Two types of adjusted odds ratio estimates are computed by PROC FREQ. One type is the Mantel- Haenszel (MH) estimator, which is obtained as a weighted average of the stratum specific odds ratios. Another type is the logit-based estimator, which is obtained from a weighted average of the stratum-specific log-odds ratios. However, zero frequencies pose a computational problem, so one- half is added to each cell of any table that contains a zero frequency. Therefore, a common recommendation is to use the MH estimators when you have a small sample size because it is less sensitive to small numbers than the logit-based estimator. It should be noted that the MH estimator and the logit-based estimator are similar when the data is not too sparse within the strata.",CD,766,"['two', 'type', 'adjusted', 'odds_ratio', 'estimate', 'computed', 'proc', 'freq', 'one', 'type', 'mantel', 'haenszel', 'mh', 'estimator', 'obtained', 'weighted', 'average', 'stratum', 'specific', 'odds_ratio', 'another', 'type', 'logitbased', 'estimator', 'obtained', 'weighted', 'average', 'stratumspecific', 'logodds', 'ratio', 'however', 'zero', 'frequency', 'pose', 'computational', 'problem', 'one', 'half', 'added', 'cell', 'table', 'contains', 'zero', 'frequency', 'therefore', 'common', 'recommendation', 'use', 'mh', 'estimator', 'small', 'sample_size', 'le', 'sensitive', 'small', 'number', 'logitbased', 'estimator', 'noted', 'mh', 'estimator', 'logitbased', 'estimator', 'similar', 'data', 'sparse', 'within', 'stratum']"
635,"The odds ratio for bending indicates that women who say that bending aggravates their back pain have 2.4 times the odds to be in a higher severity level of back pain than women who say that bending does not aggravate their back pain. Because the confidence bounds do not include 1.0, the odds ratio is significant at the 0.05 significance level. Association of Predicted Probabilities and Observed Responses",CD,407,"['odds_ratio', 'bending', 'indicates', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '24', 'time', 'odds', 'higher', 'severity', 'level', 'back', 'pain', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain', 'confidence', 'bound', 'include', '10', 'odds_ratio', 'significant', '005', 'significance', 'level', 'association', 'predicted', 'probability', 'observed', 'response']"
636,"Before building a multivariate model, the analyst should perform an exploratory data analysis with contingency tables and logit plots. Contingency table analysis may detect confounders and interactions. Confounders are variables that are associated with both the response variable and a primary predictor variable. When confounding is present, the estimate of the effect of the primary predictor variable to the response is distorted because it is mixed with the effect of the confounder or extraneous variable. Identifying confounders may help the analyst gain an understanding of the relationships among the variables and may help the analyst build a better multivariate model (Rothman 1986). The next two graphs illustrate the concept of confounding. It can be seen that there is a large difference in the log odds of the response between males (Y1) and females (Y2). However, a large portion of this difference may be due to differences in the age of the groups. Therefore, it may not be possible to determine the effect of gender without first eliminating the discrepancy in age.",CD,1084,"['building', 'multivariate', 'model', 'analyst', 'perform', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'contingency', 'table', 'analysis', 'may', 'detect', 'confounders', 'interaction', 'confounders', 'variable', 'associated', 'response_variable', 'primary', 'predictor_variable', 'confounding', 'present', 'estimate', 'effect', 'primary', 'predictor_variable', 'response', 'distorted', 'mixed', 'effect', 'confounder', 'extraneous', 'variable', 'identifying', 'confounders', 'may', 'help', 'analyst', 'gain', 'understanding', 'relationship', 'among', 'variable', 'may', 'help', 'analyst', 'build', 'better', 'multivariate', 'model', 'rothman', '1986', 'next', 'two', 'graph', 'illustrate', 'concept', 'confounding', 'seen', 'large', 'difference', 'log', 'odds', 'response', 'male', 'y1', 'female', 'y2', 'however', 'large', 'portion', 'difference', 'may', 'due', 'difference', 'age', 'group', 'therefore', 'may', 'possible', 'determine', 'effect', 'gender', 'without', 'first', 'eliminating', 'discrepancy', 'age']"
637,"The Type III Analysis of Effects table shows that the variable size is significant in the model. This means that for at least one of the generalized logits, size has a significant effect. Analysis of Maximum Likelihood Estimates",CD,228,"['type', 'iii', 'analysis', 'effect', 'table', 'show', 'variable', 'size', 'significant', 'model', 'mean', 'least', 'one', 'generalized', 'logits', 'size', 'ha', 'significant', 'effect', 'analysis', 'maximum', 'likelihood', 'estimate']"
638,"Because there are 16 predictor variables, it would be wise to reduce the number of redundant variables before building a model in PROC LOGISTIC. One approach to variable reduction is variable clustering. Variable clustering finds groups of variables that are as correlated as possible among themselves and as uncorrelated as possible with variables in other clusters. A common strategy is to pick one variable from each cluster based on subject-matter knowledge.",CD,462,"['16', 'predictor_variable', 'would', 'wise', 'reduce', 'number', 'redundant', 'variable', 'building', 'model', 'proc_logistic', 'one', 'approach', 'variable', 'reduction', 'variable', 'clustering', 'variable', 'clustering', 'find', 'group', 'variable', 'correlated', 'possible', 'among', 'uncorrelated', 'possible', 'variable', 'cluster', 'common', 'strategy', 'pick', 'one', 'variable', 'cluster', 'based', 'subjectmatter', 'knowledge']"
639,"In a matched case-control study, the conditional likelihood allows the model to predict the odds for the event given the predictor variable values. This involves setting up the probabilities for having the observed predictor variable values given the event and then using Bayes? theorem to determine a relevant conditional probability concerning the event. The conditional likelihood is derived by computing the conditional probability of observing the predictor variable values given the outcome (event or not). A predictor variable that is constant within a stratum cancels out of the conditional likelihood. This is the reason why the conditional logistic models cannot estimate a between-cluster effect. Statistics providing information about the between-cluster effect use subject totals at different levels of the relevant predictor variable. However, those totals sum the sufficient statistics for the stratum- specific intercepts, so they themselves are fixed and have degenerate distributions after conditioning on the sufficient statistics (Agresti 2002). Note that the conditional likelihood for the 1:1 matched case-control data is the unconditional likelihood for a logistic regression model where the response is always equal to 1, the predictor variable values are equal to the differences between the values for the case and the control, and there is no intercept. Before SAS?9, you could use PROC LOGISTIC by configuring your data appropriately and eliminating the intercept term. However, you would have to use PROC PHREG for 1:m and m:n matching.",CD,1565,"['matched', 'casecontrol', 'study', 'conditional', 'likelihood', 'allows', 'model', 'predict', 'odds', 'event', 'given', 'predictor_variable', 'value', 'involves', 'setting', 'probability', 'observed', 'predictor_variable', 'value', 'given', 'event', 'using', 'bayes', 'theorem', 'determine', 'relevant', 'conditional', 'probability', 'concerning', 'event', 'conditional', 'likelihood', 'derived', 'computing', 'conditional', 'probability', 'observing', 'predictor_variable', 'value', 'given', 'outcome', 'event', 'predictor_variable', 'constant', 'within', 'stratum', 'cancel', 'conditional', 'likelihood', 'reason', 'conditional', 'logistic', 'model', 'cannot', 'estimate', 'betweencluster', 'effect', 'statistic', 'providing', 'information', 'betweencluster', 'effect', 'use', 'subject', 'total', 'different', 'level', 'relevant', 'predictor_variable', 'however', 'total', 'sum', 'sufficient', 'statistic', 'stratum', 'specific', 'intercept', 'fixed', 'degenerate', 'distribution', 'conditioning', 'sufficient', 'statistic', 'agresti', '2002', 'note', 'conditional', 'likelihood', '11', 'matched', 'casecontrol', 'data', 'unconditional', 'likelihood', 'logistic_regression_model', 'response', 'always', 'equal', '1', 'predictor_variable', 'value', 'equal', 'difference', 'value', 'case', 'control', 'intercept', 'sas9', 'could', 'use', 'proc_logistic', 'configuring', 'data', 'appropriately', 'eliminating', 'intercept', 'term', 'however', 'would', 'use', 'proc', 'phreg', '1m', 'mn', 'matching']"
640,Cases are allocated to classes based on cutoff values of the predicted probability. The steps include the following: 1.	Estimate the predicted probability of class 1 for each case by the logistic regression model. 2.	Choose a cutoff probability. 3.	Assign cases to class 1 if their estimated predicted probability exceeds the cutoff; otherwise assign the case to class 0.,CD,371,"['case', 'allocated', 'class', 'based', 'cutoff', 'value', 'predicted', 'probability', 'step', 'include', 'following', '1\testimate', 'predicted', 'probability', 'class', '1', 'case', 'logistic_regression_model', '2\tchoose', 'cutoff', 'probability', '3\tassign', 'case', 'class', '1', 'estimated', 'predicted', 'probability', 'exceeds', 'cutoff', 'otherwise', 'assign', 'case', 'class', '0']"
641,"After the model fit has been assessed using summary statistics, it is important to identify which observations are poorly fit and which observations have a great deal of influence on the values of the estimated parameters. The LOGISTIC procedure produces a number of statistics that are designed to detect outliers and influential observations. Most of these statistics measure how much some aspect of the model changes when a particular observation is deleted. After identifying these observations, you can begin to address the role they play in the analysis.",CD,560,"['model', 'fit', 'ha', 'assessed', 'using', 'summary', 'statistic', 'important', 'identify', 'observation', 'poorly', 'fit', 'observation', 'great', 'deal', 'influence', 'value', 'estimated', 'parameter', 'logistic', 'procedure', 'produce', 'number', 'statistic', 'designed', 'detect', 'outlier', 'influential', 'observation', 'statistic', 'measure', 'much', 'aspect', 'model', 'change', 'particular', 'observation', 'deleted', 'identifying', 'observation', 'begin', 'address', 'role', 'play', 'analysis']"
642,The logit plot can also show serious nonlinearities between the response variable and the predictor variable. The above graph reveals a quadratic relationship between the response and predictor variables. Adding a polynomial term or binning the predictor variable into three groups (because of the quadratic relationship) and treating it as a classification variable may improve the model fit.,CD,393,"['logit', 'plot', 'also', 'show', 'serious', 'nonlinearities', 'response_variable', 'predictor_variable', 'graph', 'reveals', 'quadratic', 'relationship', 'response', 'predictor_variable', 'adding', 'polynomial', 'term', 'binning', 'predictor_variable', 'three', 'group', 'quadratic', 'relationship', 'treating', 'classification', 'variable', 'may', 'improve', 'model', 'fit']"
643,"The parameter estimate for cephalexin is a median unbiased estimate, which is more accurate than the asymptotic estimate in this example. The exact p-value for age is different than the p- value reported for the exact conditional tests. The reason for the discrepancy is that the exact p- values for the single parameters are the results of likelihood ratio tests based on the conditional probability density function used to estimate them. In most cases, you would rely on the exact p- values reported in the ?Exact Conditional Analysis? table (Stokes, Davis, and Koch 2000). ?	The score test is preferred over the probability test because if the resulting distribution of the conditional sufficient statistic is bimodal, then the probability test can pick up probability from within the valley as well as the tails. The score p-value is always a tail statistic. Exact Odds Ratios",CD,881,"['parameter_estimate', 'cephalexin', 'median', 'unbiased', 'estimate', 'accurate', 'asymptotic', 'estimate', 'example', 'exact', 'pvalue', 'age', 'different', 'p', 'value', 'reported', 'exact', 'conditional', 'test', 'reason', 'discrepancy', 'exact', 'p', 'value', 'single', 'parameter', 'result', 'likelihood', 'ratio', 'test', 'based', 'conditional', 'probability', 'density', 'function', 'used', 'estimate', 'case', 'would', 'rely', 'exact', 'p', 'value', 'reported', 'exact', 'conditional', 'analysis', 'table', 'stokes', 'davis', 'koch', '2000', '\tthe', 'score', 'test', 'preferred', 'probability', 'test', 'resulting', 'distribution', 'conditional', 'sufficient', 'statistic', 'bimodal', 'probability', 'test', 'pick', 'probability', 'within', 'valley', 'well', 'tail', 'score', 'pvalue', 'always', 'tail', 'statistic', 'exact', 'odds_ratio']"
644,Example:	Generate the regression diagnostic statistics for each observation. /* c2demo11a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / influence; title 'Logistic Regression Diagnostic Statistics'; run; Selected MODEL statement options: INFLUENCE	displays diagnostic measures for identifying influential observations in the case of the binary outcome model. Partial Output Logistic Regression Diagnostic Statistics,CD,527,"['example\tgenerate', 'regression', 'diagnostic', 'statistic', 'observation', '', 'c2demo11a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'influence', 'title', 'logistic_regression', 'diagnostic', 'statistic', 'run', 'selected', 'model_statement', 'option', 'influence\tdisplays', 'diagnostic', 'measure', 'identifying', 'influential', 'observation', 'case', 'binary', 'outcome', 'model', 'partial', 'output', 'logistic_regression', 'diagnostic', 'statistic']"
645,"Exact inference on regression parameter estimates is based on the permutation distribution of their sufficient statistics. Inference on the parameters of the specified effects is performed by conditioning on the sufficient statistics of all other model parameters. Some of these other parameters might be regarded as nuisance parameters, which are in the model to adjust for relevant effects, but their values are not of special interest. For example, suppose you are interested in estimating the regression parameter for the predictor variable A, and regard the intercept as a nuisance parameter. You can eliminate the intercept by conditioning on the observed value of its sufficient statistic, which yields the conditional likelihood function. In other words, some of the sufficient statistics are fixed at their observed values and others are allowed to vary over their permissible ranges. This is different from an unconditional likelihood function used in the asymptotic methods, which estimates all the parameters in the model. To understand the methodology of exact logistic regression, three questions need to be addressed: What are sufficient statistics? What is a permutation distribution? What is a median unbiased estimate?",CD,1236,"['exact', 'inference', 'regression', 'parameter_estimate', 'based', 'permutation', 'distribution', 'sufficient', 'statistic', 'inference', 'parameter', 'specified', 'effect', 'performed', 'conditioning', 'sufficient', 'statistic', 'model', 'parameter', 'parameter', 'might', 'regarded', 'nuisance', 'parameter', 'model', 'adjust', 'relevant', 'effect', 'value', 'special', 'interest', 'example', 'suppose', 'interested', 'estimating', 'regression', 'parameter', 'predictor_variable', 'regard', 'intercept', 'nuisance', 'parameter', 'eliminate', 'intercept', 'conditioning', 'observed', 'value', 'sufficient', 'statistic', 'yield', 'conditional', 'likelihood', 'function', 'word', 'sufficient', 'statistic', 'fixed', 'observed', 'value', 'others', 'allowed', 'vary', 'permissible', 'range', 'different', 'unconditional', 'likelihood', 'function', 'used', 'asymptotic', 'method', 'estimate', 'parameter', 'model', 'understand', 'methodology', 'exact', 'logistic_regression', 'three', 'question', 'need', 'addressed', 'sufficient', 'statistic', 'permutation', 'distribution', 'median', 'unbiased', 'estimate']"
646,"The first order autoregressive structure (TYPE=AR(1)) specifies that the correlations are raised to the power of the number of time points the measurements are apart. Therefore, if the measurements are three time points apart, the correlation is . The AR(1) model might be a good choice in a longitudinal model where measurements are taken repeatedly over time. One shortcoming is that the correlation decays very quickly as the spacing between measurements increases (Davis 2002).",CD,481,"['first', 'order', 'autoregressive', 'structure', 'typear1', 'specifies', 'correlation', 'raised', 'power', 'number', 'time', 'point', 'measurement', 'apart', 'therefore', 'measurement', 'three', 'time', 'point', 'apart', 'correlation', '', 'ar1', 'model', 'might', 'good', 'choice', 'longitudinal', 'model', 'measurement', 'taken', 'repeatedly', 'time', 'one', 'shortcoming', 'correlation', 'decay', 'quickly', 'spacing', 'measurement', 'increase', 'davis', '2002']"
647,Matching is carried out in the design phase of the study where you want to balance two or more groups with respect to one or more risk factors that are either known or thought to be associated with the outcome.,CD,210,"['matching', 'carried', 'design', 'phase', 'study', 'want', 'balance', 'two', 'group', 'respect', 'one', 'risk', 'factor', 'either', 'known', 'thought', 'associated', 'outcome']"
648,Example: 	Illustrate the mother?s age by physician visit interaction. First create a data set with the plotting points for the interaction. Score the data set with the plotting points and plot the predicted logits and predicted probabilities by the plotting points. /* c1demo07a */ proc univariate data=sasuser.birth; var mother_age; run; Partial Output Quantile Estimate,CD,371,"['example', '\tillustrate', 'mother', 'age', 'physician', 'visit', 'interaction', 'first', 'create', 'data_set', 'plotting', 'point', 'interaction', 'score', 'data_set', 'plotting', 'point', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', '', 'c1demo07a', '', 'proc', 'univariate', 'datasasuserbirth', 'var', 'motherage', 'run', 'partial', 'output', 'quantile', 'estimate']"
649,"In GEE regression models, the number of observations is not the number of subjects, but rather the number of measurements taken on all the subjects. The variance-covariance matrix is now a block- diagonal matrix in which the observations within each block (the block corresponds to a subject) are assumed to be correlated and the observations outside of the blocks are assumed to be independent. In other words, the subjects are still assumed to be independent of each other and the measurements within each subject are assumed to be correlated.",CD,545,"['gee', 'regression_model', 'number', 'observation', 'number', 'subject', 'rather', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'block', 'corresponds', 'subject', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'word', 'subject', 'still', 'assumed', 'independent', 'measurement', 'within', 'subject', 'assumed', 'correlated']"
650,"When fitting a GEE model in PROC GENMOD, you should decide what is a reasonable model for the correlation between measurements within subject. PROC GENMOD offers several common structures to use to model the working correlation matrix. The choice of the structure should be consistent with the empirical correlations. Liang and Zeger (1986) showed that there could be important gains in efficiency by correctly specifying the working correlation matrix. However, the loss of efficiency is inconsequential when the number of clusters is large (Davis 2002).",CD,555,"['fitting', 'gee', 'model', 'proc', 'genmod', 'decide', 'reasonable', 'model', 'correlation', 'measurement', 'within', 'subject', 'proc', 'genmod', 'offer', 'several', 'common', 'structure', 'use', 'model', 'working', 'correlation', 'matrix', 'choice', 'structure', 'consistent', 'empirical', 'correlation', 'liang', 'zeger', '1986', 'showed', 'could', 'important', 'gain', 'efficiency', 'correctly', 'specifying', 'working', 'correlation', 'matrix', 'however', 'loss', 'efficiency', 'inconsequential', 'number', 'cluster', 'large', 'davis', '2002']"
651,"Mother_age is the matching variable that is constant within the strata. Therefore, the parameter estimate for Mother_age is 0. The matching variable can be used in interactions however. Model Fit Statistics",CD,206,"['motherage', 'matching', 'variable', 'constant', 'within', 'stratum', 'therefore', 'parameter_estimate', 'motherage', '0', 'matching', 'variable', 'used', 'interaction', 'however', 'model', 'fit', 'statistic']"
652,"Based on subject-matter knowledge, one variable was selected from each cluster. Backache in previous pregnancy is a class variable because the levels can be considered nominal (1=not applicable, 2=no, 3=yes). The next step is to build an ordinal logistic regression model in PROC LOGISTIC. A reasonable approach is to search for interactions using forward selection with a very conservative significance level for entry. Then eliminate predictor variables that are not involved in any interactions, are clearly not significant, are not potential confounders, and have no subject-matter importance. Fitting Multiple Ordinal Logistic Regression Models",CD,649,"['based', 'subjectmatter', 'knowledge', 'one', 'variable', 'wa', 'selected', 'cluster', 'backache', 'previous', 'pregnancy', 'class', 'variable', 'level', 'considered', 'nominal', '1not', 'applicable', '2no', '3yes', 'next', 'step', 'build', 'ordinal', 'logistic_regression_model', 'proc_logistic', 'reasonable', 'approach', 'search', 'interaction', 'using', 'forward', 'selection', 'conservative', 'significance', 'level', 'entry', 'eliminate', 'predictor_variable', 'involved', 'interaction', 'clearly', 'significant', 'potential', 'confounders', 'subjectmatter', 'importance', 'fitting', 'multiple', 'ordinal', 'logistic_regression_model']"
653,"Example:	Compute the deviance and Pearson chi-square statistics, the Hosmer-Lemeshow test, and the generalized R2 statistic on the model with all of the main effects and the mother_age*phy_visit interaction. /* c2demo09a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / aggregate scale=none lackfit rsq; title 'Low Birth Weight Model'; run; Selected MODEL statement options: AGGREGATE	requests that PROC LOGISTIC treat each unique combination of the predictor variable values as a distinct group in computing the goodness-of-fit statistics. SCALE=	specifies the value of the dispersion parameter or the method for estimating the dispersion parameter. This option is normally used to correct for overdispersion or underdispersion, but in this case it is required to display the goodness-of-fit statistics. LACKFIT	performs the Hosmer and Lemeshow goodness-of-fit test for the case of a binary outcome model. RSQ	requests a generalized R2 for the fitted model. Partial Output Deviance and Pearson Goodness-of-Fit Statistics",CD,1131,"['example\tcompute', 'deviance', 'pearson', 'chisquare', 'statistic', 'hosmerlemeshow', 'test', 'generalized', 'r2', 'statistic', 'model', 'main_effect', 'motheragephyvisit', 'interaction', '', 'c2demo09a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'aggregate', 'scalenone', 'lackfit', 'rsq', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'aggregate\trequests', 'proc_logistic', 'treat', 'unique', 'combination', 'predictor_variable', 'value', 'distinct', 'group', 'computing', 'goodnessoffit', 'statistic', 'scale\tspecifies', 'value', 'dispersion', 'parameter', 'method', 'estimating', 'dispersion', 'parameter', 'option', 'normally', 'used', 'correct', 'overdispersion', 'underdispersion', 'case', 'required', 'display', 'goodnessoffit', 'statistic', 'lackfit\tperforms', 'hosmer', 'lemeshow', 'goodnessoffit', 'test', 'case', 'binary', 'outcome', 'model', 'rsq\trequests', 'generalized', 'r2', 'fitted', 'model', 'partial', 'output', 'deviance', 'pearson', 'goodnessoffit', 'statistic']"
654,"After the model fit has been assessed using summary statistics, it is important to identify which observations are poorly fit and which observations have a great deal of influence on the values of the estimated parameters. The LOGISTIC procedure produces a number of statistics that are designed to detect outliers and influential observations. Most of these statistics measure how much some aspect of the model changes when a particular observation is deleted. After identifying these observations, you can begin to address the role they play in the analysis.",CD,560,"['model', 'fit', 'ha', 'assessed', 'using', 'summary', 'statistic', 'important', 'identify', 'observation', 'poorly', 'fit', 'observation', 'great', 'deal', 'influence', 'value', 'estimated', 'parameter', 'logistic', 'procedure', 'produce', 'number', 'statistic', 'designed', 'detect', 'outlier', 'influential', 'observation', 'statistic', 'measure', 'much', 'aspect', 'model', 'change', 'particular', 'observation', 'deleted', 'identifying', 'observation', 'begin', 'address', 'role', 'play', 'analysis']"
655,"A key assumption in the logistic regression model is that the logits are linearly related to each predictor variable. For binary predictor variables, this is not a problem because a straight line connects two points. However, for ordinal or continuous predictor variables, this assumption should be examined with the use of logit plots.",CD,336,"['key', 'assumption', 'logistic_regression_model', 'logits', 'linearly', 'related', 'predictor_variable', 'binary', 'predictor_variable', 'problem', 'straight', 'line', 'connects', 'two', 'point', 'however', 'ordinal', 'continuous', 'predictor_variable', 'assumption', 'examined', 'use', 'logit', 'plot']"
656,"The analyst should be aware that after the predictor variables have been chosen based on subject- matter knowledge, refitting many submodels in terms of an optimum fit to the data distorts the significance levels of conventional statistical tests. Basically, you are using the data to make decisions about the form of the model. After a model is developed, the entire modeling process is routinely forgotten, and statistical quantities such as standard errors, confidence limits, p-values, and R-squared are computed as if the resulting model was entirely prespecified. These inferences are inaccurate, tending to err on the side of overstating the significance of predictors and making predictions with overly optimistic confidence. This problem is very evident when there are many iterative stages in model building. When there are many variables and you use stepwise selection to find a small subset of variables, inferences become less accurate (Chatfield 1995, Raftery 1994, Freedman 1983). One solution to this problem is to split your data. One part could be used for finding the regression model and the other part could be used for inference. However, if your data set is small, the loss of efficiency can be prohibitive (Faraway 1992). Another solution is to use bootstrapping methods to obtain the correct standard errors and p-values. Bootstrapping is a resampling method that tries to approximate the distribution of the parameter estimates to estimate the standard error. Unfortunately, bootstrapping is not part of PROC LOGISTIC and the computer programming is beyond the scope of this course.",CD,1608,"['analyst', 'aware', 'predictor_variable', 'chosen', 'based', 'subject', 'matter', 'knowledge', 'refitting', 'many', 'submodels', 'term', 'optimum', 'fit', 'data', 'distorts', 'significance', 'level', 'conventional', 'statistical', 'test', 'basically', 'using', 'data', 'make', 'decision', 'form', 'model', 'model', 'developed', 'entire', 'modeling', 'process', 'routinely', 'forgotten', 'statistical', 'quantity', 'standard_error', 'confidence', 'limit', 'pvalues', 'rsquared', 'computed', 'resulting', 'model', 'wa', 'entirely', 'prespecified', 'inference', 'inaccurate', 'tending', 'err', 'side', 'overstating', 'significance', 'predictor', 'making', 'prediction', 'overly', 'optimistic', 'confidence', 'problem', 'evident', 'many', 'iterative', 'stage', 'model', 'building', 'many', 'variable', 'use', 'stepwise', 'selection', 'find', 'small', 'subset', 'variable', 'inference', 'become', 'le', 'accurate', 'chatfield', '1995', 'raftery', '1994', 'freedman', '1983', 'one', 'solution', 'problem', 'split', 'data', 'one', 'part', 'could', 'used', 'finding', 'regression_model', 'part', 'could', 'used', 'inference', 'however', 'data_set', 'small', 'loss', 'efficiency', 'prohibitive', 'faraway', '1992', 'another', 'solution', 'use', 'bootstrapping', 'method', 'obtain', 'correct', 'standard_error', 'pvalues', 'bootstrapping', 'resampling', 'method', 'try', 'approximate', 'distribution', 'parameter_estimate', 'estimate', 'standard_error', 'unfortunately', 'bootstrapping', 'part', 'proc_logistic', 'computer', 'programming', 'beyond', 'scope', 'course']"
657,"Special methods of statistical analysis are needed for clustered data because the set of measurements on one subject tends to be correlated and measurements on the same subject close in time tend to be more highly correlated than measurements far apart in time. These potential patterns of correlation must be taken into account to draw valid statistical inferences. Therefore, models fit in PROC LOGISTIC might produce invalid results because the independence assumption might not be valid.",CD,491,"['special', 'method', 'statistical', 'analysis', 'needed', 'clustered', 'data_set', 'measurement', 'one', 'subject', 'tends', 'correlated', 'measurement', 'subject', 'close', 'time', 'tend', 'highly', 'correlated', 'measurement', 'far', 'apart', 'time', 'potential', 'pattern', 'correlation', 'must', 'taken', 'account', 'draw', 'valid', 'statistical', 'inference', 'therefore', 'model', 'fit', 'proc_logistic', 'might', 'produce', 'invalid', 'result', 'independence', 'assumption', 'might', 'valid']"
658,"Provided that the mean model is correctly specified and the measurements between subjects are independent, robust standard errors ensure consistent inferences from a GEE regression model even if the chosen correlation structure is incorrect or if the strength of the correlation between measurements varies from subject to subject. Although model-based standard errors are also produced, they are only consistent if the specified correlation structure is correct. Consequently, the robust standard errors, which are usually larger, are usually preferred especially when the number of clusters is large. The desired number of clusters depends on the number of predictor variables in the model. If you have fewer than 5 predictor variables, approximately 25 clusters might be enough to use the robust standard errors. If you have 5 to 12 predictor variables, then you need at least 100 clusters. If you want to be reasonably confident, then you need around 200 clusters (Stokes, Davis, Koch 2000). However, when the number of clusters is very small (less than 20), the model-based standard errors might have better properties even if the specified correlation structure is wrong (Prentice 1988). This is because the robust standard errors are asymptotically unbiased, but could be highly biased when the number of clusters is small. Robust standard errors are derived by the sandwich estimator of the covariance matrix of the regression coefficients. In general, the sandwich estimator uses a matrix with the diagonal elements equal to the individual squared residuals to estimate the common variance (the square of any residual is an estimate of the variance at that predictor variable value). This works because the average of a lot of poor estimators (individual squared residuals) can be a good estimator of the common variance. In fact, Liang and Zeger (1986) showed that the robust standard errors are robust to departures of the working correlation matrix from the true correlation structure.",CD,1997,"['provided', 'mean', 'model', 'correctly', 'specified', 'measurement', 'subject', 'independent', 'robust', 'standard_error', 'ensure', 'consistent', 'inference', 'gee', 'regression_model', 'even', 'chosen', 'correlation_structure', 'incorrect', 'strength', 'correlation', 'measurement', 'varies', 'subject', 'subject', 'although', 'modelbased', 'standard_error', 'also', 'produced', 'consistent', 'specified', 'correlation_structure', 'correct', 'consequently', 'robust', 'standard_error', 'usually', 'larger', 'usually', 'preferred', 'especially', 'number', 'cluster', 'large', 'desired', 'number', 'cluster', 'depends', 'number', 'predictor_variable', 'model', 'fewer', '5', 'predictor_variable', 'approximately', '25', 'cluster', 'might', 'enough', 'use', 'robust', 'standard_error', '5', '12', 'predictor_variable', 'need', 'least', '100', 'cluster', 'want', 'reasonably', 'confident', 'need', 'around', '200', 'cluster', 'stokes', 'davis', 'koch', '2000', 'however', 'number', 'cluster', 'small', 'le', '20', 'modelbased', 'standard_error', 'might', 'better', 'property', 'even', 'specified', 'correlation_structure', 'wrong', 'prentice', '1988', 'robust', 'standard_error', 'asymptotically', 'unbiased', 'could', 'highly', 'biased', 'number', 'cluster', 'small', 'robust', 'standard_error', 'derived', 'sandwich', 'estimator', 'covariance', 'matrix', 'regression', 'coefficient', 'general', 'sandwich', 'estimator', 'us', 'matrix', 'diagonal', 'element', 'equal', 'individual', 'squared', 'residual', 'estimate', 'common', 'variance', 'square', 'residual', 'estimate', 'variance', 'predictor_variable', 'value', 'work', 'average', 'lot', 'poor', 'estimator', 'individual', 'squared', 'residual', 'good', 'estimator', 'common', 'variance', 'fact', 'liang', 'zeger', '1986', 'showed', 'robust', 'standard_error', 'robust', 'departure', 'working', 'correlation', 'matrix', 'true', 'correlation_structure']"
659,"The score test for the proportional odds assumption tends to reject the null hypothesis more often than is warranted. If there are many predictor variables and if the sample size is large, the test usually produces p-values below 0.05 (Allison 1999). Given such a liberal test, it may be useful to graph the cumulative logits to visually inspect the proportional odds assumption. Cumulative logit plots are graphs of cumulative logits for each predictor variable. If the proportional odds assumption is true, then the slopes of the logits should be parallel. If the plotted lines diverge greatly from parallelism, then you should consider a different modeling approach such as modeling generalized logits. Agresti (2002) also recommends trying a link function for which the response curve is nonsymmetric (in other words, complementary log-log), adding additional parameters such as interactions, and adding dispersion parameters. Cumulative Logit Plots",CD,953,"['score', 'test', 'proportional', 'odds', 'assumption', 'tends', 'reject', 'null', 'hypothesis', 'often', 'warranted', 'many', 'predictor_variable', 'sample_size', 'large', 'test', 'usually', 'produce', 'pvalues', '005', 'allison', '1999', 'given', 'liberal', 'test', 'may', 'useful', 'graph', 'cumulative', 'logits', 'visually', 'inspect', 'proportional', 'odds', 'assumption', 'cumulative', 'logit', 'plot', 'graph', 'cumulative', 'logits', 'predictor_variable', 'proportional', 'odds', 'assumption', 'true', 'slope', 'logits', 'parallel', 'plotted', 'line', 'diverge', 'greatly', 'parallelism', 'consider', 'different', 'modeling', 'approach', 'modeling', 'generalized', 'logits', 'agresti', '2002', 'also', 'recommends', 'trying', 'link', 'function', 'response', 'curve', 'nonsymmetric', 'word', 'complementary', 'loglog', 'adding', 'additional', 'parameter', 'interaction', 'adding', 'dispersion', 'parameter', 'cumulative', 'logit', 'plot']"
660,"Subject-matter knowledge does not always enable you to choose the best predictor variables and the structure for how the predictor variables appear in the model. Thus you are often forced to use the data to make these decisions (Harrell 1997). A common approach in variable selection is to use univariate associations to detect significant predictor variables. Each predictor variable is screened individually and only those with a p-value below an established cutoff (such as .05) are retained for the analysis. However, this approach has serious shortcomings. Because univariate screening does not account for partial associations (effect of one variable changes in the presence of another variable), some predictor variables may be erroneously omitted. Furthermore, the presence of interactions can give misleading univariate associations. A better approach is to consider a subset of variables jointly.",CD,906,"['subjectmatter', 'knowledge', 'doe', 'always', 'enable', 'choose', 'best', 'predictor_variable', 'structure', 'predictor_variable', 'appear', 'model', 'thus', 'often', 'forced', 'use', 'data', 'make', 'decision', 'harrell', '1997', 'common', 'approach', 'variable', 'selection', 'use', 'univariate', 'association', 'detect', 'significant', 'predictor_variable', 'predictor_variable', 'screened', 'individually', 'pvalue', 'established', 'cutoff', '05', 'retained', 'analysis', 'however', 'approach', 'ha', 'serious', 'shortcoming', 'univariate', 'screening', 'doe', 'account', 'partial', 'association', 'effect', 'one', 'variable', 'change', 'presence', 'another', 'variable', 'predictor_variable', 'may', 'erroneously', 'omitted', 'furthermore', 'presence', 'interaction', 'give', 'misleading', 'univariate', 'association', 'better', 'approach', 'consider', 'subset', 'variable', 'jointly']"
661,"Adjusted odds ratios provide a correct estimate of the effect of the predictor variable on the response only when the odds ratio is constant across the strata. Therefore, it is crucial to check for interactions among the predictor variables. For binary predictors, stratified data analysis can be used to detect interactions with the use of the Breslow-Day statistic. The Breslow-Day statistic *	tests the null hypothesis of homogeneity of the odds ratios *	has a chi-square distribution if the sample size is sufficiently large in each stratum and the null hypothesis is true *	requires a large sample size in each stratum. The sample size requirements are that at least 80% of the cells in all the tables have expected cell counts greater than 5. If the sample size is too small in any of the strata, then the p-value calculated from the chi-square distribution will not be accurate. The computation of the Breslow-Day statistic does not include any strata with zero rows or columns. If the Breslow-Day test is significant and valid, then the stratum-specific odds ratios should be displayed. It should be noted that the adjusted odds ratio may be misleading if the stratum-specific odds ratios vary widely across 1 (one stratum-specific odds ratio is less than 1 while the other is greater than 1). The computation of the Breslow-Day statistic includes the Mantel-Haenszel adjusted odds ratio. Tarone (1985) showed that because of the inefficiency of the Mantel-Haenszel adjusted odds ratio, you must adjust the Breslow-Day statistic for it to have a limiting chi-squared null distribution with degrees of freedom equal to the number of strata ? 1. This adjustment is usually minor. Frequency Table Analysis",CD,1710,"['adjusted', 'odds_ratio', 'provide', 'correct', 'estimate', 'effect', 'predictor_variable', 'response', 'odds_ratio', 'constant', 'across', 'stratum', 'therefore', 'crucial', 'check', 'interaction', 'among', 'predictor_variable', 'binary', 'predictor', 'stratified', 'data', 'analysis', 'used', 'detect', 'interaction', 'use', 'breslowday', 'statistic', 'breslowday', 'statistic', '\ttests', 'null', 'hypothesis', 'homogeneity', 'odds_ratio', '\thas', 'chisquare', 'distribution', 'sample_size', 'sufficiently', 'large', 'stratum', 'null', 'hypothesis', 'true', '\trequires', 'large', 'sample_size', 'stratum', 'sample_size', 'requirement', 'least', '80', 'cell', 'table', 'expected', 'cell', 'count', 'greater', '5', 'sample_size', 'small', 'stratum', 'pvalue', 'calculated', 'chisquare', 'distribution', 'accurate', 'computation', 'breslowday', 'statistic', 'doe', 'include', 'stratum', 'zero', 'row', 'column', 'breslowday', 'test', 'significant', 'valid', 'stratumspecific', 'odds_ratio', 'displayed', 'noted', 'adjusted', 'odds_ratio', 'may', 'misleading', 'stratumspecific', 'odds_ratio', 'vary', 'widely', 'across', '1', 'one', 'stratumspecific', 'odds_ratio', 'le', '1', 'greater', '1', 'computation', 'breslowday', 'statistic', 'includes', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'tarone', '1985', 'showed', 'inefficiency', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'must', 'adjust', 'breslowday', 'statistic', 'limiting', 'chisquared', 'null', 'distribution', 'degree', 'freedom', 'equal', 'number', 'stratum', '', '1', 'adjustment', 'usually', 'minor', 'frequency', 'table', 'analysis']"
662,The plot of the change in the deviance by predicted probabilities shows several observations that need to be examined. The points in the upper-left corner represent women who had low birth weight babies with very favorable covariate patterns. The points in the upper-right corner represent women who had normal weight babies with very unfavorable covariate patterns. Careful examination of these observations may lead to strategies to improve the fit of the model (Hosmer and Lemeshow 2000). Example:	Generate a bubble plot of the change in the Pearson chi-square statistic by predicted probabilities with the plotting symbol proportional to the c diagnostic statistic. Create an ActiveX graph in HTML output. /* c2demo11c */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difchisq=difchisq c=c; run;,CD,942,"['plot', 'change', 'deviance', 'predicted', 'probability', 'show', 'several', 'observation', 'need', 'examined', 'point', 'upperleft', 'corner', 'represent', 'woman', 'low', 'birth', 'weight', 'baby', 'favorable', 'covariate', 'pattern', 'point', 'upperright', 'corner', 'represent', 'woman', 'normal', 'weight', 'baby', 'unfavorable', 'covariate', 'pattern', 'careful', 'examination', 'observation', 'may', 'lead', 'strategy', 'improve', 'fit', 'model', 'hosmer', 'lemeshow', '2000', 'example\tgenerate', 'bubble', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'plotting', 'symbol', 'proportional', 'c', 'diagnostic', 'statistic', 'create', 'activex', 'graph', 'html', 'output', '', 'c2demo11c', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difchisqdifchisq', 'cc', 'run']"
663,"From the classification table you can compute sensitivity, which is the proportion of event observations (in this example low birth weight babies) that were predicted to have an event response. The formula is (true positives) / (total actual positives).",CD,253,"['classification', 'table', 'compute', 'sensitivity', 'proportion', 'event', 'observation', 'example', 'low', 'birth', 'weight', 'baby', 'predicted', 'event', 'response', 'formula', 'true', 'positive', '', 'total', 'actual', 'positive']"
664,"Adjusted odds ratios provide a correct estimate of the effect of the predictor variable on the response only when the odds ratio is constant across the strata. Therefore, it is crucial to check for interactions among the predictor variables. For binary predictors, stratified data analysis can be used to detect interactions with the use of the Breslow-Day statistic. The Breslow-Day statistic *	tests the null hypothesis of homogeneity of the odds ratios *	has a chi-square distribution if the sample size is sufficiently large in each stratum and the null hypothesis is true *	requires a large sample size in each stratum. The sample size requirements are that at least 80% of the cells in all the tables have expected cell counts greater than 5. If the sample size is too small in any of the strata, then the p-value calculated from the chi-square distribution will not be accurate. The computation of the Breslow-Day statistic does not include any strata with zero rows or columns. If the Breslow-Day test is significant and valid, then the stratum-specific odds ratios should be displayed. It should be noted that the adjusted odds ratio may be misleading if the stratum-specific odds ratios vary widely across 1 (one stratum-specific odds ratio is less than 1 while the other is greater than 1). The computation of the Breslow-Day statistic includes the Mantel-Haenszel adjusted odds ratio. Tarone (1985) showed that because of the inefficiency of the Mantel-Haenszel adjusted odds ratio, you must adjust the Breslow-Day statistic for it to have a limiting chi-squared null distribution with degrees of freedom equal to the number of strata ? 1. This adjustment is usually minor. Frequency Table Analysis",CD,1710,"['adjusted', 'odds_ratio', 'provide', 'correct', 'estimate', 'effect', 'predictor_variable', 'response', 'odds_ratio', 'constant', 'across', 'stratum', 'therefore', 'crucial', 'check', 'interaction', 'among', 'predictor_variable', 'binary', 'predictor', 'stratified', 'data', 'analysis', 'used', 'detect', 'interaction', 'use', 'breslowday', 'statistic', 'breslowday', 'statistic', '\ttests', 'null', 'hypothesis', 'homogeneity', 'odds_ratio', '\thas', 'chisquare', 'distribution', 'sample_size', 'sufficiently', 'large', 'stratum', 'null', 'hypothesis', 'true', '\trequires', 'large', 'sample_size', 'stratum', 'sample_size', 'requirement', 'least', '80', 'cell', 'table', 'expected', 'cell', 'count', 'greater', '5', 'sample_size', 'small', 'stratum', 'pvalue', 'calculated', 'chisquare', 'distribution', 'accurate', 'computation', 'breslowday', 'statistic', 'doe', 'include', 'stratum', 'zero', 'row', 'column', 'breslowday', 'test', 'significant', 'valid', 'stratumspecific', 'odds_ratio', 'displayed', 'noted', 'adjusted', 'odds_ratio', 'may', 'misleading', 'stratumspecific', 'odds_ratio', 'vary', 'widely', 'across', '1', 'one', 'stratumspecific', 'odds_ratio', 'le', '1', 'greater', '1', 'computation', 'breslowday', 'statistic', 'includes', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'tarone', '1985', 'showed', 'inefficiency', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'must', 'adjust', 'breslowday', 'statistic', 'limiting', 'chisquared', 'null', 'distribution', 'degree', 'freedom', 'equal', 'number', 'stratum', '', '1', 'adjustment', 'usually', 'minor', 'frequency', 'table', 'analysis']"
665,"Example:	Fit an exact logistic regression model to the Cephalexin data set. Request that the individual parameters and the odds ratios be estimated. Use the events/trials syntax and use reference cell coding for each predictor variable and specify No for the reference cell for cephalexin, 50+ for age, and less than a week for length_of_stay. Also create a data set with the exact conditional distributions. /* c3demo18a */ proc logistic data=sasuser.cephalexin; class cephalexin (param=ref ref='No') age (param=ref ref='50+') length_of_stay (param=ref ref='less than a week'); model cases/patients = cephalexin age length_of_stay; exact cephalexin age length_of_stay / estimate=both outdist=dist; title 'Cephalexin in Hospital Model'; run; EXACT statement options: ESTIMATE=	estimates the individual parameters (conditional on all other parameters) for the effects specified in the EXACT statement. For each parameter, a point estimate, a confidence interval, and a p-value for a two-sided test that the parameter is zero are displayed. The keyword BOTH specifies that the parameters and odds ratios be displayed. OUTDIST=	creates the SAS data set containing the exact conditional distributions. The data set contains the possible sufficient statistics for the parameters of the effects specified in the EXACT statement, the counts, the probability of occurrence, and the score value for each sufficient statistic. Cephalexin in Hospital Model",CD,1445,"['example\tfit', 'exact', 'logistic_regression_model', 'cephalexin', 'data_set', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'use', 'eventstrials', 'syntax', 'use', 'reference', 'cell', 'coding', 'predictor_variable', 'specify', 'reference', 'cell', 'cephalexin', '50', 'age', 'le', 'week', 'lengthofstay', 'also', 'create', 'data_set', 'exact', 'conditional', 'distribution', '', 'c3demo18a', '', 'proc_logistic', 'datasasusercephalexin', 'class', 'cephalexin', 'paramref', 'refno', 'age', 'paramref', 'ref50', 'lengthofstay', 'paramref', 'refless', 'week', 'model', 'casespatients', '', 'cephalexin', 'age', 'lengthofstay', 'exact', 'cephalexin', 'age', 'lengthofstay', '', 'estimateboth', 'outdistdist', 'title', 'cephalexin', 'hospital', 'model', 'run', 'exact', 'statement', 'option', 'estimate\testimates', 'individual', 'parameter', 'conditional', 'parameter', 'effect', 'specified', 'exact', 'statement', 'parameter', 'point', 'estimate', 'confidence', 'interval', 'pvalue', 'twosided', 'test', 'parameter', 'zero', 'displayed', 'keyword', 'specifies', 'parameter', 'odds_ratio', 'displayed', 'outdist\tcreates', 'sa', 'data_set', 'containing', 'exact', 'conditional', 'distribution', 'data_set', 'contains', 'possible', 'sufficient', 'statistic', 'parameter', 'effect', 'specified', 'exact', 'statement', 'count', 'probability', 'occurrence', 'score', 'value', 'sufficient', 'statistic', 'cephalexin', 'hospital', 'model']"
666,"The problem of biasing the inferences can be avoided by prespecifying the model. When you have a large number of variables, however, prespecifying the model is not feasible. Therefore, analysts use the results of the model selection techniques (usually the p-values for the predictor variables) to select a model. However, the p-values calculated in the model selection techniques are not p-values in the traditional hypothesis-testing context. Instead, they should be viewed as indicators of relative importance among variables (Hosmer and Lemeshow 2000). Because the biased p-values overstate the significance of the predictor variables, the traditional cutoff of .05 is not very useful unless the sample size is small (30-50). For large sample sizes, much smaller p-values are required to imply that the data provide evidence for the effect of interest. The slide above provides approximate two-sided p-values corresponding to different grades of evidence for tests involving one additional parameter (one degree of freedom). Significance levels for tests involving more than one degree of freedom would even be lower, especially for the larger sample sizes (Raftery 1994).",CD,1176,"['problem', 'biasing', 'inference', 'avoided', 'prespecifying', 'model', 'large', 'number', 'variable', 'however', 'prespecifying', 'model', 'feasible', 'therefore', 'analyst', 'use', 'result', 'model', 'selection', 'technique', 'usually', 'pvalues', 'predictor_variable', 'select', 'model', 'however', 'pvalues', 'calculated', 'model', 'selection', 'technique', 'pvalues', 'traditional', 'hypothesistesting', 'context', 'instead', 'viewed', 'indicator', 'relative', 'importance', 'among', 'variable', 'hosmer', 'lemeshow', '2000', 'biased', 'pvalues', 'overstate', 'significance', 'predictor_variable', 'traditional', 'cutoff', '05', 'useful', 'unless', 'sample_size', 'small', '3050', 'large', 'sample_size', 'much', 'smaller', 'pvalues', 'required', 'imply', 'data', 'provide', 'evidence', 'effect', 'interest', 'slide', 'provides', 'approximate', 'twosided', 'pvalues', 'corresponding', 'different', 'grade', 'evidence', 'test', 'involving', 'one', 'additional', 'parameter', 'one', 'degree', 'freedom', 'significance', 'level', 'test', 'involving', 'one', 'degree', 'freedom', 'would', 'even', 'lower', 'especially', 'larger', 'sample_size', 'raftery', '1994']"
667,The odds ratio indicates that women with previous preterm deliveries are 4.3 times more likely to have a low birth weight baby than women without previous preterm deliveries. The confidence interval is not symmetric around the estimate because distributions of ratios are asymmetric. The exact confidence interval is not needed because of the large sample size. Summary Statistics for prev_pretrm by low,CD,403,"['odds_ratio', 'indicates', 'woman', 'previous', 'preterm', 'delivery', '43', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'woman', 'without', 'previous', 'preterm', 'delivery', 'confidence', 'interval', 'symmetric', 'around', 'estimate', 'distribution', 'ratio', 'asymmetric', 'exact', 'confidence', 'interval', 'needed', 'large', 'sample_size', 'summary', 'statistic', 'prevpretrm', 'low']"
668,"Missing values that occur intermixed with nonmissing values are called intermittent missing values. If these missing values are missing completely at random (MCAR), then the consistency results established by Liang and Zeger (1986) hold. A simple check of MCAR is to divide the subjects into two groups: those with a complete set of measurements and those with missing measurements. If the MCAR assumption holds, then both groups (with their measurements) should be random samples of the same population of measurements. In other words, the probability of missing is independent of the observed measurements and the measurements that would have been available had they not been missing. The t-tests for location and more general tests of equality of distribution can be used to test the MCAR assumption (Little 1995). Tests of MCAR for repeatedly measured categorical data were discussed by Park and Davis (1993). Some intermittent missing values can arise due to censoring rules. For example, values outside a stated range might be simply unreliable because of the limitations of the measuring techniques in use (Diggle, Heagerty, Liang, and Zeger 2002). Methods for handling censored data in correlation data structures are addressed in Laird (1988) and Hughes (1999). Intermittent missing values can also be related to the outcome. For example, a patient might miss an appointment because of an adverse reaction to the treatment. The fact that the subject remains in the study means that the investigator should have the opportunity to ascertain the reason for the missing appointment and take corrective action accordingly (Diggle, Heagerty, Liang, and Zeger 2002, Little 1995). If all the missing values occur after a certain time point for a subject, then the missing values are called dropouts. These are a more significant problem compared to intermittent missing values because usually the subject is withdrawn for reasons directly or indirectly connected to the outcome and are lost to follow-up. If you treat the dropouts as MCAR when they are in fact informative dropouts, the parameter estimates will be biased (Diggle and Kenward 1994). Diggle, Heagerty, Liang, and Zeger (2002) state that ?An emerging consensus is that analysis of data with potentially informative dropouts necessarily involves assumptions that are difficult, or even impossible, to check from the observed data. This suggests that it would be unwise to rely on the precise conclusions of an analysis based on a particular informative dropout model.? They recommend that a sensitivity analysis be conducted on the informative dropout model. This provides some protection against the possibility that conclusions reached from a random dropout model are critically dependent on the validity of MCAR. Scharstein et al. (1999) provides a discussion on how such sensitivity analyses might be conducted.",CD,2880,"['missing', 'value', 'occur', 'intermixed', 'nonmissing', 'value', 'called', 'intermittent', 'missing', 'value', 'missing', 'value', 'missing', 'completely', 'random', 'mcar', 'consistency', 'result', 'established', 'liang', 'zeger', '1986', 'hold', 'simple', 'check', 'mcar', 'divide', 'subject', 'two', 'group', 'complete', 'set', 'measurement', 'missing', 'measurement', 'mcar', 'assumption', 'hold', 'group', 'measurement', 'random', 'sample', 'population', 'measurement', 'word', 'probability', 'missing', 'independent', 'observed', 'measurement', 'measurement', 'would', 'available', 'missing', 'ttests', 'location', 'general', 'test', 'equality', 'distribution', 'used', 'test', 'mcar', 'assumption', 'little', '1995', 'test', 'mcar', 'repeatedly', 'measured', 'categorical', 'data', 'discussed', 'park', 'davis', '1993', 'intermittent', 'missing', 'value', 'arise', 'due', 'censoring', 'rule', 'example', 'value', 'outside', 'stated', 'range', 'might', 'simply', 'unreliable', 'limitation', 'measuring', 'technique', 'use', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'method', 'handling', 'censored', 'data', 'correlation', 'data', 'structure', 'addressed', 'laird', '1988', 'hughes', '1999', 'intermittent', 'missing', 'value', 'also', 'related', 'outcome', 'example', 'patient', 'might', 'miss', 'appointment', 'adverse', 'reaction', 'treatment', 'fact', 'subject', 'remains', 'study', 'mean', 'investigator', 'opportunity', 'ascertain', 'reason', 'missing', 'appointment', 'take', 'corrective', 'action', 'accordingly', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'little', '1995', 'missing', 'value', 'occur', 'certain', 'time', 'point', 'subject', 'missing', 'value', 'called', 'dropout', 'significant', 'problem', 'compared', 'intermittent', 'missing', 'value', 'usually', 'subject', 'withdrawn', 'reason', 'directly', 'indirectly', 'connected', 'outcome', 'lost', 'followup', 'treat', 'dropout', 'mcar', 'fact', 'informative', 'dropout', 'parameter_estimate', 'biased', 'diggle', 'kenward', '1994', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'state', 'emerging', 'consensus', 'analysis', 'data', 'potentially', 'informative', 'dropout', 'necessarily', 'involves', 'assumption', 'difficult', 'even', 'impossible', 'check', 'observed', 'data', 'suggests', 'would', 'unwise', 'rely', 'precise', 'conclusion', 'analysis', 'based', 'particular', 'informative', 'dropout', 'model', 'recommend', 'sensitivity', 'analysis', 'conducted', 'informative', 'dropout', 'model', 'provides', 'protection', 'possibility', 'conclusion', 'reached', 'random', 'dropout', 'model', 'critically', 'dependent', 'validity', 'mcar', 'scharstein', 'et', 'al', '1999', 'provides', 'discussion', 'sensitivity', 'analysis', 'might', 'conducted']"
669,"The likelihood ratio statistic that compares the main effects model to the interaction model is clearly significant at the 0.05 level. Therefore, a candidate final model should include the mother_age*phy_visit interaction and the main effects. Example:	Compute a likelihood ratio test comparing a model treating socio as a continuous variable and a model treating socio as a classification variable. /* c1demo06e */ ods listing close;",CD,434,"['likelihood', 'ratio', 'statistic', 'compare', 'main_effect', 'model', 'interaction', 'model', 'clearly', 'significant', '005', 'level', 'therefore', 'candidate', 'final', 'model', 'include', 'motheragephyvisit', 'interaction', 'main_effect', 'example\tcompute', 'likelihood', 'ratio', 'test', 'comparing', 'model', 'treating', 'socio', 'continuous', 'variable', 'model', 'treating', 'socio', 'classification', 'variable', '', 'c1demo06e', '', 'od', 'listing', 'close']"
670,"Backward elimination starts off with the full model. Results of the Wald test for individual parameter estimates are examined, and the least significant variable that falls above the specified significance level (specified by the SLSTAY= option) is removed. After a variable is removed from the model, it remains excluded. The process is repeated until no other variable in the model meets the specified significance level for removal. By default, SLSTAY=0.05. When using backward elimination, you could use the FAST option to increase efficiency. This method only requires passing through the data matrix once to get the initial full model fit. Then the method uses an algorithm to manipulate the full model fit to approximate the parameter estimates for the reduced models. This eliminates the need to refit the model every time a variable is removed. Simulations examining variable selection techniques found that backward elimination methods usually performed better than the forward stepwise methods, especially when collinearity is present among the predictor variables. However, a relatively large number of predictor variables increases the risk of complete separation (Hosmer and Lemeshow 2000). Furthermore, sparseness in the data causes unstable parameter estimates that negatively impact the performance of the backward elimination method (Harrell 1997).",CD,1366,"['backward', 'elimination', 'start', 'full', 'model', 'result', 'wald', 'test', 'individual', 'parameter_estimate', 'examined', 'least', 'significant', 'variable', 'fall', 'specified', 'significance', 'level', 'specified', 'slstay', 'option', 'removed', 'variable', 'removed', 'model', 'remains', 'excluded', 'process', 'repeated', 'variable', 'model', 'meet', 'specified', 'significance', 'level', 'removal', 'default', 'slstay005', 'using', 'backward', 'elimination', 'could', 'use', 'fast', 'option', 'increase', 'efficiency', 'method', 'requires', 'passing', 'data', 'matrix', 'get', 'initial', 'full', 'model', 'fit', 'method', 'us', 'algorithm', 'manipulate', 'full', 'model', 'fit', 'approximate', 'parameter_estimate', 'reduced', 'model', 'eliminates', 'need', 'refit', 'model', 'every', 'time', 'variable', 'removed', 'simulation', 'examining', 'variable', 'selection', 'technique', 'found', 'backward', 'elimination', 'method', 'usually', 'performed', 'better', 'forward', 'stepwise', 'method', 'especially', 'collinearity', 'present', 'among', 'predictor_variable', 'however', 'relatively', 'large', 'number', 'predictor_variable', 'increase', 'risk', 'complete', 'separation', 'hosmer', 'lemeshow', '2000', 'furthermore', 'sparseness', 'data', 'cause', 'unstable', 'parameter_estimate', 'negatively', 'impact', 'performance', 'backward', 'elimination', 'method', 'harrell', '1997']"
671,"Adjusted odds ratios provide a correct estimate of the effect of the predictor variable on the response only when the odds ratio is constant across the strata. Therefore, it is crucial to check for interactions among the predictor variables. For binary predictors, stratified data analysis can be used to detect interactions with the use of the Breslow-Day statistic. The Breslow-Day statistic *	tests the null hypothesis of homogeneity of the odds ratios *	has a chi-square distribution if the sample size is sufficiently large in each stratum and the null hypothesis is true *	requires a large sample size in each stratum. The sample size requirements are that at least 80% of the cells in all the tables have expected cell counts greater than 5. If the sample size is too small in any of the strata, then the p-value calculated from the chi-square distribution will not be accurate. The computation of the Breslow-Day statistic does not include any strata with zero rows or columns. If the Breslow-Day test is significant and valid, then the stratum-specific odds ratios should be displayed. It should be noted that the adjusted odds ratio may be misleading if the stratum-specific odds ratios vary widely across 1 (one stratum-specific odds ratio is less than 1 while the other is greater than 1). The computation of the Breslow-Day statistic includes the Mantel-Haenszel adjusted odds ratio. Tarone (1985) showed that because of the inefficiency of the Mantel-Haenszel adjusted odds ratio, you must adjust the Breslow-Day statistic for it to have a limiting chi-squared null distribution with degrees of freedom equal to the number of strata ? 1. This adjustment is usually minor. Frequency Table Analysis",CD,1710,"['adjusted', 'odds_ratio', 'provide', 'correct', 'estimate', 'effect', 'predictor_variable', 'response', 'odds_ratio', 'constant', 'across', 'stratum', 'therefore', 'crucial', 'check', 'interaction', 'among', 'predictor_variable', 'binary', 'predictor', 'stratified', 'data', 'analysis', 'used', 'detect', 'interaction', 'use', 'breslowday', 'statistic', 'breslowday', 'statistic', '\ttests', 'null', 'hypothesis', 'homogeneity', 'odds_ratio', '\thas', 'chisquare', 'distribution', 'sample_size', 'sufficiently', 'large', 'stratum', 'null', 'hypothesis', 'true', '\trequires', 'large', 'sample_size', 'stratum', 'sample_size', 'requirement', 'least', '80', 'cell', 'table', 'expected', 'cell', 'count', 'greater', '5', 'sample_size', 'small', 'stratum', 'pvalue', 'calculated', 'chisquare', 'distribution', 'accurate', 'computation', 'breslowday', 'statistic', 'doe', 'include', 'stratum', 'zero', 'row', 'column', 'breslowday', 'test', 'significant', 'valid', 'stratumspecific', 'odds_ratio', 'displayed', 'noted', 'adjusted', 'odds_ratio', 'may', 'misleading', 'stratumspecific', 'odds_ratio', 'vary', 'widely', 'across', '1', 'one', 'stratumspecific', 'odds_ratio', 'le', '1', 'greater', '1', 'computation', 'breslowday', 'statistic', 'includes', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'tarone', '1985', 'showed', 'inefficiency', 'mantelhaenszel', 'adjusted', 'odds_ratio', 'must', 'adjust', 'breslowday', 'statistic', 'limiting', 'chisquared', 'null', 'distribution', 'degree', 'freedom', 'equal', 'number', 'stratum', '', '1', 'adjustment', 'usually', 'minor', 'frequency', 'table', 'analysis']"
672,"The estimated logit plot shows no apparent pattern. Therefore, mother_age may be entered into the model as a continuous variable because creating several groups will probably not improve the fit of the model. Although it seems mother_age is not an important predictor for low birth weight, the estimated logit plot is a univariate plot that can be misleading in the presence of partial associations and interactions. A model with two-factor interactions and main effects should be evaluated before mother_age is eliminated. Estimated logit plots should never be used to eliminate variables.",CD,590,"['estimated', 'logit', 'plot', 'show', 'apparent', 'pattern', 'therefore', 'motherage', 'may', 'entered', 'model', 'continuous', 'variable', 'creating', 'several', 'group', 'probably', 'improve', 'fit', 'model', 'although', 'seems', 'motherage', 'important', 'predictor', 'low', 'birth', 'weight', 'estimated', 'logit', 'plot', 'univariate', 'plot', 'misleading', 'presence', 'partial', 'association', 'interaction', 'model', 'twofactor', 'interaction', 'main_effect', 'evaluated', 'motherage', 'eliminated', 'estimated', 'logit', 'plot', 'never', 'used', 'eliminate', 'variable']"
673,"For logistic regression, the sufficient statistics for the in the model are where j=1,?, number of predictor variables. Therefore, the sufficient statistics for the parameters of the predictor variables are the sum of the cross-products of the response value and the predictor variable values. The sufficient statistic for the intercept is the total number of events since the intercept variable is constant at 1.",CD,413,"['logistic_regression', 'sufficient', 'statistic', 'model', 'j1', 'number', 'predictor_variable', 'therefore', 'sufficient', 'statistic', 'parameter', 'predictor_variable', 'sum', 'crossproducts', 'response', 'value', 'predictor_variable', 'value', 'sufficient', 'statistic', 'intercept', 'total', 'number', 'event', 'since', 'intercept', 'variable', 'constant', '1']"
674,"For backward elimination, the model selected when you allow multiple effects to leave the model at one time is the same as the model selected when you allow single effects to leave the model at one time. This is because only one main effect, not involved in a significant interaction, was itself not significant. Therefore, the method did not have the chance to eliminate the interaction along with its main effects in one step. When you include all the main effects in the model, the backward elimination method finds one significant interaction (mother_age*phy_visit). This is the same model as the one selected in forward selection including all the main effects. This model also has the highest c statistic (.793).",CD,718,"['backward', 'elimination', 'model', 'selected', 'allow', 'multiple', 'effect', 'leave', 'model', 'one', 'time', 'model', 'selected', 'allow', 'single', 'effect', 'leave', 'model', 'one', 'time', 'one', 'main_effect', 'involved', 'significant', 'interaction', 'wa', 'significant', 'therefore', 'method', 'chance', 'eliminate', 'interaction', 'along', 'main_effect', 'one', 'step', 'include', 'main_effect', 'model', 'backward', 'elimination', 'method', 'find', 'one', 'significant', 'interaction', 'motheragephyvisit', 'model', 'one', 'selected', 'forward', 'selection', 'including', 'main_effect', 'model', 'also', 'ha', 'highest', 'c', 'statistic', '793']"
675,"The logit transformation is the log of the odds, which is the ratio of the probability of the outcome to the probability of no outcome. To create a linear model, the logit transformation is applied to the probability. Unlike a probability, the logit is unbounded because transforming the probability to odds removes the upper bound, whereas taking the natural logarithm of the odds removes the lower bound. The model (also called the logistic regression model) is now linear because the logit is linear in its parameters. Furthermore, the model gives estimated probabilities that are between 0 and 1.",CD,600,"['logit', 'transformation', 'log', 'odds_ratio', 'probability', 'outcome', 'probability', 'outcome', 'create', 'linear', 'model', 'logit', 'transformation', 'applied', 'probability', 'unlike', 'probability', 'logit', 'unbounded', 'transforming', 'probability', 'odds', 'remove', 'upper', 'bound', 'whereas', 'taking', 'natural', 'logarithm', 'odds', 'remove', 'lower', 'bound', 'model', 'also', 'called', 'logistic_regression_model', 'linear', 'logit', 'linear', 'parameter', 'furthermore', 'model', 'give', 'estimated', 'probability', '0', '1']"
676,SUBJECT=	identifies subjects in the input data set. This is a required option and the variables used in defining the subjects must be listed in the CLASS statement. The input data set does not need to be sorted by subject. TYPE=	specifies the structure of the working correlation matrix used to model the correlation of responses from subjects. The default working correlation type is the independent correlation structure.,CD,423,"['subject\tidentifies', 'subject', 'input', 'data_set', 'required', 'option', 'variable', 'used', 'defining', 'subject', 'must', 'listed', 'class', 'statement', 'input', 'data_set', 'doe', 'need', 'sorted', 'subject', 'type\tspecifies', 'structure', 'working', 'correlation', 'matrix', 'used', 'model', 'correlation', 'response', 'subject', 'default', 'working', 'correlation', 'type', 'independent', 'correlation_structure']"
677,"For health-related studies, certain types of interactions have frequently been found to be significant. For example, the interaction between treatment and severity of disease sometimes shows that patients with mild severity have little opportunity to receive the treatment?s benefit. An example of an interaction between measurement and the state of the subject during a measurement is when the respiration rate measured during sleep has greater predictive value compared to the respiration rate measured during activity (Harrell 1997). Forward Selection",CD,554,"['healthrelated', 'study', 'certain', 'type', 'interaction', 'frequently', 'found', 'significant', 'example', 'interaction', 'treatment', 'severity', 'disease', 'sometimes', 'show', 'patient', 'mild', 'severity', 'little', 'opportunity', 'receive', 'treatment', 'benefit', 'example', 'interaction', 'measurement', 'state', 'subject', 'measurement', 'respiration', 'rate', 'measured', 'sleep', 'ha', 'greater', 'predictive', 'value', 'compared', 'respiration', 'rate', 'measured', 'activity', 'harrell', '1997', 'forward', 'selection']"
678,"In the CLASS statement in PROC LOGISTIC, you can specify the coding scheme for the design variables created from the CLASS variable. For effect coding (also called deviation from the mean coding), the number of design variables created is the number of levels of the CLASS variable minus 1. For example, because the variable socio has three levels, only two design variables are created. For the last level of the CLASS variable, all the design variables have a value of ?1. Parameter estimates of the CLASS main effects using this coding scheme estimate the difference between the effect of each level and the average effect over all levels. Effect coding is the default in PROC LOGISTIC.",CD,689,"['class', 'statement', 'proc_logistic', 'specify', 'coding', 'scheme', 'design', 'variable', 'created', 'class', 'variable', 'effect', 'coding', 'also', 'called', 'deviation', 'mean', 'coding', 'number', 'design', 'variable', 'created', 'number', 'level', 'class', 'variable', 'minus', '1', 'example', 'variable', 'socio', 'ha', 'three', 'level', 'two', 'design', 'variable', 'created', 'last', 'level', 'class', 'variable', 'design', 'variable', 'value', '1', 'parameter_estimate', 'class', 'main_effect', 'using', 'coding', 'scheme', 'estimate', 'difference', 'effect', 'level', 'average', 'effect', 'level', 'effect', 'coding', 'default', 'proc_logistic']"
679,The Analysis of Initial Parameter Estimates table shows the parameter estimates when the observations are treated as independent. These parameter estimates are used as the starting values for the GEE solution. Notice that both smoker and age are significant at the 0.05 significance level. GEE Model Information,CD,311,"['analysis', 'initial', 'parameter_estimate', 'table', 'show', 'parameter_estimate', 'observation', 'treated', 'independent', 'parameter_estimate', 'used', 'starting', 'value', 'gee', 'solution', 'notice', 'smoker', 'age', 'significant', '005', 'significance', 'level', 'gee', 'model', 'information']"
680,"The stepwise selection with HIERARCHY=SINGLE selected the same model as the forward selection method with HIERARCHY=SINGLE. This makes sense because both methods start with an empty model and select variables based on their significance. Stepwise selection has a backward component, which was not used in this case because all of the selected variables maintained their significance. The six techniques (not including forward and backward selection that included the main effects) selected four different models. This illustrates the precariousness of relying on these techniques to formulate a final model. However, the problem is not in the selection techniques, but rather in the analyst who fails to carefully scrutinize the resulting model and reports the results as the best model. Hosmer and Lemeshow (2000) commented as follows: The wide availability and ease with which stepwise methods can be used has undoubtedly reduced some analysts to a role where they are assisting the computer in model selection rather than the more appropriate alternative. It is only when the analyst understands the strengths, and especially the limitations, of the methods that these methods can serve as a useful tool in the model-building process. Best Subsets Selection",CD,1260,"['stepwise', 'selection', 'hierarchysingle', 'selected', 'model', 'forward', 'selection', 'method', 'hierarchysingle', 'make', 'sense', 'method', 'start', 'empty', 'model', 'select', 'variable', 'based', 'significance', 'stepwise', 'selection', 'ha', 'backward', 'component', 'wa', 'used', 'case', 'selected', 'variable', 'maintained', 'significance', 'six', 'technique', 'including', 'forward', 'backward', 'selection', 'included', 'main_effect', 'selected', 'four', 'different', 'model', 'illustrates', 'precariousness', 'relying', 'technique', 'formulate', 'final', 'model', 'however', 'problem', 'selection', 'technique', 'rather', 'analyst', 'fails', 'carefully', 'scrutinize', 'resulting', 'model', 'report', 'result', 'best', 'model', 'hosmer', 'lemeshow', '2000', 'commented', 'follows', 'wide', 'availability', 'ease', 'stepwise', 'method', 'used', 'ha', 'undoubtedly', 'reduced', 'analyst', 'role', 'assisting', 'computer', 'model', 'selection', 'rather', 'appropriate', 'alternative', 'analyst', 'understands', 'strength', 'especially', 'limitation', 'method', 'method', 'serve', 'useful', 'tool', 'modelbuilding', 'process', 'best', 'subset', 'selection']"
681,"Because repeated measurements are taken on each subject, a GEE model should be fit. However, the model building strategy is similar to the one used on the binary logistic regression model with independent observations. First, do an exploratory data analysis with contingency tables and logit plots. A useful contingency table would be the subject?s identification number by the response variable. Then fit a GEE model using various correlation structures based on subject-matter knowledge. The choice of correlation structure is irrelevant if the primary objective of the study is to estimate regression coefficients and there are a large number of subjects. Exploratory Data Analysis Using Logit Plots",CD,702,"['repeated', 'measurement', 'taken', 'subject', 'gee', 'model', 'fit', 'however', 'model', 'building', 'strategy', 'similar', 'one', 'used', 'binary', 'logistic_regression_model', 'independent', 'observation', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'useful', 'contingency', 'table', 'would', 'subject', 'identification', 'number', 'response_variable', 'fit', 'gee', 'model', 'using', 'various', 'correlation_structure', 'based', 'subjectmatter', 'knowledge', 'choice', 'correlation_structure', 'irrelevant', 'primary', 'objective', 'study', 'estimate', 'regression', 'coefficient', 'large', 'number', 'subject', 'exploratory', 'data', 'analysis', 'using', 'logit', 'plot']"
682,"A key assumption in the logistic regression model is that the logits are linearly related to each predictor variable. For binary predictor variables, this is not a problem because a straight line connects two points. However, for ordinal or continuous predictor variables, this assumption should be examined with the use of logit plots.",CD,336,"['key', 'assumption', 'logistic_regression_model', 'logits', 'linearly', 'related', 'predictor_variable', 'binary', 'predictor_variable', 'problem', 'straight', 'line', 'connects', 'two', 'point', 'however', 'ordinal', 'continuous', 'predictor_variable', 'assumption', 'examined', 'use', 'logit', 'plot']"
683,"For health-related studies, certain types of interactions have frequently been found to be significant. For example, the interaction between treatment and severity of disease sometimes shows that patients with mild severity have little opportunity to receive the treatment?s benefit. An example of an interaction between measurement and the state of the subject during a measurement is when the respiration rate measured during sleep has greater predictive value compared to the respiration rate measured during activity (Harrell 1997). Forward Selection",CD,554,"['healthrelated', 'study', 'certain', 'type', 'interaction', 'frequently', 'found', 'significant', 'example', 'interaction', 'treatment', 'severity', 'disease', 'sometimes', 'show', 'patient', 'mild', 'severity', 'little', 'opportunity', 'receive', 'treatment', 'benefit', 'example', 'interaction', 'measurement', 'state', 'subject', 'measurement', 'respiration', 'rate', 'measured', 'sleep', 'ha', 'greater', 'predictive', 'value', 'compared', 'respiration', 'rate', 'measured', 'activity', 'harrell', '1997', 'forward', 'selection']"
684,"The exchangeable correlation structure (TYPE=EXCH) assumes that the correlations are equal across time points. Although this structure may not be justified in longitudinal studies, it is often reasonable in situations where the repeated measurements are not obtained over time (Allison 1999). For example, the exchangeable correlation structure might be a good choice if the independent experimental units were classrooms and the responses obtained were from each student in the classroom (Davis 2002).",CD,502,"['exchangeable', 'correlation_structure', 'typeexch', 'assumes', 'correlation', 'equal', 'across', 'time', 'point', 'although', 'structure', 'may', 'justified', 'longitudinal', 'study', 'often', 'reasonable', 'situation', 'repeated', 'measurement', 'obtained', 'time', 'allison', '1999', 'example', 'exchangeable', 'correlation_structure', 'might', 'good', 'choice', 'independent', 'experimental', 'unit', 'classroom', 'response', 'obtained', 'student', 'classroom', 'davis', '2002']"
685,"Example:	Compute the deviance and Pearson chi-square statistics, the Hosmer-Lemeshow test, and the generalized R2 statistic on the model with all of the main effects and the mother_age*phy_visit interaction. /* c2demo09a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / aggregate scale=none lackfit rsq; title 'Low Birth Weight Model'; run; Selected MODEL statement options: AGGREGATE	requests that PROC LOGISTIC treat each unique combination of the predictor variable values as a distinct group in computing the goodness-of-fit statistics. SCALE=	specifies the value of the dispersion parameter or the method for estimating the dispersion parameter. This option is normally used to correct for overdispersion or underdispersion, but in this case it is required to display the goodness-of-fit statistics. LACKFIT	performs the Hosmer and Lemeshow goodness-of-fit test for the case of a binary outcome model. RSQ	requests a generalized R2 for the fitted model. Partial Output Deviance and Pearson Goodness-of-Fit Statistics",CD,1131,"['example\tcompute', 'deviance', 'pearson', 'chisquare', 'statistic', 'hosmerlemeshow', 'test', 'generalized', 'r2', 'statistic', 'model', 'main_effect', 'motheragephyvisit', 'interaction', '', 'c2demo09a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'aggregate', 'scalenone', 'lackfit', 'rsq', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'aggregate\trequests', 'proc_logistic', 'treat', 'unique', 'combination', 'predictor_variable', 'value', 'distinct', 'group', 'computing', 'goodnessoffit', 'statistic', 'scale\tspecifies', 'value', 'dispersion', 'parameter', 'method', 'estimating', 'dispersion', 'parameter', 'option', 'normally', 'used', 'correct', 'overdispersion', 'underdispersion', 'case', 'required', 'display', 'goodnessoffit', 'statistic', 'lackfit\tperforms', 'hosmer', 'lemeshow', 'goodnessoffit', 'test', 'case', 'binary', 'outcome', 'model', 'rsq\trequests', 'generalized', 'r2', 'fitted', 'model', 'partial', 'output', 'deviance', 'pearson', 'goodnessoffit', 'statistic']"
686,"After an extensive univariate and stratified data analysis, the above variables were identified as potential confounders. The criterion was a big difference between the crude odds ratio of the main effect and the adjusted odds ratio. For example, the crude odds ratio for history of hypertension is 3.365 and the odds ratio adjusted for mother?s weight is 6.435. Therefore, to obtain an accurate, unconfounded effect of history of hypertension, mother?s weight should be in the model.",CD,484,"['extensive', 'univariate', 'stratified', 'data', 'analysis', 'variable', 'identified', 'potential', 'confounders', 'criterion', 'wa', 'big', 'difference', 'crude', 'odds_ratio', 'main_effect', 'adjusted', 'odds_ratio', 'example', 'crude', 'odds_ratio', 'history', 'hypertension', '3365', 'odds_ratio', 'adjusted', 'mother', 'weight', '6435', 'therefore', 'obtain', 'accurate', 'unconfounded', 'effect', 'history', 'hypertension', 'mother', 'weight', 'model']"
687,"The p-value is the probability of getting an equal or less likely statistic. Thus, you would add the probabilities less than or equal to the probability of obtaining the vector of the observed sufficient statistics.",CD,215,"['pvalue', 'probability', 'getting', 'equal', 'le', 'likely', 'statistic', 'thus', 'would', 'add', 'probability', 'le', 'equal', 'probability', 'obtaining', 'vector', 'observed', 'sufficient', 'statistic']"
688,"Generalized linear models use the likelihood function in statistical inference. However, the distribution of the response variable must be specified. For discrete outcomes, it might be difficult to specify the appropriate theoretical probability distribution. Therefore, GEE regression models use the quasi-likelihood method of estimation. This estimation method only requires that you specify the relationships between the response mean and covariates and between the response mean and variance. Quasi-likelihood estimation possesses many of the advantages of maximum likelihood estimation without requiring full distributional assumptions. This is why the GEE approach is applicable to several types of response variables (Zeger and Liang 1986).",CD,747,"['generalized', 'linear', 'model', 'use', 'likelihood', 'function', 'statistical', 'inference', 'however', 'distribution', 'response_variable', 'must', 'specified', 'discrete', 'outcome', 'might', 'difficult', 'specify', 'appropriate', 'theoretical', 'probability', 'distribution', 'therefore', 'gee', 'regression_model', 'use', 'quasilikelihood', 'method', 'estimation', 'estimation', 'method', 'requires', 'specify', 'relationship', 'response', 'mean', 'covariates', 'response', 'mean', 'variance', 'quasilikelihood', 'estimation', 'posse', 'many', 'advantage', 'maximum', 'likelihood', 'estimation', 'without', 'requiring', 'full', 'distributional', 'assumption', 'gee', 'approach', 'applicable', 'several', 'type', 'response_variable', 'zeger', 'liang', '1986']"
689,"Based on subject-matter knowledge, one variable was selected from each cluster. Backache in previous pregnancy is a class variable because the levels can be considered nominal (1=not applicable, 2=no, 3=yes). The next step is to build an ordinal logistic regression model in PROC LOGISTIC. A reasonable approach is to search for interactions using forward selection with a very conservative significance level for entry. Then eliminate predictor variables that are not involved in any interactions, are clearly not significant, are not potential confounders, and have no subject-matter importance. Fitting Multiple Ordinal Logistic Regression Models",CD,649,"['based', 'subjectmatter', 'knowledge', 'one', 'variable', 'wa', 'selected', 'cluster', 'backache', 'previous', 'pregnancy', 'class', 'variable', 'level', 'considered', 'nominal', '1not', 'applicable', '2no', '3yes', 'next', 'step', 'build', 'ordinal', 'logistic_regression_model', 'proc_logistic', 'reasonable', 'approach', 'search', 'interaction', 'using', 'forward', 'selection', 'conservative', 'significance', 'level', 'entry', 'eliminate', 'predictor_variable', 'involved', 'interaction', 'clearly', 'significant', 'potential', 'confounders', 'subjectmatter', 'importance', 'fitting', 'multiple', 'ordinal', 'logistic_regression_model']"
690,"Forward selection starts with an empty model. The method computes an adjusted chi-square statistic for each predictor variable not in the model and examines the largest of these statistics. If it is significant at a specified significance level (specified by the SLENTRY= option), the corresponding variable is added to the model. After a variable is entered in the model, it is never removed from the model. The process is repeated until none of the remaining variables meet the specified level for entry. By default, SLENTRY=0.05. The forward selection method may be useful in assessing interactions. You start with the main effects only model (using the INCLUDE= option) and then let the forward selection method search for any significant interactions. The significance level should be relatively low (.01 or less) because you only want to include relatively strong interactions in your final model.",CD,903,"['forward', 'selection', 'start', 'empty', 'model', 'method', 'computes', 'adjusted', 'chisquare', 'statistic', 'predictor_variable', 'model', 'examines', 'largest', 'statistic', 'significant', 'specified', 'significance', 'level', 'specified', 'slentry', 'option', 'corresponding', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'never', 'removed', 'model', 'process', 'repeated', 'none', 'remaining', 'variable', 'meet', 'specified', 'level', 'entry', 'default', 'slentry005', 'forward', 'selection', 'method', 'may', 'useful', 'assessing', 'interaction', 'start', 'main_effect', 'model', 'using', 'include', 'option', 'let', 'forward', 'selection', 'method', 'search', 'significant', 'interaction', 'significance', 'level', 'relatively', 'low', '01', 'le', 'want', 'include', 'relatively', 'strong', 'interaction', 'final', 'model']"
691,"The TRACE statement produces a trace record of each output object, including the name and label. The LISTING option writes this information, interleaved with the procedure output, to the SAS listing. Partial Output Low Birth Weight Model",CD,237,"['trace', 'statement', 'produce', 'trace', 'record', 'output', 'object', 'including', 'name', 'label', 'listing', 'option', 'writes', 'information', 'interleaved', 'procedure', 'output', 'sa', 'listing', 'partial', 'output', 'low', 'birth', 'weight', 'model']"
692,The odds ratio indicates that women with previous preterm deliveries are 4.3 times more likely to have a low birth weight baby than women without previous preterm deliveries. The confidence interval is not symmetric around the estimate because distributions of ratios are asymmetric. The exact confidence interval is not needed because of the large sample size. Summary Statistics for prev_pretrm by low,CD,403,"['odds_ratio', 'indicates', 'woman', 'previous', 'preterm', 'delivery', '43', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'woman', 'without', 'previous', 'preterm', 'delivery', 'confidence', 'interval', 'symmetric', 'around', 'estimate', 'distribution', 'ratio', 'asymmetric', 'exact', 'confidence', 'interval', 'needed', 'large', 'sample_size', 'summary', 'statistic', 'prevpretrm', 'low']"
693,"It is common in fitting logistic regression models to have problems with convergence. This occurs because maximum likelihood estimates are determined using an iterative algorithm. In the LOGISTIC procedure, the iterations are considered to have converged when the maximum change in parameter estimates between successive steps is less than a certain value (the default is 1E-4). However, sometimes the algorithm fails to converge after a number of iterations (in PROC LOGISTIC the default limit is 25 iterations). A common cause of convergence problems is quasi- complete separation. Quasi-complete separation occurs when the level of a categorical predictor variable perfectly predicts the response. In other words, there is a frequency of 0 in a contingency table. The table above demonstrates the effects of quasi-complete separation. Because of the 0 count, the parameter estimate for the effect of level B will be infinite (PROC LOGISTIC reports the estimate after several iterations). It is obvious something is wrong with the model because of the large parameter estimate for B and the large standard error. The presence of 0 cell counts should be detected during the univariate screening of the data. Solutions to this problem include any of the following: *	collapsing the categories of the predictor variable to eliminate the 0 cell count *	performing exact logistic regression *	eliminating the category altogether *	treating the predictor variable as continuous if it is ordinal *	adding a very small constant to the cell counts. If you add the small constants, it is recommended that you do a sensitivity analysis by adding constants of various sizes in order to gauge their effect on the parameter estimates. You should be very concerned if the results of your model vary with small changes in the data (Allison 1999).",CD,1832,"['common', 'fitting', 'logistic_regression_model', 'problem', 'convergence', 'occurs', 'maximum', 'likelihood', 'estimate', 'determined', 'using', 'iterative', 'algorithm', 'logistic', 'procedure', 'iteration', 'considered', 'converged', 'maximum', 'change', 'parameter_estimate', 'successive', 'step', 'le', 'certain', 'value', 'default', '1e4', 'however', 'sometimes', 'algorithm', 'fails', 'converge', 'number', 'iteration', 'proc_logistic', 'default', 'limit', '25', 'iteration', 'common', 'cause', 'convergence', 'problem', 'quasi', 'complete', 'separation', 'quasicomplete', 'separation', 'occurs', 'level', 'categorical', 'predictor_variable', 'perfectly', 'predicts', 'response', 'word', 'frequency', '0', 'contingency', 'table', 'table', 'demonstrates', 'effect', 'quasicomplete', 'separation', '0', 'count', 'parameter_estimate', 'effect', 'level', 'b', 'infinite', 'proc_logistic', 'report', 'estimate', 'several', 'iteration', 'obvious', 'something', 'wrong', 'model', 'large', 'parameter_estimate', 'b', 'large', 'standard_error', 'presence', '0', 'cell', 'count', 'detected', 'univariate', 'screening', 'data', 'solution', 'problem', 'include', 'following', '\tcollapsing', 'category', 'predictor_variable', 'eliminate', '0', 'cell', 'count', '\tperforming', 'exact', 'logistic_regression', '\teliminating', 'category', 'altogether', '\ttreating', 'predictor_variable', 'continuous', 'ordinal', '\tadding', 'small', 'constant', 'cell', 'count', 'add', 'small', 'constant', 'recommended', 'sensitivity', 'analysis', 'adding', 'constant', 'various', 'size', 'order', 'gauge', 'effect', 'parameter_estimate', 'concerned', 'result', 'model', 'vary', 'small', 'change', 'data', 'allison', '1999']"
694,"The stepwise selection with HIERARCHY=SINGLE selected the same model as the forward selection method with HIERARCHY=SINGLE. This makes sense because both methods start with an empty model and select variables based on their significance. Stepwise selection has a backward component, which was not used in this case because all of the selected variables maintained their significance. The six techniques (not including forward and backward selection that included the main effects) selected four different models. This illustrates the precariousness of relying on these techniques to formulate a final model. However, the problem is not in the selection techniques, but rather in the analyst who fails to carefully scrutinize the resulting model and reports the results as the best model. Hosmer and Lemeshow (2000) commented as follows: The wide availability and ease with which stepwise methods can be used has undoubtedly reduced some analysts to a role where they are assisting the computer in model selection rather than the more appropriate alternative. It is only when the analyst understands the strengths, and especially the limitations, of the methods that these methods can serve as a useful tool in the model-building process. Best Subsets Selection",CD,1260,"['stepwise', 'selection', 'hierarchysingle', 'selected', 'model', 'forward', 'selection', 'method', 'hierarchysingle', 'make', 'sense', 'method', 'start', 'empty', 'model', 'select', 'variable', 'based', 'significance', 'stepwise', 'selection', 'ha', 'backward', 'component', 'wa', 'used', 'case', 'selected', 'variable', 'maintained', 'significance', 'six', 'technique', 'including', 'forward', 'backward', 'selection', 'included', 'main_effect', 'selected', 'four', 'different', 'model', 'illustrates', 'precariousness', 'relying', 'technique', 'formulate', 'final', 'model', 'however', 'problem', 'selection', 'technique', 'rather', 'analyst', 'fails', 'carefully', 'scrutinize', 'resulting', 'model', 'report', 'result', 'best', 'model', 'hosmer', 'lemeshow', '2000', 'commented', 'follows', 'wide', 'availability', 'ease', 'stepwise', 'method', 'used', 'ha', 'undoubtedly', 'reduced', 'analyst', 'role', 'assisting', 'computer', 'model', 'selection', 'rather', 'appropriate', 'alternative', 'analyst', 'understands', 'strength', 'especially', 'limitation', 'method', 'method', 'serve', 'useful', 'tool', 'modelbuilding', 'process', 'best', 'subset', 'selection']"
695,"The common effect of the predictor variable for different cumulative logits in the proportional odds model can be motivated by assuming that a regression model holds when the response is measured more finely (Anderson and Phillips 1981). For example, suppose there is an underlying continuous response variable with ordered categories that are produced via cutoff points. The relationship between the predictor variable and the response should not depend on the cutoff points. In other words, the effect parameters are invariant to the choice of categories for the response variable. Only the intercepts are affected by the cutoff points. The proportional odds model is therefore invariant to the choice of the outcome categories. There is some loss of efficiency when you collapse the ordinal categories, but when the observations are evenly spread among the categories the efficiency loss is minor. However, the efficiency loss is large when you collapse the ordinal categories to a binary response (Agresti 1996). Allison (1999) recommends that you need at least 10 observations for each category of the response variable. As the number of categories increases, ordinary least squares might be appropriate. However, Hastie et al. (1989) showed that ordinary least squares methods could give misleading results with up to 13 categories of the response variable. The proportional odds model also makes no assumptions about the distances between the categories. Therefore, how you code the ordinal outcome variable has no effect on the odds ratios. Fitting Simple Ordinal Logistic Regression Models",CD,1598,"['common', 'effect', 'predictor_variable', 'different', 'cumulative', 'logits', 'proportional', 'odds', 'model', 'motivated', 'assuming', 'regression_model', 'hold', 'response', 'measured', 'finely', 'anderson', 'phillips', '1981', 'example', 'suppose', 'underlying', 'continuous', 'response_variable', 'ordered', 'category', 'produced', 'via', 'cutoff', 'point', 'relationship', 'predictor_variable', 'response', 'depend', 'cutoff', 'point', 'word', 'effect', 'parameter', 'invariant', 'choice', 'category', 'response_variable', 'intercept', 'affected', 'cutoff', 'point', 'proportional', 'odds', 'model', 'therefore', 'invariant', 'choice', 'outcome', 'category', 'loss', 'efficiency', 'collapse', 'ordinal', 'category', 'observation', 'evenly', 'spread', 'among', 'category', 'efficiency', 'loss', 'minor', 'however', 'efficiency', 'loss', 'large', 'collapse', 'ordinal', 'category', 'binary', 'response', 'agresti', '1996', 'allison', '1999', 'recommends', 'need', 'least', '10', 'observation', 'category', 'response_variable', 'number', 'category', 'increase', 'ordinary', 'least', 'square', 'might', 'appropriate', 'however', 'hastie', 'et', 'al', '1989', 'showed', 'ordinary', 'least', 'square', 'method', 'could', 'give', 'misleading', 'result', '13', 'category', 'response_variable', 'proportional', 'odds', 'model', 'also', 'make', 'assumption', 'distance', 'category', 'therefore', 'code', 'ordinal', 'outcome', 'variable', 'ha', 'effect', 'odds_ratio', 'fitting', 'simple', 'ordinal', 'logistic_regression_model']"
696,"The algorithm for variable clustering starts off with all the variables in one cluster. A principal components analysis is then done on the variables and the algorithm examines the eigenvalues computed for each principal component. Eigenvalues measure how much variability is explained by the principal components. They are scaled so that the sum of the eigenvalues is equal to the number of variables. When the predictor variables are uncorrelated, then all of the eigenvalues equal 1. If there is only one group of variables that is related to each other, then the first eigenvalue (corresponding to the first principal component) is large and the others are all close to 0. However, if there are several groups of related variables, then several eigenvalues are much larger than 1. The algorithm examines the second eigenvalue because that determines whether there is more than one dominant dimension in the variable cluster. If the second eigenvalue is greater than a specified threshold, then the variable cluster is split into 2 groups. The process is repeated until the second eigenvalue drops below the threshold. Larger thresholds for the second eigenvalue give fewer clusters and less variation is explained among the predictor variables. Smaller thresholds give more clusters and more variation is explained. The default threshold is 1 because it represents the average size of the eigenvalues (if the correlation matrix is analyzed). To account for sampling variability, smaller values such as .70 have been suggested (Jackson 1991). However, the threshold should be chosen based on the results of variable clustering.",CD,1630,"['algorithm', 'variable', 'clustering', 'start', 'variable', 'one', 'cluster', 'principal', 'component', 'analysis', 'done', 'variable', 'algorithm', 'examines', 'eigenvalue', 'computed', 'principal', 'component', 'eigenvalue', 'measure', 'much', 'variability', 'explained', 'principal', 'component', 'scaled', 'sum', 'eigenvalue', 'equal', 'number', 'variable', 'predictor_variable', 'uncorrelated', 'eigenvalue', 'equal', '1', 'one', 'group', 'variable', 'related', 'first', 'eigenvalue', 'corresponding', 'first', 'principal', 'component', 'large', 'others', 'close', '0', 'however', 'several', 'group', 'related', 'variable', 'several', 'eigenvalue', 'much', 'larger', '1', 'algorithm', 'examines', 'second', 'eigenvalue', 'determines', 'whether', 'one', 'dominant', 'dimension', 'variable', 'cluster', 'second', 'eigenvalue', 'greater', 'specified', 'threshold', 'variable', 'cluster', 'split', '2', 'group', 'process', 'repeated', 'second', 'eigenvalue', 'drop', 'threshold', 'larger', 'threshold', 'second', 'eigenvalue', 'give', 'fewer', 'cluster', 'le', 'variation', 'explained', 'among', 'predictor_variable', 'smaller', 'threshold', 'give', 'cluster', 'variation', 'explained', 'default', 'threshold', '1', 'represents', 'average', 'size', 'eigenvalue', 'correlation', 'matrix', 'analyzed', 'account', 'sampling', 'variability', 'smaller', 'value', '70', 'suggested', 'jackson', '1991', 'however', 'threshold', 'chosen', 'based', 'result', 'variable', 'clustering']"
697,"A model using the same data and ignoring the matched pairs was run for illustrative purposes. The standard errors (in parentheses) are all lower for the unconditional parameter estimates compared to the conditional parameter estimates. The reason for the difference is that ignoring the matched pairs and treating the observations as though they are independent produces standard errors that are underestimated. The conditional parameter estimates are also quite different from the unconditional parameter estimates. The reason for this difference is that the conditional parameter estimates are stratum-specific because they are defined at the stratum level. The unconditional parameter estimates are population-averaged, rather than based on individual stratum. 3.5	Nominal Logistic Regression",CD,795,"['model', 'using', 'data', 'ignoring', 'matched', 'pair', 'wa', 'run', 'illustrative', 'purpose', 'standard_error', 'parenthesis', 'lower', 'unconditional', 'parameter_estimate', 'compared', 'conditional', 'parameter_estimate', 'reason', 'difference', 'ignoring', 'matched', 'pair', 'treating', 'observation', 'though', 'independent', 'produce', 'standard_error', 'underestimated', 'conditional', 'parameter_estimate', 'also', 'quite', 'different', 'unconditional', 'parameter_estimate', 'reason', 'difference', 'conditional', 'parameter_estimate', 'stratumspecific', 'defined', 'stratum', 'level', 'unconditional', 'parameter_estimate', 'populationaveraged', 'rather', 'based', 'individual', 'stratum', '35\tnominal', 'logistic_regression']"
698,"After you have formulated the final model, you need to assess how well it fits the data. In other words, you need to assess how close the model-predicted values are to the corresponding observed values. Test statistics that assess the fit of the model are called goodness-of-fit statistics. If departures of the predicted values from the observed values are essentially random, then the goodness-of-fit statistics are not statistically significant. Some of the problems that can cause the goodness-of-fit statistics to be statistically significant are having outliers in the data, omitting important terms in the model such as interactions, needing to transform some predictor variables, having a nonlinear relationship between the logits and a predictor variable, and having a model that has greater variability than predicted by the random component of the model. This latter problem is also known as overdispersion, and it occurs when the assumption of binomial variability may not be valid. These problems should be examined before proceeding to use methods to correct for overdispersion (SAS Institute Inc. 1995). Another problem with logistic regression, as in linear regression, is multicollinearity. This occurs when there are strong linear dependencies among the predictor variables. Although multicollinearity does not bias the parameter estimates, it does increase their variances, which results in less precise estimates of the parameters (Allison 1999). There are no multicollinearity diagnostics in the LOGISTIC procedure. However, you can use the diagnostics in the REG procedure because multicollinearity only deals with the predictor variables, not the outcome variable. Some of the options in the MODEL statement in PROC REG include TOL, VIF, COLLIN, and COLLINOINT. In most cases, serious multicollinearity will be detected. In rare instances you may fail to detect the problem because the linear combinations should actually be adjusted by the weight matrix used in the maximum likelihood algorithm (Allison 1999).",CD,2034,"['formulated', 'final', 'model', 'need', 'ass', 'well', 'fit', 'data', 'word', 'need', 'ass', 'close', 'modelpredicted', 'value', 'corresponding', 'observed', 'value', 'test', 'statistic', 'ass', 'fit', 'model', 'called', 'goodnessoffit', 'statistic', 'departure', 'predicted', 'value', 'observed', 'value', 'essentially', 'random', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'problem', 'cause', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'outlier', 'data', 'omitting', 'important', 'term', 'model', 'interaction', 'needing', 'transform', 'predictor_variable', 'nonlinear', 'relationship', 'logits', 'predictor_variable', 'model', 'ha', 'greater', 'variability', 'predicted', 'random', 'component', 'model', 'latter', 'problem', 'also', 'known', 'overdispersion', 'occurs', 'assumption', 'binomial', 'variability', 'may', 'valid', 'problem', 'examined', 'proceeding', 'use', 'method', 'correct', 'overdispersion', 'sa', 'institute', 'inc', '1995', 'another', 'problem', 'logistic_regression', 'linear', 'regression', 'multicollinearity', 'occurs', 'strong', 'linear', 'dependency', 'among', 'predictor_variable', 'although', 'multicollinearity', 'doe', 'bias', 'parameter_estimate', 'doe', 'increase', 'variance', 'result', 'le', 'precise', 'estimate', 'parameter', 'allison', '1999', 'multicollinearity', 'diagnostics', 'logistic', 'procedure', 'however', 'use', 'diagnostics', 'reg', 'procedure', 'multicollinearity', 'deal', 'predictor_variable', 'outcome', 'variable', 'option', 'model_statement', 'proc', 'reg', 'include', 'tol', 'vif', 'collin', 'collinoint', 'case', 'serious', 'multicollinearity', 'detected', 'rare', 'instance', 'may', 'fail', 'detect', 'problem', 'linear', 'combination', 'actually', 'adjusted', 'weight', 'matrix', 'used', 'maximum', 'likelihood', 'algorithm', 'allison', '1999']"
699,"Because the response variable has more than 2 levels, by default PROC LOGISTIC models cumulative logits. With the DESCENDING option, the probabilities modeled are cumulated by the jth category and higher. Score Test for the Proportional Odds Assumption",CD,252,"['response_variable', 'ha', '2', 'level', 'default', 'proc_logistic', 'model', 'cumulative', 'logits', 'descending', 'option', 'probability', 'modeled', 'cumulated', 'jth', 'category', 'higher', 'score', 'test', 'proportional', 'odds', 'assumption']"
700,"The goal of conditional exact inference is to determine how likely the observed sequence of binary response values is with respect to all other sequences of binary response values having the same sufficient statistics for the nuisance parameters. All possible sequences of binary response values is referred to as the permutation distribution. To accomplish this goal, the conditional permutation distribution for the sufficient statistics of the parameters of interest needs to be generated. In other words, for every possible sequence of binary responses, the sufficient statistics for the parameters needs to be computed. A simple example illustrates the method. Suppose you had 5 observations in your data with a binary response variable and a dummy-coded predictor variable (values of 0 or 1). The observed data values are on the above slide. The sufficient statistic values are 1 for the intercept and 1 for the parameter for the dummy-coded predictor variable. The number of possible sequences of response values is 32 (25).",CD,1031,"['goal', 'conditional', 'exact', 'inference', 'determine', 'likely', 'observed', 'sequence', 'binary', 'response', 'value', 'respect', 'sequence', 'binary', 'response', 'value', 'sufficient', 'statistic', 'nuisance', 'parameter', 'possible', 'sequence', 'binary', 'response', 'value', 'referred', 'permutation', 'distribution', 'accomplish', 'goal', 'conditional', 'permutation', 'distribution', 'sufficient', 'statistic', 'parameter', 'interest', 'need', 'generated', 'word', 'every', 'possible', 'sequence', 'binary', 'response', 'sufficient', 'statistic', 'parameter', 'need', 'computed', 'simple', 'example', 'illustrates', 'method', 'suppose', '5', 'observation', 'data', 'binary', 'response_variable', 'dummycoded', 'predictor_variable', 'value', '0', '1', 'observed', 'data', 'value', 'slide', 'sufficient', 'statistic', 'value', '1', 'intercept', '1', 'parameter', 'dummycoded', 'predictor_variable', 'number', 'possible', 'sequence', 'response', 'value', '32', '25']"
701,"In this course, contrasts are used to compute the odds ratio that compares one level of a CLASS variable to another level. However, in order to construct a contrast, you need to be able to define the coefficients for the test of the hypothesis. For example, to compute the odds ratio that compares low to medium for the variable socio in a CONTRAST statement, you should first write the model equation for each of the levels.",CD,425,"['course', 'contrast', 'used', 'compute', 'odds_ratio', 'compare', 'one', 'level', 'class', 'variable', 'another', 'level', 'however', 'order', 'construct', 'contrast', 'need', 'able', 'define', 'coefficient', 'test', 'hypothesis', 'example', 'compute', 'odds_ratio', 'compare', 'low', 'medium', 'variable', 'socio', 'contrast', 'statement', 'first', 'write', 'model', 'equation', 'level']"
702,"PROC FREQ computes three different types of CMH statistics: TYPE 1	is the correlation statistic, which is sensitive only to linear associations. This statistic is appropriate only when both the row and the column variable are ordinally scaled. TYPE 2	is the mean score statistic, which is sensitive to different means among the levels or groups of the nominal predictor. This statistic requires that the column variable be ordinally scaled. TYPE 3	is a generalization of the Pearson chi-square, which is sensitive to general patterns of association. This statistic is always interpretable because it does not require an ordinal scale for either variable.",CD,654,"['proc', 'freq', 'computes', 'three', 'different', 'type', 'cmh', 'statistic', 'type', '1\tis', 'correlation', 'statistic', 'sensitive', 'linear', 'association', 'statistic', 'appropriate', 'row', 'column', 'variable', 'ordinally', 'scaled', 'type', '2\tis', 'mean', 'score', 'statistic', 'sensitive', 'different', 'mean', 'among', 'level', 'group', 'nominal', 'predictor', 'statistic', 'requires', 'column', 'variable', 'ordinally', 'scaled', 'type', '3\tis', 'generalization', 'pearson', 'chisquare', 'sensitive', 'general', 'pattern', 'association', 'statistic', 'always', 'interpretable', 'doe', 'require', 'ordinal', 'scale', 'either', 'variable']"
703,"PROC GENMOD can be used to fit GEE models to clustered data. The layout of the data corresponds to the number of observations being equal to the number of measurements taken on all the subjects. The variance-covariance matrix is a block diagonal matrix in which the observations within each block are assumed to be correlated and the observations outside of the blocks are assumed to be independent. Selected GENMOD procedure statements: CLASS	specifies the classification variables to be used in the analysis. If the CLASS statement is used, it must appear before the MODEL statement. MODEL	specifies the response variable and the predictor variables. REPEATED	invokes the GEE method, specifies the correlation structure, and controls the displayed output from the longitudinal model. ESTIMATE	provides a means for obtaining a test for a specified hypothesis concerning the model parameters. It can also be used to produce the odds ratio estimate along with the 95% confidence limits. OUTPUT	creates a new SAS data set that contains all the variables in the input data set and, optionally, the estimated linear predictors and their standard error estimates, the weights for the Hessian matrix, predicted values of the mean, confidence limits for predicted values, and residuals. Selected CLASS statement options: PARAM=	specifies the parameterization method for the classification variable or variables. Design matrix columns are created from CLASS variables according to the following coding schemes: 	EFFECT	species effect coding. GLM	specifies less than full rank, reference-cell coding. This coding is the default. ORDINAL	specifies the cumulative parameterization for an ordinal CLASS variable. 	POLY	specifies polynomial coding. 	REF	specifies reference cell coding. 	ORTHEFFECT	orthogonalizes PARAM=EFFECT. 	ORTHORDINAL	orthogonalizes PARAM=ORDINAL. 	ORTHPOLY	orthogonalizes PARAM=POLY. 	ORTHREF	orthogonalizes PARAM=REF. REF=	specifies the reference cell for PARAM=EFFECT, PARAM=REF, and their orthogonalizations.",CD,2022,"['proc', 'genmod', 'used', 'fit', 'gee', 'model', 'clustered', 'data', 'layout', 'data', 'corresponds', 'number', 'observation', 'equal', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'selected', 'genmod', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'used', 'must', 'appear', 'model_statement', 'model\tspecifies', 'response_variable', 'predictor_variable', 'repeated\tinvokes', 'gee', 'method', 'specifies', 'correlation_structure', 'control', 'displayed', 'output', 'longitudinal', 'model', 'estimate\tprovides', 'mean', 'obtaining', 'test', 'specified', 'hypothesis', 'concerning', 'model', 'parameter', 'also', 'used', 'produce', 'odds_ratio', 'estimate', 'along', '95', 'confidence', 'limit', 'output\tcreates', 'new', 'sa', 'data_set', 'contains', 'variable', 'input', 'data_set', 'optionally', 'estimated', 'linear', 'predictor', 'standard_error', 'estimate', 'weight', 'hessian', 'matrix', 'predicted', 'value', 'mean', 'confidence', 'limit', 'predicted', 'value', 'residual', 'selected', 'class', 'statement', 'option', 'param\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'design', 'matrix', 'column', 'created', 'class', 'variable', 'according', 'following', 'coding', 'scheme', '\teffect\tspecies', 'effect', 'coding', 'glm\tspecifies', 'le', 'full', 'rank', 'referencecell', 'coding', 'coding', 'default', 'ordinal\tspecifies', 'cumulative', 'parameterization', 'ordinal', 'class', 'variable', '\tpoly\tspecifies', 'polynomial', 'coding', '\tref\tspecifies', 'reference', 'cell', 'coding', '\tortheffect\torthogonalizes', 'parameffect', '\torthordinal\torthogonalizes', 'paramordinal', '\torthpoly\torthogonalizes', 'parampoly', '\torthref\torthogonalizes', 'paramref', 'ref\tspecifies', 'reference', 'cell', 'parameffect', 'paramref', 'orthogonalizations']"
704,"Unfortunately, the distributions of the diagnostic statistics are not known, so cutoff values cannot be given for determining when the values are large (Pregibon 1981). Therefore, you have to rely on visual inspection of these statistics. Hosmer and Lemeshow (2000) recommend plotting the influence statistics such as the change in the Pearson chi-square against the predicted values. Graphing these influence statistics may enable you to identify those covariate patterns (subjects) that are poorly fit by the model. Examination of these patterns may indicate that important variables are missing from the model or that some of the variables in the model have not been entered in the correct scale. These patterns may also identify erroneous data values. The plot above is a plot of the change in the Pearson chi-square statistic by the predicted probabilities. The points on the curve going from the upper-left to the lower-right corner correspond to the covariate patterns with a response value of 1. The points on the curve going from the upper- right to the lower-left corners correspond to the covariate patterns with a response value of 0. Covariate patterns that are poorly fit by the model will lie in the upper-right and left corners of the plot. Hosmer and Lemeshow (2000) suggest that values of the change in the Pearson chi-square statistic above 4 are potential outliers. ?	Another graph that can be used to identify influential observations and outliers in relatively small data sets is the index plot. In an index plot, the diagnostic statistic is plotted against the observation number. This enables visual inspection and comparison of the values across observations. If the model is correctly specified and fits all observations well, then no extreme points should appear. The IPLOTS option in the MODEL statement requests an index plot for each regression diagnostic statistic.",CD,1896,"['unfortunately', 'distribution', 'diagnostic', 'statistic', 'known', 'cutoff', 'value', 'cannot', 'given', 'determining', 'value', 'large', 'pregibon', '1981', 'therefore', 'rely', 'visual', 'inspection', 'statistic', 'hosmer', 'lemeshow', '2000', 'recommend', 'plotting', 'influence', 'statistic', 'change', 'pearson', 'chisquare', 'predicted', 'value', 'graphing', 'influence', 'statistic', 'may', 'enable', 'identify', 'covariate', 'pattern', 'subject', 'poorly', 'fit', 'model', 'examination', 'pattern', 'may', 'indicate', 'important', 'variable', 'missing', 'model', 'variable', 'model', 'entered', 'correct', 'scale', 'pattern', 'may', 'also', 'identify', 'erroneous', 'data', 'value', 'plot', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'point', 'curve', 'going', 'upperleft', 'lowerright', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '1', 'point', 'curve', 'going', 'upper', 'right', 'lowerleft', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '0', 'covariate', 'pattern', 'poorly', 'fit', 'model', 'lie', 'upperright', 'left', 'corner', 'plot', 'hosmer', 'lemeshow', '2000', 'suggest', 'value', 'change', 'pearson', 'chisquare', 'statistic', '4', 'potential', 'outlier', '\tanother', 'graph', 'used', 'identify', 'influential', 'observation', 'outlier', 'relatively', 'small', 'data_set', 'index', 'plot', 'index', 'plot', 'diagnostic', 'statistic', 'plotted', 'observation', 'number', 'enables', 'visual', 'inspection', 'comparison', 'value', 'across', 'observation', 'model', 'correctly', 'specified', 'fit', 'observation', 'well', 'extreme', 'point', 'appear', 'iplots', 'option', 'model_statement', 'request', 'index', 'plot', 'regression', 'diagnostic', 'statistic']"
705,"Example:	An insurance company wants to relate the safety of vehicles to several other variables. A score has been given to each vehicle model, using the frequency of insurance claims as a basis. The data is in the sasuser.safety data set. The variables in the data set are safety	safety score (1=Below Average, 0=Average or Above) type	type of vehicle (Sports, Small, Medium, Large, and Sport/Utility) region	manufacturing region (Asia, N America) weight	weight of the vehicle in thousands of pounds. Recall from the exercises that the logistic model for the car safety data detected quasi-complete separation of data. This occurred because none of the large cars had below average safety records. The parameter estimate and standard error for the large effect were deemed unreliable. Fitting Exact Logistic Regression Models with the Hybrid Network ? Monte Carlo Algorithm Example:	Fit an exact logistic regression model using the Monte Carlo algorithm with safety as the response variable and type, region, and weight as the predictor variables. Model the probability of below average safety scores and request that the individual parameters and the odds ratios be estimated. Specify type and region as classification variables using reference cell coding. Specify Small as the reference level for type and Asia as the reference level for region. Also, add the observed sufficient statistic to the sampled exact distribution, specify that 100,000 Monte Carlo samples be taken, and set the seed at 27514. /* c3demo19a */ proc logistic data=sasuser.safety exactoptions(method=networkmc addtobs n=100000 seed=27514); class type (param=ref ref='Small') region (param=ref ref='Asia'); model safety = type region weight; exact type weight region / estimate=both; title 'Car Safety Model'; run; PROC LOGISTIC statement options: EXACTOPTIONS(options)	specifies options that apply to every EXACT statement in the program. Selected EXACTOPTIONS options: ADDTOBS	adds the observed sufficient statistic to the sampled exact distribution if the statistic was not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified and the ESTIMATE option is specified in the EXACT statement. If the observed statistic has not been sampled, then the parameter estimate does not exist: by specifying this option, you can produce (biased) estimates. METHOD=	specifies which exact conditional algorithm to use for every EXACT statement specified. The keywords are DIRECT (invokes the multivariate shift algorithm), NETWORK (invokes a network algorithm) and NETWORKMC (invokes the hybrid network and Monte Carlo algorithm). N=	specifies the number of Monte Carlo samples to take when METHOD=NETWORKMC. By default n=10,000. SEED=	specifies the initial seed for the random number generator used to take the Monte Carlo samples for METHOD=NETWORKMC. The value of the SEED= option must be an integer. If you do not specify a seed, or if you specify a value less than or equal to zero, then PROC LOGISTIC uses the time of day from the computer?s clock to generate the initial seed. Car Safety Model",CD,3092,"['example\tan', 'insurance', 'company', 'want', 'relate', 'safety', 'vehicle', 'several', 'variable', 'score', 'ha', 'given', 'vehicle', 'model', 'using', 'frequency', 'insurance', 'claim', 'basis', 'data', 'sasusersafety', 'data_set', 'variable', 'data_set', 'safety\tsafety', 'score', '1below', 'average', '0average', 'type\ttype', 'vehicle', 'sport', 'small', 'medium', 'large', 'sportutility', 'region\tmanufacturing', 'region', 'asia', 'n', 'america', 'weight\tweight', 'vehicle', 'thousand', 'pound', 'recall', 'exercise', 'logistic', 'model', 'car', 'safety', 'data', 'detected', 'quasicomplete', 'separation', 'data', 'occurred', 'none', 'large', 'car', 'average', 'safety', 'record', 'parameter_estimate', 'standard_error', 'large', 'effect', 'deemed', 'unreliable', 'fitting', 'exact', 'logistic_regression_model', 'hybrid', 'network', '', 'monte', 'carlo', 'algorithm', 'example\tfit', 'exact', 'logistic_regression_model', 'using', 'monte', 'carlo', 'algorithm', 'safety', 'response_variable', 'type', 'region', 'weight', 'predictor_variable', 'model', 'probability', 'average', 'safety', 'score', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'specify', 'type', 'region', 'classification', 'variable', 'using', 'reference', 'cell', 'coding', 'specify', 'small', 'reference', 'level', 'type', 'asia', 'reference', 'level', 'region', 'also', 'add', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'specify', '100000', 'monte', 'carlo', 'sample', 'taken', 'set', 'seed', '27514', '', 'c3demo19a', '', 'proc_logistic', 'datasasusersafety', 'exactoptionsmethodnetworkmc', 'addtobs', 'n100000', 'seed27514', 'class', 'type', 'paramref', 'refsmall', 'region', 'paramref', 'refasia', 'model', 'safety', '', 'type', 'region', 'weight', 'exact', 'type', 'weight', 'region', '', 'estimateboth', 'title', 'car', 'safety', 'model', 'run', 'proc_logistic', 'statement', 'option', 'exactoptionsoptions\tspecifies', 'option', 'apply', 'every', 'exact', 'statement', 'program', 'selected', 'exactoptions', 'option', 'addtobs\tadds', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'statistic', 'wa', 'sampled', 'option', 'ha', 'effect', 'unless', 'methodnetworkmc', 'option', 'specified', 'estimate', 'option', 'specified', 'exact', 'statement', 'observed', 'statistic', 'ha', 'sampled', 'parameter_estimate', 'doe', 'exist', 'specifying', 'option', 'produce', 'biased', 'estimate', 'method\tspecifies', 'exact', 'conditional', 'algorithm', 'use', 'every', 'exact', 'statement', 'specified', 'keywords', 'direct', 'invokes', 'multivariate', 'shift', 'algorithm', 'network', 'invokes', 'network', 'algorithm', 'networkmc', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'algorithm', 'n\tspecifies', 'number', 'monte', 'carlo', 'sample', 'take', 'methodnetworkmc', 'default', 'n10000', 'seed\tspecifies', 'initial', 'seed', 'random', 'number', 'generator', 'used', 'take', 'monte', 'carlo', 'sample', 'methodnetworkmc', 'value', 'seed', 'option', 'must', 'integer', 'specify', 'seed', 'specify', 'value', 'le', 'equal', 'zero', 'proc_logistic', 'us', 'time', 'day', 'computer', 'clock', 'generate', 'initial', 'seed', 'car', 'safety', 'model']"
706,"Generating the exact conditional distribution becomes unfeasible with a large number of observations. For example, if you had 30 observations you would have to scan 230 or more than a billion different sequences of the binary response values. However, PROC LOGISTIC has several numerical algorithms that use faster methods of generating and counting the response value vectors for larger problems. The multivariate shift algorithm developed by Hirji, Mehta, and Patel (1987) is invoked using the METHOD=DIRECT option. This method uses a number of shortcuts in a brand and bound algorithm to build the exact distribution, but it may require an excessive amount of memory in its intermediate stages. The METHOD=NETWORK option invokes a method (described in Mehta, Patel, and Senchaudhuri (1992)) that is faster and requires less memory than the DIRECT method. The NETWORK method is invoked by default for most analyses. Finally, the METHOD=NETWORKMC option invokes a hybrid network and a Monte Carlo sampling algorithm (described in Mehta, Patel, and Senchaudhuri (2000)) that samples from the combined network to estimate the exact distribution. This method is most useful for producing parameter estimates for problems that are too large for the DIRECT and NETWORK methods to handle and for which the asymptotic methods are invalid (sparse data on a large grid). ?	Monte Carlo simulation is performed using random sampling from the probability density functions. This is different than a bootstrapped sample where you sample with replacement from a given data set, compute statistics, and repeat many times. With bootstrapping, you are basically creating a distribution for a target statistic. The Monte Carlo algorithm starts with a network where every path through the network corresponds to a sequence with the correct sufficient statistics. Then the algorithm does a weighted random traversal of the network to sample a binary sequence to create a sampled distribution.",CD,1973,"['generating', 'exact', 'conditional', 'distribution', 'becomes', 'unfeasible', 'large', 'number', 'observation', 'example', '30', 'observation', 'would', 'scan', '230', 'billion', 'different', 'sequence', 'binary', 'response', 'value', 'however', 'proc_logistic', 'ha', 'several', 'numerical', 'algorithm', 'use', 'faster', 'method', 'generating', 'counting', 'response', 'value', 'vector', 'larger', 'problem', 'multivariate', 'shift', 'algorithm', 'developed', 'hirji', 'mehta', 'patel', '1987', 'invoked', 'using', 'methoddirect', 'option', 'method', 'us', 'number', 'shortcut', 'brand', 'bound', 'algorithm', 'build', 'exact', 'distribution', 'may', 'require', 'excessive', 'amount', 'memory', 'intermediate', 'stage', 'methodnetwork', 'option', 'invokes', 'method', 'described', 'mehta', 'patel', 'senchaudhuri', '1992', 'faster', 'requires', 'le', 'memory', 'direct', 'method', 'network', 'method', 'invoked', 'default', 'analysis', 'finally', 'methodnetworkmc', 'option', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'sampling', 'algorithm', 'described', 'mehta', 'patel', 'senchaudhuri', '2000', 'sample', 'combined', 'network', 'estimate', 'exact', 'distribution', 'method', 'useful', 'producing', 'parameter_estimate', 'problem', 'large', 'direct', 'network', 'method', 'handle', 'asymptotic', 'method', 'invalid', 'sparse', 'data', 'large', 'grid', '\tmonte', 'carlo', 'simulation', 'performed', 'using', 'random', 'sampling', 'probability', 'density', 'function', 'different', 'bootstrapped', 'sample', 'sample', 'replacement', 'given', 'data_set', 'compute', 'statistic', 'repeat', 'many', 'time', 'bootstrapping', 'basically', 'creating', 'distribution', 'target', 'statistic', 'monte', 'carlo', 'algorithm', 'start', 'network', 'every', 'path', 'network', 'corresponds', 'sequence', 'correct', 'sufficient', 'statistic', 'algorithm', 'doe', 'weighted', 'random', 'traversal', 'network', 'sample', 'binary', 'sequence', 'create', 'sampled', 'distribution']"
707,Variables with the lowest 1 minus R-squared ratio are variables with a high correlation with their own cluster and with a low correlation with the other clusters. These variables may be good representative variables from each cluster.,CD,234,"['variable', 'lowest', '1', 'minus', 'rsquared', 'ratio', 'variable', 'high', 'correlation', 'cluster', 'low', 'correlation', 'cluster', 'variable', 'may', 'good', 'representative', 'variable', 'cluster']"
708,"For the 2-dependent correlation structure (TYPE=MDEP(2)), measurements are correlated if they are two or less time periods apart. Measurements that are one time period apart have different correlations than measurements that are two time periods apart. These last two correlation structures are generally called m-dependent correlation structures. The m represents how many time periods apart the measurements are still correlated. Therefore, a 5- dependent correlation structure would indicate that measurements are correlated if they are five or fewer time periods apart.",CD,573,"['2dependent', 'correlation_structure', 'typemdep2', 'measurement', 'correlated', 'two', 'le', 'time', 'period', 'apart', 'measurement', 'one', 'time', 'period', 'apart', 'different', 'correlation', 'measurement', 'two', 'time', 'period', 'apart', 'last', 'two', 'correlation_structure', 'generally', 'called', 'mdependent', 'correlation_structure', 'represents', 'many', 'time', 'period', 'apart', 'measurement', 'still', 'correlated', 'therefore', '5', 'dependent', 'correlation_structure', 'would', 'indicate', 'measurement', 'correlated', 'five', 'fewer', 'time', 'period', 'apart']"
709,"When fitting a GEE model in PROC GENMOD, you should decide what is a reasonable model for the correlation between measurements within subject. PROC GENMOD offers several common structures to use to model the working correlation matrix. The choice of the structure should be consistent with the empirical correlations. Liang and Zeger (1986) showed that there could be important gains in efficiency by correctly specifying the working correlation matrix. However, the loss of efficiency is inconsequential when the number of clusters is large (Davis 2002).",CD,555,"['fitting', 'gee', 'model', 'proc', 'genmod', 'decide', 'reasonable', 'model', 'correlation', 'measurement', 'within', 'subject', 'proc', 'genmod', 'offer', 'several', 'common', 'structure', 'use', 'model', 'working', 'correlation', 'matrix', 'choice', 'structure', 'consistent', 'empirical', 'correlation', 'liang', 'zeger', '1986', 'showed', 'could', 'important', 'gain', 'efficiency', 'correctly', 'specifying', 'working', 'correlation', 'matrix', 'however', 'loss', 'efficiency', 'inconsequential', 'number', 'cluster', 'large', 'davis', '2002']"
710,"The stepwise selection with HIERARCHY=SINGLE selected the same model as the forward selection method with HIERARCHY=SINGLE. This makes sense because both methods start with an empty model and select variables based on their significance. Stepwise selection has a backward component, which was not used in this case because all of the selected variables maintained their significance. The six techniques (not including forward and backward selection that included the main effects) selected four different models. This illustrates the precariousness of relying on these techniques to formulate a final model. However, the problem is not in the selection techniques, but rather in the analyst who fails to carefully scrutinize the resulting model and reports the results as the best model. Hosmer and Lemeshow (2000) commented as follows: The wide availability and ease with which stepwise methods can be used has undoubtedly reduced some analysts to a role where they are assisting the computer in model selection rather than the more appropriate alternative. It is only when the analyst understands the strengths, and especially the limitations, of the methods that these methods can serve as a useful tool in the model-building process. Best Subsets Selection",CD,1260,"['stepwise', 'selection', 'hierarchysingle', 'selected', 'model', 'forward', 'selection', 'method', 'hierarchysingle', 'make', 'sense', 'method', 'start', 'empty', 'model', 'select', 'variable', 'based', 'significance', 'stepwise', 'selection', 'ha', 'backward', 'component', 'wa', 'used', 'case', 'selected', 'variable', 'maintained', 'significance', 'six', 'technique', 'including', 'forward', 'backward', 'selection', 'included', 'main_effect', 'selected', 'four', 'different', 'model', 'illustrates', 'precariousness', 'relying', 'technique', 'formulate', 'final', 'model', 'however', 'problem', 'selection', 'technique', 'rather', 'analyst', 'fails', 'carefully', 'scrutinize', 'resulting', 'model', 'report', 'result', 'best', 'model', 'hosmer', 'lemeshow', '2000', 'commented', 'follows', 'wide', 'availability', 'ease', 'stepwise', 'method', 'used', 'ha', 'undoubtedly', 'reduced', 'analyst', 'role', 'assisting', 'computer', 'model', 'selection', 'rather', 'appropriate', 'alternative', 'analyst', 'understands', 'strength', 'especially', 'limitation', 'method', 'method', 'serve', 'useful', 'tool', 'modelbuilding', 'process', 'best', 'subset', 'selection']"
711,"In this example the number of subjects is very large and the number of time points very small. Therefore, there should be little difference in the parameter estimates and the robust standard errors across the different correlation structures. The above slide illustrates the robustness of the GEE methods with regard to obtaining consistent parameter estimates and standard errors. Notice the standard errors increased for smoker and decreased for age when compared to the initial independent model. 3.2	Proportional Odds Model",CD,527,"['example', 'number', 'subject', 'large', 'number', 'time', 'point', 'small', 'therefore', 'little', 'difference', 'parameter_estimate', 'robust', 'standard_error', 'across', 'different', 'correlation_structure', 'slide', 'illustrates', 'robustness', 'gee', 'method', 'regard', 'obtaining', 'consistent', 'parameter_estimate', 'standard_error', 'notice', 'standard_error', 'increased', 'smoker', 'decreased', 'age', 'compared', 'initial', 'independent', 'model', '32\tproportional', 'odds', 'model']"
712,"Unlike the binary and ordinal logistic models, the nominal logistic model has separate intercept parameters and separate slope parameters for each generalized logit. Therefore, there are multiple sets of parameters for both the intercept terms and the predictor variables. When building nominal models, you should consider whether the sample size is large enough to support the number of generalized logits you are modeling. Because you are estimating many parameters, you may encounter parameter estimation problems with small sample sizes. As a general rule you need each possible outcome to have at least five observations per explanatory variable in the model for valid estimation to proceed (Stokes, Davis, and Koch 2000). If you have a small sample size, one solution is to use the EXACT statement to fit an exact logistic regression model.",CD,846,"['unlike', 'binary', 'ordinal', 'logistic', 'model', 'nominal', 'logistic', 'model', 'ha', 'separate', 'intercept', 'parameter', 'separate', 'slope', 'parameter', 'generalized', 'logit', 'therefore', 'multiple', 'set', 'parameter', 'intercept', 'term', 'predictor_variable', 'building', 'nominal', 'model', 'consider', 'whether', 'sample_size', 'large', 'enough', 'support', 'number', 'generalized', 'logits', 'modeling', 'estimating', 'many', 'parameter', 'may', 'encounter', 'parameter', 'estimation', 'problem', 'small', 'sample_size', 'general', 'rule', 'need', 'possible', 'outcome', 'least', 'five', 'observation', 'per', 'explanatory', 'variable', 'model', 'valid', 'estimation', 'proceed', 'stokes', 'davis', 'koch', '2000', 'small', 'sample_size', 'one', 'solution', 'use', 'exact', 'statement', 'fit', 'exact', 'logistic_regression_model']"
713,"The forward selection method selected three different models when you changed the options. Allowing single effects to enter the model at one step did not detect any significant interactions, whereas allowing multiple effects to enter the model at one step put two nonsignificant interactions in the model.",CD,305,"['forward', 'selection', 'method', 'selected', 'three', 'different', 'model', 'changed', 'option', 'allowing', 'single', 'effect', 'enter', 'model', 'one', 'step', 'detect', 'significant', 'interaction', 'whereas', 'allowing', 'multiple', 'effect', 'enter', 'model', 'one', 'step', 'put', 'two', 'nonsignificant', 'interaction', 'model']"
714,"MAXEIGEN=n	specifies the largest permissible value of the second eigenvalue in each cluster. SHORT	suppresses printing of the cluster structure, scoring coefficient, and intercluster correlation matrices. Selected VARCLUS procedure statement: VAR	specifies the variables to be clustered. If you do not specify the VAR statement, all numeric variables not listed in other statements are processed. Variable Clustering",CD,416,"['maxeigenn\tspecifies', 'largest', 'permissible', 'value', 'second', 'eigenvalue', 'cluster', 'short\tsuppresses', 'printing', 'cluster', 'structure', 'scoring', 'coefficient', 'intercluster', 'correlation', 'matrix', 'selected', 'varclus', 'procedure', 'statement', 'var\tspecifies', 'variable', 'clustered', 'specify', 'var', 'statement', 'numeric', 'variable', 'listed', 'statement', 'processed', 'variable', 'clustering']"
715,The number of observations in the contingency table prev_pretrm by low controlling for uterine_irr=1 is fairly small. This may be a problem for the Breslow-Day test and the asymptotic confidence limits for the odds ratio. Statistics for Table 2 of prev_pretrm by low Controlling for uterine_irr=1,CD,296,"['number', 'observation', 'contingency', 'table', 'prevpretrm', 'low', 'controlling', 'uterineirr1', 'fairly', 'small', 'may', 'problem', 'breslowday', 'test', 'asymptotic', 'confidence', 'limit', 'odds_ratio', 'statistic', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
716,"A key assumption in the logistic regression model is that the logits are linearly related to each predictor variable. For binary predictor variables, this is not a problem because a straight line connects two points. However, for ordinal or continuous predictor variables, this assumption should be examined with the use of logit plots.",CD,336,"['key', 'assumption', 'logistic_regression_model', 'logits', 'linearly', 'related', 'predictor_variable', 'binary', 'predictor_variable', 'problem', 'straight', 'line', 'connects', 'two', 'point', 'however', 'ordinal', 'continuous', 'predictor_variable', 'assumption', 'examined', 'use', 'logit', 'plot']"
717,Cases are allocated to classes based on cutoff values of the predicted probability. The steps include the following: 1.	Estimate the predicted probability of class 1 for each case by the logistic regression model. 2.	Choose a cutoff probability. 3.	Assign cases to class 1 if their estimated predicted probability exceeds the cutoff; otherwise assign the case to class 0.,CD,371,"['case', 'allocated', 'class', 'based', 'cutoff', 'value', 'predicted', 'probability', 'step', 'include', 'following', '1\testimate', 'predicted', 'probability', 'class', '1', 'case', 'logistic_regression_model', '2\tchoose', 'cutoff', 'probability', '3\tassign', 'case', 'class', '1', 'estimated', 'predicted', 'probability', 'exceeds', 'cutoff', 'otherwise', 'assign', 'case', 'class', '0']"
718,"PROC GENMOD can be used to fit GEE models to clustered data. The layout of the data corresponds to the number of observations being equal to the number of measurements taken on all the subjects. The variance-covariance matrix is a block diagonal matrix in which the observations within each block are assumed to be correlated and the observations outside of the blocks are assumed to be independent. Selected GENMOD procedure statements: CLASS	specifies the classification variables to be used in the analysis. If the CLASS statement is used, it must appear before the MODEL statement. MODEL	specifies the response variable and the predictor variables. REPEATED	invokes the GEE method, specifies the correlation structure, and controls the displayed output from the longitudinal model. ESTIMATE	provides a means for obtaining a test for a specified hypothesis concerning the model parameters. It can also be used to produce the odds ratio estimate along with the 95% confidence limits. OUTPUT	creates a new SAS data set that contains all the variables in the input data set and, optionally, the estimated linear predictors and their standard error estimates, the weights for the Hessian matrix, predicted values of the mean, confidence limits for predicted values, and residuals. Selected CLASS statement options: PARAM=	specifies the parameterization method for the classification variable or variables. Design matrix columns are created from CLASS variables according to the following coding schemes: 	EFFECT	species effect coding. GLM	specifies less than full rank, reference-cell coding. This coding is the default. ORDINAL	specifies the cumulative parameterization for an ordinal CLASS variable. 	POLY	specifies polynomial coding. 	REF	specifies reference cell coding. 	ORTHEFFECT	orthogonalizes PARAM=EFFECT. 	ORTHORDINAL	orthogonalizes PARAM=ORDINAL. 	ORTHPOLY	orthogonalizes PARAM=POLY. 	ORTHREF	orthogonalizes PARAM=REF. REF=	specifies the reference cell for PARAM=EFFECT, PARAM=REF, and their orthogonalizations.",CD,2022,"['proc', 'genmod', 'used', 'fit', 'gee', 'model', 'clustered', 'data', 'layout', 'data', 'corresponds', 'number', 'observation', 'equal', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'selected', 'genmod', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'used', 'must', 'appear', 'model_statement', 'model\tspecifies', 'response_variable', 'predictor_variable', 'repeated\tinvokes', 'gee', 'method', 'specifies', 'correlation_structure', 'control', 'displayed', 'output', 'longitudinal', 'model', 'estimate\tprovides', 'mean', 'obtaining', 'test', 'specified', 'hypothesis', 'concerning', 'model', 'parameter', 'also', 'used', 'produce', 'odds_ratio', 'estimate', 'along', '95', 'confidence', 'limit', 'output\tcreates', 'new', 'sa', 'data_set', 'contains', 'variable', 'input', 'data_set', 'optionally', 'estimated', 'linear', 'predictor', 'standard_error', 'estimate', 'weight', 'hessian', 'matrix', 'predicted', 'value', 'mean', 'confidence', 'limit', 'predicted', 'value', 'residual', 'selected', 'class', 'statement', 'option', 'param\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'design', 'matrix', 'column', 'created', 'class', 'variable', 'according', 'following', 'coding', 'scheme', '\teffect\tspecies', 'effect', 'coding', 'glm\tspecifies', 'le', 'full', 'rank', 'referencecell', 'coding', 'coding', 'default', 'ordinal\tspecifies', 'cumulative', 'parameterization', 'ordinal', 'class', 'variable', '\tpoly\tspecifies', 'polynomial', 'coding', '\tref\tspecifies', 'reference', 'cell', 'coding', '\tortheffect\torthogonalizes', 'parameffect', '\torthordinal\torthogonalizes', 'paramordinal', '\torthpoly\torthogonalizes', 'parampoly', '\torthref\torthogonalizes', 'paramref', 'ref\tspecifies', 'reference', 'cell', 'parameffect', 'paramref', 'orthogonalizations']"
719,"Exploratory data analysis should be the first step in model building to identify any numerical problems and nonlinearity. Contingency table analysis of categorical predictors should also be performed so that you can compare the univariate effect and the multivariate effect of each predictor variable. You should be concerned about predictor variables whose coefficients have changed substantially in magnitude when other predictor variables are added to or eliminated from the model. This may identify one or more variables that were important in providing a needed adjustment of the effects of the variables that remained in the model. Finally, after a candidate model has been identified, you should assess the fit of the model and identify any outliers or influential observations that are contributing to a poor fitting model (Hosmer and Lemeshow 2000). 1.2	Exploratory Data Analysis",CD,888,"['exploratory', 'data', 'analysis', 'first', 'step', 'model', 'building', 'identify', 'numerical', 'problem', 'nonlinearity', 'contingency', 'table', 'analysis', 'categorical', 'predictor', 'also', 'performed', 'compare', 'univariate', 'effect', 'multivariate', 'effect', 'predictor_variable', 'concerned', 'predictor_variable', 'whose', 'coefficient', 'changed', 'substantially', 'magnitude', 'predictor_variable', 'added', 'eliminated', 'model', 'may', 'identify', 'one', 'variable', 'important', 'providing', 'needed', 'adjustment', 'effect', 'variable', 'remained', 'model', 'finally', 'candidate', 'model', 'ha', 'identified', 'ass', 'fit', 'model', 'identify', 'outlier', 'influential', 'observation', 'contributing', 'poor', 'fitting', 'model', 'hosmer', 'lemeshow', '2000', '12\texploratory', 'data', 'analysis']"
720,"The goal of conditional exact inference is to determine how likely the observed sequence of binary response values is with respect to all other sequences of binary response values having the same sufficient statistics for the nuisance parameters. All possible sequences of binary response values is referred to as the permutation distribution. To accomplish this goal, the conditional permutation distribution for the sufficient statistics of the parameters of interest needs to be generated. In other words, for every possible sequence of binary responses, the sufficient statistics for the parameters needs to be computed. A simple example illustrates the method. Suppose you had 5 observations in your data with a binary response variable and a dummy-coded predictor variable (values of 0 or 1). The observed data values are on the above slide. The sufficient statistic values are 1 for the intercept and 1 for the parameter for the dummy-coded predictor variable. The number of possible sequences of response values is 32 (25).",CD,1031,"['goal', 'conditional', 'exact', 'inference', 'determine', 'likely', 'observed', 'sequence', 'binary', 'response', 'value', 'respect', 'sequence', 'binary', 'response', 'value', 'sufficient', 'statistic', 'nuisance', 'parameter', 'possible', 'sequence', 'binary', 'response', 'value', 'referred', 'permutation', 'distribution', 'accomplish', 'goal', 'conditional', 'permutation', 'distribution', 'sufficient', 'statistic', 'parameter', 'interest', 'need', 'generated', 'word', 'every', 'possible', 'sequence', 'binary', 'response', 'sufficient', 'statistic', 'parameter', 'need', 'computed', 'simple', 'example', 'illustrates', 'method', 'suppose', '5', 'observation', 'data', 'binary', 'response_variable', 'dummycoded', 'predictor_variable', 'value', '0', '1', 'observed', 'data', 'value', 'slide', 'sufficient', 'statistic', 'value', '1', 'intercept', '1', 'parameter', 'dummycoded', 'predictor_variable', 'number', 'possible', 'sequence', 'response', 'value', '32', '25']"
721,"In some estimation problems, you need to be able to summarize the information in the sample or find some function in the sample that tells you just as much about the parameter of interest as the sample itself. This function is sufficient for estimation purposes and therefore is called a sufficient statistic. In other words, a sufficient statistic condenses the data in such a way that no information is lost about the parameter. When a statistic loses no information, it contains all the information about the parameter that is contained in the sample. There can be more than one set of sufficient statistics. A minimal sufficient statistic is the most condensed summary of the data.",CD,685,"['estimation', 'problem', 'need', 'able', 'summarize', 'information', 'sample', 'find', 'function', 'sample', 'tell', 'much', 'parameter', 'interest', 'sample', 'function', 'sufficient', 'estimation', 'purpose', 'therefore', 'called', 'sufficient', 'statistic', 'word', 'sufficient', 'statistic', 'condenses', 'data', 'way', 'information', 'lost', 'parameter', 'statistic', 'loses', 'information', 'contains', 'information', 'parameter', 'contained', 'sample', 'one', 'set', 'sufficient', 'statistic', 'minimal', 'sufficient', 'statistic', 'condensed', 'summary', 'data']"
722,"In some situations, maximum likelihood estimation can fail, or small cell counts make the resulting maximum likelihood estimates inaccurate. An alternative to the asymptotic methods of maximum likelihood is exact logistic regression, which is available for binary outcomes in PROC LOGISTIC. This method has become an important analytical technique, especially in the pharmaceutical industry, for analyzing small, skewed, or sparse data sets.",CD,441,"['situation', 'maximum', 'likelihood', 'estimation', 'fail', 'small', 'cell', 'count', 'make', 'resulting', 'maximum', 'likelihood', 'estimate', 'inaccurate', 'alternative', 'asymptotic', 'method', 'maximum', 'likelihood', 'exact', 'logistic_regression', 'available', 'binary', 'outcome', 'proc_logistic', 'method', 'ha', 'become', 'important', 'analytical', 'technique', 'especially', 'pharmaceutical', 'industry', 'analyzing', 'small', 'skewed', 'sparse', 'data_set']"
723,"The parameter estimate for cephalexin is a median unbiased estimate, which is more accurate than the asymptotic estimate in this example. The exact p-value for age is different than the p- value reported for the exact conditional tests. The reason for the discrepancy is that the exact p- values for the single parameters are the results of likelihood ratio tests based on the conditional probability density function used to estimate them. In most cases, you would rely on the exact p- values reported in the ?Exact Conditional Analysis? table (Stokes, Davis, and Koch 2000). ?	The score test is preferred over the probability test because if the resulting distribution of the conditional sufficient statistic is bimodal, then the probability test can pick up probability from within the valley as well as the tails. The score p-value is always a tail statistic. Exact Odds Ratios",CD,881,"['parameter_estimate', 'cephalexin', 'median', 'unbiased', 'estimate', 'accurate', 'asymptotic', 'estimate', 'example', 'exact', 'pvalue', 'age', 'different', 'p', 'value', 'reported', 'exact', 'conditional', 'test', 'reason', 'discrepancy', 'exact', 'p', 'value', 'single', 'parameter', 'result', 'likelihood', 'ratio', 'test', 'based', 'conditional', 'probability', 'density', 'function', 'used', 'estimate', 'case', 'would', 'rely', 'exact', 'p', 'value', 'reported', 'exact', 'conditional', 'analysis', 'table', 'stokes', 'davis', 'koch', '2000', '\tthe', 'score', 'test', 'preferred', 'probability', 'test', 'resulting', 'distribution', 'conditional', 'sufficient', 'statistic', 'bimodal', 'probability', 'test', 'pick', 'probability', 'within', 'valley', 'well', 'tail', 'score', 'pvalue', 'always', 'tail', 'statistic', 'exact', 'odds_ratio']"
724,"In conclusion, careful exploratory data analysis may help you identify scientifically relevant variables to include in your candidate model. Exploratory data analysis may also help you build a model that better depicts the relationships you are studying. Relying on the variable selection techniques in PROC LOGISTIC is no substitute for this stage in the modeling process. 1.3	Subsets Selection Methods",CD,403,"['conclusion', 'careful', 'exploratory', 'data', 'analysis', 'may', 'help', 'identify', 'scientifically', 'relevant', 'variable', 'include', 'candidate', 'model', 'exploratory', 'data', 'analysis', 'may', 'also', 'help', 'build', 'model', 'better', 'depicts', 'relationship', 'studying', 'relying', 'variable', 'selection', 'technique', 'proc_logistic', 'substitute', 'stage', 'modeling', 'process', '13\tsubsets', 'selection', 'method']"
725,"The contingency table analysis revealed that several variables had very small numbers in their levels (the details of the analysis were omitted to save time and space). Therefore, several variables had levels collapsed and several predictor variables were eliminated from the analysis. For example, there was only one woman whose bowel action aggravated her back pain. Therefore, a total of 16 predictor variables were selected for the analysis.",CD,445,"['contingency', 'table', 'analysis', 'revealed', 'several', 'variable', 'small', 'number', 'level', 'detail', 'analysis', 'omitted', 'save', 'time', 'space', 'therefore', 'several', 'variable', 'level', 'collapsed', 'several', 'predictor_variable', 'eliminated', 'analysis', 'example', 'wa', 'one', 'woman', 'whose', 'bowel', 'action', 'aggravated', 'back', 'pain', 'therefore', 'total', '16', 'predictor_variable', 'selected', 'analysis']"
726,"For backward elimination, the model selected when you allow multiple effects to leave the model at one time is the same as the model selected when you allow single effects to leave the model at one time. This is because only one main effect, not involved in a significant interaction, was itself not significant. Therefore, the method did not have the chance to eliminate the interaction along with its main effects in one step. When you include all the main effects in the model, the backward elimination method finds one significant interaction (mother_age*phy_visit). This is the same model as the one selected in forward selection including all the main effects. This model also has the highest c statistic (.793).",CD,718,"['backward', 'elimination', 'model', 'selected', 'allow', 'multiple', 'effect', 'leave', 'model', 'one', 'time', 'model', 'selected', 'allow', 'single', 'effect', 'leave', 'model', 'one', 'time', 'one', 'main_effect', 'involved', 'significant', 'interaction', 'wa', 'significant', 'therefore', 'method', 'chance', 'eliminate', 'interaction', 'along', 'main_effect', 'one', 'step', 'include', 'main_effect', 'model', 'backward', 'elimination', 'method', 'find', 'one', 'significant', 'interaction', 'motheragephyvisit', 'model', 'one', 'selected', 'forward', 'selection', 'including', 'main_effect', 'model', 'also', 'ha', 'highest', 'c', 'statistic', '793']"
727,"Example:	Output the predicted probabilities and examine the distribution using the HISTOGRAM statement in PROC UNIVARIATE. Then create a classification table and a ROC curve for the final model. The sample is a stratified random sample, so specify a list of prior probabilities for low birth weight. /* c2demo10a */ options label;",CD,330,"['example\toutput', 'predicted', 'probability', 'examine', 'distribution', 'using', 'histogram', 'statement', 'proc', 'univariate', 'create', 'classification', 'table', 'roc', 'curve', 'final', 'model', 'sample', 'stratified', 'random', 'sample', 'specify', 'list', 'prior', 'probability', 'low', 'birth', 'weight', '', 'c2demo10a', '', 'option', 'label']"
728,"TABLES	requests one-way to n-way frequency and crosstabulation tables and statistics for those tables. You can use multiple TABLES statements in the PROC FREQ step. EXACT	requests exact tests or confidence limits for the specified statistics. PROC FREQ also computes Monte Carlo estimates of the exact p-values. The statistic options specify the statistics for which to provide exact tests or confidence limits. The computation options specify options for the computation of exact statistics. TEST	requests asymptotic tests for the specified measures of association and measures of agreement. You must use a TABLES statement with the TEST statement. For each measure of association or agreement that you specify, the TEST statement provides an asymptotic test that the measure equals zero. OUTPUT	creates a SAS data set containing statistics computed by PROC FREQ. Only one OUTPUT statement is allowed for each execution of PROC FREQ. You must specify a TABLES statement with the OUTPUT statement. ?	Exact tests are appropriate when a data set is small, sparse, skewed, or heavily tied. For some large problems, computation of exact tests may require a large amount of time and memory. Consider using asymptotic tests for such problems. Alternatively, when asymptotic methods may not be sufficient for such large problems, consider using Monte Carlo estimation of exact p-values.",CD,1379,"['tables\trequests', 'oneway', 'nway', 'frequency', 'crosstabulation', 'table', 'statistic', 'table', 'use', 'multiple', 'table', 'statement', 'proc', 'freq', 'step', 'exact\trequests', 'exact', 'test', 'confidence', 'limit', 'specified', 'statistic', 'proc', 'freq', 'also', 'computes', 'monte', 'carlo', 'estimate', 'exact', 'pvalues', 'statistic', 'option', 'specify', 'statistic', 'provide', 'exact', 'test', 'confidence', 'limit', 'computation', 'option', 'specify', 'option', 'computation', 'exact', 'statistic', 'test\trequests', 'asymptotic', 'test', 'specified', 'measure', 'association', 'measure', 'agreement', 'must', 'use', 'table', 'statement', 'test', 'statement', 'measure', 'association', 'agreement', 'specify', 'test', 'statement', 'provides', 'asymptotic', 'test', 'measure', 'equal', 'zero', 'output\tcreates', 'sa', 'data_set', 'containing', 'statistic', 'computed', 'proc', 'freq', 'one', 'output', 'statement', 'allowed', 'execution', 'proc', 'freq', 'must', 'specify', 'table', 'statement', 'output', 'statement', '\texact', 'test', 'appropriate', 'data_set', 'small', 'sparse', 'skewed', 'heavily', 'tied', 'large', 'problem', 'computation', 'exact', 'test', 'may', 'require', 'large', 'amount', 'time', 'memory', 'consider', 'using', 'asymptotic', 'test', 'problem', 'alternatively', 'asymptotic', 'method', 'may', 'sufficient', 'large', 'problem', 'consider', 'using', 'monte', 'carlo', 'estimation', 'exact', 'pvalues']"
729,"Exact inference on regression parameter estimates is based on the permutation distribution of their sufficient statistics. Inference on the parameters of the specified effects is performed by conditioning on the sufficient statistics of all other model parameters. Some of these other parameters might be regarded as nuisance parameters, which are in the model to adjust for relevant effects, but their values are not of special interest. For example, suppose you are interested in estimating the regression parameter for the predictor variable A, and regard the intercept as a nuisance parameter. You can eliminate the intercept by conditioning on the observed value of its sufficient statistic, which yields the conditional likelihood function. In other words, some of the sufficient statistics are fixed at their observed values and others are allowed to vary over their permissible ranges. This is different from an unconditional likelihood function used in the asymptotic methods, which estimates all the parameters in the model. To understand the methodology of exact logistic regression, three questions need to be addressed: What are sufficient statistics? What is a permutation distribution? What is a median unbiased estimate?",CD,1236,"['exact', 'inference', 'regression', 'parameter_estimate', 'based', 'permutation', 'distribution', 'sufficient', 'statistic', 'inference', 'parameter', 'specified', 'effect', 'performed', 'conditioning', 'sufficient', 'statistic', 'model', 'parameter', 'parameter', 'might', 'regarded', 'nuisance', 'parameter', 'model', 'adjust', 'relevant', 'effect', 'value', 'special', 'interest', 'example', 'suppose', 'interested', 'estimating', 'regression', 'parameter', 'predictor_variable', 'regard', 'intercept', 'nuisance', 'parameter', 'eliminate', 'intercept', 'conditioning', 'observed', 'value', 'sufficient', 'statistic', 'yield', 'conditional', 'likelihood', 'function', 'word', 'sufficient', 'statistic', 'fixed', 'observed', 'value', 'others', 'allowed', 'vary', 'permissible', 'range', 'different', 'unconditional', 'likelihood', 'function', 'used', 'asymptotic', 'method', 'estimate', 'parameter', 'model', 'understand', 'methodology', 'exact', 'logistic_regression', 'three', 'question', 'need', 'addressed', 'sufficient', 'statistic', 'permutation', 'distribution', 'median', 'unbiased', 'estimate']"
730,"The above graph reveals a cubic relationship between the response variable and the predictor variable. Adding higher order terms for the predictor variable may approximate this relationship, but polynomials have some undesirable properties (undesirable peaks and valleys) and may not adequately fit many functional forms (Magee 1998). Developing a model with a linear spline function may be a better option (Harrell 1997).",CD,422,"['graph', 'reveals', 'cubic', 'relationship', 'response_variable', 'predictor_variable', 'adding', 'higher', 'order', 'term', 'predictor_variable', 'may', 'approximate', 'relationship', 'polynomial', 'undesirable', 'property', 'undesirable', 'peak', 'valley', 'may', 'adequately', 'fit', 'many', 'functional', 'form', 'magee', '1998', 'developing', 'model', 'linear', 'spline', 'function', 'may', 'better', 'option', 'harrell', '1997']"
731,"The table shown above shows the difference between discordant and concordant pairs. For all pairs of observations with different outcomes (in this example, having a low birth weight baby), a comparison is made of the predicted outcome probabilities. If the observation with the outcome has a higher predicted outcome probability compared to an observation without the outcome, the pair is concordant. However, if the observation with the outcome has a lower predicted outcome probability compared to the predicted outcome probability of an observation without the outcome, the pair is discordant. If the predicted outcome probabilities are the same, the pair is tied. Binary Logistic Regression (continued)",CD,706,"['table', 'shown', 'show', 'difference', 'discordant', 'concordant', 'pair', 'pair', 'observation', 'different', 'outcome', 'example', 'low', 'birth', 'weight', 'baby', 'comparison', 'made', 'predicted', 'outcome', 'probability', 'observation', 'outcome', 'ha', 'higher', 'predicted', 'outcome', 'probability', 'compared', 'observation', 'without', 'outcome', 'pair', 'concordant', 'however', 'observation', 'outcome', 'ha', 'lower', 'predicted', 'outcome', 'probability', 'compared', 'predicted', 'outcome', 'probability', 'observation', 'without', 'outcome', 'pair', 'discordant', 'predicted', 'outcome', 'probability', 'pair', 'tied', 'binary', 'logistic_regression', 'continued']"
732,"Unfortunately, the distributions of the diagnostic statistics are not known, so cutoff values cannot be given for determining when the values are large (Pregibon 1981). Therefore, you have to rely on visual inspection of these statistics. Hosmer and Lemeshow (2000) recommend plotting the influence statistics such as the change in the Pearson chi-square against the predicted values. Graphing these influence statistics may enable you to identify those covariate patterns (subjects) that are poorly fit by the model. Examination of these patterns may indicate that important variables are missing from the model or that some of the variables in the model have not been entered in the correct scale. These patterns may also identify erroneous data values. The plot above is a plot of the change in the Pearson chi-square statistic by the predicted probabilities. The points on the curve going from the upper-left to the lower-right corner correspond to the covariate patterns with a response value of 1. The points on the curve going from the upper- right to the lower-left corners correspond to the covariate patterns with a response value of 0. Covariate patterns that are poorly fit by the model will lie in the upper-right and left corners of the plot. Hosmer and Lemeshow (2000) suggest that values of the change in the Pearson chi-square statistic above 4 are potential outliers. ?	Another graph that can be used to identify influential observations and outliers in relatively small data sets is the index plot. In an index plot, the diagnostic statistic is plotted against the observation number. This enables visual inspection and comparison of the values across observations. If the model is correctly specified and fits all observations well, then no extreme points should appear. The IPLOTS option in the MODEL statement requests an index plot for each regression diagnostic statistic.",CD,1896,"['unfortunately', 'distribution', 'diagnostic', 'statistic', 'known', 'cutoff', 'value', 'cannot', 'given', 'determining', 'value', 'large', 'pregibon', '1981', 'therefore', 'rely', 'visual', 'inspection', 'statistic', 'hosmer', 'lemeshow', '2000', 'recommend', 'plotting', 'influence', 'statistic', 'change', 'pearson', 'chisquare', 'predicted', 'value', 'graphing', 'influence', 'statistic', 'may', 'enable', 'identify', 'covariate', 'pattern', 'subject', 'poorly', 'fit', 'model', 'examination', 'pattern', 'may', 'indicate', 'important', 'variable', 'missing', 'model', 'variable', 'model', 'entered', 'correct', 'scale', 'pattern', 'may', 'also', 'identify', 'erroneous', 'data', 'value', 'plot', 'plot', 'change', 'pearson', 'chisquare', 'statistic', 'predicted', 'probability', 'point', 'curve', 'going', 'upperleft', 'lowerright', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '1', 'point', 'curve', 'going', 'upper', 'right', 'lowerleft', 'corner', 'correspond', 'covariate', 'pattern', 'response', 'value', '0', 'covariate', 'pattern', 'poorly', 'fit', 'model', 'lie', 'upperright', 'left', 'corner', 'plot', 'hosmer', 'lemeshow', '2000', 'suggest', 'value', 'change', 'pearson', 'chisquare', 'statistic', '4', 'potential', 'outlier', '\tanother', 'graph', 'used', 'identify', 'influential', 'observation', 'outlier', 'relatively', 'small', 'data_set', 'index', 'plot', 'index', 'plot', 'diagnostic', 'statistic', 'plotted', 'observation', 'number', 'enables', 'visual', 'inspection', 'comparison', 'value', 'across', 'observation', 'model', 'correctly', 'specified', 'fit', 'observation', 'well', 'extreme', 'point', 'appear', 'iplots', 'option', 'model_statement', 'request', 'index', 'plot', 'regression', 'diagnostic', 'statistic']"
733,"Because the GEE method is semiparametric (not nonparametric), the mean model and variance function needs to be correctly specified. Consistent results of the GEE models depend on the correct specification of the model for the mean. Furthermore, robust standard errors should only be used with a large number of subjects. Park (1993) compared GEE estimators with normal-theory maximum likelihood estimators and reported that GEE estimators were more sensitive to the occurrence of missing data. Several studies have shown that the bias and efficiency of the GEE method may depend on the number of subjects, number of repeated measurements, magnitudes of the correlations among repeated measurements, and number and type of covariates. Lipsitz et al. (1991) reported that the parameter estimates for a binary GEE model were biased slightly upward and the bias increased as the magnitude of the correlation increased. Paik (1988) reported that as the number of covariates increases, the number of subjects needs to increase for the point estimates and confidence intervals to perform satisfactorily (with 4 repeated measurements and 4 covariates, he recommended a sample size over 50). ?	One solution to the MCAR limitation is to use the MI procedure to impute the missing values. PROC MI invokes the MAR assumption. Then fit the GEE model in PROC GENMOD on the complete data.",CD,1373,"['gee', 'method', 'semiparametric', 'nonparametric', 'mean', 'model', 'variance', 'function', 'need', 'correctly', 'specified', 'consistent', 'result', 'gee', 'model', 'depend', 'correct', 'specification', 'model', 'mean', 'furthermore', 'robust', 'standard_error', 'used', 'large', 'number', 'subject', 'park', '1993', 'compared', 'gee', 'estimator', 'normaltheory', 'maximum', 'likelihood', 'estimator', 'reported', 'gee', 'estimator', 'sensitive', 'occurrence', 'missing', 'data', 'several', 'study', 'shown', 'bias', 'efficiency', 'gee', 'method', 'may', 'depend', 'number', 'subject', 'number', 'repeated', 'measurement', 'magnitude', 'correlation', 'among', 'repeated', 'measurement', 'number', 'type', 'covariates', 'lipsitz', 'et', 'al', '1991', 'reported', 'parameter_estimate', 'binary', 'gee', 'model', 'biased', 'slightly', 'upward', 'bias', 'increased', 'magnitude', 'correlation', 'increased', 'paik', '1988', 'reported', 'number', 'covariates', 'increase', 'number', 'subject', 'need', 'increase', 'point', 'estimate', 'confidence', 'interval', 'perform', 'satisfactorily', '4', 'repeated', 'measurement', '4', 'covariates', 'recommended', 'sample_size', '50', '\tone', 'solution', 'mcar', 'limitation', 'use', 'mi', 'procedure', 'impute', 'missing', 'value', 'proc', 'mi', 'invokes', 'mar', 'assumption', 'fit', 'gee', 'model', 'proc', 'genmod', 'complete', 'data']"
734,SUBJECT=	identifies subjects in the input data set. This is a required option and the variables used in defining the subjects must be listed in the CLASS statement. The input data set does not need to be sorted by subject. TYPE=	specifies the structure of the working correlation matrix used to model the correlation of responses from subjects. The default working correlation type is the independent correlation structure.,CD,423,"['subject\tidentifies', 'subject', 'input', 'data_set', 'required', 'option', 'variable', 'used', 'defining', 'subject', 'must', 'listed', 'class', 'statement', 'input', 'data_set', 'doe', 'need', 'sorted', 'subject', 'type\tspecifies', 'structure', 'working', 'correlation', 'matrix', 'used', 'model', 'correlation', 'response', 'subject', 'default', 'working', 'correlation', 'type', 'independent', 'correlation_structure']"
735,"Exact inference on regression parameter estimates is based on the permutation distribution of their sufficient statistics. Inference on the parameters of the specified effects is performed by conditioning on the sufficient statistics of all other model parameters. Some of these other parameters might be regarded as nuisance parameters, which are in the model to adjust for relevant effects, but their values are not of special interest. For example, suppose you are interested in estimating the regression parameter for the predictor variable A, and regard the intercept as a nuisance parameter. You can eliminate the intercept by conditioning on the observed value of its sufficient statistic, which yields the conditional likelihood function. In other words, some of the sufficient statistics are fixed at their observed values and others are allowed to vary over their permissible ranges. This is different from an unconditional likelihood function used in the asymptotic methods, which estimates all the parameters in the model. To understand the methodology of exact logistic regression, three questions need to be addressed: What are sufficient statistics? What is a permutation distribution? What is a median unbiased estimate?",CD,1236,"['exact', 'inference', 'regression', 'parameter_estimate', 'based', 'permutation', 'distribution', 'sufficient', 'statistic', 'inference', 'parameter', 'specified', 'effect', 'performed', 'conditioning', 'sufficient', 'statistic', 'model', 'parameter', 'parameter', 'might', 'regarded', 'nuisance', 'parameter', 'model', 'adjust', 'relevant', 'effect', 'value', 'special', 'interest', 'example', 'suppose', 'interested', 'estimating', 'regression', 'parameter', 'predictor_variable', 'regard', 'intercept', 'nuisance', 'parameter', 'eliminate', 'intercept', 'conditioning', 'observed', 'value', 'sufficient', 'statistic', 'yield', 'conditional', 'likelihood', 'function', 'word', 'sufficient', 'statistic', 'fixed', 'observed', 'value', 'others', 'allowed', 'vary', 'permissible', 'range', 'different', 'unconditional', 'likelihood', 'function', 'used', 'asymptotic', 'method', 'estimate', 'parameter', 'model', 'understand', 'methodology', 'exact', 'logistic_regression', 'three', 'question', 'need', 'addressed', 'sufficient', 'statistic', 'permutation', 'distribution', 'median', 'unbiased', 'estimate']"
736,"The table shown above shows the difference between discordant and concordant pairs. For all pairs of observations with different outcomes (in this example, having a low birth weight baby), a comparison is made of the predicted outcome probabilities. If the observation with the outcome has a higher predicted outcome probability compared to an observation without the outcome, the pair is concordant. However, if the observation with the outcome has a lower predicted outcome probability compared to the predicted outcome probability of an observation without the outcome, the pair is discordant. If the predicted outcome probabilities are the same, the pair is tied. Binary Logistic Regression (continued)",CD,706,"['table', 'shown', 'show', 'difference', 'discordant', 'concordant', 'pair', 'pair', 'observation', 'different', 'outcome', 'example', 'low', 'birth', 'weight', 'baby', 'comparison', 'made', 'predicted', 'outcome', 'probability', 'observation', 'outcome', 'ha', 'higher', 'predicted', 'outcome', 'probability', 'compared', 'observation', 'without', 'outcome', 'pair', 'concordant', 'however', 'observation', 'outcome', 'ha', 'lower', 'predicted', 'outcome', 'probability', 'compared', 'predicted', 'outcome', 'probability', 'observation', 'without', 'outcome', 'pair', 'discordant', 'predicted', 'outcome', 'probability', 'pair', 'tied', 'binary', 'logistic_regression', 'continued']"
737,"PROC LOGISTIC estimates a separate intercept for each cumulative logit. However, PROC LOGISTIC does not estimate a separate slope for each cumulative logit, but rather a common slope across the cumulative logits for each predictor variable. This common slope is a weighted average across the logits. Therefore, a parallel-lines regression model is fitted in which each curve that describes the cumulative probabilities has the same shape. The only difference in the curves is the difference between the values of the intercept parameters. This model is called a proportional odds model.",CD,586,"['proc_logistic', 'estimate', 'separate', 'intercept', 'cumulative', 'logit', 'however', 'proc_logistic', 'doe', 'estimate', 'separate', 'slope', 'cumulative', 'logit', 'rather', 'common', 'slope', 'across', 'cumulative', 'logits', 'predictor_variable', 'common', 'slope', 'weighted', 'average', 'across', 'logits', 'therefore', 'parallellines', 'regression_model', 'fitted', 'curve', 'describes', 'cumulative', 'probability', 'ha', 'shape', 'difference', 'curve', 'difference', 'value', 'intercept', 'parameter', 'model', 'called', 'proportional', 'odds', 'model']"
738,"Quasi-complete separation can also occur when you create interaction terms. The example above shows that there is no separation problem with the predictor variable, but that when you separate it by gender, a 0 cell count occurs. Therefore, the interaction term that consists of the predictor variable and gender should cause some convergence problems in your model.",CD,365,"['quasicomplete', 'separation', 'also', 'occur', 'create', 'interaction', 'term', 'example', 'show', 'separation', 'problem', 'predictor_variable', 'separate', 'gender', '0', 'cell', 'count', 'occurs', 'therefore', 'interaction', 'term', 'consists', 'predictor_variable', 'gender', 'cause', 'convergence', 'problem', 'model']"
739,"After an extensive univariate and stratified data analysis, the above variables were identified as potential confounders. The criterion was a big difference between the crude odds ratio of the main effect and the adjusted odds ratio. For example, the crude odds ratio for history of hypertension is 3.365 and the odds ratio adjusted for mother?s weight is 6.435. Therefore, to obtain an accurate, unconfounded effect of history of hypertension, mother?s weight should be in the model.",CD,484,"['extensive', 'univariate', 'stratified', 'data', 'analysis', 'variable', 'identified', 'potential', 'confounders', 'criterion', 'wa', 'big', 'difference', 'crude', 'odds_ratio', 'main_effect', 'adjusted', 'odds_ratio', 'example', 'crude', 'odds_ratio', 'history', 'hypertension', '3365', 'odds_ratio', 'adjusted', 'mother', 'weight', '6435', 'therefore', 'obtain', 'accurate', 'unconfounded', 'effect', 'history', 'hypertension', 'mother', 'weight', 'model']"
740,"The common effect of the predictor variable for different cumulative logits in the proportional odds model can be motivated by assuming that a regression model holds when the response is measured more finely (Anderson and Phillips 1981). For example, suppose there is an underlying continuous response variable with ordered categories that are produced via cutoff points. The relationship between the predictor variable and the response should not depend on the cutoff points. In other words, the effect parameters are invariant to the choice of categories for the response variable. Only the intercepts are affected by the cutoff points. The proportional odds model is therefore invariant to the choice of the outcome categories. There is some loss of efficiency when you collapse the ordinal categories, but when the observations are evenly spread among the categories the efficiency loss is minor. However, the efficiency loss is large when you collapse the ordinal categories to a binary response (Agresti 1996). Allison (1999) recommends that you need at least 10 observations for each category of the response variable. As the number of categories increases, ordinary least squares might be appropriate. However, Hastie et al. (1989) showed that ordinary least squares methods could give misleading results with up to 13 categories of the response variable. The proportional odds model also makes no assumptions about the distances between the categories. Therefore, how you code the ordinal outcome variable has no effect on the odds ratios. Fitting Simple Ordinal Logistic Regression Models",CD,1598,"['common', 'effect', 'predictor_variable', 'different', 'cumulative', 'logits', 'proportional', 'odds', 'model', 'motivated', 'assuming', 'regression_model', 'hold', 'response', 'measured', 'finely', 'anderson', 'phillips', '1981', 'example', 'suppose', 'underlying', 'continuous', 'response_variable', 'ordered', 'category', 'produced', 'via', 'cutoff', 'point', 'relationship', 'predictor_variable', 'response', 'depend', 'cutoff', 'point', 'word', 'effect', 'parameter', 'invariant', 'choice', 'category', 'response_variable', 'intercept', 'affected', 'cutoff', 'point', 'proportional', 'odds', 'model', 'therefore', 'invariant', 'choice', 'outcome', 'category', 'loss', 'efficiency', 'collapse', 'ordinal', 'category', 'observation', 'evenly', 'spread', 'among', 'category', 'efficiency', 'loss', 'minor', 'however', 'efficiency', 'loss', 'large', 'collapse', 'ordinal', 'category', 'binary', 'response', 'agresti', '1996', 'allison', '1999', 'recommends', 'need', 'least', '10', 'observation', 'category', 'response_variable', 'number', 'category', 'increase', 'ordinary', 'least', 'square', 'might', 'appropriate', 'however', 'hastie', 'et', 'al', '1989', 'showed', 'ordinary', 'least', 'square', 'method', 'could', 'give', 'misleading', 'result', '13', 'category', 'response_variable', 'proportional', 'odds', 'model', 'also', 'make', 'assumption', 'distance', 'category', 'therefore', 'code', 'ordinal', 'outcome', 'variable', 'ha', 'effect', 'odds_ratio', 'fitting', 'simple', 'ordinal', 'logistic_regression_model']"
741,"Example: 	Select a subset of variables using the forward selection method. In the MODEL statement specify all the main effects and two-factor interactions. Examine the differences in which variables were selected when you use HIERARCHY=SINGLE and when you include all the main effects in the model to assess interactions. /* c1demo04a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age|phy_visit|alcohol|hist_hyp| mother_wt|prev_pretrm|socio|uterine_irr @2 / selection=forward slentry=.05 hierarchy=single; title 'Low Birth Weight Model'; run; Selected MODEL statement options: SELECTION= 	specifies the method used to select the variables in the model. SLENTRY=	specifies the significance level for entry into the model. HIERARCHY=	specifies how model hierarchy is to be applied. Available methods are NONE, SINGLE, MULTIPLE, SINGLECLASS (same as HIERACHY=SINGLE except only class variables are subject to the hierarchy requirement), and MULTIPLECLASS (same as HIERACHY=MULTIPLE except only the class variables are subject to the hierarchy requirement). ?	The bar notation with @2 constructs a model with all the main effects and the two-factor interactions. If you increased it to @3, then you would construct a model with all of the main effects, the two-factor interactions, and the three factor interactions. Low Birth Weight Model",CD,1354,"['example', '\tselect', 'subset', 'variable', 'using', 'forward', 'selection', 'method', 'model_statement', 'specify', 'main_effect', 'twofactor', 'interaction', 'examine', 'difference', 'variable', 'selected', 'use', 'hierarchysingle', 'include', 'main_effect', 'model', 'ass', 'interaction', '', 'c1demo04a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motheragephyvisitalcoholhisthyp', 'motherwtprevpretrmsociouterineirr', '2', '', 'selectionforward', 'slentry05', 'hierarchysingle', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'selection', '\tspecifies', 'method', 'used', 'select', 'variable', 'model', 'slentry\tspecifies', 'significance', 'level', 'entry', 'model', 'hierarchy\tspecifies', 'model', 'hierarchy', 'applied', 'available', 'method', 'none', 'single', 'multiple', 'singleclass', 'hierachysingle', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', 'multipleclass', 'hierachymultiple', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', '\tthe', 'bar', 'notation', '2', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'increased', '3', 'would', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'three', 'factor', 'interaction', 'low', 'birth', 'weight', 'model']"
742,where is the diagonal elements of the hat matrix and is the change in the Pearson chi- square due to the deleted observation. The formula illustrates that the c diagnostic statistic can be large due to either lack-of-fit (large difchisq) or high leverage (large hat diagonal). Regression Diagnostics,CD,299,"['diagonal', 'element', 'hat', 'matrix', 'change', 'pearson', 'chi', 'square', 'due', 'deleted', 'observation', 'formula', 'illustrates', 'c', 'diagnostic', 'statistic', 'large', 'due', 'either', 'lackoffit', 'large', 'difchisq', 'high', 'leverage', 'large', 'hat', 'diagonal', 'regression', 'diagnostics']"
743,"The DIFDEV and DIFCHISQ are diagnostics for detecting which observations contribute heavily to the disagreement between the data and the predicted values of the fitted model. The range of DIFCHISQ is much greater then DIFDEV. DFBETAS are diagnostics that can be used to assess the effect of an individual observation on each estimated parameter of the fitted model. These statistics are useful in detecting observations that are causing instability in the selected parameter estimates. Instead of re-estimating the parameter each time an observation is deleted, PROC LOGISTIC uses the one-step estimate. C and CBAR are confidence interval displacement diagnostics. These statistics are based on the same idea as the Cook distance in linear regression. PROC LOGISTIC also computes these using the one-step estimate. H is the hat matrix diagonal. The diagonal elements of the hat matrix are useful in detecting extreme points in the design space. However, if the estimated probability is extreme (less than 0.1 and greater than 0.9), then the hat diagonal may be greatly reduced in value. Consequently, when an observation has a very large or very small estimated probability, its hat diagonal value is not a good indicator of the observation?s distance from the design space (Hosmer and Lemeshow 2000). The deviance residuals (contribution of each observation to the deviance chi-square) and Pearson residuals (contribution of each observation to the Pearson chi-square) can also be used to determine which observations are poorly fit by the model.",CD,1547,"['difdev', 'difchisq', 'diagnostics', 'detecting', 'observation', 'contribute', 'heavily', 'disagreement', 'data', 'predicted', 'value', 'fitted', 'model', 'range', 'difchisq', 'much', 'greater', 'difdev', 'dfbetas', 'diagnostics', 'used', 'ass', 'effect', 'individual', 'observation', 'estimated', 'parameter', 'fitted', 'model', 'statistic', 'useful', 'detecting', 'observation', 'causing', 'instability', 'selected', 'parameter_estimate', 'instead', 'reestimating', 'parameter', 'time', 'observation', 'deleted', 'proc_logistic', 'us', 'onestep', 'estimate', 'c', 'cbar', 'confidence', 'interval', 'displacement', 'diagnostics', 'statistic', 'based', 'idea', 'cook', 'distance', 'linear', 'regression', 'proc_logistic', 'also', 'computes', 'using', 'onestep', 'estimate', 'h', 'hat', 'matrix', 'diagonal', 'diagonal', 'element', 'hat', 'matrix', 'useful', 'detecting', 'extreme', 'point', 'design', 'space', 'however', 'estimated', 'probability', 'extreme', 'le', '01', 'greater', '09', 'hat', 'diagonal', 'may', 'greatly', 'reduced', 'value', 'consequently', 'observation', 'ha', 'large', 'small', 'estimated', 'probability', 'hat', 'diagonal', 'value', 'good', 'indicator', 'observation', 'distance', 'design', 'space', 'hosmer', 'lemeshow', '2000', 'deviance', 'residual', 'contribution', 'observation', 'deviance', 'chisquare', 'pearson', 'residual', 'contribution', 'observation', 'pearson', 'chisquare', 'also', 'used', 'determine', 'observation', 'poorly', 'fit', 'model']"
744,"The logit transformation is the log of the odds, which is the ratio of the probability of the outcome to the probability of no outcome. To create a linear model, the logit transformation is applied to the probability. Unlike a probability, the logit is unbounded because transforming the probability to odds removes the upper bound, whereas taking the natural logarithm of the odds removes the lower bound. The model (also called the logistic regression model) is now linear because the logit is linear in its parameters. Furthermore, the model gives estimated probabilities that are between 0 and 1.",CD,600,"['logit', 'transformation', 'log', 'odds_ratio', 'probability', 'outcome', 'probability', 'outcome', 'create', 'linear', 'model', 'logit', 'transformation', 'applied', 'probability', 'unlike', 'probability', 'logit', 'unbounded', 'transforming', 'probability', 'odds', 'remove', 'upper', 'bound', 'whereas', 'taking', 'natural', 'logarithm', 'odds', 'remove', 'lower', 'bound', 'model', 'also', 'called', 'logistic_regression_model', 'linear', 'logit', 'linear', 'parameter', 'furthermore', 'model', 'give', 'estimated', 'probability', '0', '1']"
745,"CMH statistics have low power (probability of correctly rejecting the null hypothesis) for detecting associations where the pattern of association in some of the strata is in the opposite direction of the pattern displayed by other strata (there is an interaction between the stratum variable and the predictor variable). Generally, this is not a problem because if there is an association, it is usually in the same direction across the set of tables, albeit in varying degrees. However, you should always examine the individual tables even if you fail to reject the null hypothesis (Stokes, Davis, and Koch 2000).",CD,615,"['cmh', 'statistic', 'low', 'power', 'probability', 'correctly', 'rejecting', 'null', 'hypothesis', 'detecting', 'association', 'pattern', 'association', 'stratum', 'opposite', 'direction', 'pattern', 'displayed', 'stratum', 'interaction', 'stratum', 'variable', 'predictor_variable', 'generally', 'problem', 'association', 'usually', 'direction', 'across', 'set', 'table', 'albeit', 'varying', 'degree', 'however', 'always', 'examine', 'individual', 'table', 'even', 'fail', 'reject', 'null', 'hypothesis', 'stokes', 'davis', 'koch', '2000']"
746,"If the estimation of the regression coefficients is the primary objective of your study and there are a large number of clusters (approximately 200) and a small number of time points, then you should not spend much time choosing a correlation structure. If the mean model is correctly specified, the GEE method for the parameter estimates was designed to guarantee consistency of the parameter estimates under minimal assumptions about the time dependence (Diggle, Heagerty, Liang, and Zeger 2002). Furthermore, the loss of efficiency from an incorrect choice of the working correlation structure is inconsequential when the number of subjects is large (Davis 2002).",CD,666,"['estimation', 'regression', 'coefficient', 'primary', 'objective', 'study', 'large', 'number', 'cluster', 'approximately', '200', 'small', 'number', 'time', 'point', 'spend', 'much', 'time', 'choosing', 'correlation_structure', 'mean', 'model', 'correctly', 'specified', 'gee', 'method', 'parameter_estimate', 'wa', 'designed', 'guarantee', 'consistency', 'parameter_estimate', 'minimal', 'assumption', 'time', 'dependence', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'furthermore', 'loss', 'efficiency', 'incorrect', 'choice', 'working', 'correlation_structure', 'inconsequential', 'number', 'subject', 'large', 'davis', '2002']"
747,The Parameter Information table displays the names of the parameters. Notice PROC GENMOD shows which value of the response variable is being modeled. Criteria For Assessing Goodness Of Fit,CD,188,"['parameter', 'information', 'table', 'display', 'name', 'parameter', 'notice', 'proc', 'genmod', 'show', 'value', 'response_variable', 'modeled', 'criterion', 'assessing', 'goodness', 'fit']"
748,Total Proportion Minimum Maximum Minimum Maximum Number Variation of Variation Proportion Second R-squared 1-R**2 Ratio of Explained Explained Explained Eigenvalue for a for a Clusters by Clusters by Clusters by a Cluster in a Cluster Variable Variable,CD,252,"['total', 'proportion', 'minimum', 'maximum', 'minimum', 'maximum', 'number', 'variation', 'variation', 'proportion', 'second', 'rsquared', '1r2', 'ratio', 'explained', 'explained', 'explained', 'eigenvalue', 'cluster', 'cluster', 'cluster', 'cluster', 'cluster', 'variable', 'variable']"
749,"If you do not know which working correlation structure to choose, one recommendation is to compare the parameter estimates and standard errors from several different correlation structures. This might indicate whether there is sensitivity to the misspecification of the correlation structure. PROC GENMOD also enables you to choose a user-defined correlation matrix.",CD,366,"['know', 'working', 'correlation_structure', 'choose', 'one', 'recommendation', 'compare', 'parameter_estimate', 'standard_error', 'several', 'different', 'correlation_structure', 'might', 'indicate', 'whether', 'sensitivity', 'misspecification', 'correlation_structure', 'proc', 'genmod', 'also', 'enables', 'choose', 'userdefined', 'correlation', 'matrix']"
750,"Variable clustering is based on principal components. Principal components are weighted linear combinations of the predictor variables where the weights are chosen to account for the largest amount of variation in the data; total variation in this case is the sum of the sample variances of the predictor variables. The principal components are numbered according to how much variation in the data is accounted for (first principal component accounts for the largest, second principal component accounts for the second largest, and so on) and each principal component accounts for a unique portion of the variation in the data. In other words, they are not correlated.",CD,668,"['variable', 'clustering', 'based', 'principal', 'component', 'principal', 'component', 'weighted', 'linear', 'combination', 'predictor_variable', 'weight', 'chosen', 'account', 'largest', 'amount', 'variation', 'data', 'total', 'variation', 'case', 'sum', 'sample', 'variance', 'predictor_variable', 'principal', 'component', 'numbered', 'according', 'much', 'variation', 'data', 'accounted', 'first', 'principal', 'component', 'account', 'largest', 'second', 'principal', 'component', 'account', 'second', 'largest', 'principal', 'component', 'account', 'unique', 'portion', 'variation', 'data', 'word', 'correlated']"
751,"When you statistically adjust for age, you are comparing the two groups at some common value of age. If there is no interaction, then any common value of age could be used, because it would yield the same difference between the two groups. In the logistic regression model with age and gender as predictor variables, the coefficient for gender would be the log odds ratio expected from a univariate comparison if the two groups had the same distribution of age. Age is a confounder in the relationship between gender and the response because it distorts the effect of gender on the response. The distribution of age is not the same in the two groups, and age is related to the response. For variables with few unique values, a stratified contingency table analysis may help identify confounders. For continuous variables, fitting the logistic model with and without the possible confounder and documenting any changes in the coefficient of the other predictor variable will be necessary.",CD,987,"['statistically', 'adjust', 'age', 'comparing', 'two', 'group', 'common', 'value', 'age', 'interaction', 'common', 'value', 'age', 'could', 'used', 'would', 'yield', 'difference', 'two', 'group', 'logistic_regression_model', 'age', 'gender', 'predictor_variable', 'coefficient', 'gender', 'would', 'log', 'odds_ratio', 'expected', 'univariate', 'comparison', 'two', 'group', 'distribution', 'age', 'age', 'confounder', 'relationship', 'gender', 'response', 'distorts', 'effect', 'gender', 'response', 'distribution', 'age', 'two', 'group', 'age', 'related', 'response_variable', 'unique', 'value', 'stratified', 'contingency', 'table', 'analysis', 'may', 'help', 'identify', 'confounders', 'continuous', 'variable', 'fitting', 'logistic', 'model', 'without', 'possible', 'confounder', 'documenting', 'change', 'coefficient', 'predictor_variable', 'necessary']"
752,Matching is carried out in the design phase of the study where you want to balance two or more groups with respect to one or more risk factors that are either known or thought to be associated with the outcome.,CD,210,"['matching', 'carried', 'design', 'phase', 'study', 'want', 'balance', 'two', 'group', 'respect', 'one', 'risk', 'factor', 'either', 'known', 'thought', 'associated', 'outcome']"
753,"When you statistically adjust for age, you are comparing the two groups at some common value of age. If there is no interaction, then any common value of age could be used, because it would yield the same difference between the two groups. In the logistic regression model with age and gender as predictor variables, the coefficient for gender would be the log odds ratio expected from a univariate comparison if the two groups had the same distribution of age. Age is a confounder in the relationship between gender and the response because it distorts the effect of gender on the response. The distribution of age is not the same in the two groups, and age is related to the response. For variables with few unique values, a stratified contingency table analysis may help identify confounders. For continuous variables, fitting the logistic model with and without the possible confounder and documenting any changes in the coefficient of the other predictor variable will be necessary.",CD,987,"['statistically', 'adjust', 'age', 'comparing', 'two', 'group', 'common', 'value', 'age', 'interaction', 'common', 'value', 'age', 'could', 'used', 'would', 'yield', 'difference', 'two', 'group', 'logistic_regression_model', 'age', 'gender', 'predictor_variable', 'coefficient', 'gender', 'would', 'log', 'odds_ratio', 'expected', 'univariate', 'comparison', 'two', 'group', 'distribution', 'age', 'age', 'confounder', 'relationship', 'gender', 'response', 'distorts', 'effect', 'gender', 'response', 'distribution', 'age', 'two', 'group', 'age', 'related', 'response_variable', 'unique', 'value', 'stratified', 'contingency', 'table', 'analysis', 'may', 'help', 'identify', 'confounders', 'continuous', 'variable', 'fitting', 'logistic', 'model', 'without', 'possible', 'confounder', 'documenting', 'change', 'coefficient', 'predictor_variable', 'necessary']"
754,"The Criteria For Assessing Goodness Of Fit table displays the scaled deviance and scaled Pearson chi-squares, which both measure the goodness-of-fit of the model. However, the model being evaluated is the independence-only model, not the GEE model. Notice also that the log likelihood is based on the independence model and should not be used to construct a likelihood-ratio test comparing GEE models. Because the GEE method is quasi-likelihood based, there is no reported log likelihood for the GEE model. Analysis Of Initial Parameter Estimates",CD,546,"['criterion', 'assessing', 'goodness', 'fit', 'table', 'display', 'scaled', 'deviance', 'scaled', 'pearson', 'chisquares', 'measure', 'goodnessoffit', 'model', 'however', 'model', 'evaluated', 'independenceonly', 'model', 'gee', 'model', 'notice', 'also', 'log', 'likelihood', 'based', 'independence', 'model', 'used', 'construct', 'likelihoodratio', 'test', 'comparing', 'gee', 'model', 'gee', 'method', 'quasilikelihood', 'based', 'reported', 'log', 'likelihood', 'gee', 'model', 'analysis', 'initial', 'parameter_estimate']"
755,"Logits modeled use food='Fish' as the reference category. The first part of the output is similar to the output for the binary logit model. Because the MODEL statement option REF='Fish', the response category Fish is used as the reference category. Class Level Information",CD,272,"['logits', 'modeled', 'use', 'foodfish', 'reference', 'category', 'first', 'part', 'output', 'similar', 'output', 'binary', 'logit', 'model', 'model_statement', 'option', 'reffish', 'response', 'category', 'fish', 'used', 'reference', 'category', 'class', 'level', 'information']"
756,PROC GENMOD is modeling the probability that wheeze='1'. The Class Level Information table displays the levels of the class variables while the response profile table displays the levels of the response variable. Parameter Information,CD,234,"['proc', 'genmod', 'modeling', 'probability', 'wheeze1', 'class', 'level', 'information', 'table', 'display', 'level', 'class', 'variable', 'response', 'profile', 'table', 'display', 'level', 'response_variable', 'parameter', 'information']"
757,"In this course, contrasts are used to compute the odds ratio that compares one level of a CLASS variable to another level. However, in order to construct a contrast, you need to be able to define the coefficients for the test of the hypothesis. For example, to compute the odds ratio that compares low to medium for the variable socio in a CONTRAST statement, you should first write the model equation for each of the levels.",CD,425,"['course', 'contrast', 'used', 'compute', 'odds_ratio', 'compare', 'one', 'level', 'class', 'variable', 'another', 'level', 'however', 'order', 'construct', 'contrast', 'need', 'able', 'define', 'coefficient', 'test', 'hypothesis', 'example', 'compute', 'odds_ratio', 'compare', 'low', 'medium', 'variable', 'socio', 'contrast', 'statement', 'first', 'write', 'model', 'equation', 'level']"
758,"To document the strength of the association, the odds ratio could be used for the binary predictors. For the ordinal predictors, the Spearman correlation statistic (which correlates the ranks of the data) would be helpful. For nominal predictors, the uncertainty coefficient c|r (column given the row, which means the column variable is the outcome variable and the row variable is the predictor variable) could be used. The uncertainty coefficient is defined as the proportion of the entropy (or uncertainty) in the response variable that is explained by the predictor variable. This statistic is comparable to the R2 statistic used in regression analysis.",CD,657,"['document', 'strength', 'association', 'odds_ratio', 'could', 'used', 'binary', 'predictor', 'ordinal', 'predictor', 'spearman', 'correlation', 'statistic', 'correlate', 'rank', 'data', 'would', 'helpful', 'nominal', 'predictor', 'uncertainty', 'coefficient', 'cr', 'column', 'given', 'row', 'mean', 'column', 'variable', 'outcome', 'variable', 'row', 'variable', 'predictor_variable', 'could', 'used', 'uncertainty', 'coefficient', 'defined', 'proportion', 'entropy', 'uncertainty', 'response_variable', 'explained', 'predictor_variable', 'statistic', 'comparable', 'r2', 'statistic', 'used', 'regression', 'analysis']"
759,"In ordinal logistic regression, the logit is now a cumulative logit. If k is the number of categories for the outcome variable, then the number of cumulative logits is k-1. The model generates cumulative probabilities, which is the probability that an individual is in the jth ordered category or lower. If you use the DESCENDING option in PROC LOGISTIC, then the model generates probabilities that an individual is in the jth category or higher.",CD,446,"['ordinal', 'logistic_regression', 'logit', 'cumulative', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'cumulative', 'logits', 'k1', 'model', 'generates', 'cumulative', 'probability', 'probability', 'individual', 'jth', 'ordered', 'category', 'lower', 'use', 'descending', 'option', 'proc_logistic', 'model', 'generates', 'probability', 'individual', 'jth', 'category', 'higher']"
760,"In the CLASS statement in PROC LOGISTIC, you can specify the coding scheme for the design variables created from the CLASS variable. For effect coding (also called deviation from the mean coding), the number of design variables created is the number of levels of the CLASS variable minus 1. For example, because the variable socio has three levels, only two design variables are created. For the last level of the CLASS variable, all the design variables have a value of ?1. Parameter estimates of the CLASS main effects using this coding scheme estimate the difference between the effect of each level and the average effect over all levels. Effect coding is the default in PROC LOGISTIC.",CD,689,"['class', 'statement', 'proc_logistic', 'specify', 'coding', 'scheme', 'design', 'variable', 'created', 'class', 'variable', 'effect', 'coding', 'also', 'called', 'deviation', 'mean', 'coding', 'number', 'design', 'variable', 'created', 'number', 'level', 'class', 'variable', 'minus', '1', 'example', 'variable', 'socio', 'ha', 'three', 'level', 'two', 'design', 'variable', 'created', 'last', 'level', 'class', 'variable', 'design', 'variable', 'value', '1', 'parameter_estimate', 'class', 'main_effect', 'using', 'coding', 'scheme', 'estimate', 'difference', 'effect', 'level', 'average', 'effect', 'level', 'effect', 'coding', 'default', 'proc_logistic']"
761,"Building a nominal logistic regression model employs the same strategy as building any other model. The first step is to examine the distribution of the predictor variables and take note of any missing values and unusual data values. Contingency table analysis should also be performed to examine the associations between the outcome variable and each of the ordinal predictor variables. You should carefully look for cells with no observations, because this may cause a problem in PROC LOGISTIC.",CD,496,"['building', 'nominal', 'logistic_regression_model', 'employ', 'strategy', 'building', 'model', 'first', 'step', 'examine', 'distribution', 'predictor_variable', 'take', 'note', 'missing', 'value', 'unusual', 'data', 'value', 'contingency', 'table', 'analysis', 'also', 'performed', 'examine', 'association', 'outcome', 'variable', 'ordinal', 'predictor_variable', 'carefully', 'look', 'cell', 'observation', 'may', 'cause', 'problem', 'proc_logistic']"
762,"To document the strength of the association, the odds ratio could be used for the binary predictors. For the ordinal predictors, the Spearman correlation statistic (which correlates the ranks of the data) would be helpful. For nominal predictors, the uncertainty coefficient c|r (column given the row, which means the column variable is the outcome variable and the row variable is the predictor variable) could be used. The uncertainty coefficient is defined as the proportion of the entropy (or uncertainty) in the response variable that is explained by the predictor variable. This statistic is comparable to the R2 statistic used in regression analysis.",CD,657,"['document', 'strength', 'association', 'odds_ratio', 'could', 'used', 'binary', 'predictor', 'ordinal', 'predictor', 'spearman', 'correlation', 'statistic', 'correlate', 'rank', 'data', 'would', 'helpful', 'nominal', 'predictor', 'uncertainty', 'coefficient', 'cr', 'column', 'given', 'row', 'mean', 'column', 'variable', 'outcome', 'variable', 'row', 'variable', 'predictor_variable', 'could', 'used', 'uncertainty', 'coefficient', 'defined', 'proportion', 'entropy', 'uncertainty', 'response_variable', 'explained', 'predictor_variable', 'statistic', 'comparable', 'r2', 'statistic', 'used', 'regression', 'analysis']"
763,"Exploratory data analysis should be the first step in model building to identify any numerical problems and nonlinearity. Contingency table analysis of categorical predictors should also be performed so that you can compare the univariate effect and the multivariate effect of each predictor variable. You should be concerned about predictor variables whose coefficients have changed substantially in magnitude when other predictor variables are added to or eliminated from the model. This may identify one or more variables that were important in providing a needed adjustment of the effects of the variables that remained in the model. Finally, after a candidate model has been identified, you should assess the fit of the model and identify any outliers or influential observations that are contributing to a poor fitting model (Hosmer and Lemeshow 2000). 1.2	Exploratory Data Analysis",CD,888,"['exploratory', 'data', 'analysis', 'first', 'step', 'model', 'building', 'identify', 'numerical', 'problem', 'nonlinearity', 'contingency', 'table', 'analysis', 'categorical', 'predictor', 'also', 'performed', 'compare', 'univariate', 'effect', 'multivariate', 'effect', 'predictor_variable', 'concerned', 'predictor_variable', 'whose', 'coefficient', 'changed', 'substantially', 'magnitude', 'predictor_variable', 'added', 'eliminated', 'model', 'may', 'identify', 'one', 'variable', 'important', 'providing', 'needed', 'adjustment', 'effect', 'variable', 'remained', 'model', 'finally', 'candidate', 'model', 'ha', 'identified', 'ass', 'fit', 'model', 'identify', 'outlier', 'influential', 'observation', 'contributing', 'poor', 'fitting', 'model', 'hosmer', 'lemeshow', '2000', '12\texploratory', 'data', 'analysis']"
764,"A useful way to explain significant interactions is to graph them. For example, to visualize the interaction between mother?s age and physician visit, first create a data set that contains the information about the fitted model. Then create a data set with plotting points, which include the median for each predictor variable not involved in the interaction and the 5th, 25th, 50th, 75th, and 95th percentiles of mother?s age and both values of physician visit. Then score the data set in PROC LOGISTIC with the SCORE statement. Finally, plot the predicted logits and the predicted probabilities by the plotting points for the two variables to illustrate how the slope for mother?s age differs by the level of physician visit. Illustrating Interactions",CD,753,"['useful', 'way', 'explain', 'significant', 'interaction', 'graph', 'example', 'visualize', 'interaction', 'mother', 'age', 'physician', 'visit', 'first', 'create', 'data_set', 'contains', 'information', 'fitted', 'model', 'create', 'data_set', 'plotting', 'point', 'include', 'median', 'predictor_variable', 'involved', 'interaction', '5th', '25th', '50th', '75th', '95th', 'percentile', 'mother', 'age', 'value', 'physician', 'visit', 'score', 'data_set', 'proc_logistic', 'score', 'statement', 'finally', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', 'two', 'variable', 'illustrate', 'slope', 'mother', 'age', 'differs', 'level', 'physician', 'visit', 'illustrating', 'interaction']"
765,"The likelihood ratio statistic that compares the main effects model to the interaction model is clearly significant at the 0.05 level. Therefore, a candidate final model should include the mother_age*phy_visit interaction and the main effects. Example:	Compute a likelihood ratio test comparing a model treating socio as a continuous variable and a model treating socio as a classification variable. /* c1demo06e */ ods listing close;",CD,434,"['likelihood', 'ratio', 'statistic', 'compare', 'main_effect', 'model', 'interaction', 'model', 'clearly', 'significant', '005', 'level', 'therefore', 'candidate', 'final', 'model', 'include', 'motheragephyvisit', 'interaction', 'main_effect', 'example\tcompute', 'likelihood', 'ratio', 'test', 'comparing', 'model', 'treating', 'socio', 'continuous', 'variable', 'model', 'treating', 'socio', 'classification', 'variable', '', 'c1demo06e', '', 'od', 'listing', 'close']"
766,The number of observations in the contingency table prev_pretrm by low controlling for uterine_irr=1 is fairly small. This may be a problem for the Breslow-Day test and the asymptotic confidence limits for the odds ratio. Statistics for Table 2 of prev_pretrm by low Controlling for uterine_irr=1,CD,296,"['number', 'observation', 'contingency', 'table', 'prevpretrm', 'low', 'controlling', 'uterineirr1', 'fairly', 'small', 'may', 'problem', 'breslowday', 'test', 'asymptotic', 'confidence', 'limit', 'odds_ratio', 'statistic', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
767,"In nominal logistic regression, the logit is now a generalized logit. If k is the number of categories for the outcome variable, then the number of generalized logits is k-1. The last category is the reference category or the denominator of each logit.",CD,252,"['nominal', 'logistic_regression', 'logit', 'generalized', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'generalized', 'logits', 'k1', 'last', 'category', 'reference', 'category', 'denominator', 'logit']"
768,"Hosmer and Lemeshow (2000) also recommend plotting the diagnostic statistics by the predicted probabilities where the size of the plotting symbol is proportional to the effect of each covariate pattern on the value of the estimated parameters. The GPLOT procedure can accomplish this with the use of a bubble plot. In the bubble plot above, the size of the bubbles is proportional to the c diagnostic statistic. In general, the largest values of the c diagnostic statistic are likely to occur when the change in the Pearson chi-square is large or when the leverage is large (the diagonal of the hat matrix). The position of the bubbles in the graph can give a general idea which statistic contributed to the high c diagnostic statistic. For example, if the large bubbles occur in the upper-right or upper-left corner, then the change in the Pearson chi-square contributed the most to the high c diagnostic statistic because leverage values tend to be low when the estimated probabilities are below .10 or above .90. However, if the bubbles fall in the bottom of the cup defined by the two quadratic curves, then the leverage values contributed the most to the high c diagnostic statistic. The points in the plot that are of greatest concern are those with large circles falling within the cup. These correspond to covariate patterns that are not fit very well and have high leverage values (Hosmer and Lemeshow 2000). The formula for the c diagnostic is:",CD,1454,"['hosmer', 'lemeshow', '2000', 'also', 'recommend', 'plotting', 'diagnostic', 'statistic', 'predicted', 'probability', 'size', 'plotting', 'symbol', 'proportional', 'effect', 'covariate', 'pattern', 'value', 'estimated', 'parameter', 'gplot', 'procedure', 'accomplish', 'use', 'bubble', 'plot', 'bubble', 'plot', 'size', 'bubble', 'proportional', 'c', 'diagnostic', 'statistic', 'general', 'largest', 'value', 'c', 'diagnostic', 'statistic', 'likely', 'occur', 'change', 'pearson', 'chisquare', 'large', 'leverage', 'large', 'diagonal', 'hat', 'matrix', 'position', 'bubble', 'graph', 'give', 'general', 'idea', 'statistic', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'example', 'large', 'bubble', 'occur', 'upperright', 'upperleft', 'corner', 'change', 'pearson', 'chisquare', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'leverage', 'value', 'tend', 'low', 'estimated', 'probability', '10', '90', 'however', 'bubble', 'fall', 'bottom', 'cup', 'defined', 'two', 'quadratic', 'curve', 'leverage', 'value', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'point', 'plot', 'greatest', 'concern', 'large', 'circle', 'falling', 'within', 'cup', 'correspond', 'covariate', 'pattern', 'fit', 'well', 'high', 'leverage', 'value', 'hosmer', 'lemeshow', '2000', 'formula', 'c', 'diagnostic']"
769,The Analysis of Initial Parameter Estimates table shows the parameter estimates when the observations are treated as independent. These parameter estimates are used as the starting values for the GEE solution. Notice that both smoker and age are significant at the 0.05 significance level. GEE Model Information,CD,311,"['analysis', 'initial', 'parameter_estimate', 'table', 'show', 'parameter_estimate', 'observation', 'treated', 'independent', 'parameter_estimate', 'used', 'starting', 'value', 'gee', 'solution', 'notice', 'smoker', 'age', 'significant', '005', 'significance', 'level', 'gee', 'model', 'information']"
770,"Correlation Structure Unstructured Subject Effect case (537 levels) Number of Clusters 537 Correlation Matrix Dimension 4 Maximum Cluster Size 4 Minimum Cluster Size 4 Algorithm converged. The GEE Model Information table displays information about the model fit with GEEs. Because TYPE=UNSTR option is requested, the unstructured correlation structure is used. Furthermore, because there are 537 children, there are 537 clusters. Notice there are no missing data values. Working Correlation Matrix",CD,497,"['correlation_structure', 'unstructured', 'subject', 'effect', 'case', '537', 'level', 'number', 'cluster', '537', 'correlation', 'matrix', 'dimension', '4', 'maximum', 'cluster', 'size', '4', 'minimum', 'cluster', 'size', '4', 'algorithm', 'converged', 'gee', 'model', 'information', 'table', 'display', 'information', 'model', 'fit', 'gee', 'typeunstr', 'option', 'requested', 'unstructured', 'correlation_structure', 'used', 'furthermore', '537', 'child', '537', 'cluster', 'notice', 'missing', 'data', 'value', 'working', 'correlation', 'matrix']"
771,Example:	Generate the regression diagnostic statistics for each observation. /* c2demo11a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / influence; title 'Logistic Regression Diagnostic Statistics'; run; Selected MODEL statement options: INFLUENCE	displays diagnostic measures for identifying influential observations in the case of the binary outcome model. Partial Output Logistic Regression Diagnostic Statistics,CD,527,"['example\tgenerate', 'regression', 'diagnostic', 'statistic', 'observation', '', 'c2demo11a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'influence', 'title', 'logistic_regression', 'diagnostic', 'statistic', 'run', 'selected', 'model_statement', 'option', 'influence\tdisplays', 'diagnostic', 'measure', 'identifying', 'influential', 'observation', 'case', 'binary', 'outcome', 'model', 'partial', 'output', 'logistic_regression', 'diagnostic', 'statistic']"
772,"The problem of biasing the inferences can be avoided by prespecifying the model. When you have a large number of variables, however, prespecifying the model is not feasible. Therefore, analysts use the results of the model selection techniques (usually the p-values for the predictor variables) to select a model. However, the p-values calculated in the model selection techniques are not p-values in the traditional hypothesis-testing context. Instead, they should be viewed as indicators of relative importance among variables (Hosmer and Lemeshow 2000). Because the biased p-values overstate the significance of the predictor variables, the traditional cutoff of .05 is not very useful unless the sample size is small (30-50). For large sample sizes, much smaller p-values are required to imply that the data provide evidence for the effect of interest. The slide above provides approximate two-sided p-values corresponding to different grades of evidence for tests involving one additional parameter (one degree of freedom). Significance levels for tests involving more than one degree of freedom would even be lower, especially for the larger sample sizes (Raftery 1994).",CD,1176,"['problem', 'biasing', 'inference', 'avoided', 'prespecifying', 'model', 'large', 'number', 'variable', 'however', 'prespecifying', 'model', 'feasible', 'therefore', 'analyst', 'use', 'result', 'model', 'selection', 'technique', 'usually', 'pvalues', 'predictor_variable', 'select', 'model', 'however', 'pvalues', 'calculated', 'model', 'selection', 'technique', 'pvalues', 'traditional', 'hypothesistesting', 'context', 'instead', 'viewed', 'indicator', 'relative', 'importance', 'among', 'variable', 'hosmer', 'lemeshow', '2000', 'biased', 'pvalues', 'overstate', 'significance', 'predictor_variable', 'traditional', 'cutoff', '05', 'useful', 'unless', 'sample_size', 'small', '3050', 'large', 'sample_size', 'much', 'smaller', 'pvalues', 'required', 'imply', 'data', 'provide', 'evidence', 'effect', 'interest', 'slide', 'provides', 'approximate', 'twosided', 'pvalues', 'corresponding', 'different', 'grade', 'evidence', 'test', 'involving', 'one', 'additional', 'parameter', 'one', 'degree', 'freedom', 'significance', 'level', 'test', 'involving', 'one', 'degree', 'freedom', 'would', 'even', 'lower', 'especially', 'larger', 'sample_size', 'raftery', '1994']"
773,"Besides the observations with the large change in the Pearson chi-square statistic, the observations with large circles near the bottom of the cup defined by the quadratic curves should also be examined. These are observations that influenced the parameter estimates to a relatively large extent but are not poorly fitted observations (Hosmer and Lemeshow 2000). Example:	Print the observations with possible outlying covariate patterns. Examine each observation to determine what made the observation influential or an outlier. Establish a cutoff of the 95th percentile for the distribution of DIFDEV, DIFCHISQ, H, and C. ?	Because there are no published statistical cutoffs for the logistic regression diagnostic statistics, these suggested cutoffs are only used to detect possible outliers and influential observations. A more thorough approach would be to examine all of the diagnostic plots to identify all of the unusual observations. /* c2demo11d */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difdev=difdev difchisq=difchisq h=h c=c dfbetas=dfint dfage dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; run; For the DFBETAS keyword, a list of variable names is specified to correspond to the parameter estimates in the model. The first variable contains the standardized differences in the intercept estimate, the second variable contains the standardized differences in the parameter estimate for the first predictor variable in the MODEL statement, and so on. /* c2demo11e */ proc rank data=predict groups=20 out=bins; var difdev difchisq h c; ranks difdevbin difchisqbin hbin cbin; run; PROC RANK is used to bin the observations into groups. The variable difdevbin is the group identification number for difdev that ranges from 0 (the first group) to 19 (the last group). The variables difchisqbin, hbin, and cbin are the group identification numbers for difchisq, h, and c respectively. /* c2demo11f */ proc print data=bins; where difdevbin=19 or difchisqbin=19 or hbin=19 or cbin=19; var low mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio pred difdev difchisq h c dfint dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; title 'Observations with Possible Outlying Covariate ' 'Patterns'; run;",CD,2400,"['besides', 'observation', 'large', 'change', 'pearson', 'chisquare', 'statistic', 'observation', 'large', 'circle', 'near', 'bottom', 'cup', 'defined', 'quadratic', 'curve', 'also', 'examined', 'observation', 'influenced', 'parameter_estimate', 'relatively', 'large', 'extent', 'poorly', 'fitted', 'observation', 'hosmer', 'lemeshow', '2000', 'example\tprint', 'observation', 'possible', 'outlying', 'covariate', 'pattern', 'examine', 'observation', 'determine', 'made', 'observation', 'influential', 'outlier', 'establish', 'cutoff', '95th', 'percentile', 'distribution', 'difdev', 'difchisq', 'h', 'c', '\tbecause', 'published', 'statistical', 'cutoff', 'logistic_regression', 'diagnostic', 'statistic', 'suggested', 'cutoff', 'used', 'detect', 'possible', 'outlier', 'influential', 'observation', 'thorough', 'approach', 'would', 'examine', 'diagnostic', 'plot', 'identify', 'unusual', 'observation', '', 'c2demo11d', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difdevdifdev', 'difchisqdifchisq', 'hh', 'cc', 'dfbetasdfint', 'dfage', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'run', 'dfbetas', 'keyword', 'list', 'variable', 'name', 'specified', 'correspond', 'parameter_estimate', 'model', 'first', 'variable', 'contains', 'standardized', 'difference', 'intercept', 'estimate', 'second', 'variable', 'contains', 'standardized', 'difference', 'parameter_estimate', 'first', 'predictor_variable', 'model_statement', '', 'c2demo11e', '', 'proc', 'rank', 'datapredict', 'groups20', 'outbins', 'var', 'difdev', 'difchisq', 'h', 'c', 'rank', 'difdevbin', 'difchisqbin', 'hbin', 'cbin', 'run', 'proc', 'rank', 'used', 'bin', 'observation', 'group', 'variable', 'difdevbin', 'group', 'identification', 'number', 'difdev', 'range', '0', 'first', 'group', '19', 'last', 'group', 'variable', 'difchisqbin', 'hbin', 'cbin', 'group', 'identification', 'number', 'difchisq', 'h', 'c', 'respectively', '', 'c2demo11f', '', 'proc', 'print', 'databins', 'difdevbin19', 'difchisqbin19', 'hbin19', 'cbin19', 'var', 'low', 'motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'pred', 'difdev', 'difchisq', 'h', 'c', 'dfint', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'title', 'observation', 'possible', 'outlying', 'covariate', '', 'pattern', 'run']"
774,"If the estimation of the regression coefficients is the primary objective of your study and there are a large number of clusters (approximately 200) and a small number of time points, then you should not spend much time choosing a correlation structure. If the mean model is correctly specified, the GEE method for the parameter estimates was designed to guarantee consistency of the parameter estimates under minimal assumptions about the time dependence (Diggle, Heagerty, Liang, and Zeger 2002). Furthermore, the loss of efficiency from an incorrect choice of the working correlation structure is inconsequential when the number of subjects is large (Davis 2002).",CD,666,"['estimation', 'regression', 'coefficient', 'primary', 'objective', 'study', 'large', 'number', 'cluster', 'approximately', '200', 'small', 'number', 'time', 'point', 'spend', 'much', 'time', 'choosing', 'correlation_structure', 'mean', 'model', 'correctly', 'specified', 'gee', 'method', 'parameter_estimate', 'wa', 'designed', 'guarantee', 'consistency', 'parameter_estimate', 'minimal', 'assumption', 'time', 'dependence', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'furthermore', 'loss', 'efficiency', 'incorrect', 'choice', 'working', 'correlation_structure', 'inconsequential', 'number', 'subject', 'large', 'davis', '2002']"
775,"Backward elimination starts off with the full model. Results of the Wald test for individual parameter estimates are examined, and the least significant variable that falls above the specified significance level (specified by the SLSTAY= option) is removed. After a variable is removed from the model, it remains excluded. The process is repeated until no other variable in the model meets the specified significance level for removal. By default, SLSTAY=0.05. When using backward elimination, you could use the FAST option to increase efficiency. This method only requires passing through the data matrix once to get the initial full model fit. Then the method uses an algorithm to manipulate the full model fit to approximate the parameter estimates for the reduced models. This eliminates the need to refit the model every time a variable is removed. Simulations examining variable selection techniques found that backward elimination methods usually performed better than the forward stepwise methods, especially when collinearity is present among the predictor variables. However, a relatively large number of predictor variables increases the risk of complete separation (Hosmer and Lemeshow 2000). Furthermore, sparseness in the data causes unstable parameter estimates that negatively impact the performance of the backward elimination method (Harrell 1997).",CD,1366,"['backward', 'elimination', 'start', 'full', 'model', 'result', 'wald', 'test', 'individual', 'parameter_estimate', 'examined', 'least', 'significant', 'variable', 'fall', 'specified', 'significance', 'level', 'specified', 'slstay', 'option', 'removed', 'variable', 'removed', 'model', 'remains', 'excluded', 'process', 'repeated', 'variable', 'model', 'meet', 'specified', 'significance', 'level', 'removal', 'default', 'slstay005', 'using', 'backward', 'elimination', 'could', 'use', 'fast', 'option', 'increase', 'efficiency', 'method', 'requires', 'passing', 'data', 'matrix', 'get', 'initial', 'full', 'model', 'fit', 'method', 'us', 'algorithm', 'manipulate', 'full', 'model', 'fit', 'approximate', 'parameter_estimate', 'reduced', 'model', 'eliminates', 'need', 'refit', 'model', 'every', 'time', 'variable', 'removed', 'simulation', 'examining', 'variable', 'selection', 'technique', 'found', 'backward', 'elimination', 'method', 'usually', 'performed', 'better', 'forward', 'stepwise', 'method', 'especially', 'collinearity', 'present', 'among', 'predictor_variable', 'however', 'relatively', 'large', 'number', 'predictor_variable', 'increase', 'risk', 'complete', 'separation', 'hosmer', 'lemeshow', '2000', 'furthermore', 'sparseness', 'data', 'cause', 'unstable', 'parameter_estimate', 'negatively', 'impact', 'performance', 'backward', 'elimination', 'method', 'harrell', '1997']"
776,"If the responses are positively correlated, which often occurs when repeated measurements are taken on the same subject, then the variance of the time-independent predictor variables (variables whose values do not vary within a cluster or across time, such as gender and race) is underestimated if the data is analyzed as though the observations are independent. In other words, the Type I error rates are inflated for these variables (Dunlop 1994).",CD,449,"['response', 'positively', 'correlated', 'often', 'occurs', 'repeated', 'measurement', 'taken', 'subject', 'variance', 'timeindependent', 'predictor_variable', 'variable', 'whose', 'value', 'vary', 'within', 'cluster', 'across', 'time', 'gender', 'race', 'underestimated', 'data', 'analyzed', 'though', 'observation', 'independent', 'word', 'type', 'error', 'rate', 'inflated', 'variable', 'dunlop', '1994']"
777,"The first section of the output describes the data set, the response variable, the number of response levels, the type of model, the algorithm used to obtain the parameter estimates, and the number of observations read and used. The Response Profile table shows the response variable values listed according to their ordered values. By default, PROC LOGISTIC orders the response variable alphanumerically so that it bases the logistic regression model on the probability of the smallest value. Because you used the EVENT=option, in this example, the model is based on the probability of low birth weight (low=1). The Response Profile table also shows the value of the response variable and the frequency. The class level information shows that socio was dummy coded into two design variables. Because you used the PARAM=REF and REF='3' options, this table reflects your choice of socio=3 as the reference level. Model Fit Statistics",CD,932,"['first', 'section', 'output', 'describes', 'data_set', 'response_variable', 'number', 'response', 'level', 'type', 'model', 'algorithm', 'used', 'obtain', 'parameter_estimate', 'number', 'observation', 'read', 'used', 'response', 'profile', 'table', 'show', 'response_variable', 'value', 'listed', 'according', 'ordered', 'value', 'default', 'proc_logistic', 'order', 'response_variable', 'alphanumerically', 'base', 'logistic_regression_model', 'probability', 'smallest', 'value', 'used', 'eventoption', 'example', 'model', 'based', 'probability', 'low', 'birth', 'weight', 'low1', 'response', 'profile', 'table', 'also', 'show', 'value', 'response_variable', 'frequency', 'class', 'level', 'information', 'show', 'socio', 'wa', 'dummy', 'coded', 'two', 'design', 'variable', 'used', 'paramref', 'ref3', 'option', 'table', 'reflects', 'choice', 'socio3', 'reference', 'level', 'model', 'fit', 'statistic']"
778,"A key component of exploratory data analysis is to graphically examine the relationship between the response variable and the predictor variables. In linear regression, it is standard practice to examine scatter plots of the response variable and the continuous predictor variables. However, when the response variable is a binary variable, these scatter plots are not very useful. A more enlightening scatter plot for logistic regression is to transform the vertical axis to the logit scale and plot the logit by the continuous predictor variable. In this way you can check the assumption of linearity in the logit (Hosmer and Lemeshow 2000).",CD,643,"['key', 'component', 'exploratory', 'data', 'analysis', 'graphically', 'examine', 'relationship', 'response_variable', 'predictor_variable', 'linear', 'regression', 'standard', 'practice', 'examine', 'scatter', 'plot', 'response_variable', 'continuous', 'predictor_variable', 'however', 'response_variable', 'binary', 'variable', 'scatter', 'plot', 'useful', 'enlightening', 'scatter', 'plot', 'logistic_regression', 'transform', 'vertical', 'axis', 'logit', 'scale', 'plot', 'logit', 'continuous', 'predictor_variable', 'way', 'check', 'assumption', 'linearity', 'logit', 'hosmer', 'lemeshow', '2000']"
779,title 'Nominal Logistic Regression Model on Alligator Food Data'; run; Selected MODEL statement options: REF=	specifies the reference group for the nominal and binary response model. You can specify the reference category in quotes or the keyword FIRST (designates the first ordered category as the reference) or the keyword LAST (designates the last ordered category as the reference). The default is REF=LAST. LINK=	specifies the function linking the response probabilities to the linear predictors. The keyword GLOGIT requests the generalized logit function. The default is LINK=LOGIT (the log odds function). Nominal Logistic Regression Model on Alligator Food Data,CD,669,"['title', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data', 'run', 'selected', 'model_statement', 'option', 'ref\tspecifies', 'reference', 'group', 'nominal', 'binary', 'response', 'model', 'specify', 'reference', 'category', 'quote', 'keyword', 'first', 'designates', 'first', 'ordered', 'category', 'reference', 'keyword', 'last', 'designates', 'last', 'ordered', 'category', 'reference', 'default', 'reflast', 'link\tspecifies', 'function', 'linking', 'response', 'probability', 'linear', 'predictor', 'keyword', 'glogit', 'request', 'generalized', 'logit', 'function', 'default', 'linklogit', 'log', 'odds', 'function', 'nominal', 'logistic_regression_model', 'alligator', 'food', 'data']"
780,"random component	identifies the response variable and its probability distribution. systematic component	specifies the predictor variables used in a linear predictor. link function	specifies the function of E(Y) that the model equates to the systematic component. For the general linear model, the link function is the identity link (modeling the mean), the response variable is normally distributed, and the variance is constant. For logistic regression, the link function is the logit link ( ) and the response variable follows a binomial distribution (a common distribution for binary outcomes). For Poisson regression, the link function is the natural log and the response variable follows the Poisson distribution. The link function that transforms the mean to the natural location parameter is called the canonical link. For example, in the normal distribution the natural location parameter is the mean. Models with canonical links usually make the best sense on scientific grounds, but you can choose other link functions besides the canonical links. ?	The reason for restricting the distribution of the response variable to the family of exponential distributions is that the same algorithm to compute maximum likelihood parameter estimates applies to this entire family for any choice of link function.",CD,1312,"['random', 'component\tidentifies', 'response_variable', 'probability', 'distribution', 'systematic', 'component\tspecifies', 'predictor_variable', 'used', 'linear', 'predictor', 'link', 'function\tspecifies', 'function', 'ey', 'model', 'equates', 'systematic', 'component', 'general', 'linear', 'model', 'link', 'function', 'identity', 'link', 'modeling', 'mean', 'response_variable', 'normally', 'distributed', 'variance', 'constant', 'logistic_regression', 'link', 'function', 'logit', 'link', '', '', 'response_variable', 'follows', 'binomial', 'distribution', 'common', 'distribution', 'binary', 'outcome', 'poisson', 'regression', 'link', 'function', 'natural', 'log', 'response_variable', 'follows', 'poisson', 'distribution', 'link', 'function', 'transforms', 'mean', 'natural', 'location', 'parameter', 'called', 'canonical', 'link', 'example', 'normal', 'distribution', 'natural', 'location', 'parameter', 'mean', 'model', 'canonical', 'link', 'usually', 'make', 'best', 'sense', 'scientific', 'ground', 'choose', 'link', 'function', 'besides', 'canonical', 'link', '\tthe', 'reason', 'restricting', 'distribution', 'response_variable', 'family', 'exponential', 'distribution', 'algorithm', 'compute', 'maximum', 'likelihood', 'parameter_estimate', 'applies', 'entire', 'family', 'choice', 'link', 'function']"
781,proc varclus data=sasuser.backache maxeigen=.70 short; var bending lifting age numberchd height weightend trimester weightbaby weightgain sitting fatigue standing makingbeds ironing walking; title 'Variable Clustering of the Backache Example'; run; Partial Output Variable Clustering of the Backache Example,CD,307,"['proc', 'varclus', 'datasasuserbackache', 'maxeigen70', 'short', 'var', 'bending', 'lifting', 'age', 'numberchd', 'height', 'weightend', 'trimester', 'weightbaby', 'weightgain', 'sitting', 'fatigue', 'standing', 'makingbeds', 'ironing', 'walking', 'title', 'variable', 'clustering', 'backache', 'example', 'run', 'partial', 'output', 'variable', 'clustering', 'backache', 'example']"
782,"In some situations, maximum likelihood estimation can fail, or small cell counts make the resulting maximum likelihood estimates inaccurate. An alternative to the asymptotic methods of maximum likelihood is exact logistic regression, which is available for binary outcomes in PROC LOGISTIC. This method has become an important analytical technique, especially in the pharmaceutical industry, for analyzing small, skewed, or sparse data sets.",CD,441,"['situation', 'maximum', 'likelihood', 'estimation', 'fail', 'small', 'cell', 'count', 'make', 'resulting', 'maximum', 'likelihood', 'estimate', 'inaccurate', 'alternative', 'asymptotic', 'method', 'maximum', 'likelihood', 'exact', 'logistic_regression', 'available', 'binary', 'outcome', 'proc_logistic', 'method', 'ha', 'become', 'important', 'analytical', 'technique', 'especially', 'pharmaceutical', 'industry', 'analyzing', 'small', 'skewed', 'sparse', 'data_set']"
783,"The independent correlation structure (TYPE=IND) forces the off-diagonals to be 0. Therefore, no working correlation structure is estimated in this case. Under this constraint, the coefficients and model-based standard errors (requested by the MODELSE option in the REPEATED statement) are the same as those reported in the LOGISTIC procedure. However, PROC GENMOD, by default, computes robust standard error estimates. These estimates take into account the correlations among the repeated measurements and usually are different from the model-based standard errors assuming independence. The independent correlation structure might be a good choice when you have a large number of subjects with few measurements per subject. The correlation influence is often small enough to have little impact on the regression coefficients, but the robust standard errors will give the correct inferences. This model gives consistent estimates of the parameters and standard errors when the mean model is correctly specified (Davis 2002).",CD,1025,"['independent', 'correlation_structure', 'typeind', 'force', 'offdiagonals', '0', 'therefore', 'working', 'correlation_structure', 'estimated', 'case', 'constraint', 'coefficient', 'modelbased', 'standard_error', 'requested', 'modelse', 'option', 'repeated', 'statement', 'reported', 'logistic', 'procedure', 'however', 'proc', 'genmod', 'default', 'computes', 'robust', 'standard_error', 'estimate', 'estimate', 'take', 'account', 'correlation', 'among', 'repeated', 'measurement', 'usually', 'different', 'modelbased', 'standard_error', 'assuming', 'independence', 'independent', 'correlation_structure', 'might', 'good', 'choice', 'large', 'number', 'subject', 'measurement', 'per', 'subject', 'correlation', 'influence', 'often', 'small', 'enough', 'little', 'impact', 'regression', 'coefficient', 'robust', 'standard_error', 'give', 'correct', 'inference', 'model', 'give', 'consistent', 'estimate', 'parameter', 'standard_error', 'mean', 'model', 'correctly', 'specified', 'davis', '2002']"
784,"The logit transformation is the log of the odds, which is the ratio of the probability of the outcome to the probability of no outcome. To create a linear model, the logit transformation is applied to the probability. Unlike a probability, the logit is unbounded because transforming the probability to odds removes the upper bound, whereas taking the natural logarithm of the odds removes the lower bound. The model (also called the logistic regression model) is now linear because the logit is linear in its parameters. Furthermore, the model gives estimated probabilities that are between 0 and 1.",CD,600,"['logit', 'transformation', 'log', 'odds_ratio', 'probability', 'outcome', 'probability', 'outcome', 'create', 'linear', 'model', 'logit', 'transformation', 'applied', 'probability', 'unlike', 'probability', 'logit', 'unbounded', 'transforming', 'probability', 'odds', 'remove', 'upper', 'bound', 'whereas', 'taking', 'natural', 'logarithm', 'odds', 'remove', 'lower', 'bound', 'model', 'also', 'called', 'logistic_regression_model', 'linear', 'logit', 'linear', 'parameter', 'furthermore', 'model', 'give', 'estimated', 'probability', '0', '1']"
785,"A model using the same data and ignoring the matched pairs was run for illustrative purposes. The standard errors (in parentheses) are all lower for the unconditional parameter estimates compared to the conditional parameter estimates. The reason for the difference is that ignoring the matched pairs and treating the observations as though they are independent produces standard errors that are underestimated. The conditional parameter estimates are also quite different from the unconditional parameter estimates. The reason for this difference is that the conditional parameter estimates are stratum-specific because they are defined at the stratum level. The unconditional parameter estimates are population-averaged, rather than based on individual stratum. 3.5	Nominal Logistic Regression",CD,795,"['model', 'using', 'data', 'ignoring', 'matched', 'pair', 'wa', 'run', 'illustrative', 'purpose', 'standard_error', 'parenthesis', 'lower', 'unconditional', 'parameter_estimate', 'compared', 'conditional', 'parameter_estimate', 'reason', 'difference', 'ignoring', 'matched', 'pair', 'treating', 'observation', 'though', 'independent', 'produce', 'standard_error', 'underestimated', 'conditional', 'parameter_estimate', 'also', 'quite', 'different', 'unconditional', 'parameter_estimate', 'reason', 'difference', 'conditional', 'parameter_estimate', 'stratumspecific', 'defined', 'stratum', 'level', 'unconditional', 'parameter_estimate', 'populationaveraged', 'rather', 'based', 'individual', 'stratum', '35\tnominal', 'logistic_regression']"
786,"PROC FREQ computes three different types of CMH statistics: TYPE 1	is the correlation statistic, which is sensitive only to linear associations. This statistic is appropriate only when both the row and the column variable are ordinally scaled. TYPE 2	is the mean score statistic, which is sensitive to different means among the levels or groups of the nominal predictor. This statistic requires that the column variable be ordinally scaled. TYPE 3	is a generalization of the Pearson chi-square, which is sensitive to general patterns of association. This statistic is always interpretable because it does not require an ordinal scale for either variable.",CD,654,"['proc', 'freq', 'computes', 'three', 'different', 'type', 'cmh', 'statistic', 'type', '1\tis', 'correlation', 'statistic', 'sensitive', 'linear', 'association', 'statistic', 'appropriate', 'row', 'column', 'variable', 'ordinally', 'scaled', 'type', '2\tis', 'mean', 'score', 'statistic', 'sensitive', 'different', 'mean', 'among', 'level', 'group', 'nominal', 'predictor', 'statistic', 'requires', 'column', 'variable', 'ordinally', 'scaled', 'type', '3\tis', 'generalization', 'pearson', 'chisquare', 'sensitive', 'general', 'pattern', 'association', 'statistic', 'always', 'interpretable', 'doe', 'require', 'ordinal', 'scale', 'either', 'variable']"
787,"A key assumption in the logistic regression model is that the logits are linearly related to each predictor variable. For binary predictor variables, this is not a problem because a straight line connects two points. However, for ordinal or continuous predictor variables, this assumption should be examined with the use of logit plots.",CD,336,"['key', 'assumption', 'logistic_regression_model', 'logits', 'linearly', 'related', 'predictor_variable', 'binary', 'predictor_variable', 'problem', 'straight', 'line', 'connects', 'two', 'point', 'however', 'ordinal', 'continuous', 'predictor_variable', 'assumption', 'examined', 'use', 'logit', 'plot']"
788,"For reference cell coding, parameter estimates of the CLASS main effects estimate the difference between the effect of each level and the last level. For example, the effect for the low level would estimate the difference between low and high. You can choose the reference level with the REF= option.",CD,300,"['reference', 'cell', 'coding', 'parameter_estimate', 'class', 'main_effect', 'estimate', 'difference', 'effect', 'level', 'last', 'level', 'example', 'effect', 'low', 'level', 'would', 'estimate', 'difference', 'low', 'high', 'choose', 'reference', 'level', 'ref', 'option']"
789,"The odds ratio indicates that among women with no uterine irritability, those with previous preterm deliveries are 5.5 times more likely to have a low birth weight baby. The exact confidence limits are not needed because of the large sample size. Table 2 of prev_pretrm by low Controlling for uterine_irr=1",CD,306,"['odds_ratio', 'indicates', 'among', 'woman', 'uterine', 'irritability', 'previous', 'preterm', 'delivery', '55', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'exact', 'confidence', 'limit', 'needed', 'large', 'sample_size', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
790,"When you statistically adjust for age, you are comparing the two groups at some common value of age. If there is no interaction, then any common value of age could be used, because it would yield the same difference between the two groups. In the logistic regression model with age and gender as predictor variables, the coefficient for gender would be the log odds ratio expected from a univariate comparison if the two groups had the same distribution of age. Age is a confounder in the relationship between gender and the response because it distorts the effect of gender on the response. The distribution of age is not the same in the two groups, and age is related to the response. For variables with few unique values, a stratified contingency table analysis may help identify confounders. For continuous variables, fitting the logistic model with and without the possible confounder and documenting any changes in the coefficient of the other predictor variable will be necessary.",CD,987,"['statistically', 'adjust', 'age', 'comparing', 'two', 'group', 'common', 'value', 'age', 'interaction', 'common', 'value', 'age', 'could', 'used', 'would', 'yield', 'difference', 'two', 'group', 'logistic_regression_model', 'age', 'gender', 'predictor_variable', 'coefficient', 'gender', 'would', 'log', 'odds_ratio', 'expected', 'univariate', 'comparison', 'two', 'group', 'distribution', 'age', 'age', 'confounder', 'relationship', 'gender', 'response', 'distorts', 'effect', 'gender', 'response', 'distribution', 'age', 'two', 'group', 'age', 'related', 'response_variable', 'unique', 'value', 'stratified', 'contingency', 'table', 'analysis', 'may', 'help', 'identify', 'confounders', 'continuous', 'variable', 'fitting', 'logistic', 'model', 'without', 'possible', 'confounder', 'documenting', 'change', 'coefficient', 'predictor_variable', 'necessary']"
791,"Stepwise selection is similar to forward selection in that it starts with an empty model and incrementally builds a model one variable at a time. However, the method differs from forward selection in that variables already in the model do not necessarily remain. The backward component of the method removes variables from the model that do not meet the significance criteria specified in the SLSTAY= option. The stepwise selection process terminates if no further variable can be added to the model or if the variable just entered into the model is the only variable removed in the subsequent backward elimination. Stepwise selection in PROC LOGISTIC is not an efficient method to select variables. In fact, its performance acutely deteriorates if the full model has over approximately 60 effects (Potts and Patetta 1999). Stepwise selection has some serious shortcomings. Simulation studies (Derksen and Keselman 1992) evaluating variable selection techniques found the following: 1.	The degree of collinearity among the predictor variables affected the frequency with which authentic predictor variables found their way into the final model. 2.	The number of candidate predictor variables affected the number of noise variables that gained entry to the model. 3.	The size of the sample was of little practical importance in determining the number of authentic variables contained in the final model. One recommendation is to use the variable selection methods to create several candidate models, and then use subject-matter knowledge to select the variables that result in the best model within the scientific or business context of the problem. Therefore, you are simply using these methods as a useful tool in the model-building process (Hosmer and Lemeshow 2000).",CD,1769,"['stepwise', 'selection', 'similar', 'forward', 'selection', 'start', 'empty', 'model', 'incrementally', 'build', 'model', 'one', 'variable', 'time', 'however', 'method', 'differs', 'forward', 'selection', 'variable', 'already', 'model', 'necessarily', 'remain', 'backward', 'component', 'method', 'remove', 'variable', 'model', 'meet', 'significance', 'criterion', 'specified', 'slstay', 'option', 'stepwise', 'selection', 'process', 'terminates', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'variable', 'removed', 'subsequent', 'backward', 'elimination', 'stepwise', 'selection', 'proc_logistic', 'efficient', 'method', 'select', 'variable', 'fact', 'performance', 'acutely', 'deteriorates', 'full', 'model', 'ha', 'approximately', '60', 'effect', 'potts', 'patetta', '1999', 'stepwise', 'selection', 'ha', 'serious', 'shortcoming', 'simulation', 'study', 'derksen', 'keselman', '1992', 'evaluating', 'variable', 'selection', 'technique', 'found', 'following', '1\tthe', 'degree', 'collinearity', 'among', 'predictor_variable', 'affected', 'frequency', 'authentic', 'predictor_variable', 'found', 'way', 'final', 'model', '2\tthe', 'number', 'candidate', 'predictor_variable', 'affected', 'number', 'noise', 'variable', 'gained', 'entry', 'model', '3\tthe', 'size', 'sample', 'wa', 'little', 'practical', 'importance', 'determining', 'number', 'authentic', 'variable', 'contained', 'final', 'model', 'one', 'recommendation', 'use', 'variable', 'selection', 'method', 'create', 'several', 'candidate', 'model', 'use', 'subjectmatter', 'knowledge', 'select', 'variable', 'result', 'best', 'model', 'within', 'scientific', 'business', 'context', 'problem', 'therefore', 'simply', 'using', 'method', 'useful', 'tool', 'modelbuilding', 'process', 'hosmer', 'lemeshow', '2000']"
792,"If the responses are positively correlated, which often occurs when repeated measurements are taken on the same subject, then the variance of the time-independent predictor variables (variables whose values do not vary within a cluster or across time, such as gender and race) is underestimated if the data is analyzed as though the observations are independent. In other words, the Type I error rates are inflated for these variables (Dunlop 1994).",CD,449,"['response', 'positively', 'correlated', 'often', 'occurs', 'repeated', 'measurement', 'taken', 'subject', 'variance', 'timeindependent', 'predictor_variable', 'variable', 'whose', 'value', 'vary', 'within', 'cluster', 'across', 'time', 'gender', 'race', 'underestimated', 'data', 'analyzed', 'though', 'observation', 'independent', 'word', 'type', 'error', 'rate', 'inflated', 'variable', 'dunlop', '1994']"
793,"The analyst should be aware that after the predictor variables have been chosen based on subject- matter knowledge, refitting many submodels in terms of an optimum fit to the data distorts the significance levels of conventional statistical tests. Basically, you are using the data to make decisions about the form of the model. After a model is developed, the entire modeling process is routinely forgotten, and statistical quantities such as standard errors, confidence limits, p-values, and R-squared are computed as if the resulting model was entirely prespecified. These inferences are inaccurate, tending to err on the side of overstating the significance of predictors and making predictions with overly optimistic confidence. This problem is very evident when there are many iterative stages in model building. When there are many variables and you use stepwise selection to find a small subset of variables, inferences become less accurate (Chatfield 1995, Raftery 1994, Freedman 1983). One solution to this problem is to split your data. One part could be used for finding the regression model and the other part could be used for inference. However, if your data set is small, the loss of efficiency can be prohibitive (Faraway 1992). Another solution is to use bootstrapping methods to obtain the correct standard errors and p-values. Bootstrapping is a resampling method that tries to approximate the distribution of the parameter estimates to estimate the standard error. Unfortunately, bootstrapping is not part of PROC LOGISTIC and the computer programming is beyond the scope of this course.",CD,1608,"['analyst', 'aware', 'predictor_variable', 'chosen', 'based', 'subject', 'matter', 'knowledge', 'refitting', 'many', 'submodels', 'term', 'optimum', 'fit', 'data', 'distorts', 'significance', 'level', 'conventional', 'statistical', 'test', 'basically', 'using', 'data', 'make', 'decision', 'form', 'model', 'model', 'developed', 'entire', 'modeling', 'process', 'routinely', 'forgotten', 'statistical', 'quantity', 'standard_error', 'confidence', 'limit', 'pvalues', 'rsquared', 'computed', 'resulting', 'model', 'wa', 'entirely', 'prespecified', 'inference', 'inaccurate', 'tending', 'err', 'side', 'overstating', 'significance', 'predictor', 'making', 'prediction', 'overly', 'optimistic', 'confidence', 'problem', 'evident', 'many', 'iterative', 'stage', 'model', 'building', 'many', 'variable', 'use', 'stepwise', 'selection', 'find', 'small', 'subset', 'variable', 'inference', 'become', 'le', 'accurate', 'chatfield', '1995', 'raftery', '1994', 'freedman', '1983', 'one', 'solution', 'problem', 'split', 'data', 'one', 'part', 'could', 'used', 'finding', 'regression_model', 'part', 'could', 'used', 'inference', 'however', 'data_set', 'small', 'loss', 'efficiency', 'prohibitive', 'faraway', '1992', 'another', 'solution', 'use', 'bootstrapping', 'method', 'obtain', 'correct', 'standard_error', 'pvalues', 'bootstrapping', 'resampling', 'method', 'try', 'approximate', 'distribution', 'parameter_estimate', 'estimate', 'standard_error', 'unfortunately', 'bootstrapping', 'part', 'proc_logistic', 'computer', 'programming', 'beyond', 'scope', 'course']"
794,"Because the MODELSE option is used, the Analysis Of GEE Parameter Estimates table shows both the empirical standard error estimates and the model-based standard error estimates. The empirical standard error estimates are robust estimates that do not depend on the correctness of the structure imposed on the working correlation matrix. The model-based standard error estimates are based directly on the assumed correlation structure. The model-based standard errors are better estimates if the assumed model for the correlation structure is correct, but worse if the assumed model is incorrect (Allison 1999). Because the sample size is large and the number of repeated measurements is small, the robust standard errors are generally preferred. Notice that smoker is now not significant and age is even more significant. Because smoker is a time-independent variable, the standard error was underestimated (0.1235) in the initial parameter estimates where the standard errors are based on the assumption of independence. The empirical standard error estimate using GEEs is 0.1782, which makes smoker not significant (p-value of 0.1550). This illustrates how ignoring correlated observations can inflate the Type I error rate for time-independent predictor variables. The standard error for age, a time-dependent variable, is estimated at 0.0541 in the initial parameter estimates. The empirical standard error is 0.0442, which lowers the p-value of age (0.036 to 0.0094). This illustrates how ignoring correlated observations can inflate the Type II error rate for time-dependent predictor variables. Score Statistics For Type 3 GEE Analysis",CD,1641,"['modelse', 'option', 'used', 'analysis', 'gee', 'parameter_estimate', 'table', 'show', 'empirical', 'standard_error', 'estimate', 'modelbased', 'standard_error', 'estimate', 'empirical', 'standard_error', 'estimate', 'robust', 'estimate', 'depend', 'correctness', 'structure', 'imposed', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'estimate', 'based', 'directly', 'assumed', 'correlation_structure', 'modelbased', 'standard_error', 'better', 'estimate', 'assumed', 'model', 'correlation_structure', 'correct', 'worse', 'assumed', 'model', 'incorrect', 'allison', '1999', 'sample_size', 'large', 'number', 'repeated', 'measurement', 'small', 'robust', 'standard_error', 'generally', 'preferred', 'notice', 'smoker', 'significant', 'age', 'even', 'significant', 'smoker', 'timeindependent', 'variable', 'standard_error', 'wa', 'underestimated', '01235', 'initial', 'parameter_estimate', 'standard_error', 'based', 'assumption', 'independence', 'empirical', 'standard_error', 'estimate', 'using', 'gee', '01782', 'make', 'smoker', 'significant', 'pvalue', '01550', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'error', 'rate', 'timeindependent', 'predictor_variable', 'standard_error', 'age', 'timedependent', 'variable', 'estimated', '00541', 'initial', 'parameter_estimate', 'empirical', 'standard_error', '00442', 'lower', 'pvalue', 'age', '0036', '00094', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'ii', 'error', 'rate', 'timedependent', 'predictor_variable', 'score', 'statistic', 'type', '3', 'gee', 'analysis']"
795,"Generalized estimating equations (GEE) were developed to accommodate correlated observations within subjects. An estimating equation is simply the equation you solve to calculate the parameter estimates. The extra term generalized distinguishes the GEE as the estimating equations that accommodate the correlation structure of the repeated measurements. GEE are marginal models where the marginal expectation (average response for observations sharing the same covariates) is modeled as a function of the predictor variables. The parameters in marginal models can be interpreted as the influence of the covariates on the population-averaged response. These models are appropriate when the scientific objectives are to characterize and contrast populations of subjects. A useful feature of the GEE is that the parameter estimates along with the covariance matrix are consistently estimated (as the sample size increases, the estimates converge to the true values) even if the correlation structure within subject is not known. Therefore, the variances along with the inferences regarding the parameter estimates are asymptotically correct (Zeger and Liang 1986). It is also not necessary that the observations for all subjects have the same correlation structure.",CD,1262,"['generalized', 'estimating', 'equation', 'gee', 'developed', 'accommodate', 'correlated', 'observation', 'within', 'subject', 'estimating', 'equation', 'simply', 'equation', 'solve', 'calculate', 'parameter_estimate', 'extra', 'term', 'generalized', 'distinguishes', 'gee', 'estimating', 'equation', 'accommodate', 'correlation_structure', 'repeated', 'measurement', 'gee', 'marginal', 'model', 'marginal', 'expectation', 'average', 'response', 'observation', 'sharing', 'covariates', 'modeled', 'function', 'predictor_variable', 'parameter', 'marginal', 'model', 'interpreted', 'influence', 'covariates', 'populationaveraged', 'response', 'model', 'appropriate', 'scientific', 'objective', 'characterize', 'contrast', 'population', 'subject', 'useful', 'feature', 'gee', 'parameter_estimate', 'along', 'covariance', 'matrix', 'consistently', 'estimated', 'sample_size', 'increase', 'estimate', 'converge', 'true', 'value', 'even', 'correlation_structure', 'within', 'subject', 'known', 'therefore', 'variance', 'along', 'inference', 'regarding', 'parameter_estimate', 'asymptotically', 'correct', 'zeger', 'liang', '1986', 'also', 'necessary', 'observation', 'subject', 'correlation_structure']"
796,"Example:	Fit an exact logistic regression model to the Cephalexin data set. Request that the individual parameters and the odds ratios be estimated. Use the events/trials syntax and use reference cell coding for each predictor variable and specify No for the reference cell for cephalexin, 50+ for age, and less than a week for length_of_stay. Also create a data set with the exact conditional distributions. /* c3demo18a */ proc logistic data=sasuser.cephalexin; class cephalexin (param=ref ref='No') age (param=ref ref='50+') length_of_stay (param=ref ref='less than a week'); model cases/patients = cephalexin age length_of_stay; exact cephalexin age length_of_stay / estimate=both outdist=dist; title 'Cephalexin in Hospital Model'; run; EXACT statement options: ESTIMATE=	estimates the individual parameters (conditional on all other parameters) for the effects specified in the EXACT statement. For each parameter, a point estimate, a confidence interval, and a p-value for a two-sided test that the parameter is zero are displayed. The keyword BOTH specifies that the parameters and odds ratios be displayed. OUTDIST=	creates the SAS data set containing the exact conditional distributions. The data set contains the possible sufficient statistics for the parameters of the effects specified in the EXACT statement, the counts, the probability of occurrence, and the score value for each sufficient statistic. Cephalexin in Hospital Model",CD,1445,"['example\tfit', 'exact', 'logistic_regression_model', 'cephalexin', 'data_set', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'use', 'eventstrials', 'syntax', 'use', 'reference', 'cell', 'coding', 'predictor_variable', 'specify', 'reference', 'cell', 'cephalexin', '50', 'age', 'le', 'week', 'lengthofstay', 'also', 'create', 'data_set', 'exact', 'conditional', 'distribution', '', 'c3demo18a', '', 'proc_logistic', 'datasasusercephalexin', 'class', 'cephalexin', 'paramref', 'refno', 'age', 'paramref', 'ref50', 'lengthofstay', 'paramref', 'refless', 'week', 'model', 'casespatients', '', 'cephalexin', 'age', 'lengthofstay', 'exact', 'cephalexin', 'age', 'lengthofstay', '', 'estimateboth', 'outdistdist', 'title', 'cephalexin', 'hospital', 'model', 'run', 'exact', 'statement', 'option', 'estimate\testimates', 'individual', 'parameter', 'conditional', 'parameter', 'effect', 'specified', 'exact', 'statement', 'parameter', 'point', 'estimate', 'confidence', 'interval', 'pvalue', 'twosided', 'test', 'parameter', 'zero', 'displayed', 'keyword', 'specifies', 'parameter', 'odds_ratio', 'displayed', 'outdist\tcreates', 'sa', 'data_set', 'containing', 'exact', 'conditional', 'distribution', 'data_set', 'contains', 'possible', 'sufficient', 'statistic', 'parameter', 'effect', 'specified', 'exact', 'statement', 'count', 'probability', 'occurrence', 'score', 'value', 'sufficient', 'statistic', 'cephalexin', 'hospital', 'model']"
797,"Example:	To assess the significance of the interaction mother_age*phy_visit, run a model with the interaction and one with no interaction. Use ODS to calculate the likelihood ratio test statistics between the main effects model and the interaction model. Use the GLOBALTESTS output object, which contains the likelihood ratio chi-square statistic. /* c1demo06a */ ods listing close;",CD,382,"['example\tto', 'ass', 'significance', 'interaction', 'motheragephyvisit', 'run', 'model', 'interaction', 'one', 'interaction', 'use', 'od', 'calculate', 'likelihood', 'ratio', 'test', 'statistic', 'main_effect', 'model', 'interaction', 'model', 'use', 'globaltests', 'output', 'object', 'contains', 'likelihood', 'ratio', 'chisquare', 'statistic', '', 'c1demo06a', '', 'od', 'listing', 'close']"
798,"Because there are 16 predictor variables, it would be wise to reduce the number of redundant variables before building a model in PROC LOGISTIC. One approach to variable reduction is variable clustering. Variable clustering finds groups of variables that are as correlated as possible among themselves and as uncorrelated as possible with variables in other clusters. A common strategy is to pick one variable from each cluster based on subject-matter knowledge.",CD,462,"['16', 'predictor_variable', 'would', 'wise', 'reduce', 'number', 'redundant', 'variable', 'building', 'model', 'proc_logistic', 'one', 'approach', 'variable', 'reduction', 'variable', 'clustering', 'variable', 'clustering', 'find', 'group', 'variable', 'correlated', 'possible', 'among', 'uncorrelated', 'possible', 'variable', 'cluster', 'common', 'strategy', 'pick', 'one', 'variable', 'cluster', 'based', 'subjectmatter', 'knowledge']"
799,"In some estimation problems, you need to be able to summarize the information in the sample or find some function in the sample that tells you just as much about the parameter of interest as the sample itself. This function is sufficient for estimation purposes and therefore is called a sufficient statistic. In other words, a sufficient statistic condenses the data in such a way that no information is lost about the parameter. When a statistic loses no information, it contains all the information about the parameter that is contained in the sample. There can be more than one set of sufficient statistics. A minimal sufficient statistic is the most condensed summary of the data.",CD,685,"['estimation', 'problem', 'need', 'able', 'summarize', 'information', 'sample', 'find', 'function', 'sample', 'tell', 'much', 'parameter', 'interest', 'sample', 'function', 'sufficient', 'estimation', 'purpose', 'therefore', 'called', 'sufficient', 'statistic', 'word', 'sufficient', 'statistic', 'condenses', 'data', 'way', 'information', 'lost', 'parameter', 'statistic', 'loses', 'information', 'contains', 'information', 'parameter', 'contained', 'sample', 'one', 'set', 'sufficient', 'statistic', 'minimal', 'sufficient', 'statistic', 'condensed', 'summary', 'data']"
800,"Example:	Fit a conditional logistic regression model to the sasuser.matched data set. Specify low as the response variable and use all of the predictor variables. Use the EVENT= option to model the probability of low birth weight. Use the UNITS statement to obtain an odds ratio estimate for a 10-unit change in Mother_wt. Also specify socio as a CLASS variable, reference cell coding, 3 as the reference level, standardized estimates, and Wald confidence intervals for the odds ratios. /* c3demo20a */ proc logistic data=sasuser.matched; strata Pair; class Socio (param=ref ref='3'); model Low(event='1') = Mother_age Mother_wt Socio Smoke Prev_pretrm Uterine_irr Hist_hyp / stb clodds=wald; units Mother_wt=10; title 'Conditional Model for Matched Case-Control Study'; run; Selected STRATA statement options: MISSING	treats missing values as valid STRATA variable values. NOSUMMARY	suppresses the display of the ?Strata Summary? table. INFO	displays the ?Strata Information? table, which includes the stratum number, levels of the STRATA variables that define the stratum, the number of events, the number of nonevents, and the total frequency for each stratum. The STRATA statement names the variables that define strata or matched sets to use in a conditional logistic regression model. Observations having the same variable levels are in the same matched set. At least one variable must be specified to invoke the stratified analysis, and the usual unconditional asymptotic analysis is not performed. STRATA variables can also be specified in the MODEL statement as classification or continuous variables. However, the effects are nondegenerate only when crossed with a non-stratification variable. The SCORE and WEIGHT statements are not available with a STRATA statement. The following MODEL options are also not supported with a STRATA statement: CLPARM=PL, CLODDS=PL, CTABLE, LACKFIT, LINK=, NOFIT, OUTMODEL=, OUTROC=, and SCALE=. Conditional Model for Matched Case-Control Study",CD,1988,"['example\tfit', 'conditional', 'logistic_regression_model', 'sasusermatched', 'data_set', 'specify', 'low', 'response_variable', 'use', 'predictor_variable', 'use', 'event', 'option', 'model', 'probability', 'low', 'birth', 'weight', 'use', 'unit', 'statement', 'obtain', 'odds_ratio', 'estimate', '10unit', 'change', 'motherwt', 'also', 'specify', 'socio', 'class', 'variable', 'reference', 'cell', 'coding', '3', 'reference', 'level', 'standardized', 'estimate', 'wald', 'confidence', 'interval', 'odds_ratio', '', 'c3demo20a', '', 'proc_logistic', 'datasasusermatched', 'stratum', 'pair', 'class', 'socio', 'paramref', 'ref3', 'model', 'lowevent1', '', 'motherage', 'motherwt', 'socio', 'smoke', 'prevpretrm', 'uterineirr', 'histhyp', '', 'stb', 'cloddswald', 'unit', 'motherwt10', 'title', 'conditional', 'model', 'matched', 'casecontrol', 'study', 'run', 'selected', 'stratum', 'statement', 'option', 'missing\ttreats', 'missing', 'value', 'valid', 'stratum', 'variable', 'value', 'nosummary\tsuppresses', 'display', 'stratum', 'summary', 'table', 'info\tdisplays', 'stratum', 'information', 'table', 'includes', 'stratum', 'number', 'level', 'stratum', 'variable', 'define', 'stratum', 'number', 'event', 'number', 'nonevent', 'total', 'frequency', 'stratum', 'stratum', 'statement', 'name', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'conditional', 'logistic_regression_model', 'observation', 'variable', 'level', 'matched', 'set', 'least', 'one', 'variable', 'must', 'specified', 'invoke', 'stratified', 'analysis', 'usual', 'unconditional', 'asymptotic', 'analysis', 'performed', 'stratum', 'variable', 'also', 'specified', 'model_statement', 'classification', 'continuous', 'variable', 'however', 'effect', 'nondegenerate', 'crossed', 'nonstratification', 'variable', 'score', 'weight', 'statement', 'available', 'stratum', 'statement', 'following', 'model', 'option', 'also', 'supported', 'stratum', 'statement', 'clparmpl', 'cloddspl', 'ctable', 'lackfit', 'link', 'nofit', 'outmodel', 'outroc', 'scale', 'conditional', 'model', 'matched', 'casecontrol', 'study']"
801,"One solution to the incidental parameters problem is to use conditional maximum likelihood estimation. This approach eliminates the stratum-specific intercepts from the likelihood by conditioning on their sufficient statistics (just like the approach in exact logistic regression). Recall that a sufficient statistic for the intercept is simply the sum of the events. By deriving a conditional likelihood that is conditional on the sufficient statistics of the stratum-specific intercepts, you are factoring out the intercepts from the likelihood equation. In other words, you are taking the stratification into account by conditioning out (and not estimating) the stratum-specific intercepts. You are essentially modeling a meaningful conditional probability, and the model has a reduced number of parameters that can be estimated without bias. A conditional likelihood is just like an ordinary likelihood. Conditional maximum likelihood estimates are those values that maximize the conditional likelihood function. The estimates are consistent and asymptotically normal. The optimization techniques used to obtain the maximum likelihood estimates are Newton-Raphson with ridging when the number of parameters is less than 40, quasi-Newton when the number of parameters is 40-399, and conjugate gradient when the number of parameters is 400 or greater. Sometimes the log likelihood converges but the estimates diverge. This condition is flagged by having inordinately large standard errors for some of your parameter estimates. It may be possible to circumvent this problem by standardizing the predictor variables before fitting the model.",CD,1641,"['one', 'solution', 'incidental', 'parameter', 'problem', 'use', 'conditional', 'maximum', 'likelihood', 'estimation', 'approach', 'eliminates', 'stratumspecific', 'intercept', 'likelihood', 'conditioning', 'sufficient', 'statistic', 'like', 'approach', 'exact', 'logistic_regression', 'recall', 'sufficient', 'statistic', 'intercept', 'simply', 'sum', 'event', 'deriving', 'conditional', 'likelihood', 'conditional', 'sufficient', 'statistic', 'stratumspecific', 'intercept', 'factoring', 'intercept', 'likelihood', 'equation', 'word', 'taking', 'stratification', 'account', 'conditioning', 'estimating', 'stratumspecific', 'intercept', 'essentially', 'modeling', 'meaningful', 'conditional', 'probability', 'model', 'ha', 'reduced', 'number', 'parameter', 'estimated', 'without', 'bias', 'conditional', 'likelihood', 'like', 'ordinary', 'likelihood', 'conditional', 'maximum', 'likelihood', 'estimate', 'value', 'maximize', 'conditional', 'likelihood', 'function', 'estimate', 'consistent', 'asymptotically', 'normal', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'estimate', 'newtonraphson', 'ridging', 'number', 'parameter', 'le', '40', 'quasinewton', 'number', 'parameter', '40399', 'conjugate', 'gradient', 'number', 'parameter', '400', 'greater', 'sometimes', 'log', 'likelihood', 'converges', 'estimate', 'diverge', 'condition', 'flagged', 'inordinately', 'large', 'standard_error', 'parameter_estimate', 'may', 'possible', 'circumvent', 'problem', 'standardizing', 'predictor_variable', 'fitting', 'model']"
802,"One way to identify possible contributing factors to low birth weight is to build a linear probability model where the outcome is the probability of having a low birth weight baby. Such a model implies that the probability of low birth weight is a linear function of the predictor variables. The regression coefficients would therefore have a straightforward interpretation in this model. For example, you can estimate the change in the probability of low birth weight, given a one-unit change in alcohol. Unfortunately, the linear probability model has some serious shortcomings. The predicted values from a linear model can assume, theoretically, any value. However, probabilities are by definition bounded between 0 and 1. Thus, the model can only be valid over a finite range of predictor variable values. A more appropriate model would somehow constrain the predicted probabilities to be between 0 and 1. Another shortcoming is that the observed relationship between the probability of an outcome and the predictor variables is usually nonlinear rather than linear. For example, a one-unit change in the predictor variable may have less impact when the probability is near 0 or 1 than when the probability is near .50. In fact, the relationship often resembles an S-shaped curve rather than a linear function (Hosmer and Lemeshow 2000).",CD,1341,"['one', 'way', 'identify', 'possible', 'contributing', 'factor', 'low', 'birth', 'weight', 'build', 'linear', 'probability', 'model', 'outcome', 'probability', 'low', 'birth', 'weight', 'baby', 'model', 'implies', 'probability', 'low', 'birth', 'weight', 'linear', 'function', 'predictor_variable', 'regression', 'coefficient', 'would', 'therefore', 'straightforward', 'interpretation', 'model', 'example', 'estimate', 'change', 'probability', 'low', 'birth', 'weight', 'given', 'oneunit', 'change', 'alcohol', 'unfortunately', 'linear', 'probability', 'model', 'ha', 'serious', 'shortcoming', 'predicted', 'value', 'linear', 'model', 'assume', 'theoretically', 'value', 'however', 'probability', 'definition', 'bounded', '0', '1', 'thus', 'model', 'valid', 'finite', 'range', 'predictor_variable', 'value', 'appropriate', 'model', 'would', 'somehow', 'constrain', 'predicted', 'probability', '0', '1', 'another', 'shortcoming', 'observed', 'relationship', 'probability', 'outcome', 'predictor_variable', 'usually', 'nonlinear', 'rather', 'linear', 'example', 'oneunit', 'change', 'predictor_variable', 'may', 'le', 'impact', 'probability', 'near', '0', '1', 'probability', 'near', '50', 'fact', 'relationship', 'often', 'resembles', 'sshaped', 'curve', 'rather', 'linear', 'function', 'hosmer', 'lemeshow', '2000']"
803,"Optimization Technique Newton-Raphson ridge Because the number of parameters is less than 40, the Newton-Raphson with ridging optimization technique is used to obtain the maximum likelihood parameter estimates. Number of Observations Read 112 Number of Observations Used 112",CD,274,"['optimization', 'technique', 'newtonraphson', 'ridge', 'number', 'parameter', 'le', '40', 'newtonraphson', 'ridging', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'parameter_estimate', 'number', 'observation', 'read', '112', 'number', 'observation', 'used', '112']"
804,"Besides the observations with the large change in the Pearson chi-square statistic, the observations with large circles near the bottom of the cup defined by the quadratic curves should also be examined. These are observations that influenced the parameter estimates to a relatively large extent but are not poorly fitted observations (Hosmer and Lemeshow 2000). Example:	Print the observations with possible outlying covariate patterns. Examine each observation to determine what made the observation influential or an outlier. Establish a cutoff of the 95th percentile for the distribution of DIFDEV, DIFCHISQ, H, and C. ?	Because there are no published statistical cutoffs for the logistic regression diagnostic statistics, these suggested cutoffs are only used to detect possible outliers and influential observations. A more thorough approach would be to examine all of the diagnostic plots to identify all of the unusual observations. /* c2demo11d */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difdev=difdev difchisq=difchisq h=h c=c dfbetas=dfint dfage dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; run; For the DFBETAS keyword, a list of variable names is specified to correspond to the parameter estimates in the model. The first variable contains the standardized differences in the intercept estimate, the second variable contains the standardized differences in the parameter estimate for the first predictor variable in the MODEL statement, and so on. /* c2demo11e */ proc rank data=predict groups=20 out=bins; var difdev difchisq h c; ranks difdevbin difchisqbin hbin cbin; run; PROC RANK is used to bin the observations into groups. The variable difdevbin is the group identification number for difdev that ranges from 0 (the first group) to 19 (the last group). The variables difchisqbin, hbin, and cbin are the group identification numbers for difchisq, h, and c respectively. /* c2demo11f */ proc print data=bins; where difdevbin=19 or difchisqbin=19 or hbin=19 or cbin=19; var low mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio pred difdev difchisq h c dfint dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; title 'Observations with Possible Outlying Covariate ' 'Patterns'; run;",CD,2400,"['besides', 'observation', 'large', 'change', 'pearson', 'chisquare', 'statistic', 'observation', 'large', 'circle', 'near', 'bottom', 'cup', 'defined', 'quadratic', 'curve', 'also', 'examined', 'observation', 'influenced', 'parameter_estimate', 'relatively', 'large', 'extent', 'poorly', 'fitted', 'observation', 'hosmer', 'lemeshow', '2000', 'example\tprint', 'observation', 'possible', 'outlying', 'covariate', 'pattern', 'examine', 'observation', 'determine', 'made', 'observation', 'influential', 'outlier', 'establish', 'cutoff', '95th', 'percentile', 'distribution', 'difdev', 'difchisq', 'h', 'c', '\tbecause', 'published', 'statistical', 'cutoff', 'logistic_regression', 'diagnostic', 'statistic', 'suggested', 'cutoff', 'used', 'detect', 'possible', 'outlier', 'influential', 'observation', 'thorough', 'approach', 'would', 'examine', 'diagnostic', 'plot', 'identify', 'unusual', 'observation', '', 'c2demo11d', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difdevdifdev', 'difchisqdifchisq', 'hh', 'cc', 'dfbetasdfint', 'dfage', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'run', 'dfbetas', 'keyword', 'list', 'variable', 'name', 'specified', 'correspond', 'parameter_estimate', 'model', 'first', 'variable', 'contains', 'standardized', 'difference', 'intercept', 'estimate', 'second', 'variable', 'contains', 'standardized', 'difference', 'parameter_estimate', 'first', 'predictor_variable', 'model_statement', '', 'c2demo11e', '', 'proc', 'rank', 'datapredict', 'groups20', 'outbins', 'var', 'difdev', 'difchisq', 'h', 'c', 'rank', 'difdevbin', 'difchisqbin', 'hbin', 'cbin', 'run', 'proc', 'rank', 'used', 'bin', 'observation', 'group', 'variable', 'difdevbin', 'group', 'identification', 'number', 'difdev', 'range', '0', 'first', 'group', '19', 'last', 'group', 'variable', 'difchisqbin', 'hbin', 'cbin', 'group', 'identification', 'number', 'difchisq', 'h', 'c', 'respectively', '', 'c2demo11f', '', 'proc', 'print', 'databins', 'difdevbin19', 'difchisqbin19', 'hbin19', 'cbin19', 'var', 'low', 'motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'pred', 'difdev', 'difchisq', 'h', 'c', 'dfint', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'title', 'observation', 'possible', 'outlying', 'covariate', '', 'pattern', 'run']"
805,"Optimization Technique Newton-Raphson ridge Because the number of parameters is less than 40, the Newton-Raphson with ridging optimization technique is used to obtain the maximum likelihood parameter estimates. Number of Observations Read 112 Number of Observations Used 112",CD,274,"['optimization', 'technique', 'newtonraphson', 'ridge', 'number', 'parameter', 'le', '40', 'newtonraphson', 'ridging', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'parameter_estimate', 'number', 'observation', 'read', '112', 'number', 'observation', 'used', '112']"
806,"PROC GENMOD can be used to fit GEE models to clustered data. The layout of the data corresponds to the number of observations being equal to the number of measurements taken on all the subjects. The variance-covariance matrix is a block diagonal matrix in which the observations within each block are assumed to be correlated and the observations outside of the blocks are assumed to be independent. Selected GENMOD procedure statements: CLASS	specifies the classification variables to be used in the analysis. If the CLASS statement is used, it must appear before the MODEL statement. MODEL	specifies the response variable and the predictor variables. REPEATED	invokes the GEE method, specifies the correlation structure, and controls the displayed output from the longitudinal model. ESTIMATE	provides a means for obtaining a test for a specified hypothesis concerning the model parameters. It can also be used to produce the odds ratio estimate along with the 95% confidence limits. OUTPUT	creates a new SAS data set that contains all the variables in the input data set and, optionally, the estimated linear predictors and their standard error estimates, the weights for the Hessian matrix, predicted values of the mean, confidence limits for predicted values, and residuals. Selected CLASS statement options: PARAM=	specifies the parameterization method for the classification variable or variables. Design matrix columns are created from CLASS variables according to the following coding schemes: 	EFFECT	species effect coding. GLM	specifies less than full rank, reference-cell coding. This coding is the default. ORDINAL	specifies the cumulative parameterization for an ordinal CLASS variable. 	POLY	specifies polynomial coding. 	REF	specifies reference cell coding. 	ORTHEFFECT	orthogonalizes PARAM=EFFECT. 	ORTHORDINAL	orthogonalizes PARAM=ORDINAL. 	ORTHPOLY	orthogonalizes PARAM=POLY. 	ORTHREF	orthogonalizes PARAM=REF. REF=	specifies the reference cell for PARAM=EFFECT, PARAM=REF, and their orthogonalizations.",CD,2022,"['proc', 'genmod', 'used', 'fit', 'gee', 'model', 'clustered', 'data', 'layout', 'data', 'corresponds', 'number', 'observation', 'equal', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'selected', 'genmod', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'used', 'must', 'appear', 'model_statement', 'model\tspecifies', 'response_variable', 'predictor_variable', 'repeated\tinvokes', 'gee', 'method', 'specifies', 'correlation_structure', 'control', 'displayed', 'output', 'longitudinal', 'model', 'estimate\tprovides', 'mean', 'obtaining', 'test', 'specified', 'hypothesis', 'concerning', 'model', 'parameter', 'also', 'used', 'produce', 'odds_ratio', 'estimate', 'along', '95', 'confidence', 'limit', 'output\tcreates', 'new', 'sa', 'data_set', 'contains', 'variable', 'input', 'data_set', 'optionally', 'estimated', 'linear', 'predictor', 'standard_error', 'estimate', 'weight', 'hessian', 'matrix', 'predicted', 'value', 'mean', 'confidence', 'limit', 'predicted', 'value', 'residual', 'selected', 'class', 'statement', 'option', 'param\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'design', 'matrix', 'column', 'created', 'class', 'variable', 'according', 'following', 'coding', 'scheme', '\teffect\tspecies', 'effect', 'coding', 'glm\tspecifies', 'le', 'full', 'rank', 'referencecell', 'coding', 'coding', 'default', 'ordinal\tspecifies', 'cumulative', 'parameterization', 'ordinal', 'class', 'variable', '\tpoly\tspecifies', 'polynomial', 'coding', '\tref\tspecifies', 'reference', 'cell', 'coding', '\tortheffect\torthogonalizes', 'parameffect', '\torthordinal\torthogonalizes', 'paramordinal', '\torthpoly\torthogonalizes', 'parampoly', '\torthref\torthogonalizes', 'paramref', 'ref\tspecifies', 'reference', 'cell', 'parameffect', 'paramref', 'orthogonalizations']"
807,"Besides the observations with the large change in the Pearson chi-square statistic, the observations with large circles near the bottom of the cup defined by the quadratic curves should also be examined. These are observations that influenced the parameter estimates to a relatively large extent but are not poorly fitted observations (Hosmer and Lemeshow 2000). Example:	Print the observations with possible outlying covariate patterns. Examine each observation to determine what made the observation influential or an outlier. Establish a cutoff of the 95th percentile for the distribution of DIFDEV, DIFCHISQ, H, and C. ?	Because there are no published statistical cutoffs for the logistic regression diagnostic statistics, these suggested cutoffs are only used to detect possible outliers and influential observations. A more thorough approach would be to examine all of the diagnostic plots to identify all of the unusual observations. /* c2demo11d */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difdev=difdev difchisq=difchisq h=h c=c dfbetas=dfint dfage dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; run; For the DFBETAS keyword, a list of variable names is specified to correspond to the parameter estimates in the model. The first variable contains the standardized differences in the intercept estimate, the second variable contains the standardized differences in the parameter estimate for the first predictor variable in the MODEL statement, and so on. /* c2demo11e */ proc rank data=predict groups=20 out=bins; var difdev difchisq h c; ranks difdevbin difchisqbin hbin cbin; run; PROC RANK is used to bin the observations into groups. The variable difdevbin is the group identification number for difdev that ranges from 0 (the first group) to 19 (the last group). The variables difchisqbin, hbin, and cbin are the group identification numbers for difchisq, h, and c respectively. /* c2demo11f */ proc print data=bins; where difdevbin=19 or difchisqbin=19 or hbin=19 or cbin=19; var low mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio pred difdev difchisq h c dfint dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; title 'Observations with Possible Outlying Covariate ' 'Patterns'; run;",CD,2400,"['besides', 'observation', 'large', 'change', 'pearson', 'chisquare', 'statistic', 'observation', 'large', 'circle', 'near', 'bottom', 'cup', 'defined', 'quadratic', 'curve', 'also', 'examined', 'observation', 'influenced', 'parameter_estimate', 'relatively', 'large', 'extent', 'poorly', 'fitted', 'observation', 'hosmer', 'lemeshow', '2000', 'example\tprint', 'observation', 'possible', 'outlying', 'covariate', 'pattern', 'examine', 'observation', 'determine', 'made', 'observation', 'influential', 'outlier', 'establish', 'cutoff', '95th', 'percentile', 'distribution', 'difdev', 'difchisq', 'h', 'c', '\tbecause', 'published', 'statistical', 'cutoff', 'logistic_regression', 'diagnostic', 'statistic', 'suggested', 'cutoff', 'used', 'detect', 'possible', 'outlier', 'influential', 'observation', 'thorough', 'approach', 'would', 'examine', 'diagnostic', 'plot', 'identify', 'unusual', 'observation', '', 'c2demo11d', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difdevdifdev', 'difchisqdifchisq', 'hh', 'cc', 'dfbetasdfint', 'dfage', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'run', 'dfbetas', 'keyword', 'list', 'variable', 'name', 'specified', 'correspond', 'parameter_estimate', 'model', 'first', 'variable', 'contains', 'standardized', 'difference', 'intercept', 'estimate', 'second', 'variable', 'contains', 'standardized', 'difference', 'parameter_estimate', 'first', 'predictor_variable', 'model_statement', '', 'c2demo11e', '', 'proc', 'rank', 'datapredict', 'groups20', 'outbins', 'var', 'difdev', 'difchisq', 'h', 'c', 'rank', 'difdevbin', 'difchisqbin', 'hbin', 'cbin', 'run', 'proc', 'rank', 'used', 'bin', 'observation', 'group', 'variable', 'difdevbin', 'group', 'identification', 'number', 'difdev', 'range', '0', 'first', 'group', '19', 'last', 'group', 'variable', 'difchisqbin', 'hbin', 'cbin', 'group', 'identification', 'number', 'difchisq', 'h', 'c', 'respectively', '', 'c2demo11f', '', 'proc', 'print', 'databins', 'difdevbin19', 'difchisqbin19', 'hbin19', 'cbin19', 'var', 'low', 'motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'pred', 'difdev', 'difchisq', 'h', 'c', 'dfint', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'title', 'observation', 'possible', 'outlying', 'covariate', '', 'pattern', 'run']"
808,"However, when the model is fit with the main effects and the interaction term, the parameter estimates for the stratification variable and the interaction term along with their associated standard errors increase dramatically. The reason for the model instability is the presence of the 0 cell count when you stratify on the predictor variable. This problem should be detected during the stratified analysis of the predictor variables.",CD,435,"['however', 'model', 'fit', 'main_effect', 'interaction', 'term', 'parameter_estimate', 'stratification', 'variable', 'interaction', 'term', 'along', 'associated', 'standard_error', 'increase', 'dramatically', 'reason', 'model', 'instability', 'presence', '0', 'cell', 'count', 'stratify', 'predictor_variable', 'problem', 'detected', 'stratified', 'analysis', 'predictor_variable']"
809,"The process of fitting a GEE model can be summarized in a series of steps. First, a regression model is fitted that assumes independence and the Pearson standardized residuals are computed. These residuals are then used to estimate the parameters of the correlation matrix, which characterizes the correlation of the observations within subject. The correlation parameters are then incorporated into the GEE estimating equations, which generates new values for the regression coefficients and new Pearson residuals. These residuals are then used to re-estimate the correlation parameters. The cyclical process continues until the parameter estimates stabilize and model convergence is achieved. !	For more information, see the SAS online documentation.",CD,752,"['process', 'fitting', 'gee', 'model', 'summarized', 'series', 'step', 'first', 'regression_model', 'fitted', 'assumes', 'independence', 'pearson', 'standardized', 'residual', 'computed', 'residual', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'characterizes', 'correlation', 'observation', 'within', 'subject', 'correlation', 'parameter', 'incorporated', 'gee', 'estimating', 'equation', 'generates', 'new', 'value', 'regression', 'coefficient', 'new', 'pearson', 'residual', 'residual', 'used', 'reestimate', 'correlation', 'parameter', 'cyclical', 'process', 'continues', 'parameter_estimate', 'stabilize', 'model', 'convergence', 'achieved', '\tfor', 'information', 'see', 'sa', 'online', 'documentation']"
810,The chi-square test of association indicates that there is strong evidence of an association between previous preterm deliveries and low birth weight for women with no uterine irritability. Statistics for Table 1 of prev_pretrm by low Controlling for uterine_irr=0,CD,264,"['chisquare', 'test', 'association', 'indicates', 'strong', 'evidence', 'association', 'previous', 'preterm', 'delivery', 'low', 'birth', 'weight', 'woman', 'uterine', 'irritability', 'statistic', 'table', '1', 'prevpretrm', 'low', 'controlling', 'uterineirr0']"
811,"The likelihood ratio test is not significant, which means adding an extra degree of freedom to socio did not improve the model. Unless treating socio as a classification variable has subject- matter importance, the model with a continuous socio would be the model of choice.",CD,274,"['likelihood', 'ratio', 'test', 'significant', 'mean', 'adding', 'extra', 'degree', 'freedom', 'socio', 'improve', 'model', 'unless', 'treating', 'socio', 'classification', 'variable', 'ha', 'subject', 'matter', 'importance', 'model', 'continuous', 'socio', 'would', 'model', 'choice']"
812,SUBJECT=	identifies subjects in the input data set. This is a required option and the variables used in defining the subjects must be listed in the CLASS statement. The input data set does not need to be sorted by subject. TYPE=	specifies the structure of the working correlation matrix used to model the correlation of responses from subjects. The default working correlation type is the independent correlation structure.,CD,423,"['subject\tidentifies', 'subject', 'input', 'data_set', 'required', 'option', 'variable', 'used', 'defining', 'subject', 'must', 'listed', 'class', 'statement', 'input', 'data_set', 'doe', 'need', 'sorted', 'subject', 'type\tspecifies', 'structure', 'working', 'correlation', 'matrix', 'used', 'model', 'correlation', 'response', 'subject', 'default', 'working', 'correlation', 'type', 'independent', 'correlation_structure']"
813,The forward selection procedure starts with no variables in the model. At each step the variable with the largest adjusted chi-square statistic is entered into the model if its p-value is lower than the specified significance level. The residual chi-square tests the significance of the variables not in the model. Step 1. Effect prev_pretrm entered: Model Convergence Status,CD,375,"['forward', 'selection', 'procedure', 'start', 'variable', 'model', 'step', 'variable', 'largest', 'adjusted', 'chisquare', 'statistic', 'entered', 'model', 'pvalue', 'lower', 'specified', 'significance', 'level', 'residual', 'chisquare', 'test', 'significance', 'variable', 'model', 'step', '1', 'effect', 'prevpretrm', 'entered', 'model', 'convergence', 'status']"
814,"Two types of adjusted odds ratio estimates are computed by PROC FREQ. One type is the Mantel- Haenszel (MH) estimator, which is obtained as a weighted average of the stratum specific odds ratios. Another type is the logit-based estimator, which is obtained from a weighted average of the stratum-specific log-odds ratios. However, zero frequencies pose a computational problem, so one- half is added to each cell of any table that contains a zero frequency. Therefore, a common recommendation is to use the MH estimators when you have a small sample size because it is less sensitive to small numbers than the logit-based estimator. It should be noted that the MH estimator and the logit-based estimator are similar when the data is not too sparse within the strata.",CD,766,"['two', 'type', 'adjusted', 'odds_ratio', 'estimate', 'computed', 'proc', 'freq', 'one', 'type', 'mantel', 'haenszel', 'mh', 'estimator', 'obtained', 'weighted', 'average', 'stratum', 'specific', 'odds_ratio', 'another', 'type', 'logitbased', 'estimator', 'obtained', 'weighted', 'average', 'stratumspecific', 'logodds', 'ratio', 'however', 'zero', 'frequency', 'pose', 'computational', 'problem', 'one', 'half', 'added', 'cell', 'table', 'contains', 'zero', 'frequency', 'therefore', 'common', 'recommendation', 'use', 'mh', 'estimator', 'small', 'sample_size', 'le', 'sensitive', 'small', 'number', 'logitbased', 'estimator', 'noted', 'mh', 'estimator', 'logitbased', 'estimator', 'similar', 'data', 'sparse', 'within', 'stratum']"
815,"After you have formulated the final model, you need to assess how well it fits the data. In other words, you need to assess how close the model-predicted values are to the corresponding observed values. Test statistics that assess the fit of the model are called goodness-of-fit statistics. If departures of the predicted values from the observed values are essentially random, then the goodness-of-fit statistics are not statistically significant. Some of the problems that can cause the goodness-of-fit statistics to be statistically significant are having outliers in the data, omitting important terms in the model such as interactions, needing to transform some predictor variables, having a nonlinear relationship between the logits and a predictor variable, and having a model that has greater variability than predicted by the random component of the model. This latter problem is also known as overdispersion, and it occurs when the assumption of binomial variability may not be valid. These problems should be examined before proceeding to use methods to correct for overdispersion (SAS Institute Inc. 1995). Another problem with logistic regression, as in linear regression, is multicollinearity. This occurs when there are strong linear dependencies among the predictor variables. Although multicollinearity does not bias the parameter estimates, it does increase their variances, which results in less precise estimates of the parameters (Allison 1999). There are no multicollinearity diagnostics in the LOGISTIC procedure. However, you can use the diagnostics in the REG procedure because multicollinearity only deals with the predictor variables, not the outcome variable. Some of the options in the MODEL statement in PROC REG include TOL, VIF, COLLIN, and COLLINOINT. In most cases, serious multicollinearity will be detected. In rare instances you may fail to detect the problem because the linear combinations should actually be adjusted by the weight matrix used in the maximum likelihood algorithm (Allison 1999).",CD,2034,"['formulated', 'final', 'model', 'need', 'ass', 'well', 'fit', 'data', 'word', 'need', 'ass', 'close', 'modelpredicted', 'value', 'corresponding', 'observed', 'value', 'test', 'statistic', 'ass', 'fit', 'model', 'called', 'goodnessoffit', 'statistic', 'departure', 'predicted', 'value', 'observed', 'value', 'essentially', 'random', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'problem', 'cause', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'outlier', 'data', 'omitting', 'important', 'term', 'model', 'interaction', 'needing', 'transform', 'predictor_variable', 'nonlinear', 'relationship', 'logits', 'predictor_variable', 'model', 'ha', 'greater', 'variability', 'predicted', 'random', 'component', 'model', 'latter', 'problem', 'also', 'known', 'overdispersion', 'occurs', 'assumption', 'binomial', 'variability', 'may', 'valid', 'problem', 'examined', 'proceeding', 'use', 'method', 'correct', 'overdispersion', 'sa', 'institute', 'inc', '1995', 'another', 'problem', 'logistic_regression', 'linear', 'regression', 'multicollinearity', 'occurs', 'strong', 'linear', 'dependency', 'among', 'predictor_variable', 'although', 'multicollinearity', 'doe', 'bias', 'parameter_estimate', 'doe', 'increase', 'variance', 'result', 'le', 'precise', 'estimate', 'parameter', 'allison', '1999', 'multicollinearity', 'diagnostics', 'logistic', 'procedure', 'however', 'use', 'diagnostics', 'reg', 'procedure', 'multicollinearity', 'deal', 'predictor_variable', 'outcome', 'variable', 'option', 'model_statement', 'proc', 'reg', 'include', 'tol', 'vif', 'collin', 'collinoint', 'case', 'serious', 'multicollinearity', 'detected', 'rare', 'instance', 'may', 'fail', 'detect', 'problem', 'linear', 'combination', 'actually', 'adjusted', 'weight', 'matrix', 'used', 'maximum', 'likelihood', 'algorithm', 'allison', '1999']"
816,"Conditional logistic regression is a useful technique when you have paired observations. One example is the matched case-control studies. In the past, the PHREG procedure was usually used to fit a conditional logistic regression model. However, in SAS?9 the STRATA statement in PROC LOGISTIC can be used to fit conditional logistic regression models. An important feature of the conditional logistic model is that the model requires the matched data to be considered in strata. The strata represent the matched sets (paired observations). These models also allow the probabilities to vary by observation within strata. Therefore, the models permit the strata to have their own probability distributions and they account for the dependence of the matched pairs. These models are known as the conditional models because the parameter estimate ? is defined conditional on the subject. The effect is subject-specific, because it is defined at the subject level. This is in contrast to the GEE models which were marginal models. The effects in those models are population-averaged because they refer to averaging over the entire population rather than to individual subjects. For example, in a matched case-control study the probabilities modeled refer to the distribution of Y given X. Although the model permits stratum-specific distributions, it assumes a common effect ?. The parameter ? compares the response distributions. It follows that the conditional model is restricted to estimating ? that are within stratum effects. Thus only the predictor variables that vary within stratum contribute to the likelihood. Conditional models do not estimate a between-stratum effect. Therefore, a predictor variable that is constant within stratum contributes nothing to the likelihood. This is why a coefficient is not estimated for the matching variables. However, the stratum-constant variables are still being controlled for in the model. It should be noted that when there are several observations per stratum, then the GEE models can be used. For 1:1 matched case-control studies, the estimated values in the working correlation matrix are ?1 and the GEE method breaks down. Therefore, the conditional model is the only way to go for case-control matching. A good discussion about the differences between GEE models and conditional logistic models can be found in Allison (1999).",CD,2376,"['conditional', 'logistic_regression', 'useful', 'technique', 'paired', 'observation', 'one', 'example', 'matched', 'casecontrol', 'study', 'past', 'phreg', 'procedure', 'wa', 'usually', 'used', 'fit', 'conditional', 'logistic_regression_model', 'however', 'sas9', 'stratum', 'statement', 'proc_logistic', 'used', 'fit', 'conditional', 'logistic_regression_model', 'important', 'feature', 'conditional', 'logistic', 'model', 'model', 'requires', 'matched', 'data', 'considered', 'stratum', 'stratum', 'represent', 'matched', 'set', 'paired', 'observation', 'model', 'also', 'allow', 'probability', 'vary', 'observation', 'within', 'stratum', 'therefore', 'model', 'permit', 'stratum', 'probability', 'distribution', 'account', 'dependence', 'matched', 'pair', 'model', 'known', 'conditional', 'model', 'parameter_estimate', '', 'defined', 'conditional', 'subject', 'effect', 'subjectspecific', 'defined', 'subject', 'level', 'contrast', 'gee', 'model', 'marginal', 'model', 'effect', 'model', 'populationaveraged', 'refer', 'averaging', 'entire', 'population', 'rather', 'individual', 'subject', 'example', 'matched', 'casecontrol', 'study', 'probability', 'modeled', 'refer', 'distribution', 'given', 'x', 'although', 'model', 'permit', 'stratumspecific', 'distribution', 'assumes', 'common', 'effect', '', 'parameter', '', 'compare', 'response', 'distribution', 'follows', 'conditional', 'model', 'restricted', 'estimating', '', 'within', 'stratum', 'effect', 'thus', 'predictor_variable', 'vary', 'within', 'stratum', 'contribute', 'likelihood', 'conditional', 'model', 'estimate', 'betweenstratum', 'effect', 'therefore', 'predictor_variable', 'constant', 'within', 'stratum', 'contributes', 'nothing', 'likelihood', 'coefficient', 'estimated', 'matching', 'variable', 'however', 'stratumconstant', 'variable', 'still', 'controlled', 'model', 'noted', 'several', 'observation', 'per', 'stratum', 'gee', 'model', 'used', '11', 'matched', 'casecontrol', 'study', 'estimated', 'value', 'working', 'correlation', 'matrix', '1', 'gee', 'method', 'break', 'therefore', 'conditional', 'model', 'way', 'go', 'casecontrol', 'matching', 'good', 'discussion', 'difference', 'gee', 'model', 'conditional', 'logistic', 'model', 'found', 'allison', '1999']"
817,"You can also write a CONTRAST statement in PROC LOGISTIC to estimate the odds ratio for any effect along with the confidence bounds. The contrasts consist of the effects involved in the odds ratio along with the coefficients that measure the difference between the effects in the numerator and the effects in the denominator. The ESTIMATE=EXP option exponentiates the parameter estimate, which shows the odds ratio and the 95% confidence bounds. Estimating Odds Ratios in Interactions",CD,484,"['also', 'write', 'contrast', 'statement', 'proc_logistic', 'estimate', 'odds_ratio', 'effect', 'along', 'confidence', 'bound', 'contrast', 'consist', 'effect', 'involved', 'odds_ratio', 'along', 'coefficient', 'measure', 'difference', 'effect', 'numerator', 'effect', 'denominator', 'estimateexp', 'option', 'exponentiates', 'parameter_estimate', 'show', 'odds_ratio', '95', 'confidence', 'bound', 'estimating', 'odds_ratio', 'interaction']"
818,"PROC LOGISTIC reports a score test for the proportional odds assumption. This tests the null hypothesis that the slope coefficients are equal across the cumulative logits for each predictor variable. Because the p-value is not significant at the 0.05 significance level, you do not reject the assumption of equal slopes and the proportional odds assumption is validated. Model Fit Statistics",CD,391,"['proc_logistic', 'report', 'score', 'test', 'proportional', 'odds', 'assumption', 'test', 'null', 'hypothesis', 'slope', 'coefficient', 'equal', 'across', 'cumulative', 'logits', 'predictor_variable', 'pvalue', 'significant', '005', 'significance', 'level', 'reject', 'assumption', 'equal', 'slope', 'proportional', 'odds', 'assumption', 'validated', 'model', 'fit', 'statistic']"
819,"The estimated logit plot shows no apparent pattern. Therefore, mother_age may be entered into the model as a continuous variable because creating several groups will probably not improve the fit of the model. Although it seems mother_age is not an important predictor for low birth weight, the estimated logit plot is a univariate plot that can be misleading in the presence of partial associations and interactions. A model with two-factor interactions and main effects should be evaluated before mother_age is eliminated. Estimated logit plots should never be used to eliminate variables.",CD,590,"['estimated', 'logit', 'plot', 'show', 'apparent', 'pattern', 'therefore', 'motherage', 'may', 'entered', 'model', 'continuous', 'variable', 'creating', 'several', 'group', 'probably', 'improve', 'fit', 'model', 'although', 'seems', 'motherage', 'important', 'predictor', 'low', 'birth', 'weight', 'estimated', 'logit', 'plot', 'univariate', 'plot', 'misleading', 'presence', 'partial', 'association', 'interaction', 'model', 'twofactor', 'interaction', 'main_effect', 'evaluated', 'motherage', 'eliminated', 'estimated', 'logit', 'plot', 'never', 'used', 'eliminate', 'variable']"
820,"Example:	Examine the relationships between prev_pretrm and low, and prev_pretrm and low, controlling for uterine_irr. Request a Breslow-Day test for homogeneity of odds ratios with a Tarone?s adjustment, exact confidence limits for the crude odds ratios and the adjusted odds ratios, and the number of variable levels. /* c1demo02a */ proc freq data=sasuser.birth nlevels; tables prev_pretrm*low uterine_irr*prev_pretrm*low / all bdt; exact or comor; title 'Contingency Table Analysis Assessing PREV_PRETRM' ' and UTERINE_IRR'; run; PROC FREQ statement option: NLEVELS	displays a table that provides the number of levels for each variable in the TABLES statement. Selected TABLES statement options: CHISQ	produces the chi-square test of association and the measures of association based upon the chi-square statistic. MEASURES	requests several measures of association. CL 	produces confidence bounds for the MEASURES statistics. CMH	requests Cochran-Mantel-Haenszel statistics, which test for association between the row and column variables after adjusting for the remaining variables in a multiway table. ALL	requests the CHISQ, MEASURES, and CMH options. Provides all the test statistics and measures for each table along with the summary CMH statistics. BDT	request Tarone's adjustment for the Breslow-Day test. Selected EXACT statement options: OR	requests exact confidence limits for the odds ratio for 2*2 tables. COMOR	requests exact confidence limits for the adjusted odds ratio. An exact test that the adjusted odds ratio equals 1 is also computed. MAXTIME=	specifies the maximum clock time (in seconds) that PROC FREQ can use to compute an exact p-value. MC	requests Monte Carlo estimation of exact p-values instead of direct exact p-value computation.",CD,1763,"['example\texamine', 'relationship', 'prevpretrm', 'low', 'prevpretrm', 'low', 'controlling', 'uterineirr', 'request', 'breslowday', 'test', 'homogeneity', 'odds_ratio', 'tarones', 'adjustment', 'exact', 'confidence', 'limit', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'number', 'variable', 'level', '', 'c1demo02a', '', 'proc', 'freq', 'datasasuserbirth', 'nlevels', 'table', 'prevpretrmlow', 'uterineirrprevpretrmlow', '', 'bdt', 'exact', 'comor', 'title', 'contingency', 'table', 'analysis', 'assessing', 'prevpretrm', '', 'uterineirr', 'run', 'proc', 'freq', 'statement', 'option', 'nlevels\tdisplays', 'table', 'provides', 'number', 'level', 'variable', 'table', 'statement', 'selected', 'table', 'statement', 'option', 'chisq\tproduces', 'chisquare', 'test', 'association', 'measure', 'association', 'based', 'upon', 'chisquare', 'statistic', 'measures\trequests', 'several', 'measure', 'association', 'cl', '\tproduces', 'confidence', 'bound', 'measure', 'statistic', 'cmh\trequests', 'cochranmantelhaenszel', 'statistic', 'test', 'association', 'row', 'column', 'variable', 'adjusting', 'remaining', 'variable', 'multiway', 'table', 'all\trequests', 'chisq', 'measure', 'cmh', 'option', 'provides', 'test', 'statistic', 'measure', 'table', 'along', 'summary', 'cmh', 'statistic', 'bdt\trequest', 'tarones', 'adjustment', 'breslowday', 'test', 'selected', 'exact', 'statement', 'option', 'or\trequests', 'exact', 'confidence', 'limit', 'odds_ratio', '22', 'table', 'comor\trequests', 'exact', 'confidence', 'limit', 'adjusted', 'odds_ratio', 'exact', 'test', 'adjusted', 'odds_ratio', 'equal', '1', 'also', 'computed', 'maxtime\tspecifies', 'maximum', 'clock', 'time', 'second', 'proc', 'freq', 'use', 'compute', 'exact', 'pvalue', 'mc\trequests', 'monte', 'carlo', 'estimation', 'exact', 'pvalues', 'instead', 'direct', 'exact', 'pvalue', 'computation']"
821,"The CONTRAST statement is made up of the following components: label	identifies the contrast in the output. A label is required for every contrast specified, and it must 	be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement. You do not need to include all effects that are included in the MODEL statement. values	identifies the coefficients associated with the effect. To correctly specify your contrast, it is crucial to know the ordering of the parameters within each effect and the variable levels associated with each parameter. If an effect is not specified in the CONTRAST statement, all of its coefficients are set to 0. If too many values are specified for an effect, the extra ones are ignored. If too few values are specified, the remaining ones are set to 0.",CD,803,"['contrast', 'statement', 'made', 'following', 'component', 'label\tidentifies', 'contrast', 'output', 'label', 'required', 'every', 'contrast', 'specified', 'must', '\tbe', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'need', 'include', 'effect', 'included', 'model_statement', 'values\tidentifies', 'coefficient', 'associated', 'effect', 'correctly', 'specify', 'contrast', 'crucial', 'know', 'ordering', 'parameter', 'within', 'effect', 'variable', 'level', 'associated', 'parameter', 'effect', 'specified', 'contrast', 'statement', 'coefficient', 'set', '0', 'many', 'value', 'specified', 'effect', 'extra', 'one', 'ignored', 'value', 'specified', 'remaining', 'one', 'set', '0']"
822,"The algorithm for variable clustering starts off with all the variables in one cluster. A principal components analysis is then done on the variables and the algorithm examines the eigenvalues computed for each principal component. Eigenvalues measure how much variability is explained by the principal components. They are scaled so that the sum of the eigenvalues is equal to the number of variables. When the predictor variables are uncorrelated, then all of the eigenvalues equal 1. If there is only one group of variables that is related to each other, then the first eigenvalue (corresponding to the first principal component) is large and the others are all close to 0. However, if there are several groups of related variables, then several eigenvalues are much larger than 1. The algorithm examines the second eigenvalue because that determines whether there is more than one dominant dimension in the variable cluster. If the second eigenvalue is greater than a specified threshold, then the variable cluster is split into 2 groups. The process is repeated until the second eigenvalue drops below the threshold. Larger thresholds for the second eigenvalue give fewer clusters and less variation is explained among the predictor variables. Smaller thresholds give more clusters and more variation is explained. The default threshold is 1 because it represents the average size of the eigenvalues (if the correlation matrix is analyzed). To account for sampling variability, smaller values such as .70 have been suggested (Jackson 1991). However, the threshold should be chosen based on the results of variable clustering.",CD,1630,"['algorithm', 'variable', 'clustering', 'start', 'variable', 'one', 'cluster', 'principal', 'component', 'analysis', 'done', 'variable', 'algorithm', 'examines', 'eigenvalue', 'computed', 'principal', 'component', 'eigenvalue', 'measure', 'much', 'variability', 'explained', 'principal', 'component', 'scaled', 'sum', 'eigenvalue', 'equal', 'number', 'variable', 'predictor_variable', 'uncorrelated', 'eigenvalue', 'equal', '1', 'one', 'group', 'variable', 'related', 'first', 'eigenvalue', 'corresponding', 'first', 'principal', 'component', 'large', 'others', 'close', '0', 'however', 'several', 'group', 'related', 'variable', 'several', 'eigenvalue', 'much', 'larger', '1', 'algorithm', 'examines', 'second', 'eigenvalue', 'determines', 'whether', 'one', 'dominant', 'dimension', 'variable', 'cluster', 'second', 'eigenvalue', 'greater', 'specified', 'threshold', 'variable', 'cluster', 'split', '2', 'group', 'process', 'repeated', 'second', 'eigenvalue', 'drop', 'threshold', 'larger', 'threshold', 'second', 'eigenvalue', 'give', 'fewer', 'cluster', 'le', 'variation', 'explained', 'among', 'predictor_variable', 'smaller', 'threshold', 'give', 'cluster', 'variation', 'explained', 'default', 'threshold', '1', 'represents', 'average', 'size', 'eigenvalue', 'correlation', 'matrix', 'analyzed', 'account', 'sampling', 'variability', 'smaller', 'value', '70', 'suggested', 'jackson', '1991', 'however', 'threshold', 'chosen', 'based', 'result', 'variable', 'clustering']"
823,"The LOGISTIC procedure should not be used to analyze clustered data because PROC LOGISTIC assumes independent observations. In the past, the CATMOD procedure was used to analyze clustered data with a discrete response variable. However, GEE models offer some significant advantages over models fit in PROC CATMOD for the analysis of clustered data. For example, models fit in PROC CATMOD require that the data be balanced. Therefore, the measurements have to occur at the same times for all subjects and each subject has the same number of measurements. PROC CATMOD also uses complete case analysis, where only subjects with data at all time points are used. If a subject has one or more missing measurements, then PROC CATMOD deletes the entire subject. Models fit in PROC CATMOD model the distribution of the response variable (represented by the columns in an underlying contingency table) across the levels of the predictor variables (represented by the rows in an underlying contingency table). Computational difficulties might occur if you have a continuous covariate with a large number of unique values, because many rows will have a sample size of 1. PROC CATMOD might be less efficient and might be unable to allocate sufficient memory to handle this problem. GEE regression models fit in the GENMOD procedure use the all-available pairs method, where all nonmissing pairs of data are used to estimate the parameters in the correlation matrix. If there are missing values, then some correlations are computed using more observations and other correlations are computed using fewer observations.",CD,1604,"['logistic', 'procedure', 'used', 'analyze', 'clustered', 'data', 'proc_logistic', 'assumes', 'independent', 'observation', 'past', 'catmod', 'procedure', 'wa', 'used', 'analyze', 'clustered', 'data', 'discrete', 'response_variable', 'however', 'gee', 'model', 'offer', 'significant', 'advantage', 'model', 'fit', 'proc', 'catmod', 'analysis', 'clustered', 'data', 'example', 'model', 'fit', 'proc', 'catmod', 'require', 'data', 'balanced', 'therefore', 'measurement', 'occur', 'time', 'subject', 'subject', 'ha', 'number', 'measurement', 'proc', 'catmod', 'also', 'us', 'complete', 'case', 'analysis', 'subject', 'data', 'time', 'point', 'used', 'subject', 'ha', 'one', 'missing', 'measurement', 'proc', 'catmod', 'deletes', 'entire', 'subject', 'model', 'fit', 'proc', 'catmod', 'model', 'distribution', 'response_variable', 'represented', 'column', 'underlying', 'contingency', 'table', 'across', 'level', 'predictor_variable', 'represented', 'row', 'underlying', 'contingency', 'table', 'computational', 'difficulty', 'might', 'occur', 'continuous', 'covariate', 'large', 'number', 'unique', 'value', 'many', 'row', 'sample_size', '1', 'proc', 'catmod', 'might', 'le', 'efficient', 'might', 'unable', 'allocate', 'sufficient', 'memory', 'handle', 'problem', 'gee', 'regression_model', 'fit', 'genmod', 'procedure', 'use', 'allavailable', 'pair', 'method', 'nonmissing', 'pair', 'data', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'missing', 'value', 'correlation', 'computed', 'using', 'observation', 'correlation', 'computed', 'using', 'fewer', 'observation']"
824,WARNING: The maximum likelihood estimate may not exist. WARNING: The LOGISTIC procedure continues in spite of the above warning. Results shown are based on the last maximum likelihood iteration. Validity of the model fit is questionable.,CD,237,"['warning', 'maximum', 'likelihood', 'estimate', 'may', 'exist', 'warning', 'logistic', 'procedure', 'continues', 'spite', 'warning', 'result', 'shown', 'based', 'last', 'maximum', 'likelihood', 'iteration', 'validity', 'model', 'fit', 'questionable']"
825,"In the univariate analysis of the data, it is important to document, for each predictor variable, whether an association exists with the response variable and the strength of the association. For binary predictor variables, the confidence bounds around the odds ratio would indicate whether an association exists. If the confidence interval does not include 1, then there is evidence that there is an association. For ordinal predictors, the Mantel-Haenszel chi-square could be used. For nominal predictors, the mean score statistic would be helpful (Stokes, Davis, and Koch 2000). ?	Binary variables can be considered ordinal variables.",CD,637,"['univariate', 'analysis', 'data', 'important', 'document', 'predictor_variable', 'whether', 'association', 'exists', 'response_variable', 'strength', 'association', 'binary', 'predictor_variable', 'confidence', 'bound', 'around', 'odds_ratio', 'would', 'indicate', 'whether', 'association', 'exists', 'confidence', 'interval', 'doe', 'include', '1', 'evidence', 'association', 'ordinal', 'predictor', 'mantelhaenszel', 'chisquare', 'could', 'used', 'nominal', 'predictor', 'mean', 'score', 'statistic', 'would', 'helpful', 'stokes', 'davis', 'koch', '2000', '\tbinary', 'variable', 'considered', 'ordinal', 'variable']"
826,"The score test for the proportional odds assumption tends to reject the null hypothesis more often than is warranted. If there are many predictor variables and if the sample size is large, the test usually produces p-values below 0.05 (Allison 1999). Given such a liberal test, it may be useful to graph the cumulative logits to visually inspect the proportional odds assumption. Cumulative logit plots are graphs of cumulative logits for each predictor variable. If the proportional odds assumption is true, then the slopes of the logits should be parallel. If the plotted lines diverge greatly from parallelism, then you should consider a different modeling approach such as modeling generalized logits. Agresti (2002) also recommends trying a link function for which the response curve is nonsymmetric (in other words, complementary log-log), adding additional parameters such as interactions, and adding dispersion parameters. Cumulative Logit Plots",CD,953,"['score', 'test', 'proportional', 'odds', 'assumption', 'tends', 'reject', 'null', 'hypothesis', 'often', 'warranted', 'many', 'predictor_variable', 'sample_size', 'large', 'test', 'usually', 'produce', 'pvalues', '005', 'allison', '1999', 'given', 'liberal', 'test', 'may', 'useful', 'graph', 'cumulative', 'logits', 'visually', 'inspect', 'proportional', 'odds', 'assumption', 'cumulative', 'logit', 'plot', 'graph', 'cumulative', 'logits', 'predictor_variable', 'proportional', 'odds', 'assumption', 'true', 'slope', 'logits', 'parallel', 'plotted', 'line', 'diverge', 'greatly', 'parallelism', 'consider', 'different', 'modeling', 'approach', 'modeling', 'generalized', 'logits', 'agresti', '2002', 'also', 'recommends', 'trying', 'link', 'function', 'response', 'curve', 'nonsymmetric', 'word', 'complementary', 'loglog', 'adding', 'additional', 'parameter', 'interaction', 'adding', 'dispersion', 'parameter', 'cumulative', 'logit', 'plot']"
827,PROC GENMOD is modeling the probability that wheeze='1'. The Class Level Information table displays the levels of the class variables while the response profile table displays the levels of the response variable. Parameter Information,CD,234,"['proc', 'genmod', 'modeling', 'probability', 'wheeze1', 'class', 'level', 'information', 'table', 'display', 'level', 'class', 'variable', 'response', 'profile', 'table', 'display', 'level', 'response_variable', 'parameter', 'information']"
828,Variables with the lowest 1 minus R-squared ratio are variables with a high correlation with their own cluster and with a low correlation with the other clusters. These variables may be good representative variables from each cluster.,CD,234,"['variable', 'lowest', '1', 'minus', 'rsquared', 'ratio', 'variable', 'high', 'correlation', 'cluster', 'low', 'correlation', 'cluster', 'variable', 'may', 'good', 'representative', 'variable', 'cluster']"
829,"Example:	Fit a conditional logistic regression model to the sasuser.matched data set. Specify low as the response variable and use all of the predictor variables. Use the EVENT= option to model the probability of low birth weight. Use the UNITS statement to obtain an odds ratio estimate for a 10-unit change in Mother_wt. Also specify socio as a CLASS variable, reference cell coding, 3 as the reference level, standardized estimates, and Wald confidence intervals for the odds ratios. /* c3demo20a */ proc logistic data=sasuser.matched; strata Pair; class Socio (param=ref ref='3'); model Low(event='1') = Mother_age Mother_wt Socio Smoke Prev_pretrm Uterine_irr Hist_hyp / stb clodds=wald; units Mother_wt=10; title 'Conditional Model for Matched Case-Control Study'; run; Selected STRATA statement options: MISSING	treats missing values as valid STRATA variable values. NOSUMMARY	suppresses the display of the ?Strata Summary? table. INFO	displays the ?Strata Information? table, which includes the stratum number, levels of the STRATA variables that define the stratum, the number of events, the number of nonevents, and the total frequency for each stratum. The STRATA statement names the variables that define strata or matched sets to use in a conditional logistic regression model. Observations having the same variable levels are in the same matched set. At least one variable must be specified to invoke the stratified analysis, and the usual unconditional asymptotic analysis is not performed. STRATA variables can also be specified in the MODEL statement as classification or continuous variables. However, the effects are nondegenerate only when crossed with a non-stratification variable. The SCORE and WEIGHT statements are not available with a STRATA statement. The following MODEL options are also not supported with a STRATA statement: CLPARM=PL, CLODDS=PL, CTABLE, LACKFIT, LINK=, NOFIT, OUTMODEL=, OUTROC=, and SCALE=. Conditional Model for Matched Case-Control Study",CD,1988,"['example\tfit', 'conditional', 'logistic_regression_model', 'sasusermatched', 'data_set', 'specify', 'low', 'response_variable', 'use', 'predictor_variable', 'use', 'event', 'option', 'model', 'probability', 'low', 'birth', 'weight', 'use', 'unit', 'statement', 'obtain', 'odds_ratio', 'estimate', '10unit', 'change', 'motherwt', 'also', 'specify', 'socio', 'class', 'variable', 'reference', 'cell', 'coding', '3', 'reference', 'level', 'standardized', 'estimate', 'wald', 'confidence', 'interval', 'odds_ratio', '', 'c3demo20a', '', 'proc_logistic', 'datasasusermatched', 'stratum', 'pair', 'class', 'socio', 'paramref', 'ref3', 'model', 'lowevent1', '', 'motherage', 'motherwt', 'socio', 'smoke', 'prevpretrm', 'uterineirr', 'histhyp', '', 'stb', 'cloddswald', 'unit', 'motherwt10', 'title', 'conditional', 'model', 'matched', 'casecontrol', 'study', 'run', 'selected', 'stratum', 'statement', 'option', 'missing\ttreats', 'missing', 'value', 'valid', 'stratum', 'variable', 'value', 'nosummary\tsuppresses', 'display', 'stratum', 'summary', 'table', 'info\tdisplays', 'stratum', 'information', 'table', 'includes', 'stratum', 'number', 'level', 'stratum', 'variable', 'define', 'stratum', 'number', 'event', 'number', 'nonevent', 'total', 'frequency', 'stratum', 'stratum', 'statement', 'name', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'conditional', 'logistic_regression_model', 'observation', 'variable', 'level', 'matched', 'set', 'least', 'one', 'variable', 'must', 'specified', 'invoke', 'stratified', 'analysis', 'usual', 'unconditional', 'asymptotic', 'analysis', 'performed', 'stratum', 'variable', 'also', 'specified', 'model_statement', 'classification', 'continuous', 'variable', 'however', 'effect', 'nondegenerate', 'crossed', 'nonstratification', 'variable', 'score', 'weight', 'statement', 'available', 'stratum', 'statement', 'following', 'model', 'option', 'also', 'supported', 'stratum', 'statement', 'clparmpl', 'cloddspl', 'ctable', 'lackfit', 'link', 'nofit', 'outmodel', 'outroc', 'scale', 'conditional', 'model', 'matched', 'casecontrol', 'study']"
830,"From the classification table you can compute sensitivity, which is the proportion of event observations (in this example low birth weight babies) that were predicted to have an event response. The formula is (true positives) / (total actual positives).",CD,253,"['classification', 'table', 'compute', 'sensitivity', 'proportion', 'event', 'observation', 'example', 'low', 'birth', 'weight', 'baby', 'predicted', 'event', 'response', 'formula', 'true', 'positive', '', 'total', 'actual', 'positive']"
831,"The LOGISTIC procedure has five variable selection methods with the use of the SELECTION= option. The default is SELECTION=NONE, in which PROC LOGISTIC fits the complete model as specified in the MODEL statement. The other four methods are FORWARD for forward selection, BACKWARD for backward elimination, STEPWISE for stepwise selection, and SCORE for best subsets selection. Best subsets selection finds a specified number of models with the highest likelihood score (chi- square) statistic for all possible model sizes (1-, 2-, 3-variable models, and so on, up to the single model containing all predictor variables). The method requires only that the full model be fit because the results are then manipulated to calculate the likelihood score statistic for each possible combination of predictor variables. Because the method uses a branch and bound algorithm to search the many combinations of variables, the best subsets selection is relatively efficient for a relatively small number of variables. However, the performance acutely deteriorates when the model has over approximately 50 effects (predictor variables and their interactions) (Potts and Patetta 1999).",CD,1171,"['logistic', 'procedure', 'ha', 'five', 'variable', 'selection', 'method', 'use', 'selection', 'option', 'default', 'selectionnone', 'proc_logistic', 'fit', 'complete', 'model', 'specified', 'model_statement', 'four', 'method', 'forward', 'forward', 'selection', 'backward', 'backward', 'elimination', 'stepwise', 'stepwise', 'selection', 'score', 'best', 'subset', 'selection', 'best', 'subset', 'selection', 'find', 'specified', 'number', 'model', 'highest', 'likelihood', 'score', 'chi', 'square', 'statistic', 'possible', 'model', 'size', '1', '2', '3variable', 'model', 'single', 'model', 'containing', 'predictor_variable', 'method', 'requires', 'full', 'model', 'fit', 'result', 'manipulated', 'calculate', 'likelihood', 'score', 'statistic', 'possible', 'combination', 'predictor_variable', 'method', 'us', 'branch', 'bound', 'algorithm', 'search', 'many', 'combination', 'variable', 'best', 'subset', 'selection', 'relatively', 'efficient', 'relatively', 'small', 'number', 'variable', 'however', 'performance', 'acutely', 'deteriorates', 'model', 'ha', 'approximately', '50', 'effect', 'predictor_variable', 'interaction', 'potts', 'patetta', '1999']"
832,"The forward selection method selected three different models when you changed the options. Allowing single effects to enter the model at one step did not detect any significant interactions, whereas allowing multiple effects to enter the model at one step put two nonsignificant interactions in the model.",CD,305,"['forward', 'selection', 'method', 'selected', 'three', 'different', 'model', 'changed', 'option', 'allowing', 'single', 'effect', 'enter', 'model', 'one', 'step', 'detect', 'significant', 'interaction', 'whereas', 'allowing', 'multiple', 'effect', 'enter', 'model', 'one', 'step', 'put', 'two', 'nonsignificant', 'interaction', 'model']"
833,where is the diagonal elements of the hat matrix and is the change in the Pearson chi- square due to the deleted observation. The formula illustrates that the c diagnostic statistic can be large due to either lack-of-fit (large difchisq) or high leverage (large hat diagonal). Regression Diagnostics,CD,299,"['diagonal', 'element', 'hat', 'matrix', 'change', 'pearson', 'chi', 'square', 'due', 'deleted', 'observation', 'formula', 'illustrates', 'c', 'diagnostic', 'statistic', 'large', 'due', 'either', 'lackoffit', 'large', 'difchisq', 'high', 'leverage', 'large', 'hat', 'diagonal', 'regression', 'diagnostics']"
834,"Missing values that occur intermixed with nonmissing values are called intermittent missing values. If these missing values are missing completely at random (MCAR), then the consistency results established by Liang and Zeger (1986) hold. A simple check of MCAR is to divide the subjects into two groups: those with a complete set of measurements and those with missing measurements. If the MCAR assumption holds, then both groups (with their measurements) should be random samples of the same population of measurements. In other words, the probability of missing is independent of the observed measurements and the measurements that would have been available had they not been missing. The t-tests for location and more general tests of equality of distribution can be used to test the MCAR assumption (Little 1995). Tests of MCAR for repeatedly measured categorical data were discussed by Park and Davis (1993). Some intermittent missing values can arise due to censoring rules. For example, values outside a stated range might be simply unreliable because of the limitations of the measuring techniques in use (Diggle, Heagerty, Liang, and Zeger 2002). Methods for handling censored data in correlation data structures are addressed in Laird (1988) and Hughes (1999). Intermittent missing values can also be related to the outcome. For example, a patient might miss an appointment because of an adverse reaction to the treatment. The fact that the subject remains in the study means that the investigator should have the opportunity to ascertain the reason for the missing appointment and take corrective action accordingly (Diggle, Heagerty, Liang, and Zeger 2002, Little 1995). If all the missing values occur after a certain time point for a subject, then the missing values are called dropouts. These are a more significant problem compared to intermittent missing values because usually the subject is withdrawn for reasons directly or indirectly connected to the outcome and are lost to follow-up. If you treat the dropouts as MCAR when they are in fact informative dropouts, the parameter estimates will be biased (Diggle and Kenward 1994). Diggle, Heagerty, Liang, and Zeger (2002) state that ?An emerging consensus is that analysis of data with potentially informative dropouts necessarily involves assumptions that are difficult, or even impossible, to check from the observed data. This suggests that it would be unwise to rely on the precise conclusions of an analysis based on a particular informative dropout model.? They recommend that a sensitivity analysis be conducted on the informative dropout model. This provides some protection against the possibility that conclusions reached from a random dropout model are critically dependent on the validity of MCAR. Scharstein et al. (1999) provides a discussion on how such sensitivity analyses might be conducted.",CD,2880,"['missing', 'value', 'occur', 'intermixed', 'nonmissing', 'value', 'called', 'intermittent', 'missing', 'value', 'missing', 'value', 'missing', 'completely', 'random', 'mcar', 'consistency', 'result', 'established', 'liang', 'zeger', '1986', 'hold', 'simple', 'check', 'mcar', 'divide', 'subject', 'two', 'group', 'complete', 'set', 'measurement', 'missing', 'measurement', 'mcar', 'assumption', 'hold', 'group', 'measurement', 'random', 'sample', 'population', 'measurement', 'word', 'probability', 'missing', 'independent', 'observed', 'measurement', 'measurement', 'would', 'available', 'missing', 'ttests', 'location', 'general', 'test', 'equality', 'distribution', 'used', 'test', 'mcar', 'assumption', 'little', '1995', 'test', 'mcar', 'repeatedly', 'measured', 'categorical', 'data', 'discussed', 'park', 'davis', '1993', 'intermittent', 'missing', 'value', 'arise', 'due', 'censoring', 'rule', 'example', 'value', 'outside', 'stated', 'range', 'might', 'simply', 'unreliable', 'limitation', 'measuring', 'technique', 'use', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'method', 'handling', 'censored', 'data', 'correlation', 'data', 'structure', 'addressed', 'laird', '1988', 'hughes', '1999', 'intermittent', 'missing', 'value', 'also', 'related', 'outcome', 'example', 'patient', 'might', 'miss', 'appointment', 'adverse', 'reaction', 'treatment', 'fact', 'subject', 'remains', 'study', 'mean', 'investigator', 'opportunity', 'ascertain', 'reason', 'missing', 'appointment', 'take', 'corrective', 'action', 'accordingly', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'little', '1995', 'missing', 'value', 'occur', 'certain', 'time', 'point', 'subject', 'missing', 'value', 'called', 'dropout', 'significant', 'problem', 'compared', 'intermittent', 'missing', 'value', 'usually', 'subject', 'withdrawn', 'reason', 'directly', 'indirectly', 'connected', 'outcome', 'lost', 'followup', 'treat', 'dropout', 'mcar', 'fact', 'informative', 'dropout', 'parameter_estimate', 'biased', 'diggle', 'kenward', '1994', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'state', 'emerging', 'consensus', 'analysis', 'data', 'potentially', 'informative', 'dropout', 'necessarily', 'involves', 'assumption', 'difficult', 'even', 'impossible', 'check', 'observed', 'data', 'suggests', 'would', 'unwise', 'rely', 'precise', 'conclusion', 'analysis', 'based', 'particular', 'informative', 'dropout', 'model', 'recommend', 'sensitivity', 'analysis', 'conducted', 'informative', 'dropout', 'model', 'provides', 'protection', 'possibility', 'conclusion', 'reached', 'random', 'dropout', 'model', 'critically', 'dependent', 'validity', 'mcar', 'scharstein', 'et', 'al', '1999', 'provides', 'discussion', 'sensitivity', 'analysis', 'might', 'conducted']"
835,"The Strata Summary table displays the number of strata, which have a specific number of events and nonevents. Strata containing only events or only nonevents are reported in this table, but such strata are uninformative and are not used in the analysis. NOTE: The following parameters have been set to 0, since the variables are a linear combination of other variables as shown. Mother_age = 0",CD,393,"['stratum', 'summary', 'table', 'display', 'number', 'stratum', 'specific', 'number', 'event', 'nonevent', 'stratum', 'containing', 'event', 'nonevent', 'reported', 'table', 'stratum', 'uninformative', 'used', 'analysis', 'note', 'following', 'parameter', 'set', '0', 'since', 'variable', 'linear', 'combination', 'variable', 'shown', 'motherage', '', '0']"
836,"Generalized estimating equations (GEE) were developed to accommodate correlated observations within subjects. An estimating equation is simply the equation you solve to calculate the parameter estimates. The extra term generalized distinguishes the GEE as the estimating equations that accommodate the correlation structure of the repeated measurements. GEE are marginal models where the marginal expectation (average response for observations sharing the same covariates) is modeled as a function of the predictor variables. The parameters in marginal models can be interpreted as the influence of the covariates on the population-averaged response. These models are appropriate when the scientific objectives are to characterize and contrast populations of subjects. A useful feature of the GEE is that the parameter estimates along with the covariance matrix are consistently estimated (as the sample size increases, the estimates converge to the true values) even if the correlation structure within subject is not known. Therefore, the variances along with the inferences regarding the parameter estimates are asymptotically correct (Zeger and Liang 1986). It is also not necessary that the observations for all subjects have the same correlation structure.",CD,1262,"['generalized', 'estimating', 'equation', 'gee', 'developed', 'accommodate', 'correlated', 'observation', 'within', 'subject', 'estimating', 'equation', 'simply', 'equation', 'solve', 'calculate', 'parameter_estimate', 'extra', 'term', 'generalized', 'distinguishes', 'gee', 'estimating', 'equation', 'accommodate', 'correlation_structure', 'repeated', 'measurement', 'gee', 'marginal', 'model', 'marginal', 'expectation', 'average', 'response', 'observation', 'sharing', 'covariates', 'modeled', 'function', 'predictor_variable', 'parameter', 'marginal', 'model', 'interpreted', 'influence', 'covariates', 'populationaveraged', 'response', 'model', 'appropriate', 'scientific', 'objective', 'characterize', 'contrast', 'population', 'subject', 'useful', 'feature', 'gee', 'parameter_estimate', 'along', 'covariance', 'matrix', 'consistently', 'estimated', 'sample_size', 'increase', 'estimate', 'converge', 'true', 'value', 'even', 'correlation_structure', 'within', 'subject', 'known', 'therefore', 'variance', 'along', 'inference', 'regarding', 'parameter_estimate', 'asymptotically', 'correct', 'zeger', 'liang', '1986', 'also', 'necessary', 'observation', 'subject', 'correlation_structure']"
837,"The equation for the logistic regression model that refers directly to the probability of the outcome is shown above. This equation has the desired property that the predicted probabilities will always be between 0 and 1. This model is nonlinear because the parameter estimates do not enter the model equation linearly. Furthermore, the model permits the rate of change of the probabilities to vary as the predictor variable values vary.",CD,437,"['equation', 'logistic_regression_model', 'refers', 'directly', 'probability', 'outcome', 'shown', 'equation', 'ha', 'desired', 'property', 'predicted', 'probability', 'always', '0', '1', 'model', 'nonlinear', 'parameter_estimate', 'enter', 'model', 'equation', 'linearly', 'furthermore', 'model', 'permit', 'rate', 'change', 'probability', 'vary', 'predictor_variable', 'value', 'vary']"
838,"The primary advantage for matching over random sampling without matching is that matching might lead to a more statistically efficient analysis (Rothman 1986, Kleinbaum 1991). For example, matching might lead to a tighter confidence interval around the odds ratio being estimated for the predictor variables of interest. The reason for the improved precision is that matching might reduce the number of uninformative strata in a stratified analysis. An uninformative stratum in a matched case-control analysis is one in which the predictor variable?s value is constant. For example, suppose the primary predictor variable of interest is an exposure variable (1=yes, 0=no). If the case and control both have the same value of the exposure variable, then it is an uninformative stratum with regards to the exposure effect. Matching might lead to fewer uninformative strata, which will improve the efficiency of the study. Matching is attractive when there is a high price of expanding the study size (Rothman 1986). For example, if the cost of obtaining information from the subjects is large, it is desirable to optimize the amount of information obtained per subject. In other words, it is worthwhile to pay the cost of matching to take full advantage of the information that is collected.",CD,1289,"['primary', 'advantage', 'matching', 'random', 'sampling', 'without', 'matching', 'matching', 'might', 'lead', 'statistically', 'efficient', 'analysis', 'rothman', '1986', 'kleinbaum', '1991', 'example', 'matching', 'might', 'lead', 'tighter', 'confidence', 'interval', 'around', 'odds_ratio', 'estimated', 'predictor_variable', 'interest', 'reason', 'improved', 'precision', 'matching', 'might', 'reduce', 'number', 'uninformative', 'stratum', 'stratified', 'analysis', 'uninformative', 'stratum', 'matched', 'casecontrol', 'analysis', 'one', 'predictor_variable', 'value', 'constant', 'example', 'suppose', 'primary', 'predictor_variable', 'interest', 'exposure', 'variable', '1yes', '0no', 'case', 'control', 'value', 'exposure', 'variable', 'uninformative', 'stratum', 'regard', 'exposure', 'effect', 'matching', 'might', 'lead', 'fewer', 'uninformative', 'stratum', 'improve', 'efficiency', 'study', 'matching', 'attractive', 'high', 'price', 'expanding', 'study', 'size', 'rothman', '1986', 'example', 'cost', 'obtaining', 'information', 'subject', 'large', 'desirable', 'optimize', 'amount', 'information', 'obtained', 'per', 'subject', 'word', 'worthwhile', 'pay', 'cost', 'matching', 'take', 'full', 'advantage', 'information', 'collected']"
839,Example: 	Illustrate the mother?s age by physician visit interaction. First create a data set with the plotting points for the interaction. Score the data set with the plotting points and plot the predicted logits and predicted probabilities by the plotting points. /* c1demo07a */ proc univariate data=sasuser.birth; var mother_age; run; Partial Output Quantile Estimate,CD,371,"['example', '\tillustrate', 'mother', 'age', 'physician', 'visit', 'interaction', 'first', 'create', 'data_set', 'plotting', 'point', 'interaction', 'score', 'data_set', 'plotting', 'point', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', '', 'c1demo07a', '', 'proc', 'univariate', 'datasasuserbirth', 'var', 'motherage', 'run', 'partial', 'output', 'quantile', 'estimate']"
840,"A key component of exploratory data analysis is to graphically examine the relationship between the response variable and the predictor variables. In linear regression, it is standard practice to examine scatter plots of the response variable and the continuous predictor variables. However, when the response variable is a binary variable, these scatter plots are not very useful. A more enlightening scatter plot for logistic regression is to transform the vertical axis to the logit scale and plot the logit by the continuous predictor variable. In this way you can check the assumption of linearity in the logit (Hosmer and Lemeshow 2000).",CD,643,"['key', 'component', 'exploratory', 'data', 'analysis', 'graphically', 'examine', 'relationship', 'response_variable', 'predictor_variable', 'linear', 'regression', 'standard', 'practice', 'examine', 'scatter', 'plot', 'response_variable', 'continuous', 'predictor_variable', 'however', 'response_variable', 'binary', 'variable', 'scatter', 'plot', 'useful', 'enlightening', 'scatter', 'plot', 'logistic_regression', 'transform', 'vertical', 'axis', 'logit', 'scale', 'plot', 'logit', 'continuous', 'predictor_variable', 'way', 'check', 'assumption', 'linearity', 'logit', 'hosmer', 'lemeshow', '2000']"
841,"Because the GEE method is semiparametric (not nonparametric), the mean model and variance function needs to be correctly specified. Consistent results of the GEE models depend on the correct specification of the model for the mean. Furthermore, robust standard errors should only be used with a large number of subjects. Park (1993) compared GEE estimators with normal-theory maximum likelihood estimators and reported that GEE estimators were more sensitive to the occurrence of missing data. Several studies have shown that the bias and efficiency of the GEE method may depend on the number of subjects, number of repeated measurements, magnitudes of the correlations among repeated measurements, and number and type of covariates. Lipsitz et al. (1991) reported that the parameter estimates for a binary GEE model were biased slightly upward and the bias increased as the magnitude of the correlation increased. Paik (1988) reported that as the number of covariates increases, the number of subjects needs to increase for the point estimates and confidence intervals to perform satisfactorily (with 4 repeated measurements and 4 covariates, he recommended a sample size over 50). ?	One solution to the MCAR limitation is to use the MI procedure to impute the missing values. PROC MI invokes the MAR assumption. Then fit the GEE model in PROC GENMOD on the complete data.",CD,1373,"['gee', 'method', 'semiparametric', 'nonparametric', 'mean', 'model', 'variance', 'function', 'need', 'correctly', 'specified', 'consistent', 'result', 'gee', 'model', 'depend', 'correct', 'specification', 'model', 'mean', 'furthermore', 'robust', 'standard_error', 'used', 'large', 'number', 'subject', 'park', '1993', 'compared', 'gee', 'estimator', 'normaltheory', 'maximum', 'likelihood', 'estimator', 'reported', 'gee', 'estimator', 'sensitive', 'occurrence', 'missing', 'data', 'several', 'study', 'shown', 'bias', 'efficiency', 'gee', 'method', 'may', 'depend', 'number', 'subject', 'number', 'repeated', 'measurement', 'magnitude', 'correlation', 'among', 'repeated', 'measurement', 'number', 'type', 'covariates', 'lipsitz', 'et', 'al', '1991', 'reported', 'parameter_estimate', 'binary', 'gee', 'model', 'biased', 'slightly', 'upward', 'bias', 'increased', 'magnitude', 'correlation', 'increased', 'paik', '1988', 'reported', 'number', 'covariates', 'increase', 'number', 'subject', 'need', 'increase', 'point', 'estimate', 'confidence', 'interval', 'perform', 'satisfactorily', '4', 'repeated', 'measurement', '4', 'covariates', 'recommended', 'sample_size', '50', '\tone', 'solution', 'mcar', 'limitation', 'use', 'mi', 'procedure', 'impute', 'missing', 'value', 'proc', 'mi', 'invokes', 'mar', 'assumption', 'fit', 'gee', 'model', 'proc', 'genmod', 'complete', 'data']"
842,"Optimization Technique Newton-Raphson ridge Because the number of parameters is less than 40, the Newton-Raphson with ridging optimization technique is used to obtain the maximum likelihood parameter estimates. Number of Observations Read 112 Number of Observations Used 112",CD,274,"['optimization', 'technique', 'newtonraphson', 'ridge', 'number', 'parameter', 'le', '40', 'newtonraphson', 'ridging', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'parameter_estimate', 'number', 'observation', 'read', '112', 'number', 'observation', 'used', '112']"
843,"GEE regression models extend the generalized linear model, which is an extension of the traditional linear model. Generalized linear models extend the general linear model in several ways. 1.	The link function allows a wide variety of response variables to be modeled rather than just continuous response variables. For example, if the mean of the data is naturally restricted to a range of values such as a proportion, the appropriate link function ensures that the predicted values are within the appropriate range. 2.	The variance can be a specified function of the mean rather than just being constant. 3.	The distribution of error terms can come from a family of exponential distributions rather than just the normal distribution.",CD,735,"['gee', 'regression_model', 'extend', 'generalized', 'linear', 'model', 'extension', 'traditional', 'linear', 'model', 'generalized', 'linear', 'model', 'extend', 'general', 'linear', 'model', 'several', 'way', '1\tthe', 'link', 'function', 'allows', 'wide', 'variety', 'response_variable', 'modeled', 'rather', 'continuous', 'response_variable', 'example', 'mean', 'data', 'naturally', 'restricted', 'range', 'value', 'proportion', 'appropriate', 'link', 'function', 'ensures', 'predicted', 'value', 'within', 'appropriate', 'range', '2\tthe', 'variance', 'specified', 'function', 'mean', 'rather', 'constant', '3\tthe', 'distribution', 'error', 'term', 'come', 'family', 'exponential', 'distribution', 'rather', 'normal', 'distribution']"
844,Matching is carried out in the design phase of the study where you want to balance two or more groups with respect to one or more risk factors that are either known or thought to be associated with the outcome.,CD,210,"['matching', 'carried', 'design', 'phase', 'study', 'want', 'balance', 'two', 'group', 'respect', 'one', 'risk', 'factor', 'either', 'known', 'thought', 'associated', 'outcome']"
845,Cases are allocated to classes based on cutoff values of the predicted probability. The steps include the following: 1.	Estimate the predicted probability of class 1 for each case by the logistic regression model. 2.	Choose a cutoff probability. 3.	Assign cases to class 1 if their estimated predicted probability exceeds the cutoff; otherwise assign the case to class 0.,CD,371,"['case', 'allocated', 'class', 'based', 'cutoff', 'value', 'predicted', 'probability', 'step', 'include', 'following', '1\testimate', 'predicted', 'probability', 'class', '1', 'case', 'logistic_regression_model', '2\tchoose', 'cutoff', 'probability', '3\tassign', 'case', 'class', '1', 'estimated', 'predicted', 'probability', 'exceeds', 'cutoff', 'otherwise', 'assign', 'case', 'class', '0']"
846,"Mother_age is the matching variable that is constant within the strata. Therefore, the parameter estimate for Mother_age is 0. The matching variable can be used in interactions however. Model Fit Statistics",CD,206,"['motherage', 'matching', 'variable', 'constant', 'within', 'stratum', 'therefore', 'parameter_estimate', 'motherage', '0', 'matching', 'variable', 'used', 'interaction', 'however', 'model', 'fit', 'statistic']"
847,where is the diagonal elements of the hat matrix and is the change in the Pearson chi- square due to the deleted observation. The formula illustrates that the c diagnostic statistic can be large due to either lack-of-fit (large difchisq) or high leverage (large hat diagonal). Regression Diagnostics,CD,299,"['diagonal', 'element', 'hat', 'matrix', 'change', 'pearson', 'chi', 'square', 'due', 'deleted', 'observation', 'formula', 'illustrates', 'c', 'diagnostic', 'statistic', 'large', 'due', 'either', 'lackoffit', 'large', 'difchisq', 'high', 'leverage', 'large', 'hat', 'diagonal', 'regression', 'diagnostics']"
848,"The routine use of matching is seldom justified (Rothman 1986). For example, if matching does not improve study efficiency, then the effort expended in finding matched subjects would have been better spent in gathering information for a greater number of unmatched subjects. Furthermore, matching does not prevent confounding but rather introduces confounding. Therefore, it is recommended to use an analysis that removes the confounding by the matching factors since matching might cause confounding even when none existed. Finally, matching might lead to overmatching which will increase the number of uninformative strata and decrease study efficiency. For example, matching on a variable that has a strong correlation with an important exposure variable and that has no relation to the outcome might lead to overmatching because it will lead to relatively few informative strata with no offsetting gain (Rothman 1986). Kleinbaum (1991) recommends that the safest strategy is to match only on strong risk factors expected to cause confounding in the data.",CD,1058,"['routine', 'use', 'matching', 'seldom', 'justified', 'rothman', '1986', 'example', 'matching', 'doe', 'improve', 'study', 'efficiency', 'effort', 'expended', 'finding', 'matched', 'subject', 'would', 'better', 'spent', 'gathering', 'information', 'greater', 'number', 'unmatched', 'subject', 'furthermore', 'matching', 'doe', 'prevent', 'confounding', 'rather', 'introduces', 'confounding', 'therefore', 'recommended', 'use', 'analysis', 'remove', 'confounding', 'matching', 'factor', 'since', 'matching', 'might', 'cause', 'confounding', 'even', 'none', 'existed', 'finally', 'matching', 'might', 'lead', 'overmatching', 'increase', 'number', 'uninformative', 'stratum', 'decrease', 'study', 'efficiency', 'example', 'matching', 'variable', 'ha', 'strong', 'correlation', 'important', 'exposure', 'variable', 'ha', 'relation', 'outcome', 'might', 'lead', 'overmatching', 'lead', 'relatively', 'informative', 'stratum', 'offsetting', 'gain', 'rothman', '1986', 'kleinbaum', '1991', 'recommends', 'safest', 'strategy', 'match', 'strong', 'risk', 'factor', 'expected', 'cause', 'confounding', 'data']"
849,"The conditional logistic model takes into account the dependence of the matched pairs with the stratum-specific intercepts. Ignoring the strata will bias the inferences just like ignoring the clusters in the GEE models. However, dummy-coding the strata is not satisfactory either, unless there is a small number of clusters and a large number of observations per cluster. In the asymptotic theory of maximum likelihood estimation, it is assumed that as the number of observations gets large the number of parameters remains constant. In a matched 1:1 case-control study, you would have to estimate n-1 intercepts (n equaling the number of strata). This leads to the incidental parameters problem where the number of parameters increases as the number of observations increases (Kalbfleisch and Sprott 1970). This will lead to very substantial bias in the parameter estimates because you need a large sample size relative to the number of parameters.",CD,949,"['conditional', 'logistic', 'model', 'take', 'account', 'dependence', 'matched', 'pair', 'stratumspecific', 'intercept', 'ignoring', 'stratum', 'bias', 'inference', 'like', 'ignoring', 'cluster', 'gee', 'model', 'however', 'dummycoding', 'stratum', 'satisfactory', 'either', 'unless', 'small', 'number', 'cluster', 'large', 'number', 'observation', 'per', 'cluster', 'asymptotic', 'theory', 'maximum', 'likelihood', 'estimation', 'assumed', 'number', 'observation', 'get', 'large', 'number', 'parameter', 'remains', 'constant', 'matched', '11', 'casecontrol', 'study', 'would', 'estimate', 'n1', 'intercept', 'n', 'equaling', 'number', 'stratum', 'lead', 'incidental', 'parameter', 'problem', 'number', 'parameter', 'increase', 'number', 'observation', 'increase', 'kalbfleisch', 'sprott', '1970', 'lead', 'substantial', 'bias', 'parameter_estimate', 'need', 'large', 'sample_size', 'relative', 'number', 'parameter']"
850,Total Proportion Minimum Maximum Minimum Maximum Number Variation of Variation Proportion Second R-squared 1-R**2 Ratio of Explained Explained Explained Eigenvalue for a for a Clusters by Clusters by Clusters by a Cluster in a Cluster Variable Variable,CD,252,"['total', 'proportion', 'minimum', 'maximum', 'minimum', 'maximum', 'number', 'variation', 'variation', 'proportion', 'second', 'rsquared', '1r2', 'ratio', 'explained', 'explained', 'explained', 'eigenvalue', 'cluster', 'cluster', 'cluster', 'cluster', 'cluster', 'variable', 'variable']"
851,"The CONTRAST statement is made up of the following components: label	identifies the contrast in the output. A label is required for every contrast specified, and it must 	be enclosed in quotes. effect	identifies an effect that appears in the MODEL statement. You do not need to include all effects that are included in the MODEL statement. values	identifies the coefficients associated with the effect. To correctly specify your contrast, it is crucial to know the ordering of the parameters within each effect and the variable levels associated with each parameter. If an effect is not specified in the CONTRAST statement, all of its coefficients are set to 0. If too many values are specified for an effect, the extra ones are ignored. If too few values are specified, the remaining ones are set to 0.",CD,803,"['contrast', 'statement', 'made', 'following', 'component', 'label\tidentifies', 'contrast', 'output', 'label', 'required', 'every', 'contrast', 'specified', 'must', '\tbe', 'enclosed', 'quote', 'effect\tidentifies', 'effect', 'appears', 'model_statement', 'need', 'include', 'effect', 'included', 'model_statement', 'values\tidentifies', 'coefficient', 'associated', 'effect', 'correctly', 'specify', 'contrast', 'crucial', 'know', 'ordering', 'parameter', 'within', 'effect', 'variable', 'level', 'associated', 'parameter', 'effect', 'specified', 'contrast', 'statement', 'coefficient', 'set', '0', 'many', 'value', 'specified', 'effect', 'extra', 'one', 'ignored', 'value', 'specified', 'remaining', 'one', 'set', '0']"
852,"The above graph reveals a cubic relationship between the response variable and the predictor variable. Adding higher order terms for the predictor variable may approximate this relationship, but polynomials have some undesirable properties (undesirable peaks and valleys) and may not adequately fit many functional forms (Magee 1998). Developing a model with a linear spline function may be a better option (Harrell 1997).",CD,422,"['graph', 'reveals', 'cubic', 'relationship', 'response_variable', 'predictor_variable', 'adding', 'higher', 'order', 'term', 'predictor_variable', 'may', 'approximate', 'relationship', 'polynomial', 'undesirable', 'property', 'undesirable', 'peak', 'valley', 'may', 'adequately', 'fit', 'many', 'functional', 'form', 'magee', '1998', 'developing', 'model', 'linear', 'spline', 'function', 'may', 'better', 'option', 'harrell', '1997']"
853,"Stepwise selection is similar to forward selection in that it starts with an empty model and incrementally builds a model one variable at a time. However, the method differs from forward selection in that variables already in the model do not necessarily remain. The backward component of the method removes variables from the model that do not meet the significance criteria specified in the SLSTAY= option. The stepwise selection process terminates if no further variable can be added to the model or if the variable just entered into the model is the only variable removed in the subsequent backward elimination. Stepwise selection in PROC LOGISTIC is not an efficient method to select variables. In fact, its performance acutely deteriorates if the full model has over approximately 60 effects (Potts and Patetta 1999). Stepwise selection has some serious shortcomings. Simulation studies (Derksen and Keselman 1992) evaluating variable selection techniques found the following: 1.	The degree of collinearity among the predictor variables affected the frequency with which authentic predictor variables found their way into the final model. 2.	The number of candidate predictor variables affected the number of noise variables that gained entry to the model. 3.	The size of the sample was of little practical importance in determining the number of authentic variables contained in the final model. One recommendation is to use the variable selection methods to create several candidate models, and then use subject-matter knowledge to select the variables that result in the best model within the scientific or business context of the problem. Therefore, you are simply using these methods as a useful tool in the model-building process (Hosmer and Lemeshow 2000).",CD,1769,"['stepwise', 'selection', 'similar', 'forward', 'selection', 'start', 'empty', 'model', 'incrementally', 'build', 'model', 'one', 'variable', 'time', 'however', 'method', 'differs', 'forward', 'selection', 'variable', 'already', 'model', 'necessarily', 'remain', 'backward', 'component', 'method', 'remove', 'variable', 'model', 'meet', 'significance', 'criterion', 'specified', 'slstay', 'option', 'stepwise', 'selection', 'process', 'terminates', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'variable', 'removed', 'subsequent', 'backward', 'elimination', 'stepwise', 'selection', 'proc_logistic', 'efficient', 'method', 'select', 'variable', 'fact', 'performance', 'acutely', 'deteriorates', 'full', 'model', 'ha', 'approximately', '60', 'effect', 'potts', 'patetta', '1999', 'stepwise', 'selection', 'ha', 'serious', 'shortcoming', 'simulation', 'study', 'derksen', 'keselman', '1992', 'evaluating', 'variable', 'selection', 'technique', 'found', 'following', '1\tthe', 'degree', 'collinearity', 'among', 'predictor_variable', 'affected', 'frequency', 'authentic', 'predictor_variable', 'found', 'way', 'final', 'model', '2\tthe', 'number', 'candidate', 'predictor_variable', 'affected', 'number', 'noise', 'variable', 'gained', 'entry', 'model', '3\tthe', 'size', 'sample', 'wa', 'little', 'practical', 'importance', 'determining', 'number', 'authentic', 'variable', 'contained', 'final', 'model', 'one', 'recommendation', 'use', 'variable', 'selection', 'method', 'create', 'several', 'candidate', 'model', 'use', 'subjectmatter', 'knowledge', 'select', 'variable', 'result', 'best', 'model', 'within', 'scientific', 'business', 'context', 'problem', 'therefore', 'simply', 'using', 'method', 'useful', 'tool', 'modelbuilding', 'process', 'hosmer', 'lemeshow', '2000']"
854,"When building a model, it is critical that you assess the need to include interaction terms among the predictor variables. One recommendation is to assess only those interactions that are specified a priori based on subject-matter knowledge. To assess the significance of the interaction, compute a likelihood ratio test that compares the model with the interaction to the model with the main effects only. The degrees of freedom would be the difference in the number of variables. If the p-value is below a specified significance level, then you may want to include the interaction term in the final model. However, the final decision as to whether an interaction term should be included in a model should be based on statistical as well as practical considerations. In other words, the interaction term must make sense from a subject-matter point of view (Hosmer and Lemeshow 2000).",CD,884,"['building', 'model', 'critical', 'ass', 'need', 'include', 'interaction', 'term', 'among', 'predictor_variable', 'one', 'recommendation', 'ass', 'interaction', 'specified', 'priori', 'based', 'subjectmatter', 'knowledge', 'ass', 'significance', 'interaction', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'model', 'interaction', 'model', 'main_effect', 'degree', 'freedom', 'would', 'difference', 'number', 'variable', 'pvalue', 'specified', 'significance', 'level', 'may', 'want', 'include', 'interaction', 'term', 'final', 'model', 'however', 'final', 'decision', 'whether', 'interaction', 'term', 'included', 'model', 'based', 'statistical', 'well', 'practical', 'consideration', 'word', 'interaction', 'term', 'must', 'make', 'sense', 'subjectmatter', 'point', 'view', 'hosmer', 'lemeshow', '2000']"
855,"Logits modeled use food='Fish' as the reference category. The first part of the output is similar to the output for the binary logit model. Because the MODEL statement option REF='Fish', the response category Fish is used as the reference category. Class Level Information",CD,272,"['logits', 'modeled', 'use', 'foodfish', 'reference', 'category', 'first', 'part', 'output', 'similar', 'output', 'binary', 'logit', 'model', 'model_statement', 'option', 'reffish', 'response', 'category', 'fish', 'used', 'reference', 'category', 'class', 'level', 'information']"
856,The overlay plot of the ROC curves clearly shows that the model with the interaction is the superior model with regard to predictive accuracy. 2.2	Logistic Regression Diagnostics,CD,178,"['overlay', 'plot', 'roc', 'curve', 'clearly', 'show', 'model', 'interaction', 'superior', 'model', 'regard', 'predictive', 'accuracy', '22\tlogistic', 'regression', 'diagnostics']"
857,"The process of fitting a GEE model can be summarized in a series of steps. First, a regression model is fitted that assumes independence and the Pearson standardized residuals are computed. These residuals are then used to estimate the parameters of the correlation matrix, which characterizes the correlation of the observations within subject. The correlation parameters are then incorporated into the GEE estimating equations, which generates new values for the regression coefficients and new Pearson residuals. These residuals are then used to re-estimate the correlation parameters. The cyclical process continues until the parameter estimates stabilize and model convergence is achieved. !	For more information, see the SAS online documentation.",CD,752,"['process', 'fitting', 'gee', 'model', 'summarized', 'series', 'step', 'first', 'regression_model', 'fitted', 'assumes', 'independence', 'pearson', 'standardized', 'residual', 'computed', 'residual', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'characterizes', 'correlation', 'observation', 'within', 'subject', 'correlation', 'parameter', 'incorporated', 'gee', 'estimating', 'equation', 'generates', 'new', 'value', 'regression', 'coefficient', 'new', 'pearson', 'residual', 'residual', 'used', 'reestimate', 'correlation', 'parameter', 'cyclical', 'process', 'continues', 'parameter_estimate', 'stabilize', 'model', 'convergence', 'achieved', '\tfor', 'information', 'see', 'sa', 'online', 'documentation']"
858,"Example: 	Select a subset of variables using the forward selection method. In the MODEL statement specify all the main effects and two-factor interactions. Examine the differences in which variables were selected when you use HIERARCHY=SINGLE and when you include all the main effects in the model to assess interactions. /* c1demo04a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age|phy_visit|alcohol|hist_hyp| mother_wt|prev_pretrm|socio|uterine_irr @2 / selection=forward slentry=.05 hierarchy=single; title 'Low Birth Weight Model'; run; Selected MODEL statement options: SELECTION= 	specifies the method used to select the variables in the model. SLENTRY=	specifies the significance level for entry into the model. HIERARCHY=	specifies how model hierarchy is to be applied. Available methods are NONE, SINGLE, MULTIPLE, SINGLECLASS (same as HIERACHY=SINGLE except only class variables are subject to the hierarchy requirement), and MULTIPLECLASS (same as HIERACHY=MULTIPLE except only the class variables are subject to the hierarchy requirement). ?	The bar notation with @2 constructs a model with all the main effects and the two-factor interactions. If you increased it to @3, then you would construct a model with all of the main effects, the two-factor interactions, and the three factor interactions. Low Birth Weight Model",CD,1354,"['example', '\tselect', 'subset', 'variable', 'using', 'forward', 'selection', 'method', 'model_statement', 'specify', 'main_effect', 'twofactor', 'interaction', 'examine', 'difference', 'variable', 'selected', 'use', 'hierarchysingle', 'include', 'main_effect', 'model', 'ass', 'interaction', '', 'c1demo04a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motheragephyvisitalcoholhisthyp', 'motherwtprevpretrmsociouterineirr', '2', '', 'selectionforward', 'slentry05', 'hierarchysingle', 'title', 'low', 'birth', 'weight', 'model', 'run', 'selected', 'model_statement', 'option', 'selection', '\tspecifies', 'method', 'used', 'select', 'variable', 'model', 'slentry\tspecifies', 'significance', 'level', 'entry', 'model', 'hierarchy\tspecifies', 'model', 'hierarchy', 'applied', 'available', 'method', 'none', 'single', 'multiple', 'singleclass', 'hierachysingle', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', 'multipleclass', 'hierachymultiple', 'except', 'class', 'variable', 'subject', 'hierarchy', 'requirement', '\tthe', 'bar', 'notation', '2', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'increased', '3', 'would', 'construct', 'model', 'main_effect', 'twofactor', 'interaction', 'three', 'factor', 'interaction', 'low', 'birth', 'weight', 'model']"
859,"All of the binary predictors were assessed for interactions. None of the Breslow-Day statistics with the Tarone?s adjustment were significant. However, several contingency tables had 0 cell counts, which cause some instability in the model if the interactions with the 0 cell counts are entered in the model. Furthermore, some of the sample sizes are not large enough for the Breslow-Day statistics to be valid.",CD,411,"['binary', 'predictor', 'assessed', 'interaction', 'none', 'breslowday', 'statistic', 'tarones', 'adjustment', 'significant', 'however', 'several', 'contingency', 'table', '0', 'cell', 'count', 'cause', 'instability', 'model', 'interaction', '0', 'cell', 'count', 'entered', 'model', 'furthermore', 'sample_size', 'large', 'enough', 'breslowday', 'statistic', 'valid']"
860,"In a matched case-control study, the conditional likelihood allows the model to predict the odds for the event given the predictor variable values. This involves setting up the probabilities for having the observed predictor variable values given the event and then using Bayes? theorem to determine a relevant conditional probability concerning the event. The conditional likelihood is derived by computing the conditional probability of observing the predictor variable values given the outcome (event or not). A predictor variable that is constant within a stratum cancels out of the conditional likelihood. This is the reason why the conditional logistic models cannot estimate a between-cluster effect. Statistics providing information about the between-cluster effect use subject totals at different levels of the relevant predictor variable. However, those totals sum the sufficient statistics for the stratum- specific intercepts, so they themselves are fixed and have degenerate distributions after conditioning on the sufficient statistics (Agresti 2002). Note that the conditional likelihood for the 1:1 matched case-control data is the unconditional likelihood for a logistic regression model where the response is always equal to 1, the predictor variable values are equal to the differences between the values for the case and the control, and there is no intercept. Before SAS?9, you could use PROC LOGISTIC by configuring your data appropriately and eliminating the intercept term. However, you would have to use PROC PHREG for 1:m and m:n matching.",CD,1565,"['matched', 'casecontrol', 'study', 'conditional', 'likelihood', 'allows', 'model', 'predict', 'odds', 'event', 'given', 'predictor_variable', 'value', 'involves', 'setting', 'probability', 'observed', 'predictor_variable', 'value', 'given', 'event', 'using', 'bayes', 'theorem', 'determine', 'relevant', 'conditional', 'probability', 'concerning', 'event', 'conditional', 'likelihood', 'derived', 'computing', 'conditional', 'probability', 'observing', 'predictor_variable', 'value', 'given', 'outcome', 'event', 'predictor_variable', 'constant', 'within', 'stratum', 'cancel', 'conditional', 'likelihood', 'reason', 'conditional', 'logistic', 'model', 'cannot', 'estimate', 'betweencluster', 'effect', 'statistic', 'providing', 'information', 'betweencluster', 'effect', 'use', 'subject', 'total', 'different', 'level', 'relevant', 'predictor_variable', 'however', 'total', 'sum', 'sufficient', 'statistic', 'stratum', 'specific', 'intercept', 'fixed', 'degenerate', 'distribution', 'conditioning', 'sufficient', 'statistic', 'agresti', '2002', 'note', 'conditional', 'likelihood', '11', 'matched', 'casecontrol', 'data', 'unconditional', 'likelihood', 'logistic_regression_model', 'response', 'always', 'equal', '1', 'predictor_variable', 'value', 'equal', 'difference', 'value', 'case', 'control', 'intercept', 'sas9', 'could', 'use', 'proc_logistic', 'configuring', 'data', 'appropriately', 'eliminating', 'intercept', 'term', 'however', 'would', 'use', 'proc', 'phreg', '1m', 'mn', 'matching']"
861,"Provided that the mean model is correctly specified and the measurements between subjects are independent, robust standard errors ensure consistent inferences from a GEE regression model even if the chosen correlation structure is incorrect or if the strength of the correlation between measurements varies from subject to subject. Although model-based standard errors are also produced, they are only consistent if the specified correlation structure is correct. Consequently, the robust standard errors, which are usually larger, are usually preferred especially when the number of clusters is large. The desired number of clusters depends on the number of predictor variables in the model. If you have fewer than 5 predictor variables, approximately 25 clusters might be enough to use the robust standard errors. If you have 5 to 12 predictor variables, then you need at least 100 clusters. If you want to be reasonably confident, then you need around 200 clusters (Stokes, Davis, Koch 2000). However, when the number of clusters is very small (less than 20), the model-based standard errors might have better properties even if the specified correlation structure is wrong (Prentice 1988). This is because the robust standard errors are asymptotically unbiased, but could be highly biased when the number of clusters is small. Robust standard errors are derived by the sandwich estimator of the covariance matrix of the regression coefficients. In general, the sandwich estimator uses a matrix with the diagonal elements equal to the individual squared residuals to estimate the common variance (the square of any residual is an estimate of the variance at that predictor variable value). This works because the average of a lot of poor estimators (individual squared residuals) can be a good estimator of the common variance. In fact, Liang and Zeger (1986) showed that the robust standard errors are robust to departures of the working correlation matrix from the true correlation structure.",CD,1997,"['provided', 'mean', 'model', 'correctly', 'specified', 'measurement', 'subject', 'independent', 'robust', 'standard_error', 'ensure', 'consistent', 'inference', 'gee', 'regression_model', 'even', 'chosen', 'correlation_structure', 'incorrect', 'strength', 'correlation', 'measurement', 'varies', 'subject', 'subject', 'although', 'modelbased', 'standard_error', 'also', 'produced', 'consistent', 'specified', 'correlation_structure', 'correct', 'consequently', 'robust', 'standard_error', 'usually', 'larger', 'usually', 'preferred', 'especially', 'number', 'cluster', 'large', 'desired', 'number', 'cluster', 'depends', 'number', 'predictor_variable', 'model', 'fewer', '5', 'predictor_variable', 'approximately', '25', 'cluster', 'might', 'enough', 'use', 'robust', 'standard_error', '5', '12', 'predictor_variable', 'need', 'least', '100', 'cluster', 'want', 'reasonably', 'confident', 'need', 'around', '200', 'cluster', 'stokes', 'davis', 'koch', '2000', 'however', 'number', 'cluster', 'small', 'le', '20', 'modelbased', 'standard_error', 'might', 'better', 'property', 'even', 'specified', 'correlation_structure', 'wrong', 'prentice', '1988', 'robust', 'standard_error', 'asymptotically', 'unbiased', 'could', 'highly', 'biased', 'number', 'cluster', 'small', 'robust', 'standard_error', 'derived', 'sandwich', 'estimator', 'covariance', 'matrix', 'regression', 'coefficient', 'general', 'sandwich', 'estimator', 'us', 'matrix', 'diagonal', 'element', 'equal', 'individual', 'squared', 'residual', 'estimate', 'common', 'variance', 'square', 'residual', 'estimate', 'variance', 'predictor_variable', 'value', 'work', 'average', 'lot', 'poor', 'estimator', 'individual', 'squared', 'residual', 'good', 'estimator', 'common', 'variance', 'fact', 'liang', 'zeger', '1986', 'showed', 'robust', 'standard_error', 'robust', 'departure', 'working', 'correlation', 'matrix', 'true', 'correlation_structure']"
862,"An estimator of a parameter is said to be median unbiased if 	 and	 The formula shows that if the probability is greater than or equal to .50 on both sides of beta, then the estimated beta is median unbiased. The median unbiased estimators (MUE) of the parameters of a logistic model can be computed from the distribution of sufficient statistics for the parameters. A Newton-Raphson-type algorithm is used to perform the search for the MUE that corresponds to the median of the conditional distribution of the sufficient statistics for the parameters. Hirji, Tsiatis, and Mehta (1989) compared the accuracy of the MUE with that of the maximum likelihood estimator (MLE) for a logistic regression model with two binary covariates. The MUE was shown to be uniformly more accurate than MLE for small to moderately large sample sizes and a broad range of parameter values. The authors recommend that median unbiased estimation be used as an alternative to maximum likelihood estimation when the data structure is sparse.",CD,1017,"['estimator', 'parameter', 'said', 'median', 'unbiased', '\t', 'and\t', 'formula', 'show', 'probability', 'greater', 'equal', '50', 'side', 'beta', 'estimated', 'beta', 'median', 'unbiased', 'median', 'unbiased', 'estimator', 'mue', 'parameter', 'logistic', 'model', 'computed', 'distribution', 'sufficient', 'statistic', 'parameter', 'newtonraphsontype', 'algorithm', 'used', 'perform', 'search', 'mue', 'corresponds', 'median', 'conditional', 'distribution', 'sufficient', 'statistic', 'parameter', 'hirji', 'tsiatis', 'mehta', '1989', 'compared', 'accuracy', 'mue', 'maximum', 'likelihood', 'estimator', 'mle', 'logistic_regression_model', 'two', 'binary', 'covariates', 'mue', 'wa', 'shown', 'uniformly', 'accurate', 'mle', 'small', 'moderately', 'large', 'sample_size', 'broad', 'range', 'parameter', 'value', 'author', 'recommend', 'median', 'unbiased', 'estimation', 'used', 'alternative', 'maximum', 'likelihood', 'estimation', 'data', 'structure', 'sparse']"
863,"Because the response variable (painseverity) is an ordinal variable, you should analyze it as an ordinal variable. Do not dichotomize the outcome variable because that would lower the power of your hypothesis tests, especially the Wald tests for the parameter estimates of your predictor variables (Allison 1999). In some situations with a continuous outcome, there is a restricted range of values because of the limitations of the measuring techniques. This is a common feature in bioassay analyses. With restricted ranges, there is usually a lower limit of quantification (LOQ) and an upper limit of quantification. For example, suppose that the response variable had a lower LOQ of 300 and the upper LOQ of 900. Analyzing the response variable as continuous might not be optimal given the truncated nature of the distribution. An alternative way to analyze a continuous variable with a restricted range is to create ordered categories and fit an ordinal logistic regression model.",CD,983,"['response_variable', 'painseverity', 'ordinal', 'variable', 'analyze', 'ordinal', 'variable', 'dichotomize', 'outcome', 'variable', 'would', 'lower', 'power', 'hypothesis', 'test', 'especially', 'wald', 'test', 'parameter_estimate', 'predictor_variable', 'allison', '1999', 'situation', 'continuous', 'outcome', 'restricted', 'range', 'value', 'limitation', 'measuring', 'technique', 'common', 'feature', 'bioassay', 'analysis', 'restricted', 'range', 'usually', 'lower', 'limit', 'quantification', 'loq', 'upper', 'limit', 'quantification', 'example', 'suppose', 'response_variable', 'lower', 'loq', '300', 'upper', 'loq', '900', 'analyzing', 'response_variable', 'continuous', 'might', 'optimal', 'given', 'truncated', 'nature', 'distribution', 'alternative', 'way', 'analyze', 'continuous', 'variable', 'restricted', 'range', 'create', 'ordered', 'category', 'fit', 'ordinal', 'logistic_regression_model']"
864,"Logits modeled use food='Fish' as the reference category. The first part of the output is similar to the output for the binary logit model. Because the MODEL statement option REF='Fish', the response category Fish is used as the reference category. Class Level Information",CD,272,"['logits', 'modeled', 'use', 'foodfish', 'reference', 'category', 'first', 'part', 'output', 'similar', 'output', 'binary', 'logit', 'model', 'model_statement', 'option', 'reffish', 'response', 'category', 'fish', 'used', 'reference', 'category', 'class', 'level', 'information']"
865,"MAXEIGEN=n	specifies the largest permissible value of the second eigenvalue in each cluster. SHORT	suppresses printing of the cluster structure, scoring coefficient, and intercluster correlation matrices. Selected VARCLUS procedure statement: VAR	specifies the variables to be clustered. If you do not specify the VAR statement, all numeric variables not listed in other statements are processed. Variable Clustering",CD,416,"['maxeigenn\tspecifies', 'largest', 'permissible', 'value', 'second', 'eigenvalue', 'cluster', 'short\tsuppresses', 'printing', 'cluster', 'structure', 'scoring', 'coefficient', 'intercluster', 'correlation', 'matrix', 'selected', 'varclus', 'procedure', 'statement', 'var\tspecifies', 'variable', 'clustered', 'specify', 'var', 'statement', 'numeric', 'variable', 'listed', 'statement', 'processed', 'variable', 'clustering']"
866,"In Chapter 1, you saw how the quasi-complete separation of data points leads to convergence problems in logistic regression. In the example above, level B is a perfect predictor of the outcome. In this situation, the log-likelihood function cannot be maximized but approaches a finite upper bound as the parameter estimate for B goes to negative infinity. You cannot evaluate the first and second derivatives of the log-likelihood at the maximum likelihood estimates, and it is not possible to estimate the parameter estimate for the contrast of level B to C or its confidence interval by conventional maximum likelihood methods. However, exact inference is possible and can provide valid inferences in this situation. Notice that the contrast of level B to C had a p-value approaching 1 with the asymptotic methods but is statistically significant with the exact methods. Note that the exact tests do not produce standard errors for the estimates. Furthermore, the parameter estimate for the contrast of level B to C is a median unbiased estimate, which will be discussed later. ?	In SAS 9.2 PROC LOGISTIC will compute standard errors for the exact estimates.",CD,1160,"['chapter', '1', 'saw', 'quasicomplete', 'separation', 'data', 'point', 'lead', 'convergence', 'problem', 'logistic_regression', 'example', 'level', 'b', 'perfect', 'predictor', 'outcome', 'situation', 'loglikelihood', 'function', 'cannot', 'maximized', 'approach', 'finite', 'upper', 'bound', 'parameter_estimate', 'b', 'go', 'negative', 'infinity', 'cannot', 'evaluate', 'first', 'second', 'derivative', 'loglikelihood', 'maximum', 'likelihood', 'estimate', 'possible', 'estimate', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'confidence', 'interval', 'conventional', 'maximum', 'likelihood', 'method', 'however', 'exact', 'inference', 'possible', 'provide', 'valid', 'inference', 'situation', 'notice', 'contrast', 'level', 'b', 'c', 'pvalue', 'approaching', '1', 'asymptotic', 'method', 'statistically', 'significant', 'exact', 'method', 'note', 'exact', 'test', 'produce', 'standard_error', 'estimate', 'furthermore', 'parameter_estimate', 'contrast', 'level', 'b', 'c', 'median', 'unbiased', 'estimate', 'discussed', 'later', '\tin', 'sa', '92', 'proc_logistic', 'compute', 'standard_error', 'exact', 'estimate']"
867,"PROC LOGISTIC also produces statistics that measure predictive power. These statistics are not the same as the goodness-of-fit statistics because models with high predictive power do not necessarily have a good fit to the data (and vice versa). One statistic that measures predictive power is the generalized R2. It is based on the likelihood ratio chi-square for testing the null hypothesis that all of the slope parameters are 0. However, it uses the likelihood values (L1 and L0) rather than the log- likelihood values and it is adjusted by the sample size n. It can be interpreted in the same way as the rank correlation statistics in PROC LOGISTIC. The higher the statistic, the more predictive power your model has. However, it cannot be interpreted as the proportion of variance explained by the predictor variables. Therefore, it is inappropriate to compare the generalized R2 to the linear model?s R2 (Allison 1999). Goodness-of-Fit Statistics and Predictive Power",CD,973,"['proc_logistic', 'also', 'produce', 'statistic', 'measure', 'predictive', 'power', 'statistic', 'goodnessoffit', 'statistic', 'model', 'high', 'predictive', 'power', 'necessarily', 'good', 'fit', 'data', 'vice', 'versa', 'one', 'statistic', 'measure', 'predictive', 'power', 'generalized', 'r2', 'based', 'likelihood', 'ratio', 'chisquare', 'testing', 'null', 'hypothesis', 'slope', 'parameter', '0', 'however', 'us', 'likelihood', 'value', 'l1', 'l0', 'rather', 'log', 'likelihood', 'value', 'adjusted', 'sample_size', 'n', 'interpreted', 'way', 'rank', 'correlation', 'statistic', 'proc_logistic', 'higher', 'statistic', 'predictive', 'power', 'model', 'ha', 'however', 'cannot', 'interpreted', 'proportion', 'variance', 'explained', 'predictor_variable', 'therefore', 'inappropriate', 'compare', 'generalized', 'r2', 'linear', 'model', 'r2', 'allison', '1999', 'goodnessoffit', 'statistic', 'predictive', 'power']"
868,"In GEE regression models, the number of observations is not the number of subjects, but rather the number of measurements taken on all the subjects. The variance-covariance matrix is now a block- diagonal matrix in which the observations within each block (the block corresponds to a subject) are assumed to be correlated and the observations outside of the blocks are assumed to be independent. In other words, the subjects are still assumed to be independent of each other and the measurements within each subject are assumed to be correlated.",CD,545,"['gee', 'regression_model', 'number', 'observation', 'number', 'subject', 'rather', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'block', 'corresponds', 'subject', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'word', 'subject', 'still', 'assumed', 'independent', 'measurement', 'within', 'subject', 'assumed', 'correlated']"
869,"In this course, contrasts are used to compute the odds ratio that compares one level of a CLASS variable to another level. However, in order to construct a contrast, you need to be able to define the coefficients for the test of the hypothesis. For example, to compute the odds ratio that compares low to medium for the variable socio in a CONTRAST statement, you should first write the model equation for each of the levels.",CD,425,"['course', 'contrast', 'used', 'compute', 'odds_ratio', 'compare', 'one', 'level', 'class', 'variable', 'another', 'level', 'however', 'order', 'construct', 'contrast', 'need', 'able', 'define', 'coefficient', 'test', 'hypothesis', 'example', 'compute', 'odds_ratio', 'compare', 'low', 'medium', 'variable', 'socio', 'contrast', 'statement', 'first', 'write', 'model', 'equation', 'level']"
870,"Because the response variable has more than 2 levels, by default PROC LOGISTIC models cumulative logits. With the DESCENDING option, the probabilities modeled are cumulated by the jth category and higher. Score Test for the Proportional Odds Assumption",CD,252,"['response_variable', 'ha', '2', 'level', 'default', 'proc_logistic', 'model', 'cumulative', 'logits', 'descending', 'option', 'probability', 'modeled', 'cumulated', 'jth', 'category', 'higher', 'score', 'test', 'proportional', 'odds', 'assumption']"
871,"Interaction occurs when the relationship between a predictor variable and the response differs by the level of another predictor variable. For example, the graph above shows that the relationship between gender and the response differs by the level of age. Therefore, age modifies the effect of gender and the age*gender interaction should be included in the model. Furthermore, any estimate of the odds ratio for gender should be made with respect to a specific age. It should be noted that when a predictor variable is involved in an interaction, assessing it for confounding is inappropriate. The reason is that when you statistically adjust for the potential confounder, you are assuming that the effect of the predictor variable on the response is the same regardless of the level of the confounder. When interaction is present, that assumption is violated. For binary predictor variables or predictor variables with few unique values, you can assess interactions through stratified data analysis. For continuous predictor variables, you can assess interactions by including them in a multivariate model.",CD,1109,"['interaction', 'occurs', 'relationship', 'predictor_variable', 'response', 'differs', 'level', 'another', 'predictor_variable', 'example', 'graph', 'show', 'relationship', 'gender', 'response', 'differs', 'level', 'age', 'therefore', 'age', 'modifies', 'effect', 'gender', 'agegender', 'interaction', 'included', 'model', 'furthermore', 'estimate', 'odds_ratio', 'gender', 'made', 'respect', 'specific', 'age', 'noted', 'predictor_variable', 'involved', 'interaction', 'assessing', 'confounding', 'inappropriate', 'reason', 'statistically', 'adjust', 'potential', 'confounder', 'assuming', 'effect', 'predictor_variable', 'response', 'regardless', 'level', 'confounder', 'interaction', 'present', 'assumption', 'violated', 'binary', 'predictor_variable', 'predictor_variable', 'unique', 'value', 'ass', 'interaction', 'stratified', 'data', 'analysis', 'continuous', 'predictor_variable', 'ass', 'interaction', 'including', 'multivariate', 'model']"
872,"Quasi-complete separation can also occur when you create interaction terms. The example above shows that there is no separation problem with the predictor variable, but that when you separate it by gender, a 0 cell count occurs. Therefore, the interaction term that consists of the predictor variable and gender should cause some convergence problems in your model.",CD,365,"['quasicomplete', 'separation', 'also', 'occur', 'create', 'interaction', 'term', 'example', 'show', 'separation', 'problem', 'predictor_variable', 'separate', 'gender', '0', 'cell', 'count', 'occurs', 'therefore', 'interaction', 'term', 'consists', 'predictor_variable', 'gender', 'cause', 'convergence', 'problem', 'model']"
873,"All of the binary predictors were assessed for interactions. None of the Breslow-Day statistics with the Tarone?s adjustment were significant. However, several contingency tables had 0 cell counts, which cause some instability in the model if the interactions with the 0 cell counts are entered in the model. Furthermore, some of the sample sizes are not large enough for the Breslow-Day statistics to be valid.",CD,411,"['binary', 'predictor', 'assessed', 'interaction', 'none', 'breslowday', 'statistic', 'tarones', 'adjustment', 'significant', 'however', 'several', 'contingency', 'table', '0', 'cell', 'count', 'cause', 'instability', 'model', 'interaction', '0', 'cell', 'count', 'entered', 'model', 'furthermore', 'sample_size', 'large', 'enough', 'breslowday', 'statistic', 'valid']"
874,"For reference cell coding, parameter estimates of the CLASS main effects estimate the difference between the effect of each level and the last level. For example, the effect for the low level would estimate the difference between low and high. You can choose the reference level with the REF= option.",CD,300,"['reference', 'cell', 'coding', 'parameter_estimate', 'class', 'main_effect', 'estimate', 'difference', 'effect', 'level', 'last', 'level', 'example', 'effect', 'low', 'level', 'would', 'estimate', 'difference', 'low', 'high', 'choose', 'reference', 'level', 'ref', 'option']"
875,Example:	Fit a simple ordinal logistic regression model to the backache data set. Specify painseverity as the response variable and bending as the predictor variable. Also specify the DESCENDING option to reverse the sort order of the response variable. /* c3demo14a */ proc logistic data=sasuser.backache desc; model painseverity=bending; title 'Ordinal Logistic Regression Model for the Backache ' 'Example'; run; PROC LOGISTIC statement option: DESC	reverses the sorting order for the levels of the response variable. This option has the same effect as the response variable option DESCENDING in the MODEL statement. Ordinal Logistic Regression Model for the Backache Example,CD,678,"['example\tfit', 'simple', 'ordinal', 'logistic_regression_model', 'backache', 'data_set', 'specify', 'painseverity', 'response_variable', 'bending', 'predictor_variable', 'also', 'specify', 'descending', 'option', 'reverse', 'sort', 'order', 'response_variable', '', 'c3demo14a', '', 'proc_logistic', 'datasasuserbackache', 'desc', 'model', 'painseveritybending', 'title', 'ordinal', 'logistic_regression_model', 'backache', '', 'example', 'run', 'proc_logistic', 'statement', 'option', 'desc\treverses', 'sorting', 'order', 'level', 'response_variable', 'option', 'ha', 'effect', 'response_variable', 'option', 'descending', 'model_statement', 'ordinal', 'logistic_regression_model', 'backache', 'example']"
876,"The LOGISTIC procedure should not be used to analyze clustered data because PROC LOGISTIC assumes independent observations. In the past, the CATMOD procedure was used to analyze clustered data with a discrete response variable. However, GEE models offer some significant advantages over models fit in PROC CATMOD for the analysis of clustered data. For example, models fit in PROC CATMOD require that the data be balanced. Therefore, the measurements have to occur at the same times for all subjects and each subject has the same number of measurements. PROC CATMOD also uses complete case analysis, where only subjects with data at all time points are used. If a subject has one or more missing measurements, then PROC CATMOD deletes the entire subject. Models fit in PROC CATMOD model the distribution of the response variable (represented by the columns in an underlying contingency table) across the levels of the predictor variables (represented by the rows in an underlying contingency table). Computational difficulties might occur if you have a continuous covariate with a large number of unique values, because many rows will have a sample size of 1. PROC CATMOD might be less efficient and might be unable to allocate sufficient memory to handle this problem. GEE regression models fit in the GENMOD procedure use the all-available pairs method, where all nonmissing pairs of data are used to estimate the parameters in the correlation matrix. If there are missing values, then some correlations are computed using more observations and other correlations are computed using fewer observations.",CD,1604,"['logistic', 'procedure', 'used', 'analyze', 'clustered', 'data', 'proc_logistic', 'assumes', 'independent', 'observation', 'past', 'catmod', 'procedure', 'wa', 'used', 'analyze', 'clustered', 'data', 'discrete', 'response_variable', 'however', 'gee', 'model', 'offer', 'significant', 'advantage', 'model', 'fit', 'proc', 'catmod', 'analysis', 'clustered', 'data', 'example', 'model', 'fit', 'proc', 'catmod', 'require', 'data', 'balanced', 'therefore', 'measurement', 'occur', 'time', 'subject', 'subject', 'ha', 'number', 'measurement', 'proc', 'catmod', 'also', 'us', 'complete', 'case', 'analysis', 'subject', 'data', 'time', 'point', 'used', 'subject', 'ha', 'one', 'missing', 'measurement', 'proc', 'catmod', 'deletes', 'entire', 'subject', 'model', 'fit', 'proc', 'catmod', 'model', 'distribution', 'response_variable', 'represented', 'column', 'underlying', 'contingency', 'table', 'across', 'level', 'predictor_variable', 'represented', 'row', 'underlying', 'contingency', 'table', 'computational', 'difficulty', 'might', 'occur', 'continuous', 'covariate', 'large', 'number', 'unique', 'value', 'many', 'row', 'sample_size', '1', 'proc', 'catmod', 'might', 'le', 'efficient', 'might', 'unable', 'allocate', 'sufficient', 'memory', 'handle', 'problem', 'gee', 'regression_model', 'fit', 'genmod', 'procedure', 'use', 'allavailable', 'pair', 'method', 'nonmissing', 'pair', 'data', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'missing', 'value', 'correlation', 'computed', 'using', 'observation', 'correlation', 'computed', 'using', 'fewer', 'observation']"
877,"The LOGISTIC procedure enables you to specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. Model hierarchy refers to the requirement that for any effect in the model, all effects it contains must also be in the model. For example, in order for the interaction A*B to enter the model, the main effects A and B must be in the model. Model hierarchy is desirable because models that are hierarchically well formulated have inferences that are invariant to the coding you choose for your predictor variables (Kleinbaum, Kupper, and Muller 1988). If the model is not hierarchically well formulated, then the tests for the lower order terms will depend on the coding (reference versus effect coding for categorical variables). The HIERARCHY= option specifies whether hierarchy is maintained and whether a single effect or multiple effects are allowed to enter or leave the model in one step for SELECTION=FORWARD, SELECTION=BACKWARD, and SELECTION=STEPWISE. For HIERARCHY=SINGLE, only one effect can enter or leave the model at one time, subject to model hierarchy. For example, suppose that you specify the main effects A and B and the interaction of A*B in the model. For backward elimination, the interaction A*B must first be removed before the main effects are removed. For forward selection, the main effects must enter the model before the interaction. For HIERARCHY=MULTIPLE, more than one effect can enter or leave the model at one time, subject to model hierarchy. For forward selection, a single main effect can enter the model or an interaction can enter the model together with all the effects that are contained in the interaction. Backward selection can remove an interaction itself or the interaction together with all the effects that the interaction contains. If you do not want to have model hierarchy, specify HIERARCHY=NONE. In that case, any single effect can enter or leave the model at any given step of the selection process. The default is HIERARCHY=SINGLE.",CD,2087,"['logistic', 'procedure', 'enables', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'model', 'hierarchy', 'refers', 'requirement', 'effect', 'model', 'effect', 'contains', 'must', 'also', 'model', 'example', 'order', 'interaction', 'ab', 'enter', 'model', 'main_effect', 'b', 'must', 'model', 'model', 'hierarchy', 'desirable', 'model', 'hierarchically', 'well', 'formulated', 'inference', 'invariant', 'coding', 'choose', 'predictor_variable', 'kleinbaum', 'kupper', 'muller', '1988', 'model', 'hierarchically', 'well', 'formulated', 'test', 'lower', 'order', 'term', 'depend', 'coding', 'reference', 'versus', 'effect', 'coding', 'categorical', 'variable', 'hierarchy', 'option', 'specifies', 'whether', 'hierarchy', 'maintained', 'whether', 'single', 'effect', 'multiple', 'effect', 'allowed', 'enter', 'leave', 'model', 'one', 'step', 'selectionforward', 'selectionbackward', 'selectionstepwise', 'hierarchysingle', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'example', 'suppose', 'specify', 'main_effect', 'b', 'interaction', 'ab', 'model', 'backward', 'elimination', 'interaction', 'ab', 'must', 'first', 'removed', 'main_effect', 'removed', 'forward', 'selection', 'main_effect', 'must', 'enter', 'model', 'interaction', 'hierarchymultiple', 'one', 'effect', 'enter', 'leave', 'model', 'one', 'time', 'subject', 'model', 'hierarchy', 'forward', 'selection', 'single', 'main_effect', 'enter', 'model', 'interaction', 'enter', 'model', 'together', 'effect', 'contained', 'interaction', 'backward', 'selection', 'remove', 'interaction', 'interaction', 'together', 'effect', 'interaction', 'contains', 'want', 'model', 'hierarchy', 'specify', 'hierarchynone', 'case', 'single', 'effect', 'enter', 'leave', 'model', 'given', 'step', 'selection', 'process', 'default', 'hierarchysingle']"
878,"From the classification table you can compute sensitivity, which is the proportion of event observations (in this example low birth weight babies) that were predicted to have an event response. The formula is (true positives) / (total actual positives).",CD,253,"['classification', 'table', 'compute', 'sensitivity', 'proportion', 'event', 'observation', 'example', 'low', 'birth', 'weight', 'baby', 'predicted', 'event', 'response', 'formula', 'true', 'positive', '', 'total', 'actual', 'positive']"
879,"The Criteria For Assessing Goodness Of Fit table displays the scaled deviance and scaled Pearson chi-squares, which both measure the goodness-of-fit of the model. However, the model being evaluated is the independence-only model, not the GEE model. Notice also that the log likelihood is based on the independence model and should not be used to construct a likelihood-ratio test comparing GEE models. Because the GEE method is quasi-likelihood based, there is no reported log likelihood for the GEE model. Analysis Of Initial Parameter Estimates",CD,546,"['criterion', 'assessing', 'goodness', 'fit', 'table', 'display', 'scaled', 'deviance', 'scaled', 'pearson', 'chisquares', 'measure', 'goodnessoffit', 'model', 'however', 'model', 'evaluated', 'independenceonly', 'model', 'gee', 'model', 'notice', 'also', 'log', 'likelihood', 'based', 'independence', 'model', 'used', 'construct', 'likelihoodratio', 'test', 'comparing', 'gee', 'model', 'gee', 'method', 'quasilikelihood', 'based', 'reported', 'log', 'likelihood', 'gee', 'model', 'analysis', 'initial', 'parameter_estimate']"
880,"The modeling-building strategy for ordinal logistic regression is the same as for binary logistic regression. First, do an exploratory data analysis with contingency tables and logit plots. During this stage also look for confounders and interactions. Then try to find a subset of predictor variables that are associated with severity of back pain during pregnancy. In this example, there are 22 predictor variables. With so many variables, there is a good chance that many of them are collinear or redundant. A good strategy in this case is to reduce the number of redundant variables first before you try to build a model. One way to reduce the number of redundant variables is through variable clustering.",CD,708,"['modelingbuilding', 'strategy', 'ordinal', 'logistic_regression', 'binary', 'logistic_regression', 'first', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'stage', 'also', 'look', 'confounders', 'interaction', 'try', 'find', 'subset', 'predictor_variable', 'associated', 'severity', 'back', 'pain', 'pregnancy', 'example', '22', 'predictor_variable', 'many', 'variable', 'good', 'chance', 'many', 'collinear', 'redundant', 'good', 'strategy', 'case', 'reduce', 'number', 'redundant', 'variable', 'first', 'try', 'build', 'model', 'one', 'way', 'reduce', 'number', 'redundant', 'variable', 'variable', 'clustering']"
881,"To test the null hypothesis that all regression coefficients of the model are 0, the likelihood ratio test statistic is computed. This statistic compares the log-likelihood values at the fitted parameter estimates (LogL1) to the log-likelihood values when the parameter estimates are 0 (LogL0). So that it follows a chi-square distribution, the statistic is computed by the formula ?2(LogL0?LogL1). In the above diagram, the likelihood ratio statistic is twice the vertical distance between the values of the log-likelihood function at LogL1 and at LogL0.",CD,555,"['test', 'null', 'hypothesis', 'regression', 'coefficient', 'model', '0', 'likelihood', 'ratio', 'test', 'statistic', 'computed', 'statistic', 'compare', 'loglikelihood', 'value', 'fitted', 'parameter_estimate', 'logl1', 'loglikelihood', 'value', 'parameter_estimate', '0', 'logl0', 'follows', 'chisquare', 'distribution', 'statistic', 'computed', 'formula', '2logl0logl1', 'diagram', 'likelihood', 'ratio', 'statistic', 'twice', 'vertical', 'distance', 'value', 'loglikelihood', 'function', 'logl1', 'logl0']"
882,"The LOGISTIC procedure fits logistic regression models for binary, ordinal, or nominal response data. Enhancements to PROC LOGISTIC in SAS?9 include the STRATA statement, which enables you to perform a conditional logistic regression on binary response data, and the SCORE statement, which enables you to score a data set using a previously fitted model. PROC LOGISTIC has options that control how to select effects (either variables or interactions) in and out of the model. When there are no interaction terms, a CLASS variable can enter or leave a model in a single step. When there are interaction terms, the selection process also depends on whether you want to preserve model hierarchy (which is explained later in the course). For example, you can specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. PROC LOGISTIC provides a CONTRAST statement for specifying customized hypothesis tests concerning the model parameters. The CONTRAST statement can also be used to obtain odds ratio estimates for various levels of the CLASS variables and confidence intervals around odds ratios for variables that are involved in an interaction. In the MODEL statement, the response variable can be specified in two ways. *	The events/trials syntax represents a ratio of variables where the event variable indicates the number of observations with the response of interest for a particular combination of predictor variable values and the trial variable indicates the number of observations in the same combination of predictor variable values. This response is useful when you have a summarized data set where each observation represents a unique combination of predictor variable values. *	The response variable can also be specified as a positive or negative response for each observation. In other words, each observation represents a single case. Selected PROC LOGISTIC statement options: NOPRINT	suppresses all displayed output. This option temporarily disables the Output Delivery System (ODS). NAMELEN=	specifies the length of effect names in tables and output data sets to be n characters, where n is a value between 20 and 200. Because the default length is 20 characters, you may have to increase the length for some interaction terms. Selected LOGISTIC procedure statements: CLASS	specifies the classification variables to be used in the analysis. The CLASS statement must precede the MODEL statement. MODEL	specifies the response variable (which can be binary, ordinal, or nominal) and the predictor variables (which can be character or numeric). The MODEL statement is required, and only one is allowed with each invocation of PROC LOGISTIC. CONTRAST	provides a mechanism for obtaining customized hypothesis tests. There is no limit to the number of CONTRAST statements that you can specify, but they must appear after the MODEL statement. EXACT	performs exact tests of the parameters for the specified effects and optionally estimates the parameters and outputs the exact conditional distributions. You can specify several EXACT statements, but they must follow the MODEL statement. SCORE	creates a data set that contains all the data in the DATA= data set together with posterior probabilities and, optionally, prediction confidence intervals. You can specify several SCORE statements. STRATA	names the variables that define strata or matched sets to use in a stratified conditional logistic regression of binary response data. The STRATA variables can be either character or numeric, and the formatted values of the STRATA variables determine the levels. You can use formats to group values into levels. UNITS	enables you to obtain an odds ratio estimate for a specified change in a predictor variable. The unit of change can be a number, standard deviation (SD) or a number times the standard deviation (2*SD). OUTPUT	creates an output data set containing all the variables from the input data set and the requested statistics.",CD,4045,"['logistic', 'procedure', 'fit', 'logistic_regression_model', 'binary', 'ordinal', 'nominal', 'response', 'data', 'enhancement', 'proc_logistic', 'sas9', 'include', 'stratum', 'statement', 'enables', 'perform', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'score', 'statement', 'enables', 'score', 'data_set', 'using', 'previously', 'fitted', 'model', 'proc_logistic', 'ha', 'option', 'control', 'select', 'effect', 'either', 'variable', 'interaction', 'model', 'interaction', 'term', 'class', 'variable', 'enter', 'leave', 'model', 'single', 'step', 'interaction', 'term', 'selection', 'process', 'also', 'depends', 'whether', 'want', 'preserve', 'model', 'hierarchy', 'explained', 'later', 'course', 'example', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'proc_logistic', 'provides', 'contrast', 'statement', 'specifying', 'customized', 'hypothesis', 'test', 'concerning', 'model', 'parameter', 'contrast', 'statement', 'also', 'used', 'obtain', 'odds_ratio', 'estimate', 'various', 'level', 'class', 'variable', 'confidence', 'interval', 'around', 'odds_ratio', 'variable', 'involved', 'interaction', 'model_statement', 'response_variable', 'specified', 'two', 'way', '\tthe', 'eventstrials', 'syntax', 'represents', 'ratio', 'variable', 'event', 'variable', 'indicates', 'number', 'observation', 'response', 'interest', 'particular', 'combination', 'predictor_variable', 'value', 'trial', 'variable', 'indicates', 'number', 'observation', 'combination', 'predictor_variable', 'value', 'response', 'useful', 'summarized', 'data_set', 'observation', 'represents', 'unique', 'combination', 'predictor_variable', 'value', '\tthe', 'response_variable', 'also', 'specified', 'positive', 'negative', 'response', 'observation', 'word', 'observation', 'represents', 'single', 'case', 'selected', 'proc_logistic', 'statement', 'option', 'noprint\tsuppresses', 'displayed', 'output', 'option', 'temporarily', 'disables', 'output', 'delivery', 'system', 'od', 'namelen\tspecifies', 'length', 'effect', 'name', 'table', 'output', 'data_set', 'n', 'character', 'n', 'value', '20', '200', 'default', 'length', '20', 'character', 'may', 'increase', 'length', 'interaction', 'term', 'selected', 'logistic', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'must', 'precede', 'model_statement', 'model\tspecifies', 'response_variable', 'binary', 'ordinal', 'nominal', 'predictor_variable', 'character', 'numeric', 'model_statement', 'required', 'one', 'allowed', 'invocation', 'proc_logistic', 'contrast\tprovides', 'mechanism', 'obtaining', 'customized', 'hypothesis', 'test', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'exact\tperforms', 'exact', 'test', 'parameter', 'specified', 'effect', 'optionally', 'estimate', 'parameter', 'output', 'exact', 'conditional', 'distribution', 'specify', 'several', 'exact', 'statement', 'must', 'follow', 'model_statement', 'score\tcreates', 'data_set', 'contains', 'data', 'data', 'data_set', 'together', 'posterior', 'probability', 'optionally', 'prediction', 'confidence', 'interval', 'specify', 'several', 'score', 'statement', 'strata\tnames', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'stratified', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'stratum', 'variable', 'either', 'character', 'numeric', 'formatted', 'value', 'stratum', 'variable', 'determine', 'level', 'use', 'format', 'group', 'value', 'level', 'units\tenables', 'obtain', 'odds_ratio', 'estimate', 'specified', 'change', 'predictor_variable', 'unit', 'change', 'number', 'standard', 'deviation', 'sd', 'number', 'time', 'standard', 'deviation', '2sd', 'output\tcreates', 'output', 'data_set', 'containing', 'variable', 'input', 'data_set', 'requested', 'statistic']"
883,"The Criteria For Assessing Goodness Of Fit table displays the scaled deviance and scaled Pearson chi-squares, which both measure the goodness-of-fit of the model. However, the model being evaluated is the independence-only model, not the GEE model. Notice also that the log likelihood is based on the independence model and should not be used to construct a likelihood-ratio test comparing GEE models. Because the GEE method is quasi-likelihood based, there is no reported log likelihood for the GEE model. Analysis Of Initial Parameter Estimates",CD,546,"['criterion', 'assessing', 'goodness', 'fit', 'table', 'display', 'scaled', 'deviance', 'scaled', 'pearson', 'chisquares', 'measure', 'goodnessoffit', 'model', 'however', 'model', 'evaluated', 'independenceonly', 'model', 'gee', 'model', 'notice', 'also', 'log', 'likelihood', 'based', 'independence', 'model', 'used', 'construct', 'likelihoodratio', 'test', 'comparing', 'gee', 'model', 'gee', 'method', 'quasilikelihood', 'based', 'reported', 'log', 'likelihood', 'gee', 'model', 'analysis', 'initial', 'parameter_estimate']"
884,"GEE regression models are very popular because clustered data is common in many fields of research. For example, a physician might evaluate patients at weekly intervals in a clinical drug trial. A family study on liver cancer might want to estimate the degree of association between liver cancer and members of the same family to examine the possible genetic explanation of the disease process. A dental study might measure the extent of tooth decay for each tooth in a subject?s mouth. A common feature of these studies is that repeated categorical response data is collected and the independence assumption is violated.",CD,621,"['gee', 'regression_model', 'popular', 'clustered', 'data', 'common', 'many', 'field', 'research', 'example', 'physician', 'might', 'evaluate', 'patient', 'weekly', 'interval', 'clinical', 'drug', 'trial', 'family', 'study', 'liver', 'cancer', 'might', 'want', 'estimate', 'degree', 'association', 'liver', 'cancer', 'member', 'family', 'examine', 'possible', 'genetic', 'explanation', 'disease', 'process', 'dental', 'study', 'might', 'measure', 'extent', 'tooth', 'decay', 'tooth', 'subject', 'mouth', 'common', 'feature', 'study', 'repeated', 'categorical', 'response', 'data', 'collected', 'independence', 'assumption', 'violated']"
885,"One way to identify possible contributing factors to low birth weight is to build a linear probability model where the outcome is the probability of having a low birth weight baby. Such a model implies that the probability of low birth weight is a linear function of the predictor variables. The regression coefficients would therefore have a straightforward interpretation in this model. For example, you can estimate the change in the probability of low birth weight, given a one-unit change in alcohol. Unfortunately, the linear probability model has some serious shortcomings. The predicted values from a linear model can assume, theoretically, any value. However, probabilities are by definition bounded between 0 and 1. Thus, the model can only be valid over a finite range of predictor variable values. A more appropriate model would somehow constrain the predicted probabilities to be between 0 and 1. Another shortcoming is that the observed relationship between the probability of an outcome and the predictor variables is usually nonlinear rather than linear. For example, a one-unit change in the predictor variable may have less impact when the probability is near 0 or 1 than when the probability is near .50. In fact, the relationship often resembles an S-shaped curve rather than a linear function (Hosmer and Lemeshow 2000).",CD,1341,"['one', 'way', 'identify', 'possible', 'contributing', 'factor', 'low', 'birth', 'weight', 'build', 'linear', 'probability', 'model', 'outcome', 'probability', 'low', 'birth', 'weight', 'baby', 'model', 'implies', 'probability', 'low', 'birth', 'weight', 'linear', 'function', 'predictor_variable', 'regression', 'coefficient', 'would', 'therefore', 'straightforward', 'interpretation', 'model', 'example', 'estimate', 'change', 'probability', 'low', 'birth', 'weight', 'given', 'oneunit', 'change', 'alcohol', 'unfortunately', 'linear', 'probability', 'model', 'ha', 'serious', 'shortcoming', 'predicted', 'value', 'linear', 'model', 'assume', 'theoretically', 'value', 'however', 'probability', 'definition', 'bounded', '0', '1', 'thus', 'model', 'valid', 'finite', 'range', 'predictor_variable', 'value', 'appropriate', 'model', 'would', 'somehow', 'constrain', 'predicted', 'probability', '0', '1', 'another', 'shortcoming', 'observed', 'relationship', 'probability', 'outcome', 'predictor_variable', 'usually', 'nonlinear', 'rather', 'linear', 'example', 'oneunit', 'change', 'predictor_variable', 'may', 'le', 'impact', 'probability', 'near', '0', '1', 'probability', 'near', '50', 'fact', 'relationship', 'often', 'resembles', 'sshaped', 'curve', 'rather', 'linear', 'function', 'hosmer', 'lemeshow', '2000']"
886,WARNING: The maximum likelihood estimate may not exist. WARNING: The LOGISTIC procedure continues in spite of the above warning. Results shown are based on the last maximum likelihood iteration. Validity of the model fit is questionable.,CD,237,"['warning', 'maximum', 'likelihood', 'estimate', 'may', 'exist', 'warning', 'logistic', 'procedure', 'continues', 'spite', 'warning', 'result', 'shown', 'based', 'last', 'maximum', 'likelihood', 'iteration', 'validity', 'model', 'fit', 'questionable']"
887,"The contingency table analysis revealed that several variables had very small numbers in their levels (the details of the analysis were omitted to save time and space). Therefore, several variables had levels collapsed and several predictor variables were eliminated from the analysis. For example, there was only one woman whose bowel action aggravated her back pain. Therefore, a total of 16 predictor variables were selected for the analysis.",CD,445,"['contingency', 'table', 'analysis', 'revealed', 'several', 'variable', 'small', 'number', 'level', 'detail', 'analysis', 'omitted', 'save', 'time', 'space', 'therefore', 'several', 'variable', 'level', 'collapsed', 'several', 'predictor_variable', 'eliminated', 'analysis', 'example', 'wa', 'one', 'woman', 'whose', 'bowel', 'action', 'aggravated', 'back', 'pain', 'therefore', 'total', '16', 'predictor_variable', 'selected', 'analysis']"
888,PROC GENMOD is modeling the probability that wheeze='1'. The Class Level Information table displays the levels of the class variables while the response profile table displays the levels of the response variable. Parameter Information,CD,234,"['proc', 'genmod', 'modeling', 'probability', 'wheeze1', 'class', 'level', 'information', 'table', 'display', 'level', 'class', 'variable', 'response', 'profile', 'table', 'display', 'level', 'response_variable', 'parameter', 'information']"
889,The Analysis of Initial Parameter Estimates table shows the parameter estimates when the observations are treated as independent. These parameter estimates are used as the starting values for the GEE solution. Notice that both smoker and age are significant at the 0.05 significance level. GEE Model Information,CD,311,"['analysis', 'initial', 'parameter_estimate', 'table', 'show', 'parameter_estimate', 'observation', 'treated', 'independent', 'parameter_estimate', 'used', 'starting', 'value', 'gee', 'solution', 'notice', 'smoker', 'age', 'significant', '005', 'significance', 'level', 'gee', 'model', 'information']"
890,"PROC GENMOD can be used to fit GEE models to clustered data. The layout of the data corresponds to the number of observations being equal to the number of measurements taken on all the subjects. The variance-covariance matrix is a block diagonal matrix in which the observations within each block are assumed to be correlated and the observations outside of the blocks are assumed to be independent. Selected GENMOD procedure statements: CLASS	specifies the classification variables to be used in the analysis. If the CLASS statement is used, it must appear before the MODEL statement. MODEL	specifies the response variable and the predictor variables. REPEATED	invokes the GEE method, specifies the correlation structure, and controls the displayed output from the longitudinal model. ESTIMATE	provides a means for obtaining a test for a specified hypothesis concerning the model parameters. It can also be used to produce the odds ratio estimate along with the 95% confidence limits. OUTPUT	creates a new SAS data set that contains all the variables in the input data set and, optionally, the estimated linear predictors and their standard error estimates, the weights for the Hessian matrix, predicted values of the mean, confidence limits for predicted values, and residuals. Selected CLASS statement options: PARAM=	specifies the parameterization method for the classification variable or variables. Design matrix columns are created from CLASS variables according to the following coding schemes: 	EFFECT	species effect coding. GLM	specifies less than full rank, reference-cell coding. This coding is the default. ORDINAL	specifies the cumulative parameterization for an ordinal CLASS variable. 	POLY	specifies polynomial coding. 	REF	specifies reference cell coding. 	ORTHEFFECT	orthogonalizes PARAM=EFFECT. 	ORTHORDINAL	orthogonalizes PARAM=ORDINAL. 	ORTHPOLY	orthogonalizes PARAM=POLY. 	ORTHREF	orthogonalizes PARAM=REF. REF=	specifies the reference cell for PARAM=EFFECT, PARAM=REF, and their orthogonalizations.",CD,2022,"['proc', 'genmod', 'used', 'fit', 'gee', 'model', 'clustered', 'data', 'layout', 'data', 'corresponds', 'number', 'observation', 'equal', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'selected', 'genmod', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'used', 'must', 'appear', 'model_statement', 'model\tspecifies', 'response_variable', 'predictor_variable', 'repeated\tinvokes', 'gee', 'method', 'specifies', 'correlation_structure', 'control', 'displayed', 'output', 'longitudinal', 'model', 'estimate\tprovides', 'mean', 'obtaining', 'test', 'specified', 'hypothesis', 'concerning', 'model', 'parameter', 'also', 'used', 'produce', 'odds_ratio', 'estimate', 'along', '95', 'confidence', 'limit', 'output\tcreates', 'new', 'sa', 'data_set', 'contains', 'variable', 'input', 'data_set', 'optionally', 'estimated', 'linear', 'predictor', 'standard_error', 'estimate', 'weight', 'hessian', 'matrix', 'predicted', 'value', 'mean', 'confidence', 'limit', 'predicted', 'value', 'residual', 'selected', 'class', 'statement', 'option', 'param\tspecifies', 'parameterization', 'method', 'classification', 'variable', 'variable', 'design', 'matrix', 'column', 'created', 'class', 'variable', 'according', 'following', 'coding', 'scheme', '\teffect\tspecies', 'effect', 'coding', 'glm\tspecifies', 'le', 'full', 'rank', 'referencecell', 'coding', 'coding', 'default', 'ordinal\tspecifies', 'cumulative', 'parameterization', 'ordinal', 'class', 'variable', '\tpoly\tspecifies', 'polynomial', 'coding', '\tref\tspecifies', 'reference', 'cell', 'coding', '\tortheffect\torthogonalizes', 'parameffect', '\torthordinal\torthogonalizes', 'paramordinal', '\torthpoly\torthogonalizes', 'parampoly', '\torthref\torthogonalizes', 'paramref', 'ref\tspecifies', 'reference', 'cell', 'parameffect', 'paramref', 'orthogonalizations']"
891,"You can also write a CONTRAST statement in PROC LOGISTIC to estimate the odds ratio for any effect along with the confidence bounds. The contrasts consist of the effects involved in the odds ratio along with the coefficients that measure the difference between the effects in the numerator and the effects in the denominator. The ESTIMATE=EXP option exponentiates the parameter estimate, which shows the odds ratio and the 95% confidence bounds. Estimating Odds Ratios in Interactions",CD,484,"['also', 'write', 'contrast', 'statement', 'proc_logistic', 'estimate', 'odds_ratio', 'effect', 'along', 'confidence', 'bound', 'contrast', 'consist', 'effect', 'involved', 'odds_ratio', 'along', 'coefficient', 'measure', 'difference', 'effect', 'numerator', 'effect', 'denominator', 'estimateexp', 'option', 'exponentiates', 'parameter_estimate', 'show', 'odds_ratio', '95', 'confidence', 'bound', 'estimating', 'odds_ratio', 'interaction']"
892,"random component	identifies the response variable and its probability distribution. systematic component	specifies the predictor variables used in a linear predictor. link function	specifies the function of E(Y) that the model equates to the systematic component. For the general linear model, the link function is the identity link (modeling the mean), the response variable is normally distributed, and the variance is constant. For logistic regression, the link function is the logit link ( ) and the response variable follows a binomial distribution (a common distribution for binary outcomes). For Poisson regression, the link function is the natural log and the response variable follows the Poisson distribution. The link function that transforms the mean to the natural location parameter is called the canonical link. For example, in the normal distribution the natural location parameter is the mean. Models with canonical links usually make the best sense on scientific grounds, but you can choose other link functions besides the canonical links. ?	The reason for restricting the distribution of the response variable to the family of exponential distributions is that the same algorithm to compute maximum likelihood parameter estimates applies to this entire family for any choice of link function.",CD,1312,"['random', 'component\tidentifies', 'response_variable', 'probability', 'distribution', 'systematic', 'component\tspecifies', 'predictor_variable', 'used', 'linear', 'predictor', 'link', 'function\tspecifies', 'function', 'ey', 'model', 'equates', 'systematic', 'component', 'general', 'linear', 'model', 'link', 'function', 'identity', 'link', 'modeling', 'mean', 'response_variable', 'normally', 'distributed', 'variance', 'constant', 'logistic_regression', 'link', 'function', 'logit', 'link', '', '', 'response_variable', 'follows', 'binomial', 'distribution', 'common', 'distribution', 'binary', 'outcome', 'poisson', 'regression', 'link', 'function', 'natural', 'log', 'response_variable', 'follows', 'poisson', 'distribution', 'link', 'function', 'transforms', 'mean', 'natural', 'location', 'parameter', 'called', 'canonical', 'link', 'example', 'normal', 'distribution', 'natural', 'location', 'parameter', 'mean', 'model', 'canonical', 'link', 'usually', 'make', 'best', 'sense', 'scientific', 'ground', 'choose', 'link', 'function', 'besides', 'canonical', 'link', '\tthe', 'reason', 'restricting', 'distribution', 'response_variable', 'family', 'exponential', 'distribution', 'algorithm', 'compute', 'maximum', 'likelihood', 'parameter_estimate', 'applies', 'entire', 'family', 'choice', 'link', 'function']"
893,"It is common in fitting logistic regression models to have problems with convergence. This occurs because maximum likelihood estimates are determined using an iterative algorithm. In the LOGISTIC procedure, the iterations are considered to have converged when the maximum change in parameter estimates between successive steps is less than a certain value (the default is 1E-4). However, sometimes the algorithm fails to converge after a number of iterations (in PROC LOGISTIC the default limit is 25 iterations). A common cause of convergence problems is quasi- complete separation. Quasi-complete separation occurs when the level of a categorical predictor variable perfectly predicts the response. In other words, there is a frequency of 0 in a contingency table. The table above demonstrates the effects of quasi-complete separation. Because of the 0 count, the parameter estimate for the effect of level B will be infinite (PROC LOGISTIC reports the estimate after several iterations). It is obvious something is wrong with the model because of the large parameter estimate for B and the large standard error. The presence of 0 cell counts should be detected during the univariate screening of the data. Solutions to this problem include any of the following: *	collapsing the categories of the predictor variable to eliminate the 0 cell count *	performing exact logistic regression *	eliminating the category altogether *	treating the predictor variable as continuous if it is ordinal *	adding a very small constant to the cell counts. If you add the small constants, it is recommended that you do a sensitivity analysis by adding constants of various sizes in order to gauge their effect on the parameter estimates. You should be very concerned if the results of your model vary with small changes in the data (Allison 1999).",CD,1832,"['common', 'fitting', 'logistic_regression_model', 'problem', 'convergence', 'occurs', 'maximum', 'likelihood', 'estimate', 'determined', 'using', 'iterative', 'algorithm', 'logistic', 'procedure', 'iteration', 'considered', 'converged', 'maximum', 'change', 'parameter_estimate', 'successive', 'step', 'le', 'certain', 'value', 'default', '1e4', 'however', 'sometimes', 'algorithm', 'fails', 'converge', 'number', 'iteration', 'proc_logistic', 'default', 'limit', '25', 'iteration', 'common', 'cause', 'convergence', 'problem', 'quasi', 'complete', 'separation', 'quasicomplete', 'separation', 'occurs', 'level', 'categorical', 'predictor_variable', 'perfectly', 'predicts', 'response', 'word', 'frequency', '0', 'contingency', 'table', 'table', 'demonstrates', 'effect', 'quasicomplete', 'separation', '0', 'count', 'parameter_estimate', 'effect', 'level', 'b', 'infinite', 'proc_logistic', 'report', 'estimate', 'several', 'iteration', 'obvious', 'something', 'wrong', 'model', 'large', 'parameter_estimate', 'b', 'large', 'standard_error', 'presence', '0', 'cell', 'count', 'detected', 'univariate', 'screening', 'data', 'solution', 'problem', 'include', 'following', '\tcollapsing', 'category', 'predictor_variable', 'eliminate', '0', 'cell', 'count', '\tperforming', 'exact', 'logistic_regression', '\teliminating', 'category', 'altogether', '\ttreating', 'predictor_variable', 'continuous', 'ordinal', '\tadding', 'small', 'constant', 'cell', 'count', 'add', 'small', 'constant', 'recommended', 'sensitivity', 'analysis', 'adding', 'constant', 'various', 'size', 'order', 'gauge', 'effect', 'parameter_estimate', 'concerned', 'result', 'model', 'vary', 'small', 'change', 'data', 'allison', '1999']"
894,"The parameter estimate for cephalexin is a median unbiased estimate, which is more accurate than the asymptotic estimate in this example. The exact p-value for age is different than the p- value reported for the exact conditional tests. The reason for the discrepancy is that the exact p- values for the single parameters are the results of likelihood ratio tests based on the conditional probability density function used to estimate them. In most cases, you would rely on the exact p- values reported in the ?Exact Conditional Analysis? table (Stokes, Davis, and Koch 2000). ?	The score test is preferred over the probability test because if the resulting distribution of the conditional sufficient statistic is bimodal, then the probability test can pick up probability from within the valley as well as the tails. The score p-value is always a tail statistic. Exact Odds Ratios",CD,881,"['parameter_estimate', 'cephalexin', 'median', 'unbiased', 'estimate', 'accurate', 'asymptotic', 'estimate', 'example', 'exact', 'pvalue', 'age', 'different', 'p', 'value', 'reported', 'exact', 'conditional', 'test', 'reason', 'discrepancy', 'exact', 'p', 'value', 'single', 'parameter', 'result', 'likelihood', 'ratio', 'test', 'based', 'conditional', 'probability', 'density', 'function', 'used', 'estimate', 'case', 'would', 'rely', 'exact', 'p', 'value', 'reported', 'exact', 'conditional', 'analysis', 'table', 'stokes', 'davis', 'koch', '2000', '\tthe', 'score', 'test', 'preferred', 'probability', 'test', 'resulting', 'distribution', 'conditional', 'sufficient', 'statistic', 'bimodal', 'probability', 'test', 'pick', 'probability', 'within', 'valley', 'well', 'tail', 'score', 'pvalue', 'always', 'tail', 'statistic', 'exact', 'odds_ratio']"
895,"Generalized estimating equations (GEE) were developed to accommodate correlated observations within subjects. An estimating equation is simply the equation you solve to calculate the parameter estimates. The extra term generalized distinguishes the GEE as the estimating equations that accommodate the correlation structure of the repeated measurements. GEE are marginal models where the marginal expectation (average response for observations sharing the same covariates) is modeled as a function of the predictor variables. The parameters in marginal models can be interpreted as the influence of the covariates on the population-averaged response. These models are appropriate when the scientific objectives are to characterize and contrast populations of subjects. A useful feature of the GEE is that the parameter estimates along with the covariance matrix are consistently estimated (as the sample size increases, the estimates converge to the true values) even if the correlation structure within subject is not known. Therefore, the variances along with the inferences regarding the parameter estimates are asymptotically correct (Zeger and Liang 1986). It is also not necessary that the observations for all subjects have the same correlation structure.",CD,1262,"['generalized', 'estimating', 'equation', 'gee', 'developed', 'accommodate', 'correlated', 'observation', 'within', 'subject', 'estimating', 'equation', 'simply', 'equation', 'solve', 'calculate', 'parameter_estimate', 'extra', 'term', 'generalized', 'distinguishes', 'gee', 'estimating', 'equation', 'accommodate', 'correlation_structure', 'repeated', 'measurement', 'gee', 'marginal', 'model', 'marginal', 'expectation', 'average', 'response', 'observation', 'sharing', 'covariates', 'modeled', 'function', 'predictor_variable', 'parameter', 'marginal', 'model', 'interpreted', 'influence', 'covariates', 'populationaveraged', 'response', 'model', 'appropriate', 'scientific', 'objective', 'characterize', 'contrast', 'population', 'subject', 'useful', 'feature', 'gee', 'parameter_estimate', 'along', 'covariance', 'matrix', 'consistently', 'estimated', 'sample_size', 'increase', 'estimate', 'converge', 'true', 'value', 'even', 'correlation_structure', 'within', 'subject', 'known', 'therefore', 'variance', 'along', 'inference', 'regarding', 'parameter_estimate', 'asymptotically', 'correct', 'zeger', 'liang', '1986', 'also', 'necessary', 'observation', 'subject', 'correlation_structure']"
896,"Example:	Fit an exact logistic regression model to the Cephalexin data set. Request that the individual parameters and the odds ratios be estimated. Use the events/trials syntax and use reference cell coding for each predictor variable and specify No for the reference cell for cephalexin, 50+ for age, and less than a week for length_of_stay. Also create a data set with the exact conditional distributions. /* c3demo18a */ proc logistic data=sasuser.cephalexin; class cephalexin (param=ref ref='No') age (param=ref ref='50+') length_of_stay (param=ref ref='less than a week'); model cases/patients = cephalexin age length_of_stay; exact cephalexin age length_of_stay / estimate=both outdist=dist; title 'Cephalexin in Hospital Model'; run; EXACT statement options: ESTIMATE=	estimates the individual parameters (conditional on all other parameters) for the effects specified in the EXACT statement. For each parameter, a point estimate, a confidence interval, and a p-value for a two-sided test that the parameter is zero are displayed. The keyword BOTH specifies that the parameters and odds ratios be displayed. OUTDIST=	creates the SAS data set containing the exact conditional distributions. The data set contains the possible sufficient statistics for the parameters of the effects specified in the EXACT statement, the counts, the probability of occurrence, and the score value for each sufficient statistic. Cephalexin in Hospital Model",CD,1445,"['example\tfit', 'exact', 'logistic_regression_model', 'cephalexin', 'data_set', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'use', 'eventstrials', 'syntax', 'use', 'reference', 'cell', 'coding', 'predictor_variable', 'specify', 'reference', 'cell', 'cephalexin', '50', 'age', 'le', 'week', 'lengthofstay', 'also', 'create', 'data_set', 'exact', 'conditional', 'distribution', '', 'c3demo18a', '', 'proc_logistic', 'datasasusercephalexin', 'class', 'cephalexin', 'paramref', 'refno', 'age', 'paramref', 'ref50', 'lengthofstay', 'paramref', 'refless', 'week', 'model', 'casespatients', '', 'cephalexin', 'age', 'lengthofstay', 'exact', 'cephalexin', 'age', 'lengthofstay', '', 'estimateboth', 'outdistdist', 'title', 'cephalexin', 'hospital', 'model', 'run', 'exact', 'statement', 'option', 'estimate\testimates', 'individual', 'parameter', 'conditional', 'parameter', 'effect', 'specified', 'exact', 'statement', 'parameter', 'point', 'estimate', 'confidence', 'interval', 'pvalue', 'twosided', 'test', 'parameter', 'zero', 'displayed', 'keyword', 'specifies', 'parameter', 'odds_ratio', 'displayed', 'outdist\tcreates', 'sa', 'data_set', 'containing', 'exact', 'conditional', 'distribution', 'data_set', 'contains', 'possible', 'sufficient', 'statistic', 'parameter', 'effect', 'specified', 'exact', 'statement', 'count', 'probability', 'occurrence', 'score', 'value', 'sufficient', 'statistic', 'cephalexin', 'hospital', 'model']"
897,"The LOGISTIC procedure fits logistic regression models for binary, ordinal, or nominal response data. Enhancements to PROC LOGISTIC in SAS?9 include the STRATA statement, which enables you to perform a conditional logistic regression on binary response data, and the SCORE statement, which enables you to score a data set using a previously fitted model. PROC LOGISTIC has options that control how to select effects (either variables or interactions) in and out of the model. When there are no interaction terms, a CLASS variable can enter or leave a model in a single step. When there are interaction terms, the selection process also depends on whether you want to preserve model hierarchy (which is explained later in the course). For example, you can specify whether model hierarchy is to be preserved, how model hierarchy is applied, and whether a single effect or multiple effects can be moved in a single step. PROC LOGISTIC provides a CONTRAST statement for specifying customized hypothesis tests concerning the model parameters. The CONTRAST statement can also be used to obtain odds ratio estimates for various levels of the CLASS variables and confidence intervals around odds ratios for variables that are involved in an interaction. In the MODEL statement, the response variable can be specified in two ways. *	The events/trials syntax represents a ratio of variables where the event variable indicates the number of observations with the response of interest for a particular combination of predictor variable values and the trial variable indicates the number of observations in the same combination of predictor variable values. This response is useful when you have a summarized data set where each observation represents a unique combination of predictor variable values. *	The response variable can also be specified as a positive or negative response for each observation. In other words, each observation represents a single case. Selected PROC LOGISTIC statement options: NOPRINT	suppresses all displayed output. This option temporarily disables the Output Delivery System (ODS). NAMELEN=	specifies the length of effect names in tables and output data sets to be n characters, where n is a value between 20 and 200. Because the default length is 20 characters, you may have to increase the length for some interaction terms. Selected LOGISTIC procedure statements: CLASS	specifies the classification variables to be used in the analysis. The CLASS statement must precede the MODEL statement. MODEL	specifies the response variable (which can be binary, ordinal, or nominal) and the predictor variables (which can be character or numeric). The MODEL statement is required, and only one is allowed with each invocation of PROC LOGISTIC. CONTRAST	provides a mechanism for obtaining customized hypothesis tests. There is no limit to the number of CONTRAST statements that you can specify, but they must appear after the MODEL statement. EXACT	performs exact tests of the parameters for the specified effects and optionally estimates the parameters and outputs the exact conditional distributions. You can specify several EXACT statements, but they must follow the MODEL statement. SCORE	creates a data set that contains all the data in the DATA= data set together with posterior probabilities and, optionally, prediction confidence intervals. You can specify several SCORE statements. STRATA	names the variables that define strata or matched sets to use in a stratified conditional logistic regression of binary response data. The STRATA variables can be either character or numeric, and the formatted values of the STRATA variables determine the levels. You can use formats to group values into levels. UNITS	enables you to obtain an odds ratio estimate for a specified change in a predictor variable. The unit of change can be a number, standard deviation (SD) or a number times the standard deviation (2*SD). OUTPUT	creates an output data set containing all the variables from the input data set and the requested statistics.",CD,4045,"['logistic', 'procedure', 'fit', 'logistic_regression_model', 'binary', 'ordinal', 'nominal', 'response', 'data', 'enhancement', 'proc_logistic', 'sas9', 'include', 'stratum', 'statement', 'enables', 'perform', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'score', 'statement', 'enables', 'score', 'data_set', 'using', 'previously', 'fitted', 'model', 'proc_logistic', 'ha', 'option', 'control', 'select', 'effect', 'either', 'variable', 'interaction', 'model', 'interaction', 'term', 'class', 'variable', 'enter', 'leave', 'model', 'single', 'step', 'interaction', 'term', 'selection', 'process', 'also', 'depends', 'whether', 'want', 'preserve', 'model', 'hierarchy', 'explained', 'later', 'course', 'example', 'specify', 'whether', 'model', 'hierarchy', 'preserved', 'model', 'hierarchy', 'applied', 'whether', 'single', 'effect', 'multiple', 'effect', 'moved', 'single', 'step', 'proc_logistic', 'provides', 'contrast', 'statement', 'specifying', 'customized', 'hypothesis', 'test', 'concerning', 'model', 'parameter', 'contrast', 'statement', 'also', 'used', 'obtain', 'odds_ratio', 'estimate', 'various', 'level', 'class', 'variable', 'confidence', 'interval', 'around', 'odds_ratio', 'variable', 'involved', 'interaction', 'model_statement', 'response_variable', 'specified', 'two', 'way', '\tthe', 'eventstrials', 'syntax', 'represents', 'ratio', 'variable', 'event', 'variable', 'indicates', 'number', 'observation', 'response', 'interest', 'particular', 'combination', 'predictor_variable', 'value', 'trial', 'variable', 'indicates', 'number', 'observation', 'combination', 'predictor_variable', 'value', 'response', 'useful', 'summarized', 'data_set', 'observation', 'represents', 'unique', 'combination', 'predictor_variable', 'value', '\tthe', 'response_variable', 'also', 'specified', 'positive', 'negative', 'response', 'observation', 'word', 'observation', 'represents', 'single', 'case', 'selected', 'proc_logistic', 'statement', 'option', 'noprint\tsuppresses', 'displayed', 'output', 'option', 'temporarily', 'disables', 'output', 'delivery', 'system', 'od', 'namelen\tspecifies', 'length', 'effect', 'name', 'table', 'output', 'data_set', 'n', 'character', 'n', 'value', '20', '200', 'default', 'length', '20', 'character', 'may', 'increase', 'length', 'interaction', 'term', 'selected', 'logistic', 'procedure', 'statement', 'class\tspecifies', 'classification', 'variable', 'used', 'analysis', 'class', 'statement', 'must', 'precede', 'model_statement', 'model\tspecifies', 'response_variable', 'binary', 'ordinal', 'nominal', 'predictor_variable', 'character', 'numeric', 'model_statement', 'required', 'one', 'allowed', 'invocation', 'proc_logistic', 'contrast\tprovides', 'mechanism', 'obtaining', 'customized', 'hypothesis', 'test', 'limit', 'number', 'contrast', 'statement', 'specify', 'must', 'appear', 'model_statement', 'exact\tperforms', 'exact', 'test', 'parameter', 'specified', 'effect', 'optionally', 'estimate', 'parameter', 'output', 'exact', 'conditional', 'distribution', 'specify', 'several', 'exact', 'statement', 'must', 'follow', 'model_statement', 'score\tcreates', 'data_set', 'contains', 'data', 'data', 'data_set', 'together', 'posterior', 'probability', 'optionally', 'prediction', 'confidence', 'interval', 'specify', 'several', 'score', 'statement', 'strata\tnames', 'variable', 'define', 'stratum', 'matched', 'set', 'use', 'stratified', 'conditional', 'logistic_regression', 'binary', 'response', 'data', 'stratum', 'variable', 'either', 'character', 'numeric', 'formatted', 'value', 'stratum', 'variable', 'determine', 'level', 'use', 'format', 'group', 'value', 'level', 'units\tenables', 'obtain', 'odds_ratio', 'estimate', 'specified', 'change', 'predictor_variable', 'unit', 'change', 'number', 'standard', 'deviation', 'sd', 'number', 'time', 'standard', 'deviation', '2sd', 'output\tcreates', 'output', 'data_set', 'containing', 'variable', 'input', 'data_set', 'requested', 'statistic']"
898,"NOTE: Reported test p-values are lower-bounds for the true p-values. Notice that the p-values are different for the score test and the probability test. It is recommended that the score test results be used. Also note that the reported test p-values are lower bounds for the true p-values. This occurs because when the exact distribution has ties, the Monte Carlo algorithm estimates the probabilities with error, and hence it cannot determine which values contribute to the reported p-values. If you need more precise values, you can specify the OUTDIST= option, determine appropriate cutoff values for the observed probability and score, and then construct the true p-value estimates from the OUTDIST= data set. See the SAS/STAT software online documentation under the LOGISTIC procedure for programming statements to accomplish this task. Exact Parameter Estimates",CD,867,"['note', 'reported', 'test', 'pvalues', 'lowerbounds', 'true', 'pvalues', 'notice', 'pvalues', 'different', 'score', 'test', 'probability', 'test', 'recommended', 'score', 'test', 'result', 'used', 'also', 'note', 'reported', 'test', 'pvalues', 'lower', 'bound', 'true', 'pvalues', 'occurs', 'exact', 'distribution', 'ha', 'tie', 'monte', 'carlo', 'algorithm', 'estimate', 'probability', 'error', 'hence', 'cannot', 'determine', 'value', 'contribute', 'reported', 'pvalues', 'need', 'precise', 'value', 'specify', 'outdist', 'option', 'determine', 'appropriate', 'cutoff', 'value', 'observed', 'probability', 'score', 'construct', 'true', 'pvalue', 'estimate', 'outdist', 'data_set', 'see', 'sasstat', 'software', 'online', 'documentation', 'logistic', 'procedure', 'programming', 'statement', 'accomplish', 'task', 'exact', 'parameter_estimate']"
899,"The parameter estimate for cephalexin is a median unbiased estimate, which is more accurate than the asymptotic estimate in this example. The exact p-value for age is different than the p- value reported for the exact conditional tests. The reason for the discrepancy is that the exact p- values for the single parameters are the results of likelihood ratio tests based on the conditional probability density function used to estimate them. In most cases, you would rely on the exact p- values reported in the ?Exact Conditional Analysis? table (Stokes, Davis, and Koch 2000). ?	The score test is preferred over the probability test because if the resulting distribution of the conditional sufficient statistic is bimodal, then the probability test can pick up probability from within the valley as well as the tails. The score p-value is always a tail statistic. Exact Odds Ratios",CD,881,"['parameter_estimate', 'cephalexin', 'median', 'unbiased', 'estimate', 'accurate', 'asymptotic', 'estimate', 'example', 'exact', 'pvalue', 'age', 'different', 'p', 'value', 'reported', 'exact', 'conditional', 'test', 'reason', 'discrepancy', 'exact', 'p', 'value', 'single', 'parameter', 'result', 'likelihood', 'ratio', 'test', 'based', 'conditional', 'probability', 'density', 'function', 'used', 'estimate', 'case', 'would', 'rely', 'exact', 'p', 'value', 'reported', 'exact', 'conditional', 'analysis', 'table', 'stokes', 'davis', 'koch', '2000', '\tthe', 'score', 'test', 'preferred', 'probability', 'test', 'resulting', 'distribution', 'conditional', 'sufficient', 'statistic', 'bimodal', 'probability', 'test', 'pick', 'probability', 'within', 'valley', 'well', 'tail', 'score', 'pvalue', 'always', 'tail', 'statistic', 'exact', 'odds_ratio']"
900,"It is common in fitting logistic regression models to have problems with convergence. This occurs because maximum likelihood estimates are determined using an iterative algorithm. In the LOGISTIC procedure, the iterations are considered to have converged when the maximum change in parameter estimates between successive steps is less than a certain value (the default is 1E-4). However, sometimes the algorithm fails to converge after a number of iterations (in PROC LOGISTIC the default limit is 25 iterations). A common cause of convergence problems is quasi- complete separation. Quasi-complete separation occurs when the level of a categorical predictor variable perfectly predicts the response. In other words, there is a frequency of 0 in a contingency table. The table above demonstrates the effects of quasi-complete separation. Because of the 0 count, the parameter estimate for the effect of level B will be infinite (PROC LOGISTIC reports the estimate after several iterations). It is obvious something is wrong with the model because of the large parameter estimate for B and the large standard error. The presence of 0 cell counts should be detected during the univariate screening of the data. Solutions to this problem include any of the following: *	collapsing the categories of the predictor variable to eliminate the 0 cell count *	performing exact logistic regression *	eliminating the category altogether *	treating the predictor variable as continuous if it is ordinal *	adding a very small constant to the cell counts. If you add the small constants, it is recommended that you do a sensitivity analysis by adding constants of various sizes in order to gauge their effect on the parameter estimates. You should be very concerned if the results of your model vary with small changes in the data (Allison 1999).",CD,1832,"['common', 'fitting', 'logistic_regression_model', 'problem', 'convergence', 'occurs', 'maximum', 'likelihood', 'estimate', 'determined', 'using', 'iterative', 'algorithm', 'logistic', 'procedure', 'iteration', 'considered', 'converged', 'maximum', 'change', 'parameter_estimate', 'successive', 'step', 'le', 'certain', 'value', 'default', '1e4', 'however', 'sometimes', 'algorithm', 'fails', 'converge', 'number', 'iteration', 'proc_logistic', 'default', 'limit', '25', 'iteration', 'common', 'cause', 'convergence', 'problem', 'quasi', 'complete', 'separation', 'quasicomplete', 'separation', 'occurs', 'level', 'categorical', 'predictor_variable', 'perfectly', 'predicts', 'response', 'word', 'frequency', '0', 'contingency', 'table', 'table', 'demonstrates', 'effect', 'quasicomplete', 'separation', '0', 'count', 'parameter_estimate', 'effect', 'level', 'b', 'infinite', 'proc_logistic', 'report', 'estimate', 'several', 'iteration', 'obvious', 'something', 'wrong', 'model', 'large', 'parameter_estimate', 'b', 'large', 'standard_error', 'presence', '0', 'cell', 'count', 'detected', 'univariate', 'screening', 'data', 'solution', 'problem', 'include', 'following', '\tcollapsing', 'category', 'predictor_variable', 'eliminate', '0', 'cell', 'count', '\tperforming', 'exact', 'logistic_regression', '\teliminating', 'category', 'altogether', '\ttreating', 'predictor_variable', 'continuous', 'ordinal', '\tadding', 'small', 'constant', 'cell', 'count', 'add', 'small', 'constant', 'recommended', 'sensitivity', 'analysis', 'adding', 'constant', 'various', 'size', 'order', 'gauge', 'effect', 'parameter_estimate', 'concerned', 'result', 'model', 'vary', 'small', 'change', 'data', 'allison', '1999']"
901,"To assess the significance of the extra terms in the model, you can compute a likelihood ratio test that compares two models. One model would be the full model with all the terms, and the other model would be the reduced model with just a subset of the terms. The difference between the negative 2 log likelihood for the reduced model and the negative 2 log likelihood for the full model is the value of the test statistic for the likelihood ratio test. An alternative way to compute this test statistic is to take the difference between the likelihood ratio chi-square statistic reported for the model with the extra terms and the likelihood ratio chi-square statistic reported for the model without the extra terms. The degrees of freedom would be the difference in the number of terms between the two models. The test statistic along with the corresponding p-value can be computed using ODS. The test statistic for the likelihood ratio test follows a chi-square distribution if the reduced model is a subset of the full model. Therefore, the validity of the test would be compromised if you were comparing two entirely different models. An alternative way to compute likelihood-ratio tests is to use the GENMOD procedure with the TYPE3 option. PROC GENMOD will be shown in a later chapter. Likelihood Ratio Test Statistic",CD,1324,"['ass', 'significance', 'extra', 'term', 'model', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'two', 'model', 'one', 'model', 'would', 'full', 'model', 'term', 'model', 'would', 'reduced', 'model', 'subset', 'term', 'difference', 'negative', '2', 'log', 'likelihood', 'reduced', 'model', 'negative', '2', 'log', 'likelihood', 'full', 'model', 'value', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'alternative', 'way', 'compute', 'test', 'statistic', 'take', 'difference', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'extra', 'term', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'without', 'extra', 'term', 'degree', 'freedom', 'would', 'difference', 'number', 'term', 'two', 'model', 'test', 'statistic', 'along', 'corresponding', 'pvalue', 'computed', 'using', 'od', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'follows', 'chisquare', 'distribution', 'reduced', 'model', 'subset', 'full', 'model', 'therefore', 'validity', 'test', 'would', 'compromised', 'comparing', 'two', 'entirely', 'different', 'model', 'alternative', 'way', 'compute', 'likelihoodratio', 'test', 'use', 'genmod', 'procedure', 'type3', 'option', 'proc', 'genmod', 'shown', 'later', 'chapter', 'likelihood', 'ratio', 'test', 'statistic']"
902,"Hosmer and Lemeshow (2000) also recommend plotting the diagnostic statistics by the predicted probabilities where the size of the plotting symbol is proportional to the effect of each covariate pattern on the value of the estimated parameters. The GPLOT procedure can accomplish this with the use of a bubble plot. In the bubble plot above, the size of the bubbles is proportional to the c diagnostic statistic. In general, the largest values of the c diagnostic statistic are likely to occur when the change in the Pearson chi-square is large or when the leverage is large (the diagonal of the hat matrix). The position of the bubbles in the graph can give a general idea which statistic contributed to the high c diagnostic statistic. For example, if the large bubbles occur in the upper-right or upper-left corner, then the change in the Pearson chi-square contributed the most to the high c diagnostic statistic because leverage values tend to be low when the estimated probabilities are below .10 or above .90. However, if the bubbles fall in the bottom of the cup defined by the two quadratic curves, then the leverage values contributed the most to the high c diagnostic statistic. The points in the plot that are of greatest concern are those with large circles falling within the cup. These correspond to covariate patterns that are not fit very well and have high leverage values (Hosmer and Lemeshow 2000). The formula for the c diagnostic is:",CD,1454,"['hosmer', 'lemeshow', '2000', 'also', 'recommend', 'plotting', 'diagnostic', 'statistic', 'predicted', 'probability', 'size', 'plotting', 'symbol', 'proportional', 'effect', 'covariate', 'pattern', 'value', 'estimated', 'parameter', 'gplot', 'procedure', 'accomplish', 'use', 'bubble', 'plot', 'bubble', 'plot', 'size', 'bubble', 'proportional', 'c', 'diagnostic', 'statistic', 'general', 'largest', 'value', 'c', 'diagnostic', 'statistic', 'likely', 'occur', 'change', 'pearson', 'chisquare', 'large', 'leverage', 'large', 'diagonal', 'hat', 'matrix', 'position', 'bubble', 'graph', 'give', 'general', 'idea', 'statistic', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'example', 'large', 'bubble', 'occur', 'upperright', 'upperleft', 'corner', 'change', 'pearson', 'chisquare', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'leverage', 'value', 'tend', 'low', 'estimated', 'probability', '10', '90', 'however', 'bubble', 'fall', 'bottom', 'cup', 'defined', 'two', 'quadratic', 'curve', 'leverage', 'value', 'contributed', 'high', 'c', 'diagnostic', 'statistic', 'point', 'plot', 'greatest', 'concern', 'large', 'circle', 'falling', 'within', 'cup', 'correspond', 'covariate', 'pattern', 'fit', 'well', 'high', 'leverage', 'value', 'hosmer', 'lemeshow', '2000', 'formula', 'c', 'diagnostic']"
903,"In some situations, maximum likelihood estimation can fail, or small cell counts make the resulting maximum likelihood estimates inaccurate. An alternative to the asymptotic methods of maximum likelihood is exact logistic regression, which is available for binary outcomes in PROC LOGISTIC. This method has become an important analytical technique, especially in the pharmaceutical industry, for analyzing small, skewed, or sparse data sets.",CD,441,"['situation', 'maximum', 'likelihood', 'estimation', 'fail', 'small', 'cell', 'count', 'make', 'resulting', 'maximum', 'likelihood', 'estimate', 'inaccurate', 'alternative', 'asymptotic', 'method', 'maximum', 'likelihood', 'exact', 'logistic_regression', 'available', 'binary', 'outcome', 'proc_logistic', 'method', 'ha', 'become', 'important', 'analytical', 'technique', 'especially', 'pharmaceutical', 'industry', 'analyzing', 'small', 'skewed', 'sparse', 'data_set']"
904,"In this example the number of subjects is very large and the number of time points very small. Therefore, there should be little difference in the parameter estimates and the robust standard errors across the different correlation structures. The above slide illustrates the robustness of the GEE methods with regard to obtaining consistent parameter estimates and standard errors. Notice the standard errors increased for smoker and decreased for age when compared to the initial independent model. 3.2	Proportional Odds Model",CD,527,"['example', 'number', 'subject', 'large', 'number', 'time', 'point', 'small', 'therefore', 'little', 'difference', 'parameter_estimate', 'robust', 'standard_error', 'across', 'different', 'correlation_structure', 'slide', 'illustrates', 'robustness', 'gee', 'method', 'regard', 'obtaining', 'consistent', 'parameter_estimate', 'standard_error', 'notice', 'standard_error', 'increased', 'smoker', 'decreased', 'age', 'compared', 'initial', 'independent', 'model', '32\tproportional', 'odds', 'model']"
905,"The likelihood ratio statistic that compares the main effects model to the interaction model is clearly significant at the 0.05 level. Therefore, a candidate final model should include the mother_age*phy_visit interaction and the main effects. Example:	Compute a likelihood ratio test comparing a model treating socio as a continuous variable and a model treating socio as a classification variable. /* c1demo06e */ ods listing close;",CD,434,"['likelihood', 'ratio', 'statistic', 'compare', 'main_effect', 'model', 'interaction', 'model', 'clearly', 'significant', '005', 'level', 'therefore', 'candidate', 'final', 'model', 'include', 'motheragephyvisit', 'interaction', 'main_effect', 'example\tcompute', 'likelihood', 'ratio', 'test', 'comparing', 'model', 'treating', 'socio', 'continuous', 'variable', 'model', 'treating', 'socio', 'classification', 'variable', '', 'c1demo06e', '', 'od', 'listing', 'close']"
906,"The routine use of matching is seldom justified (Rothman 1986). For example, if matching does not improve study efficiency, then the effort expended in finding matched subjects would have been better spent in gathering information for a greater number of unmatched subjects. Furthermore, matching does not prevent confounding but rather introduces confounding. Therefore, it is recommended to use an analysis that removes the confounding by the matching factors since matching might cause confounding even when none existed. Finally, matching might lead to overmatching which will increase the number of uninformative strata and decrease study efficiency. For example, matching on a variable that has a strong correlation with an important exposure variable and that has no relation to the outcome might lead to overmatching because it will lead to relatively few informative strata with no offsetting gain (Rothman 1986). Kleinbaum (1991) recommends that the safest strategy is to match only on strong risk factors expected to cause confounding in the data.",CD,1058,"['routine', 'use', 'matching', 'seldom', 'justified', 'rothman', '1986', 'example', 'matching', 'doe', 'improve', 'study', 'efficiency', 'effort', 'expended', 'finding', 'matched', 'subject', 'would', 'better', 'spent', 'gathering', 'information', 'greater', 'number', 'unmatched', 'subject', 'furthermore', 'matching', 'doe', 'prevent', 'confounding', 'rather', 'introduces', 'confounding', 'therefore', 'recommended', 'use', 'analysis', 'remove', 'confounding', 'matching', 'factor', 'since', 'matching', 'might', 'cause', 'confounding', 'even', 'none', 'existed', 'finally', 'matching', 'might', 'lead', 'overmatching', 'increase', 'number', 'uninformative', 'stratum', 'decrease', 'study', 'efficiency', 'example', 'matching', 'variable', 'ha', 'strong', 'correlation', 'important', 'exposure', 'variable', 'ha', 'relation', 'outcome', 'might', 'lead', 'overmatching', 'lead', 'relatively', 'informative', 'stratum', 'offsetting', 'gain', 'rothman', '1986', 'kleinbaum', '1991', 'recommends', 'safest', 'strategy', 'match', 'strong', 'risk', 'factor', 'expected', 'cause', 'confounding', 'data']"
907,"Provided that the mean model is correctly specified and the measurements between subjects are independent, robust standard errors ensure consistent inferences from a GEE regression model even if the chosen correlation structure is incorrect or if the strength of the correlation between measurements varies from subject to subject. Although model-based standard errors are also produced, they are only consistent if the specified correlation structure is correct. Consequently, the robust standard errors, which are usually larger, are usually preferred especially when the number of clusters is large. The desired number of clusters depends on the number of predictor variables in the model. If you have fewer than 5 predictor variables, approximately 25 clusters might be enough to use the robust standard errors. If you have 5 to 12 predictor variables, then you need at least 100 clusters. If you want to be reasonably confident, then you need around 200 clusters (Stokes, Davis, Koch 2000). However, when the number of clusters is very small (less than 20), the model-based standard errors might have better properties even if the specified correlation structure is wrong (Prentice 1988). This is because the robust standard errors are asymptotically unbiased, but could be highly biased when the number of clusters is small. Robust standard errors are derived by the sandwich estimator of the covariance matrix of the regression coefficients. In general, the sandwich estimator uses a matrix with the diagonal elements equal to the individual squared residuals to estimate the common variance (the square of any residual is an estimate of the variance at that predictor variable value). This works because the average of a lot of poor estimators (individual squared residuals) can be a good estimator of the common variance. In fact, Liang and Zeger (1986) showed that the robust standard errors are robust to departures of the working correlation matrix from the true correlation structure.",CD,1997,"['provided', 'mean', 'model', 'correctly', 'specified', 'measurement', 'subject', 'independent', 'robust', 'standard_error', 'ensure', 'consistent', 'inference', 'gee', 'regression_model', 'even', 'chosen', 'correlation_structure', 'incorrect', 'strength', 'correlation', 'measurement', 'varies', 'subject', 'subject', 'although', 'modelbased', 'standard_error', 'also', 'produced', 'consistent', 'specified', 'correlation_structure', 'correct', 'consequently', 'robust', 'standard_error', 'usually', 'larger', 'usually', 'preferred', 'especially', 'number', 'cluster', 'large', 'desired', 'number', 'cluster', 'depends', 'number', 'predictor_variable', 'model', 'fewer', '5', 'predictor_variable', 'approximately', '25', 'cluster', 'might', 'enough', 'use', 'robust', 'standard_error', '5', '12', 'predictor_variable', 'need', 'least', '100', 'cluster', 'want', 'reasonably', 'confident', 'need', 'around', '200', 'cluster', 'stokes', 'davis', 'koch', '2000', 'however', 'number', 'cluster', 'small', 'le', '20', 'modelbased', 'standard_error', 'might', 'better', 'property', 'even', 'specified', 'correlation_structure', 'wrong', 'prentice', '1988', 'robust', 'standard_error', 'asymptotically', 'unbiased', 'could', 'highly', 'biased', 'number', 'cluster', 'small', 'robust', 'standard_error', 'derived', 'sandwich', 'estimator', 'covariance', 'matrix', 'regression', 'coefficient', 'general', 'sandwich', 'estimator', 'us', 'matrix', 'diagonal', 'element', 'equal', 'individual', 'squared', 'residual', 'estimate', 'common', 'variance', 'square', 'residual', 'estimate', 'variance', 'predictor_variable', 'value', 'work', 'average', 'lot', 'poor', 'estimator', 'individual', 'squared', 'residual', 'good', 'estimator', 'common', 'variance', 'fact', 'liang', 'zeger', '1986', 'showed', 'robust', 'standard_error', 'robust', 'departure', 'working', 'correlation', 'matrix', 'true', 'correlation_structure']"
908,HISTOGRAM	creates histograms using high-resolution graphics. Selected HISTOGRAM statement options: CFILL=	specifies the color to fill the histogram bars. CBARLINE=	specifies the color of the outline of the histogram bars.,CD,221,"['histogram\tcreates', 'histogram', 'using', 'highresolution', 'graphic', 'selected', 'histogram', 'statement', 'option', 'cfill\tspecifies', 'color', 'fill', 'histogram', 'bar', 'cbarline\tspecifies', 'color', 'outline', 'histogram', 'bar']"
909,"All of the binary predictors were assessed for interactions. None of the Breslow-Day statistics with the Tarone?s adjustment were significant. However, several contingency tables had 0 cell counts, which cause some instability in the model if the interactions with the 0 cell counts are entered in the model. Furthermore, some of the sample sizes are not large enough for the Breslow-Day statistics to be valid.",CD,411,"['binary', 'predictor', 'assessed', 'interaction', 'none', 'breslowday', 'statistic', 'tarones', 'adjustment', 'significant', 'however', 'several', 'contingency', 'table', '0', 'cell', 'count', 'cause', 'instability', 'model', 'interaction', '0', 'cell', 'count', 'entered', 'model', 'furthermore', 'sample_size', 'large', 'enough', 'breslowday', 'statistic', 'valid']"
910,"In the CLASS statement in PROC LOGISTIC, you can specify the coding scheme for the design variables created from the CLASS variable. For effect coding (also called deviation from the mean coding), the number of design variables created is the number of levels of the CLASS variable minus 1. For example, because the variable socio has three levels, only two design variables are created. For the last level of the CLASS variable, all the design variables have a value of ?1. Parameter estimates of the CLASS main effects using this coding scheme estimate the difference between the effect of each level and the average effect over all levels. Effect coding is the default in PROC LOGISTIC.",CD,689,"['class', 'statement', 'proc_logistic', 'specify', 'coding', 'scheme', 'design', 'variable', 'created', 'class', 'variable', 'effect', 'coding', 'also', 'called', 'deviation', 'mean', 'coding', 'number', 'design', 'variable', 'created', 'number', 'level', 'class', 'variable', 'minus', '1', 'example', 'variable', 'socio', 'ha', 'three', 'level', 'two', 'design', 'variable', 'created', 'last', 'level', 'class', 'variable', 'design', 'variable', 'value', '1', 'parameter_estimate', 'class', 'main_effect', 'using', 'coding', 'scheme', 'estimate', 'difference', 'effect', 'level', 'average', 'effect', 'level', 'effect', 'coding', 'default', 'proc_logistic']"
911,"Quasi-complete separation can also occur when you create interaction terms. The example above shows that there is no separation problem with the predictor variable, but that when you separate it by gender, a 0 cell count occurs. Therefore, the interaction term that consists of the predictor variable and gender should cause some convergence problems in your model.",CD,365,"['quasicomplete', 'separation', 'also', 'occur', 'create', 'interaction', 'term', 'example', 'show', 'separation', 'problem', 'predictor_variable', 'separate', 'gender', '0', 'cell', 'count', 'occurs', 'therefore', 'interaction', 'term', 'consists', 'predictor_variable', 'gender', 'cause', 'convergence', 'problem', 'model']"
912,"Quasi-complete separation can also occur when you create interaction terms. The example above shows that there is no separation problem with the predictor variable, but that when you separate it by gender, a 0 cell count occurs. Therefore, the interaction term that consists of the predictor variable and gender should cause some convergence problems in your model.",CD,365,"['quasicomplete', 'separation', 'also', 'occur', 'create', 'interaction', 'term', 'example', 'show', 'separation', 'problem', 'predictor_variable', 'separate', 'gender', '0', 'cell', 'count', 'occurs', 'therefore', 'interaction', 'term', 'consists', 'predictor_variable', 'gender', 'cause', 'convergence', 'problem', 'model']"
913,"Special methods of statistical analysis are needed for clustered data because the set of measurements on one subject tends to be correlated and measurements on the same subject close in time tend to be more highly correlated than measurements far apart in time. These potential patterns of correlation must be taken into account to draw valid statistical inferences. Therefore, models fit in PROC LOGISTIC might produce invalid results because the independence assumption might not be valid.",CD,491,"['special', 'method', 'statistical', 'analysis', 'needed', 'clustered', 'data_set', 'measurement', 'one', 'subject', 'tends', 'correlated', 'measurement', 'subject', 'close', 'time', 'tend', 'highly', 'correlated', 'measurement', 'far', 'apart', 'time', 'potential', 'pattern', 'correlation', 'must', 'taken', 'account', 'draw', 'valid', 'statistical', 'inference', 'therefore', 'model', 'fit', 'proc_logistic', 'might', 'produce', 'invalid', 'result', 'independence', 'assumption', 'might', 'valid']"
914,"Interaction occurs when the relationship between a predictor variable and the response differs by the level of another predictor variable. For example, the graph above shows that the relationship between gender and the response differs by the level of age. Therefore, age modifies the effect of gender and the age*gender interaction should be included in the model. Furthermore, any estimate of the odds ratio for gender should be made with respect to a specific age. It should be noted that when a predictor variable is involved in an interaction, assessing it for confounding is inappropriate. The reason is that when you statistically adjust for the potential confounder, you are assuming that the effect of the predictor variable on the response is the same regardless of the level of the confounder. When interaction is present, that assumption is violated. For binary predictor variables or predictor variables with few unique values, you can assess interactions through stratified data analysis. For continuous predictor variables, you can assess interactions by including them in a multivariate model.",CD,1109,"['interaction', 'occurs', 'relationship', 'predictor_variable', 'response', 'differs', 'level', 'another', 'predictor_variable', 'example', 'graph', 'show', 'relationship', 'gender', 'response', 'differs', 'level', 'age', 'therefore', 'age', 'modifies', 'effect', 'gender', 'agegender', 'interaction', 'included', 'model', 'furthermore', 'estimate', 'odds_ratio', 'gender', 'made', 'respect', 'specific', 'age', 'noted', 'predictor_variable', 'involved', 'interaction', 'assessing', 'confounding', 'inappropriate', 'reason', 'statistically', 'adjust', 'potential', 'confounder', 'assuming', 'effect', 'predictor_variable', 'response', 'regardless', 'level', 'confounder', 'interaction', 'present', 'assumption', 'violated', 'binary', 'predictor_variable', 'predictor_variable', 'unique', 'value', 'ass', 'interaction', 'stratified', 'data', 'analysis', 'continuous', 'predictor_variable', 'ass', 'interaction', 'including', 'multivariate', 'model']"
915,"In conclusion, careful exploratory data analysis may help you identify scientifically relevant variables to include in your candidate model. Exploratory data analysis may also help you build a model that better depicts the relationships you are studying. Relying on the variable selection techniques in PROC LOGISTIC is no substitute for this stage in the modeling process. 1.3	Subsets Selection Methods",CD,403,"['conclusion', 'careful', 'exploratory', 'data', 'analysis', 'may', 'help', 'identify', 'scientifically', 'relevant', 'variable', 'include', 'candidate', 'model', 'exploratory', 'data', 'analysis', 'may', 'also', 'help', 'build', 'model', 'better', 'depicts', 'relationship', 'studying', 'relying', 'variable', 'selection', 'technique', 'proc_logistic', 'substitute', 'stage', 'modeling', 'process', '13\tsubsets', 'selection', 'method']"
916,The logistic regression model with the two main effects in the model shows no problems with quasi-complete separation. The parameter estimates and their associated standard errors are all reasonable.,CD,199,"['logistic_regression_model', 'two', 'main_effect', 'model', 'show', 'problem', 'quasicomplete', 'separation', 'parameter_estimate', 'associated', 'standard_error', 'reasonable']"
917,"In conclusion, careful exploratory data analysis may help you identify scientifically relevant variables to include in your candidate model. Exploratory data analysis may also help you build a model that better depicts the relationships you are studying. Relying on the variable selection techniques in PROC LOGISTIC is no substitute for this stage in the modeling process. 1.3	Subsets Selection Methods",CD,403,"['conclusion', 'careful', 'exploratory', 'data', 'analysis', 'may', 'help', 'identify', 'scientifically', 'relevant', 'variable', 'include', 'candidate', 'model', 'exploratory', 'data', 'analysis', 'may', 'also', 'help', 'build', 'model', 'better', 'depicts', 'relationship', 'studying', 'relying', 'variable', 'selection', 'technique', 'proc_logistic', 'substitute', 'stage', 'modeling', 'process', '13\tsubsets', 'selection', 'method']"
918,"Two types of adjusted odds ratio estimates are computed by PROC FREQ. One type is the Mantel- Haenszel (MH) estimator, which is obtained as a weighted average of the stratum specific odds ratios. Another type is the logit-based estimator, which is obtained from a weighted average of the stratum-specific log-odds ratios. However, zero frequencies pose a computational problem, so one- half is added to each cell of any table that contains a zero frequency. Therefore, a common recommendation is to use the MH estimators when you have a small sample size because it is less sensitive to small numbers than the logit-based estimator. It should be noted that the MH estimator and the logit-based estimator are similar when the data is not too sparse within the strata.",CD,766,"['two', 'type', 'adjusted', 'odds_ratio', 'estimate', 'computed', 'proc', 'freq', 'one', 'type', 'mantel', 'haenszel', 'mh', 'estimator', 'obtained', 'weighted', 'average', 'stratum', 'specific', 'odds_ratio', 'another', 'type', 'logitbased', 'estimator', 'obtained', 'weighted', 'average', 'stratumspecific', 'logodds', 'ratio', 'however', 'zero', 'frequency', 'pose', 'computational', 'problem', 'one', 'half', 'added', 'cell', 'table', 'contains', 'zero', 'frequency', 'therefore', 'common', 'recommendation', 'use', 'mh', 'estimator', 'small', 'sample_size', 'le', 'sensitive', 'small', 'number', 'logitbased', 'estimator', 'noted', 'mh', 'estimator', 'logitbased', 'estimator', 'similar', 'data', 'sparse', 'within', 'stratum']"
919,"Because there is a common slope for each predictor variable, the odds ratio is constant for all the categories. The odds ratios can be interpreted as the effect of the predictor variable on the odds of being in a lower ordered value category rather than in a higher ordered value category, regardless of what cumulative logit you are examining. If you use the DESCENDING option in the PROC LOGISTIC statement, the odds ratio is the effect of the predictor variable on the odds of being in a higher rather than a lower category. For example, suppose the odds ratio for bending is 3.0 and you used the DESCENDING option (category=severe is the first ordered category and category=none is the last ordered category). You can interpret the odds ratio by stating the women who say that bending aggravates their back pain have 3 times the odds of being in a higher pain severity category compared to women who say that bending does not aggravate their back pain.",CD,956,"['common', 'slope', 'predictor_variable', 'odds_ratio', 'constant', 'category', 'odds_ratio', 'interpreted', 'effect', 'predictor_variable', 'odds', 'lower', 'ordered', 'value', 'category', 'rather', 'higher', 'ordered', 'value', 'category', 'regardless', 'cumulative', 'logit', 'examining', 'use', 'descending', 'option', 'proc_logistic', 'statement', 'odds_ratio', 'effect', 'predictor_variable', 'odds', 'higher', 'rather', 'lower', 'category', 'example', 'suppose', 'odds_ratio', 'bending', '30', 'used', 'descending', 'option', 'categorysevere', 'first', 'ordered', 'category', 'categorynone', 'last', 'ordered', 'category', 'interpret', 'odds_ratio', 'stating', 'woman', 'say', 'bending', 'aggravates', 'back', 'pain', '3', 'time', 'odds', 'higher', 'pain', 'severity', 'category', 'compared', 'woman', 'say', 'bending', 'doe', 'aggravate', 'back', 'pain']"
920,"Example:	Fit an exact logistic regression model to the Cephalexin data set. Request that the individual parameters and the odds ratios be estimated. Use the events/trials syntax and use reference cell coding for each predictor variable and specify No for the reference cell for cephalexin, 50+ for age, and less than a week for length_of_stay. Also create a data set with the exact conditional distributions. /* c3demo18a */ proc logistic data=sasuser.cephalexin; class cephalexin (param=ref ref='No') age (param=ref ref='50+') length_of_stay (param=ref ref='less than a week'); model cases/patients = cephalexin age length_of_stay; exact cephalexin age length_of_stay / estimate=both outdist=dist; title 'Cephalexin in Hospital Model'; run; EXACT statement options: ESTIMATE=	estimates the individual parameters (conditional on all other parameters) for the effects specified in the EXACT statement. For each parameter, a point estimate, a confidence interval, and a p-value for a two-sided test that the parameter is zero are displayed. The keyword BOTH specifies that the parameters and odds ratios be displayed. OUTDIST=	creates the SAS data set containing the exact conditional distributions. The data set contains the possible sufficient statistics for the parameters of the effects specified in the EXACT statement, the counts, the probability of occurrence, and the score value for each sufficient statistic. Cephalexin in Hospital Model",CD,1445,"['example\tfit', 'exact', 'logistic_regression_model', 'cephalexin', 'data_set', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'use', 'eventstrials', 'syntax', 'use', 'reference', 'cell', 'coding', 'predictor_variable', 'specify', 'reference', 'cell', 'cephalexin', '50', 'age', 'le', 'week', 'lengthofstay', 'also', 'create', 'data_set', 'exact', 'conditional', 'distribution', '', 'c3demo18a', '', 'proc_logistic', 'datasasusercephalexin', 'class', 'cephalexin', 'paramref', 'refno', 'age', 'paramref', 'ref50', 'lengthofstay', 'paramref', 'refless', 'week', 'model', 'casespatients', '', 'cephalexin', 'age', 'lengthofstay', 'exact', 'cephalexin', 'age', 'lengthofstay', '', 'estimateboth', 'outdistdist', 'title', 'cephalexin', 'hospital', 'model', 'run', 'exact', 'statement', 'option', 'estimate\testimates', 'individual', 'parameter', 'conditional', 'parameter', 'effect', 'specified', 'exact', 'statement', 'parameter', 'point', 'estimate', 'confidence', 'interval', 'pvalue', 'twosided', 'test', 'parameter', 'zero', 'displayed', 'keyword', 'specifies', 'parameter', 'odds_ratio', 'displayed', 'outdist\tcreates', 'sa', 'data_set', 'containing', 'exact', 'conditional', 'distribution', 'data_set', 'contains', 'possible', 'sufficient', 'statistic', 'parameter', 'effect', 'specified', 'exact', 'statement', 'count', 'probability', 'occurrence', 'score', 'value', 'sufficient', 'statistic', 'cephalexin', 'hospital', 'model']"
921,"PROC LOGISTIC estimates a separate intercept for each cumulative logit. However, PROC LOGISTIC does not estimate a separate slope for each cumulative logit, but rather a common slope across the cumulative logits for each predictor variable. This common slope is a weighted average across the logits. Therefore, a parallel-lines regression model is fitted in which each curve that describes the cumulative probabilities has the same shape. The only difference in the curves is the difference between the values of the intercept parameters. This model is called a proportional odds model.",CD,586,"['proc_logistic', 'estimate', 'separate', 'intercept', 'cumulative', 'logit', 'however', 'proc_logistic', 'doe', 'estimate', 'separate', 'slope', 'cumulative', 'logit', 'rather', 'common', 'slope', 'across', 'cumulative', 'logits', 'predictor_variable', 'common', 'slope', 'weighted', 'average', 'across', 'logits', 'therefore', 'parallellines', 'regression_model', 'fitted', 'curve', 'describes', 'cumulative', 'probability', 'ha', 'shape', 'difference', 'curve', 'difference', 'value', 'intercept', 'parameter', 'model', 'called', 'proportional', 'odds', 'model']"
922,"The primary advantage for matching over random sampling without matching is that matching might lead to a more statistically efficient analysis (Rothman 1986, Kleinbaum 1991). For example, matching might lead to a tighter confidence interval around the odds ratio being estimated for the predictor variables of interest. The reason for the improved precision is that matching might reduce the number of uninformative strata in a stratified analysis. An uninformative stratum in a matched case-control analysis is one in which the predictor variable?s value is constant. For example, suppose the primary predictor variable of interest is an exposure variable (1=yes, 0=no). If the case and control both have the same value of the exposure variable, then it is an uninformative stratum with regards to the exposure effect. Matching might lead to fewer uninformative strata, which will improve the efficiency of the study. Matching is attractive when there is a high price of expanding the study size (Rothman 1986). For example, if the cost of obtaining information from the subjects is large, it is desirable to optimize the amount of information obtained per subject. In other words, it is worthwhile to pay the cost of matching to take full advantage of the information that is collected.",CD,1289,"['primary', 'advantage', 'matching', 'random', 'sampling', 'without', 'matching', 'matching', 'might', 'lead', 'statistically', 'efficient', 'analysis', 'rothman', '1986', 'kleinbaum', '1991', 'example', 'matching', 'might', 'lead', 'tighter', 'confidence', 'interval', 'around', 'odds_ratio', 'estimated', 'predictor_variable', 'interest', 'reason', 'improved', 'precision', 'matching', 'might', 'reduce', 'number', 'uninformative', 'stratum', 'stratified', 'analysis', 'uninformative', 'stratum', 'matched', 'casecontrol', 'analysis', 'one', 'predictor_variable', 'value', 'constant', 'example', 'suppose', 'primary', 'predictor_variable', 'interest', 'exposure', 'variable', '1yes', '0no', 'case', 'control', 'value', 'exposure', 'variable', 'uninformative', 'stratum', 'regard', 'exposure', 'effect', 'matching', 'might', 'lead', 'fewer', 'uninformative', 'stratum', 'improve', 'efficiency', 'study', 'matching', 'attractive', 'high', 'price', 'expanding', 'study', 'size', 'rothman', '1986', 'example', 'cost', 'obtaining', 'information', 'subject', 'large', 'desirable', 'optimize', 'amount', 'information', 'obtained', 'per', 'subject', 'word', 'worthwhile', 'pay', 'cost', 'matching', 'take', 'full', 'advantage', 'information', 'collected']"
923,The chi-square test of association shows that there is strong evidence that an association exists between prev_pretrm and low. Fisher?s exact test is not needed because of the large sample size. Statistics for Table of prev_pretrm by low,CD,237,"['chisquare', 'test', 'association', 'show', 'strong', 'evidence', 'association', 'exists', 'prevpretrm', 'low', 'fisher', 'exact', 'test', 'needed', 'large', 'sample_size', 'statistic', 'table', 'prevpretrm', 'low']"
924,"The above graph reveals a cubic relationship between the response variable and the predictor variable. Adding higher order terms for the predictor variable may approximate this relationship, but polynomials have some undesirable properties (undesirable peaks and valleys) and may not adequately fit many functional forms (Magee 1998). Developing a model with a linear spline function may be a better option (Harrell 1997).",CD,422,"['graph', 'reveals', 'cubic', 'relationship', 'response_variable', 'predictor_variable', 'adding', 'higher', 'order', 'term', 'predictor_variable', 'may', 'approximate', 'relationship', 'polynomial', 'undesirable', 'property', 'undesirable', 'peak', 'valley', 'may', 'adequately', 'fit', 'many', 'functional', 'form', 'magee', '1998', 'developing', 'model', 'linear', 'spline', 'function', 'may', 'better', 'option', 'harrell', '1997']"
925,The chi-square test of association indicates that there is strong evidence of an association between previous preterm deliveries and low birth weight for women with no uterine irritability. Statistics for Table 1 of prev_pretrm by low Controlling for uterine_irr=0,CD,264,"['chisquare', 'test', 'association', 'indicates', 'strong', 'evidence', 'association', 'previous', 'preterm', 'delivery', 'low', 'birth', 'weight', 'woman', 'uterine', 'irritability', 'statistic', 'table', '1', 'prevpretrm', 'low', 'controlling', 'uterineirr0']"
926,"The analyst should be aware that after the predictor variables have been chosen based on subject- matter knowledge, refitting many submodels in terms of an optimum fit to the data distorts the significance levels of conventional statistical tests. Basically, you are using the data to make decisions about the form of the model. After a model is developed, the entire modeling process is routinely forgotten, and statistical quantities such as standard errors, confidence limits, p-values, and R-squared are computed as if the resulting model was entirely prespecified. These inferences are inaccurate, tending to err on the side of overstating the significance of predictors and making predictions with overly optimistic confidence. This problem is very evident when there are many iterative stages in model building. When there are many variables and you use stepwise selection to find a small subset of variables, inferences become less accurate (Chatfield 1995, Raftery 1994, Freedman 1983). One solution to this problem is to split your data. One part could be used for finding the regression model and the other part could be used for inference. However, if your data set is small, the loss of efficiency can be prohibitive (Faraway 1992). Another solution is to use bootstrapping methods to obtain the correct standard errors and p-values. Bootstrapping is a resampling method that tries to approximate the distribution of the parameter estimates to estimate the standard error. Unfortunately, bootstrapping is not part of PROC LOGISTIC and the computer programming is beyond the scope of this course.",CD,1608,"['analyst', 'aware', 'predictor_variable', 'chosen', 'based', 'subject', 'matter', 'knowledge', 'refitting', 'many', 'submodels', 'term', 'optimum', 'fit', 'data', 'distorts', 'significance', 'level', 'conventional', 'statistical', 'test', 'basically', 'using', 'data', 'make', 'decision', 'form', 'model', 'model', 'developed', 'entire', 'modeling', 'process', 'routinely', 'forgotten', 'statistical', 'quantity', 'standard_error', 'confidence', 'limit', 'pvalues', 'rsquared', 'computed', 'resulting', 'model', 'wa', 'entirely', 'prespecified', 'inference', 'inaccurate', 'tending', 'err', 'side', 'overstating', 'significance', 'predictor', 'making', 'prediction', 'overly', 'optimistic', 'confidence', 'problem', 'evident', 'many', 'iterative', 'stage', 'model', 'building', 'many', 'variable', 'use', 'stepwise', 'selection', 'find', 'small', 'subset', 'variable', 'inference', 'become', 'le', 'accurate', 'chatfield', '1995', 'raftery', '1994', 'freedman', '1983', 'one', 'solution', 'problem', 'split', 'data', 'one', 'part', 'could', 'used', 'finding', 'regression_model', 'part', 'could', 'used', 'inference', 'however', 'data_set', 'small', 'loss', 'efficiency', 'prohibitive', 'faraway', '1992', 'another', 'solution', 'use', 'bootstrapping', 'method', 'obtain', 'correct', 'standard_error', 'pvalues', 'bootstrapping', 'resampling', 'method', 'try', 'approximate', 'distribution', 'parameter_estimate', 'estimate', 'standard_error', 'unfortunately', 'bootstrapping', 'part', 'proc_logistic', 'computer', 'programming', 'beyond', 'scope', 'course']"
927,"Unlike the binary and ordinal logistic models, the nominal logistic model has separate intercept parameters and separate slope parameters for each generalized logit. Therefore, there are multiple sets of parameters for both the intercept terms and the predictor variables. When building nominal models, you should consider whether the sample size is large enough to support the number of generalized logits you are modeling. Because you are estimating many parameters, you may encounter parameter estimation problems with small sample sizes. As a general rule you need each possible outcome to have at least five observations per explanatory variable in the model for valid estimation to proceed (Stokes, Davis, and Koch 2000). If you have a small sample size, one solution is to use the EXACT statement to fit an exact logistic regression model.",CD,846,"['unlike', 'binary', 'ordinal', 'logistic', 'model', 'nominal', 'logistic', 'model', 'ha', 'separate', 'intercept', 'parameter', 'separate', 'slope', 'parameter', 'generalized', 'logit', 'therefore', 'multiple', 'set', 'parameter', 'intercept', 'term', 'predictor_variable', 'building', 'nominal', 'model', 'consider', 'whether', 'sample_size', 'large', 'enough', 'support', 'number', 'generalized', 'logits', 'modeling', 'estimating', 'many', 'parameter', 'may', 'encounter', 'parameter', 'estimation', 'problem', 'small', 'sample_size', 'general', 'rule', 'need', 'possible', 'outcome', 'least', 'five', 'observation', 'per', 'explanatory', 'variable', 'model', 'valid', 'estimation', 'proceed', 'stokes', 'davis', 'koch', '2000', 'small', 'sample_size', 'one', 'solution', 'use', 'exact', 'statement', 'fit', 'exact', 'logistic_regression_model']"
928,"The equation for the logistic regression model that refers directly to the probability of the outcome is shown above. This equation has the desired property that the predicted probabilities will always be between 0 and 1. This model is nonlinear because the parameter estimates do not enter the model equation linearly. Furthermore, the model permits the rate of change of the probabilities to vary as the predictor variable values vary.",CD,437,"['equation', 'logistic_regression_model', 'refers', 'directly', 'probability', 'outcome', 'shown', 'equation', 'ha', 'desired', 'property', 'predicted', 'probability', 'always', '0', '1', 'model', 'nonlinear', 'parameter_estimate', 'enter', 'model', 'equation', 'linearly', 'furthermore', 'model', 'permit', 'rate', 'change', 'probability', 'vary', 'predictor_variable', 'value', 'vary']"
929,"The exchangeable correlation structure (TYPE=EXCH) assumes that the correlations are equal across time points. Although this structure may not be justified in longitudinal studies, it is often reasonable in situations where the repeated measurements are not obtained over time (Allison 1999). For example, the exchangeable correlation structure might be a good choice if the independent experimental units were classrooms and the responses obtained were from each student in the classroom (Davis 2002).",CD,502,"['exchangeable', 'correlation_structure', 'typeexch', 'assumes', 'correlation', 'equal', 'across', 'time', 'point', 'although', 'structure', 'may', 'justified', 'longitudinal', 'study', 'often', 'reasonable', 'situation', 'repeated', 'measurement', 'obtained', 'time', 'allison', '1999', 'example', 'exchangeable', 'correlation_structure', 'might', 'good', 'choice', 'independent', 'experimental', 'unit', 'classroom', 'response', 'obtained', 'student', 'classroom', 'davis', '2002']"
930,"GEE regression models are very popular because clustered data is common in many fields of research. For example, a physician might evaluate patients at weekly intervals in a clinical drug trial. A family study on liver cancer might want to estimate the degree of association between liver cancer and members of the same family to examine the possible genetic explanation of the disease process. A dental study might measure the extent of tooth decay for each tooth in a subject?s mouth. A common feature of these studies is that repeated categorical response data is collected and the independence assumption is violated.",CD,621,"['gee', 'regression_model', 'popular', 'clustered', 'data', 'common', 'many', 'field', 'research', 'example', 'physician', 'might', 'evaluate', 'patient', 'weekly', 'interval', 'clinical', 'drug', 'trial', 'family', 'study', 'liver', 'cancer', 'might', 'want', 'estimate', 'degree', 'association', 'liver', 'cancer', 'member', 'family', 'examine', 'possible', 'genetic', 'explanation', 'disease', 'process', 'dental', 'study', 'might', 'measure', 'extent', 'tooth', 'decay', 'tooth', 'subject', 'mouth', 'common', 'feature', 'study', 'repeated', 'categorical', 'response', 'data', 'collected', 'independence', 'assumption', 'violated']"
931,Example:	Generate the regression diagnostic statistics for each observation. /* c2demo11a */ proc logistic data=sasuser.birth; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit / influence; title 'Logistic Regression Diagnostic Statistics'; run; Selected MODEL statement options: INFLUENCE	displays diagnostic measures for identifying influential observations in the case of the binary outcome model. Partial Output Logistic Regression Diagnostic Statistics,CD,527,"['example\tgenerate', 'regression', 'diagnostic', 'statistic', 'observation', '', 'c2demo11a', '', 'proc_logistic', 'datasasuserbirth', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', '', 'influence', 'title', 'logistic_regression', 'diagnostic', 'statistic', 'run', 'selected', 'model_statement', 'option', 'influence\tdisplays', 'diagnostic', 'measure', 'identifying', 'influential', 'observation', 'case', 'binary', 'outcome', 'model', 'partial', 'output', 'logistic_regression', 'diagnostic', 'statistic']"
932,"A useful way to explain significant interactions is to graph them. For example, to visualize the interaction between mother?s age and physician visit, first create a data set that contains the information about the fitted model. Then create a data set with plotting points, which include the median for each predictor variable not involved in the interaction and the 5th, 25th, 50th, 75th, and 95th percentiles of mother?s age and both values of physician visit. Then score the data set in PROC LOGISTIC with the SCORE statement. Finally, plot the predicted logits and the predicted probabilities by the plotting points for the two variables to illustrate how the slope for mother?s age differs by the level of physician visit. Illustrating Interactions",CD,753,"['useful', 'way', 'explain', 'significant', 'interaction', 'graph', 'example', 'visualize', 'interaction', 'mother', 'age', 'physician', 'visit', 'first', 'create', 'data_set', 'contains', 'information', 'fitted', 'model', 'create', 'data_set', 'plotting', 'point', 'include', 'median', 'predictor_variable', 'involved', 'interaction', '5th', '25th', '50th', '75th', '95th', 'percentile', 'mother', 'age', 'value', 'physician', 'visit', 'score', 'data_set', 'proc_logistic', 'score', 'statement', 'finally', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', 'two', 'variable', 'illustrate', 'slope', 'mother', 'age', 'differs', 'level', 'physician', 'visit', 'illustrating', 'interaction']"
933,"GEE regression models are very popular because clustered data is common in many fields of research. For example, a physician might evaluate patients at weekly intervals in a clinical drug trial. A family study on liver cancer might want to estimate the degree of association between liver cancer and members of the same family to examine the possible genetic explanation of the disease process. A dental study might measure the extent of tooth decay for each tooth in a subject?s mouth. A common feature of these studies is that repeated categorical response data is collected and the independence assumption is violated.",CD,621,"['gee', 'regression_model', 'popular', 'clustered', 'data', 'common', 'many', 'field', 'research', 'example', 'physician', 'might', 'evaluate', 'patient', 'weekly', 'interval', 'clinical', 'drug', 'trial', 'family', 'study', 'liver', 'cancer', 'might', 'want', 'estimate', 'degree', 'association', 'liver', 'cancer', 'member', 'family', 'examine', 'possible', 'genetic', 'explanation', 'disease', 'process', 'dental', 'study', 'might', 'measure', 'extent', 'tooth', 'decay', 'tooth', 'subject', 'mouth', 'common', 'feature', 'study', 'repeated', 'categorical', 'response', 'data', 'collected', 'independence', 'assumption', 'violated']"
934,"After you have formulated the final model, you need to assess how well it fits the data. In other words, you need to assess how close the model-predicted values are to the corresponding observed values. Test statistics that assess the fit of the model are called goodness-of-fit statistics. If departures of the predicted values from the observed values are essentially random, then the goodness-of-fit statistics are not statistically significant. Some of the problems that can cause the goodness-of-fit statistics to be statistically significant are having outliers in the data, omitting important terms in the model such as interactions, needing to transform some predictor variables, having a nonlinear relationship between the logits and a predictor variable, and having a model that has greater variability than predicted by the random component of the model. This latter problem is also known as overdispersion, and it occurs when the assumption of binomial variability may not be valid. These problems should be examined before proceeding to use methods to correct for overdispersion (SAS Institute Inc. 1995). Another problem with logistic regression, as in linear regression, is multicollinearity. This occurs when there are strong linear dependencies among the predictor variables. Although multicollinearity does not bias the parameter estimates, it does increase their variances, which results in less precise estimates of the parameters (Allison 1999). There are no multicollinearity diagnostics in the LOGISTIC procedure. However, you can use the diagnostics in the REG procedure because multicollinearity only deals with the predictor variables, not the outcome variable. Some of the options in the MODEL statement in PROC REG include TOL, VIF, COLLIN, and COLLINOINT. In most cases, serious multicollinearity will be detected. In rare instances you may fail to detect the problem because the linear combinations should actually be adjusted by the weight matrix used in the maximum likelihood algorithm (Allison 1999).",CD,2034,"['formulated', 'final', 'model', 'need', 'ass', 'well', 'fit', 'data', 'word', 'need', 'ass', 'close', 'modelpredicted', 'value', 'corresponding', 'observed', 'value', 'test', 'statistic', 'ass', 'fit', 'model', 'called', 'goodnessoffit', 'statistic', 'departure', 'predicted', 'value', 'observed', 'value', 'essentially', 'random', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'problem', 'cause', 'goodnessoffit', 'statistic', 'statistically', 'significant', 'outlier', 'data', 'omitting', 'important', 'term', 'model', 'interaction', 'needing', 'transform', 'predictor_variable', 'nonlinear', 'relationship', 'logits', 'predictor_variable', 'model', 'ha', 'greater', 'variability', 'predicted', 'random', 'component', 'model', 'latter', 'problem', 'also', 'known', 'overdispersion', 'occurs', 'assumption', 'binomial', 'variability', 'may', 'valid', 'problem', 'examined', 'proceeding', 'use', 'method', 'correct', 'overdispersion', 'sa', 'institute', 'inc', '1995', 'another', 'problem', 'logistic_regression', 'linear', 'regression', 'multicollinearity', 'occurs', 'strong', 'linear', 'dependency', 'among', 'predictor_variable', 'although', 'multicollinearity', 'doe', 'bias', 'parameter_estimate', 'doe', 'increase', 'variance', 'result', 'le', 'precise', 'estimate', 'parameter', 'allison', '1999', 'multicollinearity', 'diagnostics', 'logistic', 'procedure', 'however', 'use', 'diagnostics', 'reg', 'procedure', 'multicollinearity', 'deal', 'predictor_variable', 'outcome', 'variable', 'option', 'model_statement', 'proc', 'reg', 'include', 'tol', 'vif', 'collin', 'collinoint', 'case', 'serious', 'multicollinearity', 'detected', 'rare', 'instance', 'may', 'fail', 'detect', 'problem', 'linear', 'combination', 'actually', 'adjusted', 'weight', 'matrix', 'used', 'maximum', 'likelihood', 'algorithm', 'allison', '1999']"
935,Example:	Fit a simple ordinal logistic regression model to the backache data set. Specify painseverity as the response variable and bending as the predictor variable. Also specify the DESCENDING option to reverse the sort order of the response variable. /* c3demo14a */ proc logistic data=sasuser.backache desc; model painseverity=bending; title 'Ordinal Logistic Regression Model for the Backache ' 'Example'; run; PROC LOGISTIC statement option: DESC	reverses the sorting order for the levels of the response variable. This option has the same effect as the response variable option DESCENDING in the MODEL statement. Ordinal Logistic Regression Model for the Backache Example,CD,678,"['example\tfit', 'simple', 'ordinal', 'logistic_regression_model', 'backache', 'data_set', 'specify', 'painseverity', 'response_variable', 'bending', 'predictor_variable', 'also', 'specify', 'descending', 'option', 'reverse', 'sort', 'order', 'response_variable', '', 'c3demo14a', '', 'proc_logistic', 'datasasuserbackache', 'desc', 'model', 'painseveritybending', 'title', 'ordinal', 'logistic_regression_model', 'backache', '', 'example', 'run', 'proc_logistic', 'statement', 'option', 'desc\treverses', 'sorting', 'order', 'level', 'response_variable', 'option', 'ha', 'effect', 'response_variable', 'option', 'descending', 'model_statement', 'ordinal', 'logistic_regression_model', 'backache', 'example']"
936,"Finally, the unstructured correlation structure (TYPE=UNSTR) is completely unspecified. Therefore, there are t(t?1)/2 parameters to be estimated (where t is the number of time points). Although the unstructured working correlation structure is the most efficient, it is useful only when there are very few observation times. If there were many time points, you would probably want to impose some structure to the correlation matrix by selecting one of the other correlation structures (Allison 1999). Furthermore, when there are missing values or a varying number of observations per subject, a nonpositive definite matrix may occur, which would stop the parameter estimation process (Stokes, Davis, and Koch 2000).",CD,715,"['finally', 'unstructured', 'correlation_structure', 'typeunstr', 'completely', 'unspecified', 'therefore', 'tt12', 'parameter', 'estimated', 'number', 'time', 'point', 'although', 'unstructured', 'working', 'correlation_structure', 'efficient', 'useful', 'observation', 'time', 'many', 'time', 'point', 'would', 'probably', 'want', 'impose', 'structure', 'correlation', 'matrix', 'selecting', 'one', 'correlation_structure', 'allison', '1999', 'furthermore', 'missing', 'value', 'varying', 'number', 'observation', 'per', 'subject', 'nonpositive', 'definite', 'matrix', 'may', 'occur', 'would', 'stop', 'parameter', 'estimation', 'process', 'stokes', 'davis', 'koch', '2000']"
937,The Parameter Information table displays the names of the parameters. Notice PROC GENMOD shows which value of the response variable is being modeled. Criteria For Assessing Goodness Of Fit,CD,188,"['parameter', 'information', 'table', 'display', 'name', 'parameter', 'notice', 'proc', 'genmod', 'show', 'value', 'response_variable', 'modeled', 'criterion', 'assessing', 'goodness', 'fit']"
938,title 'Estimated Logit Plot of Socioeconomic Status'; run; Selected PROC MEANS statement option: NWAY	causes the output data set to have only one observation for each level of the class variable.,CD,195,"['title', 'estimated', 'logit', 'plot', 'socioeconomic', 'status', 'run', 'selected', 'proc', 'mean', 'statement', 'option', 'nway\tcauses', 'output', 'data_set', 'one', 'observation', 'level', 'class', 'variable']"
939,"NOTE: Reported test p-values are lower-bounds for the true p-values. Notice that the p-values are different for the score test and the probability test. It is recommended that the score test results be used. Also note that the reported test p-values are lower bounds for the true p-values. This occurs because when the exact distribution has ties, the Monte Carlo algorithm estimates the probabilities with error, and hence it cannot determine which values contribute to the reported p-values. If you need more precise values, you can specify the OUTDIST= option, determine appropriate cutoff values for the observed probability and score, and then construct the true p-value estimates from the OUTDIST= data set. See the SAS/STAT software online documentation under the LOGISTIC procedure for programming statements to accomplish this task. Exact Parameter Estimates",CD,867,"['note', 'reported', 'test', 'pvalues', 'lowerbounds', 'true', 'pvalues', 'notice', 'pvalues', 'different', 'score', 'test', 'probability', 'test', 'recommended', 'score', 'test', 'result', 'used', 'also', 'note', 'reported', 'test', 'pvalues', 'lower', 'bound', 'true', 'pvalues', 'occurs', 'exact', 'distribution', 'ha', 'tie', 'monte', 'carlo', 'algorithm', 'estimate', 'probability', 'error', 'hence', 'cannot', 'determine', 'value', 'contribute', 'reported', 'pvalues', 'need', 'precise', 'value', 'specify', 'outdist', 'option', 'determine', 'appropriate', 'cutoff', 'value', 'observed', 'probability', 'score', 'construct', 'true', 'pvalue', 'estimate', 'outdist', 'data_set', 'see', 'sasstat', 'software', 'online', 'documentation', 'logistic', 'procedure', 'programming', 'statement', 'accomplish', 'task', 'exact', 'parameter_estimate']"
940,"The algorithm for variable clustering starts off with all the variables in one cluster. A principal components analysis is then done on the variables and the algorithm examines the eigenvalues computed for each principal component. Eigenvalues measure how much variability is explained by the principal components. They are scaled so that the sum of the eigenvalues is equal to the number of variables. When the predictor variables are uncorrelated, then all of the eigenvalues equal 1. If there is only one group of variables that is related to each other, then the first eigenvalue (corresponding to the first principal component) is large and the others are all close to 0. However, if there are several groups of related variables, then several eigenvalues are much larger than 1. The algorithm examines the second eigenvalue because that determines whether there is more than one dominant dimension in the variable cluster. If the second eigenvalue is greater than a specified threshold, then the variable cluster is split into 2 groups. The process is repeated until the second eigenvalue drops below the threshold. Larger thresholds for the second eigenvalue give fewer clusters and less variation is explained among the predictor variables. Smaller thresholds give more clusters and more variation is explained. The default threshold is 1 because it represents the average size of the eigenvalues (if the correlation matrix is analyzed). To account for sampling variability, smaller values such as .70 have been suggested (Jackson 1991). However, the threshold should be chosen based on the results of variable clustering.",CD,1630,"['algorithm', 'variable', 'clustering', 'start', 'variable', 'one', 'cluster', 'principal', 'component', 'analysis', 'done', 'variable', 'algorithm', 'examines', 'eigenvalue', 'computed', 'principal', 'component', 'eigenvalue', 'measure', 'much', 'variability', 'explained', 'principal', 'component', 'scaled', 'sum', 'eigenvalue', 'equal', 'number', 'variable', 'predictor_variable', 'uncorrelated', 'eigenvalue', 'equal', '1', 'one', 'group', 'variable', 'related', 'first', 'eigenvalue', 'corresponding', 'first', 'principal', 'component', 'large', 'others', 'close', '0', 'however', 'several', 'group', 'related', 'variable', 'several', 'eigenvalue', 'much', 'larger', '1', 'algorithm', 'examines', 'second', 'eigenvalue', 'determines', 'whether', 'one', 'dominant', 'dimension', 'variable', 'cluster', 'second', 'eigenvalue', 'greater', 'specified', 'threshold', 'variable', 'cluster', 'split', '2', 'group', 'process', 'repeated', 'second', 'eigenvalue', 'drop', 'threshold', 'larger', 'threshold', 'second', 'eigenvalue', 'give', 'fewer', 'cluster', 'le', 'variation', 'explained', 'among', 'predictor_variable', 'smaller', 'threshold', 'give', 'cluster', 'variation', 'explained', 'default', 'threshold', '1', 'represents', 'average', 'size', 'eigenvalue', 'correlation', 'matrix', 'analyzed', 'account', 'sampling', 'variability', 'smaller', 'value', '70', 'suggested', 'jackson', '1991', 'however', 'threshold', 'chosen', 'based', 'result', 'variable', 'clustering']"
941,"Example:	An insurance company wants to relate the safety of vehicles to several other variables. A score has been given to each vehicle model, using the frequency of insurance claims as a basis. The data is in the sasuser.safety data set. The variables in the data set are safety	safety score (1=Below Average, 0=Average or Above) type	type of vehicle (Sports, Small, Medium, Large, and Sport/Utility) region	manufacturing region (Asia, N America) weight	weight of the vehicle in thousands of pounds. Recall from the exercises that the logistic model for the car safety data detected quasi-complete separation of data. This occurred because none of the large cars had below average safety records. The parameter estimate and standard error for the large effect were deemed unreliable. Fitting Exact Logistic Regression Models with the Hybrid Network ? Monte Carlo Algorithm Example:	Fit an exact logistic regression model using the Monte Carlo algorithm with safety as the response variable and type, region, and weight as the predictor variables. Model the probability of below average safety scores and request that the individual parameters and the odds ratios be estimated. Specify type and region as classification variables using reference cell coding. Specify Small as the reference level for type and Asia as the reference level for region. Also, add the observed sufficient statistic to the sampled exact distribution, specify that 100,000 Monte Carlo samples be taken, and set the seed at 27514. /* c3demo19a */ proc logistic data=sasuser.safety exactoptions(method=networkmc addtobs n=100000 seed=27514); class type (param=ref ref='Small') region (param=ref ref='Asia'); model safety = type region weight; exact type weight region / estimate=both; title 'Car Safety Model'; run; PROC LOGISTIC statement options: EXACTOPTIONS(options)	specifies options that apply to every EXACT statement in the program. Selected EXACTOPTIONS options: ADDTOBS	adds the observed sufficient statistic to the sampled exact distribution if the statistic was not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified and the ESTIMATE option is specified in the EXACT statement. If the observed statistic has not been sampled, then the parameter estimate does not exist: by specifying this option, you can produce (biased) estimates. METHOD=	specifies which exact conditional algorithm to use for every EXACT statement specified. The keywords are DIRECT (invokes the multivariate shift algorithm), NETWORK (invokes a network algorithm) and NETWORKMC (invokes the hybrid network and Monte Carlo algorithm). N=	specifies the number of Monte Carlo samples to take when METHOD=NETWORKMC. By default n=10,000. SEED=	specifies the initial seed for the random number generator used to take the Monte Carlo samples for METHOD=NETWORKMC. The value of the SEED= option must be an integer. If you do not specify a seed, or if you specify a value less than or equal to zero, then PROC LOGISTIC uses the time of day from the computer?s clock to generate the initial seed. Car Safety Model",CD,3092,"['example\tan', 'insurance', 'company', 'want', 'relate', 'safety', 'vehicle', 'several', 'variable', 'score', 'ha', 'given', 'vehicle', 'model', 'using', 'frequency', 'insurance', 'claim', 'basis', 'data', 'sasusersafety', 'data_set', 'variable', 'data_set', 'safety\tsafety', 'score', '1below', 'average', '0average', 'type\ttype', 'vehicle', 'sport', 'small', 'medium', 'large', 'sportutility', 'region\tmanufacturing', 'region', 'asia', 'n', 'america', 'weight\tweight', 'vehicle', 'thousand', 'pound', 'recall', 'exercise', 'logistic', 'model', 'car', 'safety', 'data', 'detected', 'quasicomplete', 'separation', 'data', 'occurred', 'none', 'large', 'car', 'average', 'safety', 'record', 'parameter_estimate', 'standard_error', 'large', 'effect', 'deemed', 'unreliable', 'fitting', 'exact', 'logistic_regression_model', 'hybrid', 'network', '', 'monte', 'carlo', 'algorithm', 'example\tfit', 'exact', 'logistic_regression_model', 'using', 'monte', 'carlo', 'algorithm', 'safety', 'response_variable', 'type', 'region', 'weight', 'predictor_variable', 'model', 'probability', 'average', 'safety', 'score', 'request', 'individual', 'parameter', 'odds_ratio', 'estimated', 'specify', 'type', 'region', 'classification', 'variable', 'using', 'reference', 'cell', 'coding', 'specify', 'small', 'reference', 'level', 'type', 'asia', 'reference', 'level', 'region', 'also', 'add', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'specify', '100000', 'monte', 'carlo', 'sample', 'taken', 'set', 'seed', '27514', '', 'c3demo19a', '', 'proc_logistic', 'datasasusersafety', 'exactoptionsmethodnetworkmc', 'addtobs', 'n100000', 'seed27514', 'class', 'type', 'paramref', 'refsmall', 'region', 'paramref', 'refasia', 'model', 'safety', '', 'type', 'region', 'weight', 'exact', 'type', 'weight', 'region', '', 'estimateboth', 'title', 'car', 'safety', 'model', 'run', 'proc_logistic', 'statement', 'option', 'exactoptionsoptions\tspecifies', 'option', 'apply', 'every', 'exact', 'statement', 'program', 'selected', 'exactoptions', 'option', 'addtobs\tadds', 'observed', 'sufficient', 'statistic', 'sampled', 'exact', 'distribution', 'statistic', 'wa', 'sampled', 'option', 'ha', 'effect', 'unless', 'methodnetworkmc', 'option', 'specified', 'estimate', 'option', 'specified', 'exact', 'statement', 'observed', 'statistic', 'ha', 'sampled', 'parameter_estimate', 'doe', 'exist', 'specifying', 'option', 'produce', 'biased', 'estimate', 'method\tspecifies', 'exact', 'conditional', 'algorithm', 'use', 'every', 'exact', 'statement', 'specified', 'keywords', 'direct', 'invokes', 'multivariate', 'shift', 'algorithm', 'network', 'invokes', 'network', 'algorithm', 'networkmc', 'invokes', 'hybrid', 'network', 'monte', 'carlo', 'algorithm', 'n\tspecifies', 'number', 'monte', 'carlo', 'sample', 'take', 'methodnetworkmc', 'default', 'n10000', 'seed\tspecifies', 'initial', 'seed', 'random', 'number', 'generator', 'used', 'take', 'monte', 'carlo', 'sample', 'methodnetworkmc', 'value', 'seed', 'option', 'must', 'integer', 'specify', 'seed', 'specify', 'value', 'le', 'equal', 'zero', 'proc_logistic', 'us', 'time', 'day', 'computer', 'clock', 'generate', 'initial', 'seed', 'car', 'safety', 'model']"
942,"The problem of biasing the inferences can be avoided by prespecifying the model. When you have a large number of variables, however, prespecifying the model is not feasible. Therefore, analysts use the results of the model selection techniques (usually the p-values for the predictor variables) to select a model. However, the p-values calculated in the model selection techniques are not p-values in the traditional hypothesis-testing context. Instead, they should be viewed as indicators of relative importance among variables (Hosmer and Lemeshow 2000). Because the biased p-values overstate the significance of the predictor variables, the traditional cutoff of .05 is not very useful unless the sample size is small (30-50). For large sample sizes, much smaller p-values are required to imply that the data provide evidence for the effect of interest. The slide above provides approximate two-sided p-values corresponding to different grades of evidence for tests involving one additional parameter (one degree of freedom). Significance levels for tests involving more than one degree of freedom would even be lower, especially for the larger sample sizes (Raftery 1994).",CD,1176,"['problem', 'biasing', 'inference', 'avoided', 'prespecifying', 'model', 'large', 'number', 'variable', 'however', 'prespecifying', 'model', 'feasible', 'therefore', 'analyst', 'use', 'result', 'model', 'selection', 'technique', 'usually', 'pvalues', 'predictor_variable', 'select', 'model', 'however', 'pvalues', 'calculated', 'model', 'selection', 'technique', 'pvalues', 'traditional', 'hypothesistesting', 'context', 'instead', 'viewed', 'indicator', 'relative', 'importance', 'among', 'variable', 'hosmer', 'lemeshow', '2000', 'biased', 'pvalues', 'overstate', 'significance', 'predictor_variable', 'traditional', 'cutoff', '05', 'useful', 'unless', 'sample_size', 'small', '3050', 'large', 'sample_size', 'much', 'smaller', 'pvalues', 'required', 'imply', 'data', 'provide', 'evidence', 'effect', 'interest', 'slide', 'provides', 'approximate', 'twosided', 'pvalues', 'corresponding', 'different', 'grade', 'evidence', 'test', 'involving', 'one', 'additional', 'parameter', 'one', 'degree', 'freedom', 'significance', 'level', 'test', 'involving', 'one', 'degree', 'freedom', 'would', 'even', 'lower', 'especially', 'larger', 'sample_size', 'raftery', '1994']"
943,"The estimated logit plot shows no apparent pattern. Therefore, mother_age may be entered into the model as a continuous variable because creating several groups will probably not improve the fit of the model. Although it seems mother_age is not an important predictor for low birth weight, the estimated logit plot is a univariate plot that can be misleading in the presence of partial associations and interactions. A model with two-factor interactions and main effects should be evaluated before mother_age is eliminated. Estimated logit plots should never be used to eliminate variables.",CD,590,"['estimated', 'logit', 'plot', 'show', 'apparent', 'pattern', 'therefore', 'motherage', 'may', 'entered', 'model', 'continuous', 'variable', 'creating', 'several', 'group', 'probably', 'improve', 'fit', 'model', 'although', 'seems', 'motherage', 'important', 'predictor', 'low', 'birth', 'weight', 'estimated', 'logit', 'plot', 'univariate', 'plot', 'misleading', 'presence', 'partial', 'association', 'interaction', 'model', 'twofactor', 'interaction', 'main_effect', 'evaluated', 'motherage', 'eliminated', 'estimated', 'logit', 'plot', 'never', 'used', 'eliminate', 'variable']"
944,"Missing values that occur intermixed with nonmissing values are called intermittent missing values. If these missing values are missing completely at random (MCAR), then the consistency results established by Liang and Zeger (1986) hold. A simple check of MCAR is to divide the subjects into two groups: those with a complete set of measurements and those with missing measurements. If the MCAR assumption holds, then both groups (with their measurements) should be random samples of the same population of measurements. In other words, the probability of missing is independent of the observed measurements and the measurements that would have been available had they not been missing. The t-tests for location and more general tests of equality of distribution can be used to test the MCAR assumption (Little 1995). Tests of MCAR for repeatedly measured categorical data were discussed by Park and Davis (1993). Some intermittent missing values can arise due to censoring rules. For example, values outside a stated range might be simply unreliable because of the limitations of the measuring techniques in use (Diggle, Heagerty, Liang, and Zeger 2002). Methods for handling censored data in correlation data structures are addressed in Laird (1988) and Hughes (1999). Intermittent missing values can also be related to the outcome. For example, a patient might miss an appointment because of an adverse reaction to the treatment. The fact that the subject remains in the study means that the investigator should have the opportunity to ascertain the reason for the missing appointment and take corrective action accordingly (Diggle, Heagerty, Liang, and Zeger 2002, Little 1995). If all the missing values occur after a certain time point for a subject, then the missing values are called dropouts. These are a more significant problem compared to intermittent missing values because usually the subject is withdrawn for reasons directly or indirectly connected to the outcome and are lost to follow-up. If you treat the dropouts as MCAR when they are in fact informative dropouts, the parameter estimates will be biased (Diggle and Kenward 1994). Diggle, Heagerty, Liang, and Zeger (2002) state that ?An emerging consensus is that analysis of data with potentially informative dropouts necessarily involves assumptions that are difficult, or even impossible, to check from the observed data. This suggests that it would be unwise to rely on the precise conclusions of an analysis based on a particular informative dropout model.? They recommend that a sensitivity analysis be conducted on the informative dropout model. This provides some protection against the possibility that conclusions reached from a random dropout model are critically dependent on the validity of MCAR. Scharstein et al. (1999) provides a discussion on how such sensitivity analyses might be conducted.",CD,2880,"['missing', 'value', 'occur', 'intermixed', 'nonmissing', 'value', 'called', 'intermittent', 'missing', 'value', 'missing', 'value', 'missing', 'completely', 'random', 'mcar', 'consistency', 'result', 'established', 'liang', 'zeger', '1986', 'hold', 'simple', 'check', 'mcar', 'divide', 'subject', 'two', 'group', 'complete', 'set', 'measurement', 'missing', 'measurement', 'mcar', 'assumption', 'hold', 'group', 'measurement', 'random', 'sample', 'population', 'measurement', 'word', 'probability', 'missing', 'independent', 'observed', 'measurement', 'measurement', 'would', 'available', 'missing', 'ttests', 'location', 'general', 'test', 'equality', 'distribution', 'used', 'test', 'mcar', 'assumption', 'little', '1995', 'test', 'mcar', 'repeatedly', 'measured', 'categorical', 'data', 'discussed', 'park', 'davis', '1993', 'intermittent', 'missing', 'value', 'arise', 'due', 'censoring', 'rule', 'example', 'value', 'outside', 'stated', 'range', 'might', 'simply', 'unreliable', 'limitation', 'measuring', 'technique', 'use', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'method', 'handling', 'censored', 'data', 'correlation', 'data', 'structure', 'addressed', 'laird', '1988', 'hughes', '1999', 'intermittent', 'missing', 'value', 'also', 'related', 'outcome', 'example', 'patient', 'might', 'miss', 'appointment', 'adverse', 'reaction', 'treatment', 'fact', 'subject', 'remains', 'study', 'mean', 'investigator', 'opportunity', 'ascertain', 'reason', 'missing', 'appointment', 'take', 'corrective', 'action', 'accordingly', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'little', '1995', 'missing', 'value', 'occur', 'certain', 'time', 'point', 'subject', 'missing', 'value', 'called', 'dropout', 'significant', 'problem', 'compared', 'intermittent', 'missing', 'value', 'usually', 'subject', 'withdrawn', 'reason', 'directly', 'indirectly', 'connected', 'outcome', 'lost', 'followup', 'treat', 'dropout', 'mcar', 'fact', 'informative', 'dropout', 'parameter_estimate', 'biased', 'diggle', 'kenward', '1994', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'state', 'emerging', 'consensus', 'analysis', 'data', 'potentially', 'informative', 'dropout', 'necessarily', 'involves', 'assumption', 'difficult', 'even', 'impossible', 'check', 'observed', 'data', 'suggests', 'would', 'unwise', 'rely', 'precise', 'conclusion', 'analysis', 'based', 'particular', 'informative', 'dropout', 'model', 'recommend', 'sensitivity', 'analysis', 'conducted', 'informative', 'dropout', 'model', 'provides', 'protection', 'possibility', 'conclusion', 'reached', 'random', 'dropout', 'model', 'critically', 'dependent', 'validity', 'mcar', 'scharstein', 'et', 'al', '1999', 'provides', 'discussion', 'sensitivity', 'analysis', 'might', 'conducted']"
945,"Generalized linear models use the likelihood function in statistical inference. However, the distribution of the response variable must be specified. For discrete outcomes, it might be difficult to specify the appropriate theoretical probability distribution. Therefore, GEE regression models use the quasi-likelihood method of estimation. This estimation method only requires that you specify the relationships between the response mean and covariates and between the response mean and variance. Quasi-likelihood estimation possesses many of the advantages of maximum likelihood estimation without requiring full distributional assumptions. This is why the GEE approach is applicable to several types of response variables (Zeger and Liang 1986).",CD,747,"['generalized', 'linear', 'model', 'use', 'likelihood', 'function', 'statistical', 'inference', 'however', 'distribution', 'response_variable', 'must', 'specified', 'discrete', 'outcome', 'might', 'difficult', 'specify', 'appropriate', 'theoretical', 'probability', 'distribution', 'therefore', 'gee', 'regression_model', 'use', 'quasilikelihood', 'method', 'estimation', 'estimation', 'method', 'requires', 'specify', 'relationship', 'response', 'mean', 'covariates', 'response', 'mean', 'variance', 'quasilikelihood', 'estimation', 'posse', 'many', 'advantage', 'maximum', 'likelihood', 'estimation', 'without', 'requiring', 'full', 'distributional', 'assumption', 'gee', 'approach', 'applicable', 'several', 'type', 'response_variable', 'zeger', 'liang', '1986']"
946,"Example:	Examine the relationships between prev_pretrm and low, and prev_pretrm and low, controlling for uterine_irr. Request a Breslow-Day test for homogeneity of odds ratios with a Tarone?s adjustment, exact confidence limits for the crude odds ratios and the adjusted odds ratios, and the number of variable levels. /* c1demo02a */ proc freq data=sasuser.birth nlevels; tables prev_pretrm*low uterine_irr*prev_pretrm*low / all bdt; exact or comor; title 'Contingency Table Analysis Assessing PREV_PRETRM' ' and UTERINE_IRR'; run; PROC FREQ statement option: NLEVELS	displays a table that provides the number of levels for each variable in the TABLES statement. Selected TABLES statement options: CHISQ	produces the chi-square test of association and the measures of association based upon the chi-square statistic. MEASURES	requests several measures of association. CL 	produces confidence bounds for the MEASURES statistics. CMH	requests Cochran-Mantel-Haenszel statistics, which test for association between the row and column variables after adjusting for the remaining variables in a multiway table. ALL	requests the CHISQ, MEASURES, and CMH options. Provides all the test statistics and measures for each table along with the summary CMH statistics. BDT	request Tarone's adjustment for the Breslow-Day test. Selected EXACT statement options: OR	requests exact confidence limits for the odds ratio for 2*2 tables. COMOR	requests exact confidence limits for the adjusted odds ratio. An exact test that the adjusted odds ratio equals 1 is also computed. MAXTIME=	specifies the maximum clock time (in seconds) that PROC FREQ can use to compute an exact p-value. MC	requests Monte Carlo estimation of exact p-values instead of direct exact p-value computation.",CD,1763,"['example\texamine', 'relationship', 'prevpretrm', 'low', 'prevpretrm', 'low', 'controlling', 'uterineirr', 'request', 'breslowday', 'test', 'homogeneity', 'odds_ratio', 'tarones', 'adjustment', 'exact', 'confidence', 'limit', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'number', 'variable', 'level', '', 'c1demo02a', '', 'proc', 'freq', 'datasasuserbirth', 'nlevels', 'table', 'prevpretrmlow', 'uterineirrprevpretrmlow', '', 'bdt', 'exact', 'comor', 'title', 'contingency', 'table', 'analysis', 'assessing', 'prevpretrm', '', 'uterineirr', 'run', 'proc', 'freq', 'statement', 'option', 'nlevels\tdisplays', 'table', 'provides', 'number', 'level', 'variable', 'table', 'statement', 'selected', 'table', 'statement', 'option', 'chisq\tproduces', 'chisquare', 'test', 'association', 'measure', 'association', 'based', 'upon', 'chisquare', 'statistic', 'measures\trequests', 'several', 'measure', 'association', 'cl', '\tproduces', 'confidence', 'bound', 'measure', 'statistic', 'cmh\trequests', 'cochranmantelhaenszel', 'statistic', 'test', 'association', 'row', 'column', 'variable', 'adjusting', 'remaining', 'variable', 'multiway', 'table', 'all\trequests', 'chisq', 'measure', 'cmh', 'option', 'provides', 'test', 'statistic', 'measure', 'table', 'along', 'summary', 'cmh', 'statistic', 'bdt\trequest', 'tarones', 'adjustment', 'breslowday', 'test', 'selected', 'exact', 'statement', 'option', 'or\trequests', 'exact', 'confidence', 'limit', 'odds_ratio', '22', 'table', 'comor\trequests', 'exact', 'confidence', 'limit', 'adjusted', 'odds_ratio', 'exact', 'test', 'adjusted', 'odds_ratio', 'equal', '1', 'also', 'computed', 'maxtime\tspecifies', 'maximum', 'clock', 'time', 'second', 'proc', 'freq', 'use', 'compute', 'exact', 'pvalue', 'mc\trequests', 'monte', 'carlo', 'estimation', 'exact', 'pvalues', 'instead', 'direct', 'exact', 'pvalue', 'computation']"
947,"In ordinal logistic regression, the logit is now a cumulative logit. If k is the number of categories for the outcome variable, then the number of cumulative logits is k-1. The model generates cumulative probabilities, which is the probability that an individual is in the jth ordered category or lower. If you use the DESCENDING option in PROC LOGISTIC, then the model generates probabilities that an individual is in the jth category or higher.",CD,446,"['ordinal', 'logistic_regression', 'logit', 'cumulative', 'logit', 'k', 'number', 'category', 'outcome', 'variable', 'number', 'cumulative', 'logits', 'k1', 'model', 'generates', 'cumulative', 'probability', 'probability', 'individual', 'jth', 'ordered', 'category', 'lower', 'use', 'descending', 'option', 'proc_logistic', 'model', 'generates', 'probability', 'individual', 'jth', 'category', 'higher']"
948,"The above graph reveals a cubic relationship between the response variable and the predictor variable. Adding higher order terms for the predictor variable may approximate this relationship, but polynomials have some undesirable properties (undesirable peaks and valleys) and may not adequately fit many functional forms (Magee 1998). Developing a model with a linear spline function may be a better option (Harrell 1997).",CD,422,"['graph', 'reveals', 'cubic', 'relationship', 'response_variable', 'predictor_variable', 'adding', 'higher', 'order', 'term', 'predictor_variable', 'may', 'approximate', 'relationship', 'polynomial', 'undesirable', 'property', 'undesirable', 'peak', 'valley', 'may', 'adequately', 'fit', 'many', 'functional', 'form', 'magee', '1998', 'developing', 'model', 'linear', 'spline', 'function', 'may', 'better', 'option', 'harrell', '1997']"
949,The Analysis of Initial Parameter Estimates table shows the parameter estimates when the observations are treated as independent. These parameter estimates are used as the starting values for the GEE solution. Notice that both smoker and age are significant at the 0.05 significance level. GEE Model Information,CD,311,"['analysis', 'initial', 'parameter_estimate', 'table', 'show', 'parameter_estimate', 'observation', 'treated', 'independent', 'parameter_estimate', 'used', 'starting', 'value', 'gee', 'solution', 'notice', 'smoker', 'age', 'significant', '005', 'significance', 'level', 'gee', 'model', 'information']"
950,"In GEE regression models, the number of observations is not the number of subjects, but rather the number of measurements taken on all the subjects. The variance-covariance matrix is now a block- diagonal matrix in which the observations within each block (the block corresponds to a subject) are assumed to be correlated and the observations outside of the blocks are assumed to be independent. In other words, the subjects are still assumed to be independent of each other and the measurements within each subject are assumed to be correlated.",CD,545,"['gee', 'regression_model', 'number', 'observation', 'number', 'subject', 'rather', 'number', 'measurement', 'taken', 'subject', 'variancecovariance', 'matrix', 'block', 'diagonal', 'matrix', 'observation', 'within', 'block', 'block', 'corresponds', 'subject', 'assumed', 'correlated', 'observation', 'outside', 'block', 'assumed', 'independent', 'word', 'subject', 'still', 'assumed', 'independent', 'measurement', 'within', 'subject', 'assumed', 'correlated']"
951,"Interaction occurs when the relationship between a predictor variable and the response differs by the level of another predictor variable. For example, the graph above shows that the relationship between gender and the response differs by the level of age. Therefore, age modifies the effect of gender and the age*gender interaction should be included in the model. Furthermore, any estimate of the odds ratio for gender should be made with respect to a specific age. It should be noted that when a predictor variable is involved in an interaction, assessing it for confounding is inappropriate. The reason is that when you statistically adjust for the potential confounder, you are assuming that the effect of the predictor variable on the response is the same regardless of the level of the confounder. When interaction is present, that assumption is violated. For binary predictor variables or predictor variables with few unique values, you can assess interactions through stratified data analysis. For continuous predictor variables, you can assess interactions by including them in a multivariate model.",CD,1109,"['interaction', 'occurs', 'relationship', 'predictor_variable', 'response', 'differs', 'level', 'another', 'predictor_variable', 'example', 'graph', 'show', 'relationship', 'gender', 'response', 'differs', 'level', 'age', 'therefore', 'age', 'modifies', 'effect', 'gender', 'agegender', 'interaction', 'included', 'model', 'furthermore', 'estimate', 'odds_ratio', 'gender', 'made', 'respect', 'specific', 'age', 'noted', 'predictor_variable', 'involved', 'interaction', 'assessing', 'confounding', 'inappropriate', 'reason', 'statistically', 'adjust', 'potential', 'confounder', 'assuming', 'effect', 'predictor_variable', 'response', 'regardless', 'level', 'confounder', 'interaction', 'present', 'assumption', 'violated', 'binary', 'predictor_variable', 'predictor_variable', 'unique', 'value', 'ass', 'interaction', 'stratified', 'data', 'analysis', 'continuous', 'predictor_variable', 'ass', 'interaction', 'including', 'multivariate', 'model']"
952,"For time-dependent predictor variables (variables whose values change within cluster or across time) ignoring positive correlation leads to variance estimates that are too large. In other words, the Type II error rates (failing to reject the null hypothesis when it is false, also know as, a false negative) are inflated for these variables (Dunlop 1994). Because the variances of the group effects will be underestimated and the variance of the time effects will be overestimated if positive correlation is ignored, it is evident that correlated outcomes must be addressed to obtain valid analyses.",CD,599,"['timedependent', 'predictor_variable', 'variable', 'whose', 'value', 'change', 'within', 'cluster', 'across', 'time', 'ignoring', 'positive', 'correlation', 'lead', 'variance', 'estimate', 'large', 'word', 'type', 'ii', 'error', 'rate', 'failing', 'reject', 'null', 'hypothesis', 'false', 'also', 'know', 'false', 'negative', 'inflated', 'variable', 'dunlop', '1994', 'variance', 'group', 'effect', 'underestimated', 'variance', 'time', 'effect', 'overestimated', 'positive', 'correlation', 'ignored', 'evident', 'correlated', 'outcome', 'must', 'addressed', 'obtain', 'valid', 'analysis']"
953,"Missing values that occur intermixed with nonmissing values are called intermittent missing values. If these missing values are missing completely at random (MCAR), then the consistency results established by Liang and Zeger (1986) hold. A simple check of MCAR is to divide the subjects into two groups: those with a complete set of measurements and those with missing measurements. If the MCAR assumption holds, then both groups (with their measurements) should be random samples of the same population of measurements. In other words, the probability of missing is independent of the observed measurements and the measurements that would have been available had they not been missing. The t-tests for location and more general tests of equality of distribution can be used to test the MCAR assumption (Little 1995). Tests of MCAR for repeatedly measured categorical data were discussed by Park and Davis (1993). Some intermittent missing values can arise due to censoring rules. For example, values outside a stated range might be simply unreliable because of the limitations of the measuring techniques in use (Diggle, Heagerty, Liang, and Zeger 2002). Methods for handling censored data in correlation data structures are addressed in Laird (1988) and Hughes (1999). Intermittent missing values can also be related to the outcome. For example, a patient might miss an appointment because of an adverse reaction to the treatment. The fact that the subject remains in the study means that the investigator should have the opportunity to ascertain the reason for the missing appointment and take corrective action accordingly (Diggle, Heagerty, Liang, and Zeger 2002, Little 1995). If all the missing values occur after a certain time point for a subject, then the missing values are called dropouts. These are a more significant problem compared to intermittent missing values because usually the subject is withdrawn for reasons directly or indirectly connected to the outcome and are lost to follow-up. If you treat the dropouts as MCAR when they are in fact informative dropouts, the parameter estimates will be biased (Diggle and Kenward 1994). Diggle, Heagerty, Liang, and Zeger (2002) state that ?An emerging consensus is that analysis of data with potentially informative dropouts necessarily involves assumptions that are difficult, or even impossible, to check from the observed data. This suggests that it would be unwise to rely on the precise conclusions of an analysis based on a particular informative dropout model.? They recommend that a sensitivity analysis be conducted on the informative dropout model. This provides some protection against the possibility that conclusions reached from a random dropout model are critically dependent on the validity of MCAR. Scharstein et al. (1999) provides a discussion on how such sensitivity analyses might be conducted.",CD,2880,"['missing', 'value', 'occur', 'intermixed', 'nonmissing', 'value', 'called', 'intermittent', 'missing', 'value', 'missing', 'value', 'missing', 'completely', 'random', 'mcar', 'consistency', 'result', 'established', 'liang', 'zeger', '1986', 'hold', 'simple', 'check', 'mcar', 'divide', 'subject', 'two', 'group', 'complete', 'set', 'measurement', 'missing', 'measurement', 'mcar', 'assumption', 'hold', 'group', 'measurement', 'random', 'sample', 'population', 'measurement', 'word', 'probability', 'missing', 'independent', 'observed', 'measurement', 'measurement', 'would', 'available', 'missing', 'ttests', 'location', 'general', 'test', 'equality', 'distribution', 'used', 'test', 'mcar', 'assumption', 'little', '1995', 'test', 'mcar', 'repeatedly', 'measured', 'categorical', 'data', 'discussed', 'park', 'davis', '1993', 'intermittent', 'missing', 'value', 'arise', 'due', 'censoring', 'rule', 'example', 'value', 'outside', 'stated', 'range', 'might', 'simply', 'unreliable', 'limitation', 'measuring', 'technique', 'use', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'method', 'handling', 'censored', 'data', 'correlation', 'data', 'structure', 'addressed', 'laird', '1988', 'hughes', '1999', 'intermittent', 'missing', 'value', 'also', 'related', 'outcome', 'example', 'patient', 'might', 'miss', 'appointment', 'adverse', 'reaction', 'treatment', 'fact', 'subject', 'remains', 'study', 'mean', 'investigator', 'opportunity', 'ascertain', 'reason', 'missing', 'appointment', 'take', 'corrective', 'action', 'accordingly', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'little', '1995', 'missing', 'value', 'occur', 'certain', 'time', 'point', 'subject', 'missing', 'value', 'called', 'dropout', 'significant', 'problem', 'compared', 'intermittent', 'missing', 'value', 'usually', 'subject', 'withdrawn', 'reason', 'directly', 'indirectly', 'connected', 'outcome', 'lost', 'followup', 'treat', 'dropout', 'mcar', 'fact', 'informative', 'dropout', 'parameter_estimate', 'biased', 'diggle', 'kenward', '1994', 'diggle', 'heagerty', 'liang', 'zeger', '2002', 'state', 'emerging', 'consensus', 'analysis', 'data', 'potentially', 'informative', 'dropout', 'necessarily', 'involves', 'assumption', 'difficult', 'even', 'impossible', 'check', 'observed', 'data', 'suggests', 'would', 'unwise', 'rely', 'precise', 'conclusion', 'analysis', 'based', 'particular', 'informative', 'dropout', 'model', 'recommend', 'sensitivity', 'analysis', 'conducted', 'informative', 'dropout', 'model', 'provides', 'protection', 'possibility', 'conclusion', 'reached', 'random', 'dropout', 'model', 'critically', 'dependent', 'validity', 'mcar', 'scharstein', 'et', 'al', '1999', 'provides', 'discussion', 'sensitivity', 'analysis', 'might', 'conducted']"
954,"The variables that are significant at the 0.05 significance level are smoking status, previous preterm delivery, presence of uterine irritability, and history of hypertension. Analysis of Maximum Likelihood Estimates",CD,216,"['variable', 'significant', '005', 'significance', 'level', 'smoking', 'status', 'previous', 'preterm', 'delivery', 'presence', 'uterine', 'irritability', 'history', 'hypertension', 'analysis', 'maximum', 'likelihood', 'estimate']"
955,"Correlation Structure Unstructured Subject Effect case (537 levels) Number of Clusters 537 Correlation Matrix Dimension 4 Maximum Cluster Size 4 Minimum Cluster Size 4 Algorithm converged. The GEE Model Information table displays information about the model fit with GEEs. Because TYPE=UNSTR option is requested, the unstructured correlation structure is used. Furthermore, because there are 537 children, there are 537 clusters. Notice there are no missing data values. Working Correlation Matrix",CD,497,"['correlation_structure', 'unstructured', 'subject', 'effect', 'case', '537', 'level', 'number', 'cluster', '537', 'correlation', 'matrix', 'dimension', '4', 'maximum', 'cluster', 'size', '4', 'minimum', 'cluster', 'size', '4', 'algorithm', 'converged', 'gee', 'model', 'information', 'table', 'display', 'information', 'model', 'fit', 'gee', 'typeunstr', 'option', 'requested', 'unstructured', 'correlation_structure', 'used', 'furthermore', '537', 'child', '537', 'cluster', 'notice', 'missing', 'data', 'value', 'working', 'correlation', 'matrix']"
956,The overlay plot of the ROC curves clearly shows that the model with the interaction is the superior model with regard to predictive accuracy. 2.2	Logistic Regression Diagnostics,CD,178,"['overlay', 'plot', 'roc', 'curve', 'clearly', 'show', 'model', 'interaction', 'superior', 'model', 'regard', 'predictive', 'accuracy', '22\tlogistic', 'regression', 'diagnostics']"
957,"All of the binary predictors were assessed for interactions. None of the Breslow-Day statistics with the Tarone?s adjustment were significant. However, several contingency tables had 0 cell counts, which cause some instability in the model if the interactions with the 0 cell counts are entered in the model. Furthermore, some of the sample sizes are not large enough for the Breslow-Day statistics to be valid.",CD,411,"['binary', 'predictor', 'assessed', 'interaction', 'none', 'breslowday', 'statistic', 'tarones', 'adjustment', 'significant', 'however', 'several', 'contingency', 'table', '0', 'cell', 'count', 'cause', 'instability', 'model', 'interaction', '0', 'cell', 'count', 'entered', 'model', 'furthermore', 'sample_size', 'large', 'enough', 'breslowday', 'statistic', 'valid']"
958,"Generalized linear models use the likelihood function in statistical inference. However, the distribution of the response variable must be specified. For discrete outcomes, it might be difficult to specify the appropriate theoretical probability distribution. Therefore, GEE regression models use the quasi-likelihood method of estimation. This estimation method only requires that you specify the relationships between the response mean and covariates and between the response mean and variance. Quasi-likelihood estimation possesses many of the advantages of maximum likelihood estimation without requiring full distributional assumptions. This is why the GEE approach is applicable to several types of response variables (Zeger and Liang 1986).",CD,747,"['generalized', 'linear', 'model', 'use', 'likelihood', 'function', 'statistical', 'inference', 'however', 'distribution', 'response_variable', 'must', 'specified', 'discrete', 'outcome', 'might', 'difficult', 'specify', 'appropriate', 'theoretical', 'probability', 'distribution', 'therefore', 'gee', 'regression_model', 'use', 'quasilikelihood', 'method', 'estimation', 'estimation', 'method', 'requires', 'specify', 'relationship', 'response', 'mean', 'covariates', 'response', 'mean', 'variance', 'quasilikelihood', 'estimation', 'posse', 'many', 'advantage', 'maximum', 'likelihood', 'estimation', 'without', 'requiring', 'full', 'distributional', 'assumption', 'gee', 'approach', 'applicable', 'several', 'type', 'response_variable', 'zeger', 'liang', '1986']"
959,"Forward selection starts with an empty model. The method computes an adjusted chi-square statistic for each predictor variable not in the model and examines the largest of these statistics. If it is significant at a specified significance level (specified by the SLENTRY= option), the corresponding variable is added to the model. After a variable is entered in the model, it is never removed from the model. The process is repeated until none of the remaining variables meet the specified level for entry. By default, SLENTRY=0.05. The forward selection method may be useful in assessing interactions. You start with the main effects only model (using the INCLUDE= option) and then let the forward selection method search for any significant interactions. The significance level should be relatively low (.01 or less) because you only want to include relatively strong interactions in your final model.",CD,903,"['forward', 'selection', 'start', 'empty', 'model', 'method', 'computes', 'adjusted', 'chisquare', 'statistic', 'predictor_variable', 'model', 'examines', 'largest', 'statistic', 'significant', 'specified', 'significance', 'level', 'specified', 'slentry', 'option', 'corresponding', 'variable', 'added', 'model', 'variable', 'entered', 'model', 'never', 'removed', 'model', 'process', 'repeated', 'none', 'remaining', 'variable', 'meet', 'specified', 'level', 'entry', 'default', 'slentry005', 'forward', 'selection', 'method', 'may', 'useful', 'assessing', 'interaction', 'start', 'main_effect', 'model', 'using', 'include', 'option', 'let', 'forward', 'selection', 'method', 'search', 'significant', 'interaction', 'significance', 'level', 'relatively', 'low', '01', 'le', 'want', 'include', 'relatively', 'strong', 'interaction', 'final', 'model']"
960,"For the 2-dependent correlation structure (TYPE=MDEP(2)), measurements are correlated if they are two or less time periods apart. Measurements that are one time period apart have different correlations than measurements that are two time periods apart. These last two correlation structures are generally called m-dependent correlation structures. The m represents how many time periods apart the measurements are still correlated. Therefore, a 5- dependent correlation structure would indicate that measurements are correlated if they are five or fewer time periods apart.",CD,573,"['2dependent', 'correlation_structure', 'typemdep2', 'measurement', 'correlated', 'two', 'le', 'time', 'period', 'apart', 'measurement', 'one', 'time', 'period', 'apart', 'different', 'correlation', 'measurement', 'two', 'time', 'period', 'apart', 'last', 'two', 'correlation_structure', 'generally', 'called', 'mdependent', 'correlation_structure', 'represents', 'many', 'time', 'period', 'apart', 'measurement', 'still', 'correlated', 'therefore', '5', 'dependent', 'correlation_structure', 'would', 'indicate', 'measurement', 'correlated', 'five', 'fewer', 'time', 'period', 'apart']"
961,"Example:	Examine the relationships between prev_pretrm and low, and prev_pretrm and low, controlling for uterine_irr. Request a Breslow-Day test for homogeneity of odds ratios with a Tarone?s adjustment, exact confidence limits for the crude odds ratios and the adjusted odds ratios, and the number of variable levels. /* c1demo02a */ proc freq data=sasuser.birth nlevels; tables prev_pretrm*low uterine_irr*prev_pretrm*low / all bdt; exact or comor; title 'Contingency Table Analysis Assessing PREV_PRETRM' ' and UTERINE_IRR'; run; PROC FREQ statement option: NLEVELS	displays a table that provides the number of levels for each variable in the TABLES statement. Selected TABLES statement options: CHISQ	produces the chi-square test of association and the measures of association based upon the chi-square statistic. MEASURES	requests several measures of association. CL 	produces confidence bounds for the MEASURES statistics. CMH	requests Cochran-Mantel-Haenszel statistics, which test for association between the row and column variables after adjusting for the remaining variables in a multiway table. ALL	requests the CHISQ, MEASURES, and CMH options. Provides all the test statistics and measures for each table along with the summary CMH statistics. BDT	request Tarone's adjustment for the Breslow-Day test. Selected EXACT statement options: OR	requests exact confidence limits for the odds ratio for 2*2 tables. COMOR	requests exact confidence limits for the adjusted odds ratio. An exact test that the adjusted odds ratio equals 1 is also computed. MAXTIME=	specifies the maximum clock time (in seconds) that PROC FREQ can use to compute an exact p-value. MC	requests Monte Carlo estimation of exact p-values instead of direct exact p-value computation.",CD,1763,"['example\texamine', 'relationship', 'prevpretrm', 'low', 'prevpretrm', 'low', 'controlling', 'uterineirr', 'request', 'breslowday', 'test', 'homogeneity', 'odds_ratio', 'tarones', 'adjustment', 'exact', 'confidence', 'limit', 'crude', 'odds_ratio', 'adjusted', 'odds_ratio', 'number', 'variable', 'level', '', 'c1demo02a', '', 'proc', 'freq', 'datasasuserbirth', 'nlevels', 'table', 'prevpretrmlow', 'uterineirrprevpretrmlow', '', 'bdt', 'exact', 'comor', 'title', 'contingency', 'table', 'analysis', 'assessing', 'prevpretrm', '', 'uterineirr', 'run', 'proc', 'freq', 'statement', 'option', 'nlevels\tdisplays', 'table', 'provides', 'number', 'level', 'variable', 'table', 'statement', 'selected', 'table', 'statement', 'option', 'chisq\tproduces', 'chisquare', 'test', 'association', 'measure', 'association', 'based', 'upon', 'chisquare', 'statistic', 'measures\trequests', 'several', 'measure', 'association', 'cl', '\tproduces', 'confidence', 'bound', 'measure', 'statistic', 'cmh\trequests', 'cochranmantelhaenszel', 'statistic', 'test', 'association', 'row', 'column', 'variable', 'adjusting', 'remaining', 'variable', 'multiway', 'table', 'all\trequests', 'chisq', 'measure', 'cmh', 'option', 'provides', 'test', 'statistic', 'measure', 'table', 'along', 'summary', 'cmh', 'statistic', 'bdt\trequest', 'tarones', 'adjustment', 'breslowday', 'test', 'selected', 'exact', 'statement', 'option', 'or\trequests', 'exact', 'confidence', 'limit', 'odds_ratio', '22', 'table', 'comor\trequests', 'exact', 'confidence', 'limit', 'adjusted', 'odds_ratio', 'exact', 'test', 'adjusted', 'odds_ratio', 'equal', '1', 'also', 'computed', 'maxtime\tspecifies', 'maximum', 'clock', 'time', 'second', 'proc', 'freq', 'use', 'compute', 'exact', 'pvalue', 'mc\trequests', 'monte', 'carlo', 'estimation', 'exact', 'pvalues', 'instead', 'direct', 'exact', 'pvalue', 'computation']"
962,"One solution to the incidental parameters problem is to use conditional maximum likelihood estimation. This approach eliminates the stratum-specific intercepts from the likelihood by conditioning on their sufficient statistics (just like the approach in exact logistic regression). Recall that a sufficient statistic for the intercept is simply the sum of the events. By deriving a conditional likelihood that is conditional on the sufficient statistics of the stratum-specific intercepts, you are factoring out the intercepts from the likelihood equation. In other words, you are taking the stratification into account by conditioning out (and not estimating) the stratum-specific intercepts. You are essentially modeling a meaningful conditional probability, and the model has a reduced number of parameters that can be estimated without bias. A conditional likelihood is just like an ordinary likelihood. Conditional maximum likelihood estimates are those values that maximize the conditional likelihood function. The estimates are consistent and asymptotically normal. The optimization techniques used to obtain the maximum likelihood estimates are Newton-Raphson with ridging when the number of parameters is less than 40, quasi-Newton when the number of parameters is 40-399, and conjugate gradient when the number of parameters is 400 or greater. Sometimes the log likelihood converges but the estimates diverge. This condition is flagged by having inordinately large standard errors for some of your parameter estimates. It may be possible to circumvent this problem by standardizing the predictor variables before fitting the model.",CD,1641,"['one', 'solution', 'incidental', 'parameter', 'problem', 'use', 'conditional', 'maximum', 'likelihood', 'estimation', 'approach', 'eliminates', 'stratumspecific', 'intercept', 'likelihood', 'conditioning', 'sufficient', 'statistic', 'like', 'approach', 'exact', 'logistic_regression', 'recall', 'sufficient', 'statistic', 'intercept', 'simply', 'sum', 'event', 'deriving', 'conditional', 'likelihood', 'conditional', 'sufficient', 'statistic', 'stratumspecific', 'intercept', 'factoring', 'intercept', 'likelihood', 'equation', 'word', 'taking', 'stratification', 'account', 'conditioning', 'estimating', 'stratumspecific', 'intercept', 'essentially', 'modeling', 'meaningful', 'conditional', 'probability', 'model', 'ha', 'reduced', 'number', 'parameter', 'estimated', 'without', 'bias', 'conditional', 'likelihood', 'like', 'ordinary', 'likelihood', 'conditional', 'maximum', 'likelihood', 'estimate', 'value', 'maximize', 'conditional', 'likelihood', 'function', 'estimate', 'consistent', 'asymptotically', 'normal', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'estimate', 'newtonraphson', 'ridging', 'number', 'parameter', 'le', '40', 'quasinewton', 'number', 'parameter', '40399', 'conjugate', 'gradient', 'number', 'parameter', '400', 'greater', 'sometimes', 'log', 'likelihood', 'converges', 'estimate', 'diverge', 'condition', 'flagged', 'inordinately', 'large', 'standard_error', 'parameter_estimate', 'may', 'possible', 'circumvent', 'problem', 'standardizing', 'predictor_variable', 'fitting', 'model']"
963,"PROC FREQ computes three different types of CMH statistics: TYPE 1	is the correlation statistic, which is sensitive only to linear associations. This statistic is appropriate only when both the row and the column variable are ordinally scaled. TYPE 2	is the mean score statistic, which is sensitive to different means among the levels or groups of the nominal predictor. This statistic requires that the column variable be ordinally scaled. TYPE 3	is a generalization of the Pearson chi-square, which is sensitive to general patterns of association. This statistic is always interpretable because it does not require an ordinal scale for either variable.",CD,654,"['proc', 'freq', 'computes', 'three', 'different', 'type', 'cmh', 'statistic', 'type', '1\tis', 'correlation', 'statistic', 'sensitive', 'linear', 'association', 'statistic', 'appropriate', 'row', 'column', 'variable', 'ordinally', 'scaled', 'type', '2\tis', 'mean', 'score', 'statistic', 'sensitive', 'different', 'mean', 'among', 'level', 'group', 'nominal', 'predictor', 'statistic', 'requires', 'column', 'variable', 'ordinally', 'scaled', 'type', '3\tis', 'generalization', 'pearson', 'chisquare', 'sensitive', 'general', 'pattern', 'association', 'statistic', 'always', 'interpretable', 'doe', 'require', 'ordinal', 'scale', 'either', 'variable']"
964,The logistic regression model with the two main effects in the model shows no problems with quasi-complete separation. The parameter estimates and their associated standard errors are all reasonable.,CD,199,"['logistic_regression_model', 'two', 'main_effect', 'model', 'show', 'problem', 'quasicomplete', 'separation', 'parameter_estimate', 'associated', 'standard_error', 'reasonable']"
965,"A key component of exploratory data analysis is to graphically examine the relationship between the response variable and the predictor variables. In linear regression, it is standard practice to examine scatter plots of the response variable and the continuous predictor variables. However, when the response variable is a binary variable, these scatter plots are not very useful. A more enlightening scatter plot for logistic regression is to transform the vertical axis to the logit scale and plot the logit by the continuous predictor variable. In this way you can check the assumption of linearity in the logit (Hosmer and Lemeshow 2000).",CD,643,"['key', 'component', 'exploratory', 'data', 'analysis', 'graphically', 'examine', 'relationship', 'response_variable', 'predictor_variable', 'linear', 'regression', 'standard', 'practice', 'examine', 'scatter', 'plot', 'response_variable', 'continuous', 'predictor_variable', 'however', 'response_variable', 'binary', 'variable', 'scatter', 'plot', 'useful', 'enlightening', 'scatter', 'plot', 'logistic_regression', 'transform', 'vertical', 'axis', 'logit', 'scale', 'plot', 'logit', 'continuous', 'predictor_variable', 'way', 'check', 'assumption', 'linearity', 'logit', 'hosmer', 'lemeshow', '2000']"
966,"Provided that the mean model is correctly specified and the measurements between subjects are independent, robust standard errors ensure consistent inferences from a GEE regression model even if the chosen correlation structure is incorrect or if the strength of the correlation between measurements varies from subject to subject. Although model-based standard errors are also produced, they are only consistent if the specified correlation structure is correct. Consequently, the robust standard errors, which are usually larger, are usually preferred especially when the number of clusters is large. The desired number of clusters depends on the number of predictor variables in the model. If you have fewer than 5 predictor variables, approximately 25 clusters might be enough to use the robust standard errors. If you have 5 to 12 predictor variables, then you need at least 100 clusters. If you want to be reasonably confident, then you need around 200 clusters (Stokes, Davis, Koch 2000). However, when the number of clusters is very small (less than 20), the model-based standard errors might have better properties even if the specified correlation structure is wrong (Prentice 1988). This is because the robust standard errors are asymptotically unbiased, but could be highly biased when the number of clusters is small. Robust standard errors are derived by the sandwich estimator of the covariance matrix of the regression coefficients. In general, the sandwich estimator uses a matrix with the diagonal elements equal to the individual squared residuals to estimate the common variance (the square of any residual is an estimate of the variance at that predictor variable value). This works because the average of a lot of poor estimators (individual squared residuals) can be a good estimator of the common variance. In fact, Liang and Zeger (1986) showed that the robust standard errors are robust to departures of the working correlation matrix from the true correlation structure.",CD,1997,"['provided', 'mean', 'model', 'correctly', 'specified', 'measurement', 'subject', 'independent', 'robust', 'standard_error', 'ensure', 'consistent', 'inference', 'gee', 'regression_model', 'even', 'chosen', 'correlation_structure', 'incorrect', 'strength', 'correlation', 'measurement', 'varies', 'subject', 'subject', 'although', 'modelbased', 'standard_error', 'also', 'produced', 'consistent', 'specified', 'correlation_structure', 'correct', 'consequently', 'robust', 'standard_error', 'usually', 'larger', 'usually', 'preferred', 'especially', 'number', 'cluster', 'large', 'desired', 'number', 'cluster', 'depends', 'number', 'predictor_variable', 'model', 'fewer', '5', 'predictor_variable', 'approximately', '25', 'cluster', 'might', 'enough', 'use', 'robust', 'standard_error', '5', '12', 'predictor_variable', 'need', 'least', '100', 'cluster', 'want', 'reasonably', 'confident', 'need', 'around', '200', 'cluster', 'stokes', 'davis', 'koch', '2000', 'however', 'number', 'cluster', 'small', 'le', '20', 'modelbased', 'standard_error', 'might', 'better', 'property', 'even', 'specified', 'correlation_structure', 'wrong', 'prentice', '1988', 'robust', 'standard_error', 'asymptotically', 'unbiased', 'could', 'highly', 'biased', 'number', 'cluster', 'small', 'robust', 'standard_error', 'derived', 'sandwich', 'estimator', 'covariance', 'matrix', 'regression', 'coefficient', 'general', 'sandwich', 'estimator', 'us', 'matrix', 'diagonal', 'element', 'equal', 'individual', 'squared', 'residual', 'estimate', 'common', 'variance', 'square', 'residual', 'estimate', 'variance', 'predictor_variable', 'value', 'work', 'average', 'lot', 'poor', 'estimator', 'individual', 'squared', 'residual', 'good', 'estimator', 'common', 'variance', 'fact', 'liang', 'zeger', '1986', 'showed', 'robust', 'standard_error', 'robust', 'departure', 'working', 'correlation', 'matrix', 'true', 'correlation_structure']"
967,HISTOGRAM	creates histograms using high-resolution graphics. Selected HISTOGRAM statement options: CFILL=	specifies the color to fill the histogram bars. CBARLINE=	specifies the color of the outline of the histogram bars.,CD,221,"['histogram\tcreates', 'histogram', 'using', 'highresolution', 'graphic', 'selected', 'histogram', 'statement', 'option', 'cfill\tspecifies', 'color', 'fill', 'histogram', 'bar', 'cbarline\tspecifies', 'color', 'outline', 'histogram', 'bar']"
968,The chi-square test of association shows that there is strong evidence that an association exists between prev_pretrm and low. Fisher?s exact test is not needed because of the large sample size. Statistics for Table of prev_pretrm by low,CD,237,"['chisquare', 'test', 'association', 'show', 'strong', 'evidence', 'association', 'exists', 'prevpretrm', 'low', 'fisher', 'exact', 'test', 'needed', 'large', 'sample_size', 'statistic', 'table', 'prevpretrm', 'low']"
969,"Finally, the unstructured correlation structure (TYPE=UNSTR) is completely unspecified. Therefore, there are t(t?1)/2 parameters to be estimated (where t is the number of time points). Although the unstructured working correlation structure is the most efficient, it is useful only when there are very few observation times. If there were many time points, you would probably want to impose some structure to the correlation matrix by selecting one of the other correlation structures (Allison 1999). Furthermore, when there are missing values or a varying number of observations per subject, a nonpositive definite matrix may occur, which would stop the parameter estimation process (Stokes, Davis, and Koch 2000).",CD,715,"['finally', 'unstructured', 'correlation_structure', 'typeunstr', 'completely', 'unspecified', 'therefore', 'tt12', 'parameter', 'estimated', 'number', 'time', 'point', 'although', 'unstructured', 'working', 'correlation_structure', 'efficient', 'useful', 'observation', 'time', 'many', 'time', 'point', 'would', 'probably', 'want', 'impose', 'structure', 'correlation', 'matrix', 'selecting', 'one', 'correlation_structure', 'allison', '1999', 'furthermore', 'missing', 'value', 'varying', 'number', 'observation', 'per', 'subject', 'nonpositive', 'definite', 'matrix', 'may', 'occur', 'would', 'stop', 'parameter', 'estimation', 'process', 'stokes', 'davis', 'koch', '2000']"
970,"The forward selection method selected three different models when you changed the options. Allowing single effects to enter the model at one step did not detect any significant interactions, whereas allowing multiple effects to enter the model at one step put two nonsignificant interactions in the model.",CD,305,"['forward', 'selection', 'method', 'selected', 'three', 'different', 'model', 'changed', 'option', 'allowing', 'single', 'effect', 'enter', 'model', 'one', 'step', 'detect', 'significant', 'interaction', 'whereas', 'allowing', 'multiple', 'effect', 'enter', 'model', 'one', 'step', 'put', 'two', 'nonsignificant', 'interaction', 'model']"
971,"Based on subject-matter knowledge, one variable was selected from each cluster. Backache in previous pregnancy is a class variable because the levels can be considered nominal (1=not applicable, 2=no, 3=yes). The next step is to build an ordinal logistic regression model in PROC LOGISTIC. A reasonable approach is to search for interactions using forward selection with a very conservative significance level for entry. Then eliminate predictor variables that are not involved in any interactions, are clearly not significant, are not potential confounders, and have no subject-matter importance. Fitting Multiple Ordinal Logistic Regression Models",CD,649,"['based', 'subjectmatter', 'knowledge', 'one', 'variable', 'wa', 'selected', 'cluster', 'backache', 'previous', 'pregnancy', 'class', 'variable', 'level', 'considered', 'nominal', '1not', 'applicable', '2no', '3yes', 'next', 'step', 'build', 'ordinal', 'logistic_regression_model', 'proc_logistic', 'reasonable', 'approach', 'search', 'interaction', 'using', 'forward', 'selection', 'conservative', 'significance', 'level', 'entry', 'eliminate', 'predictor_variable', 'involved', 'interaction', 'clearly', 'significant', 'potential', 'confounders', 'subjectmatter', 'importance', 'fitting', 'multiple', 'ordinal', 'logistic_regression_model']"
972,"If the responses are positively correlated, which often occurs when repeated measurements are taken on the same subject, then the variance of the time-independent predictor variables (variables whose values do not vary within a cluster or across time, such as gender and race) is underestimated if the data is analyzed as though the observations are independent. In other words, the Type I error rates are inflated for these variables (Dunlop 1994).",CD,449,"['response', 'positively', 'correlated', 'often', 'occurs', 'repeated', 'measurement', 'taken', 'subject', 'variance', 'timeindependent', 'predictor_variable', 'variable', 'whose', 'value', 'vary', 'within', 'cluster', 'across', 'time', 'gender', 'race', 'underestimated', 'data', 'analyzed', 'though', 'observation', 'independent', 'word', 'type', 'error', 'rate', 'inflated', 'variable', 'dunlop', '1994']"
973,"If you do not know which working correlation structure to choose, one recommendation is to compare the parameter estimates and standard errors from several different correlation structures. This might indicate whether there is sensitivity to the misspecification of the correlation structure. PROC GENMOD also enables you to choose a user-defined correlation matrix.",CD,366,"['know', 'working', 'correlation_structure', 'choose', 'one', 'recommendation', 'compare', 'parameter_estimate', 'standard_error', 'several', 'different', 'correlation_structure', 'might', 'indicate', 'whether', 'sensitivity', 'misspecification', 'correlation_structure', 'proc', 'genmod', 'also', 'enables', 'choose', 'userdefined', 'correlation', 'matrix']"
974,"In some situations, maximum likelihood estimation can fail, or small cell counts make the resulting maximum likelihood estimates inaccurate. An alternative to the asymptotic methods of maximum likelihood is exact logistic regression, which is available for binary outcomes in PROC LOGISTIC. This method has become an important analytical technique, especially in the pharmaceutical industry, for analyzing small, skewed, or sparse data sets.",CD,441,"['situation', 'maximum', 'likelihood', 'estimation', 'fail', 'small', 'cell', 'count', 'make', 'resulting', 'maximum', 'likelihood', 'estimate', 'inaccurate', 'alternative', 'asymptotic', 'method', 'maximum', 'likelihood', 'exact', 'logistic_regression', 'available', 'binary', 'outcome', 'proc_logistic', 'method', 'ha', 'become', 'important', 'analytical', 'technique', 'especially', 'pharmaceutical', 'industry', 'analyzing', 'small', 'skewed', 'sparse', 'data_set']"
975,The number of observations in the contingency table prev_pretrm by low controlling for uterine_irr=1 is fairly small. This may be a problem for the Breslow-Day test and the asymptotic confidence limits for the odds ratio. Statistics for Table 2 of prev_pretrm by low Controlling for uterine_irr=1,CD,296,"['number', 'observation', 'contingency', 'table', 'prevpretrm', 'low', 'controlling', 'uterineirr1', 'fairly', 'small', 'may', 'problem', 'breslowday', 'test', 'asymptotic', 'confidence', 'limit', 'odds_ratio', 'statistic', 'table', '2', 'prevpretrm', 'low', 'controlling', 'uterineirr1']"
976,"An estimator of a parameter is said to be median unbiased if 	 and	 The formula shows that if the probability is greater than or equal to .50 on both sides of beta, then the estimated beta is median unbiased. The median unbiased estimators (MUE) of the parameters of a logistic model can be computed from the distribution of sufficient statistics for the parameters. A Newton-Raphson-type algorithm is used to perform the search for the MUE that corresponds to the median of the conditional distribution of the sufficient statistics for the parameters. Hirji, Tsiatis, and Mehta (1989) compared the accuracy of the MUE with that of the maximum likelihood estimator (MLE) for a logistic regression model with two binary covariates. The MUE was shown to be uniformly more accurate than MLE for small to moderately large sample sizes and a broad range of parameter values. The authors recommend that median unbiased estimation be used as an alternative to maximum likelihood estimation when the data structure is sparse.",CD,1017,"['estimator', 'parameter', 'said', 'median', 'unbiased', '\t', 'and\t', 'formula', 'show', 'probability', 'greater', 'equal', '50', 'side', 'beta', 'estimated', 'beta', 'median', 'unbiased', 'median', 'unbiased', 'estimator', 'mue', 'parameter', 'logistic', 'model', 'computed', 'distribution', 'sufficient', 'statistic', 'parameter', 'newtonraphsontype', 'algorithm', 'used', 'perform', 'search', 'mue', 'corresponds', 'median', 'conditional', 'distribution', 'sufficient', 'statistic', 'parameter', 'hirji', 'tsiatis', 'mehta', '1989', 'compared', 'accuracy', 'mue', 'maximum', 'likelihood', 'estimator', 'mle', 'logistic_regression_model', 'two', 'binary', 'covariates', 'mue', 'wa', 'shown', 'uniformly', 'accurate', 'mle', 'small', 'moderately', 'large', 'sample_size', 'broad', 'range', 'parameter', 'value', 'author', 'recommend', 'median', 'unbiased', 'estimation', 'used', 'alternative', 'maximum', 'likelihood', 'estimation', 'data', 'structure', 'sparse']"
977,"Because there are 16 predictor variables, it would be wise to reduce the number of redundant variables before building a model in PROC LOGISTIC. One approach to variable reduction is variable clustering. Variable clustering finds groups of variables that are as correlated as possible among themselves and as uncorrelated as possible with variables in other clusters. A common strategy is to pick one variable from each cluster based on subject-matter knowledge.",CD,462,"['16', 'predictor_variable', 'would', 'wise', 'reduce', 'number', 'redundant', 'variable', 'building', 'model', 'proc_logistic', 'one', 'approach', 'variable', 'reduction', 'variable', 'clustering', 'variable', 'clustering', 'find', 'group', 'variable', 'correlated', 'possible', 'among', 'uncorrelated', 'possible', 'variable', 'cluster', 'common', 'strategy', 'pick', 'one', 'variable', 'cluster', 'based', 'subjectmatter', 'knowledge']"
978,"The LOGISTIC procedure should not be used to analyze clustered data because PROC LOGISTIC assumes independent observations. In the past, the CATMOD procedure was used to analyze clustered data with a discrete response variable. However, GEE models offer some significant advantages over models fit in PROC CATMOD for the analysis of clustered data. For example, models fit in PROC CATMOD require that the data be balanced. Therefore, the measurements have to occur at the same times for all subjects and each subject has the same number of measurements. PROC CATMOD also uses complete case analysis, where only subjects with data at all time points are used. If a subject has one or more missing measurements, then PROC CATMOD deletes the entire subject. Models fit in PROC CATMOD model the distribution of the response variable (represented by the columns in an underlying contingency table) across the levels of the predictor variables (represented by the rows in an underlying contingency table). Computational difficulties might occur if you have a continuous covariate with a large number of unique values, because many rows will have a sample size of 1. PROC CATMOD might be less efficient and might be unable to allocate sufficient memory to handle this problem. GEE regression models fit in the GENMOD procedure use the all-available pairs method, where all nonmissing pairs of data are used to estimate the parameters in the correlation matrix. If there are missing values, then some correlations are computed using more observations and other correlations are computed using fewer observations.",CD,1604,"['logistic', 'procedure', 'used', 'analyze', 'clustered', 'data', 'proc_logistic', 'assumes', 'independent', 'observation', 'past', 'catmod', 'procedure', 'wa', 'used', 'analyze', 'clustered', 'data', 'discrete', 'response_variable', 'however', 'gee', 'model', 'offer', 'significant', 'advantage', 'model', 'fit', 'proc', 'catmod', 'analysis', 'clustered', 'data', 'example', 'model', 'fit', 'proc', 'catmod', 'require', 'data', 'balanced', 'therefore', 'measurement', 'occur', 'time', 'subject', 'subject', 'ha', 'number', 'measurement', 'proc', 'catmod', 'also', 'us', 'complete', 'case', 'analysis', 'subject', 'data', 'time', 'point', 'used', 'subject', 'ha', 'one', 'missing', 'measurement', 'proc', 'catmod', 'deletes', 'entire', 'subject', 'model', 'fit', 'proc', 'catmod', 'model', 'distribution', 'response_variable', 'represented', 'column', 'underlying', 'contingency', 'table', 'across', 'level', 'predictor_variable', 'represented', 'row', 'underlying', 'contingency', 'table', 'computational', 'difficulty', 'might', 'occur', 'continuous', 'covariate', 'large', 'number', 'unique', 'value', 'many', 'row', 'sample_size', '1', 'proc', 'catmod', 'might', 'le', 'efficient', 'might', 'unable', 'allocate', 'sufficient', 'memory', 'handle', 'problem', 'gee', 'regression_model', 'fit', 'genmod', 'procedure', 'use', 'allavailable', 'pair', 'method', 'nonmissing', 'pair', 'data', 'used', 'estimate', 'parameter', 'correlation', 'matrix', 'missing', 'value', 'correlation', 'computed', 'using', 'observation', 'correlation', 'computed', 'using', 'fewer', 'observation']"
979,"The p-value is the probability of getting an equal or less likely statistic. Thus, you would add the probabilities less than or equal to the probability of obtaining the vector of the observed sufficient statistics.",CD,215,"['pvalue', 'probability', 'getting', 'equal', 'le', 'likely', 'statistic', 'thus', 'would', 'add', 'probability', 'le', 'equal', 'probability', 'obtaining', 'vector', 'observed', 'sufficient', 'statistic']"
980,"In the univariate analysis of the data, it is important to document, for each predictor variable, whether an association exists with the response variable and the strength of the association. For binary predictor variables, the confidence bounds around the odds ratio would indicate whether an association exists. If the confidence interval does not include 1, then there is evidence that there is an association. For ordinal predictors, the Mantel-Haenszel chi-square could be used. For nominal predictors, the mean score statistic would be helpful (Stokes, Davis, and Koch 2000). ?	Binary variables can be considered ordinal variables.",CD,637,"['univariate', 'analysis', 'data', 'important', 'document', 'predictor_variable', 'whether', 'association', 'exists', 'response_variable', 'strength', 'association', 'binary', 'predictor_variable', 'confidence', 'bound', 'around', 'odds_ratio', 'would', 'indicate', 'whether', 'association', 'exists', 'confidence', 'interval', 'doe', 'include', '1', 'evidence', 'association', 'ordinal', 'predictor', 'mantelhaenszel', 'chisquare', 'could', 'used', 'nominal', 'predictor', 'mean', 'score', 'statistic', 'would', 'helpful', 'stokes', 'davis', 'koch', '2000', '\tbinary', 'variable', 'considered', 'ordinal', 'variable']"
981,"To document the strength of the association, the odds ratio could be used for the binary predictors. For the ordinal predictors, the Spearman correlation statistic (which correlates the ranks of the data) would be helpful. For nominal predictors, the uncertainty coefficient c|r (column given the row, which means the column variable is the outcome variable and the row variable is the predictor variable) could be used. The uncertainty coefficient is defined as the proportion of the entropy (or uncertainty) in the response variable that is explained by the predictor variable. This statistic is comparable to the R2 statistic used in regression analysis.",CD,657,"['document', 'strength', 'association', 'odds_ratio', 'could', 'used', 'binary', 'predictor', 'ordinal', 'predictor', 'spearman', 'correlation', 'statistic', 'correlate', 'rank', 'data', 'would', 'helpful', 'nominal', 'predictor', 'uncertainty', 'coefficient', 'cr', 'column', 'given', 'row', 'mean', 'column', 'variable', 'outcome', 'variable', 'row', 'variable', 'predictor_variable', 'could', 'used', 'uncertainty', 'coefficient', 'defined', 'proportion', 'entropy', 'uncertainty', 'response_variable', 'explained', 'predictor_variable', 'statistic', 'comparable', 'r2', 'statistic', 'used', 'regression', 'analysis']"
982,"The independent correlation structure (TYPE=IND) forces the off-diagonals to be 0. Therefore, no working correlation structure is estimated in this case. Under this constraint, the coefficients and model-based standard errors (requested by the MODELSE option in the REPEATED statement) are the same as those reported in the LOGISTIC procedure. However, PROC GENMOD, by default, computes robust standard error estimates. These estimates take into account the correlations among the repeated measurements and usually are different from the model-based standard errors assuming independence. The independent correlation structure might be a good choice when you have a large number of subjects with few measurements per subject. The correlation influence is often small enough to have little impact on the regression coefficients, but the robust standard errors will give the correct inferences. This model gives consistent estimates of the parameters and standard errors when the mean model is correctly specified (Davis 2002).",CD,1025,"['independent', 'correlation_structure', 'typeind', 'force', 'offdiagonals', '0', 'therefore', 'working', 'correlation_structure', 'estimated', 'case', 'constraint', 'coefficient', 'modelbased', 'standard_error', 'requested', 'modelse', 'option', 'repeated', 'statement', 'reported', 'logistic', 'procedure', 'however', 'proc', 'genmod', 'default', 'computes', 'robust', 'standard_error', 'estimate', 'estimate', 'take', 'account', 'correlation', 'among', 'repeated', 'measurement', 'usually', 'different', 'modelbased', 'standard_error', 'assuming', 'independence', 'independent', 'correlation_structure', 'might', 'good', 'choice', 'large', 'number', 'subject', 'measurement', 'per', 'subject', 'correlation', 'influence', 'often', 'small', 'enough', 'little', 'impact', 'regression', 'coefficient', 'robust', 'standard_error', 'give', 'correct', 'inference', 'model', 'give', 'consistent', 'estimate', 'parameter', 'standard_error', 'mean', 'model', 'correctly', 'specified', 'davis', '2002']"
983,"The Strata Summary table displays the number of strata, which have a specific number of events and nonevents. Strata containing only events or only nonevents are reported in this table, but such strata are uninformative and are not used in the analysis. NOTE: The following parameters have been set to 0, since the variables are a linear combination of other variables as shown. Mother_age = 0",CD,393,"['stratum', 'summary', 'table', 'display', 'number', 'stratum', 'specific', 'number', 'event', 'nonevent', 'stratum', 'containing', 'event', 'nonevent', 'reported', 'table', 'stratum', 'uninformative', 'used', 'analysis', 'note', 'following', 'parameter', 'set', '0', 'since', 'variable', 'linear', 'combination', 'variable', 'shown', 'motherage', '', '0']"
984,"For backward elimination, the model selected when you allow multiple effects to leave the model at one time is the same as the model selected when you allow single effects to leave the model at one time. This is because only one main effect, not involved in a significant interaction, was itself not significant. Therefore, the method did not have the chance to eliminate the interaction along with its main effects in one step. When you include all the main effects in the model, the backward elimination method finds one significant interaction (mother_age*phy_visit). This is the same model as the one selected in forward selection including all the main effects. This model also has the highest c statistic (.793).",CD,718,"['backward', 'elimination', 'model', 'selected', 'allow', 'multiple', 'effect', 'leave', 'model', 'one', 'time', 'model', 'selected', 'allow', 'single', 'effect', 'leave', 'model', 'one', 'time', 'one', 'main_effect', 'involved', 'significant', 'interaction', 'wa', 'significant', 'therefore', 'method', 'chance', 'eliminate', 'interaction', 'along', 'main_effect', 'one', 'step', 'include', 'main_effect', 'model', 'backward', 'elimination', 'method', 'find', 'one', 'significant', 'interaction', 'motheragephyvisit', 'model', 'one', 'selected', 'forward', 'selection', 'including', 'main_effect', 'model', 'also', 'ha', 'highest', 'c', 'statistic', '793']"
985,The odds ratio indicates that women with previous preterm deliveries are 4.3 times more likely to have a low birth weight baby than women without previous preterm deliveries. The confidence interval is not symmetric around the estimate because distributions of ratios are asymmetric. The exact confidence interval is not needed because of the large sample size. Summary Statistics for prev_pretrm by low,CD,403,"['odds_ratio', 'indicates', 'woman', 'previous', 'preterm', 'delivery', '43', 'time', 'likely', 'low', 'birth', 'weight', 'baby', 'woman', 'without', 'previous', 'preterm', 'delivery', 'confidence', 'interval', 'symmetric', 'around', 'estimate', 'distribution', 'ratio', 'asymmetric', 'exact', 'confidence', 'interval', 'needed', 'large', 'sample_size', 'summary', 'statistic', 'prevpretrm', 'low']"
986,"Because the mother_age*phy_visit interaction is significant, you need to compute two odds ratios for mother?s age. One odds ratio is for mothers who did visit the physician during the first trimester; the other is for mothers who did not visit the physician during the first trimester. These odds ratios can be computed using the coefficients in the model. To compute the odds ratio of interest, write out the equation for the odds ratio. Solve the expression algebraically and exponentiate the final estimate. The example above shows that among women who went to a physician during the first trimester, women who are 10 years younger are 4.95 times more likely to have a low birth weight baby.",CD,694,"['motheragephyvisit', 'interaction', 'significant', 'need', 'compute', 'two', 'odds_ratio', 'mother', 'age', 'one', 'odds_ratio', 'mother', 'visit', 'physician', 'first', 'trimester', 'mother', 'visit', 'physician', 'first', 'trimester', 'odds_ratio', 'computed', 'using', 'coefficient', 'model', 'compute', 'odds_ratio', 'interest', 'write', 'equation', 'odds_ratio', 'solve', 'expression', 'algebraically', 'exponentiate', 'final', 'estimate', 'example', 'show', 'among', 'woman', 'went', 'physician', 'first', 'trimester', 'woman', '10', 'year', 'younger', '495', 'time', 'likely', 'low', 'birth', 'weight', 'baby']"
987,Complete separation can cause severe bias in the estimates of the odds ratios and poor chi-squared approximations for the goodness-of-fit statistics. You should be concerned about your model when the three goodness-of-fit tests reported in PROC LOGISTIC vary widely. Complete separation should be detected in the univariate analysis of the predictor variables. It should be noted that the modeling strategy that includes all the predictor variables in the model is particularly sensitive to complete separation (Allison 1999).,CD,526,"['complete', 'separation', 'cause', 'severe', 'bias', 'estimate', 'odds_ratio', 'poor', 'chisquared', 'approximation', 'goodnessoffit', 'statistic', 'concerned', 'model', 'three', 'goodnessoffit', 'test', 'reported', 'proc_logistic', 'vary', 'widely', 'complete', 'separation', 'detected', 'univariate', 'analysis', 'predictor_variable', 'noted', 'modeling', 'strategy', 'includes', 'predictor_variable', 'model', 'particularly', 'sensitive', 'complete', 'separation', 'allison', '1999']"
988,"Before building a multivariate model, the analyst should perform an exploratory data analysis with contingency tables and logit plots. Contingency table analysis may detect confounders and interactions. Confounders are variables that are associated with both the response variable and a primary predictor variable. When confounding is present, the estimate of the effect of the primary predictor variable to the response is distorted because it is mixed with the effect of the confounder or extraneous variable. Identifying confounders may help the analyst gain an understanding of the relationships among the variables and may help the analyst build a better multivariate model (Rothman 1986). The next two graphs illustrate the concept of confounding. It can be seen that there is a large difference in the log odds of the response between males (Y1) and females (Y2). However, a large portion of this difference may be due to differences in the age of the groups. Therefore, it may not be possible to determine the effect of gender without first eliminating the discrepancy in age.",CD,1084,"['building', 'multivariate', 'model', 'analyst', 'perform', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'contingency', 'table', 'analysis', 'may', 'detect', 'confounders', 'interaction', 'confounders', 'variable', 'associated', 'response_variable', 'primary', 'predictor_variable', 'confounding', 'present', 'estimate', 'effect', 'primary', 'predictor_variable', 'response', 'distorted', 'mixed', 'effect', 'confounder', 'extraneous', 'variable', 'identifying', 'confounders', 'may', 'help', 'analyst', 'gain', 'understanding', 'relationship', 'among', 'variable', 'may', 'help', 'analyst', 'build', 'better', 'multivariate', 'model', 'rothman', '1986', 'next', 'two', 'graph', 'illustrate', 'concept', 'confounding', 'seen', 'large', 'difference', 'log', 'odds', 'response', 'male', 'y1', 'female', 'y2', 'however', 'large', 'portion', 'difference', 'may', 'due', 'difference', 'age', 'group', 'therefore', 'may', 'possible', 'determine', 'effect', 'gender', 'without', 'first', 'eliminating', 'discrepancy', 'age']"
989,"Convergence problems are also caused by complete separation. This occurs when some linear combination of the predictor variables perfectly predicts the response variable. The net result is infinite parameter estimates. In order to have finite maximum likelihood estimates, there must be some overlap in the distribution of the predictor variables in the model. The diagram above shows that the continuous predictor age perfectly separates the response. Thus age is a perfect predictor of the response.",CD,501,"['convergence', 'problem', 'also', 'caused', 'complete', 'separation', 'occurs', 'linear', 'combination', 'predictor_variable', 'perfectly', 'predicts', 'response_variable', 'net', 'result', 'infinite', 'parameter_estimate', 'order', 'finite', 'maximum', 'likelihood', 'estimate', 'must', 'overlap', 'distribution', 'predictor_variable', 'model', 'diagram', 'show', 'continuous', 'predictor', 'age', 'perfectly', 'separate', 'response', 'thus', 'age', 'perfect', 'predictor', 'response']"
990,"The score test for the proportional odds assumption tends to reject the null hypothesis more often than is warranted. If there are many predictor variables and if the sample size is large, the test usually produces p-values below 0.05 (Allison 1999). Given such a liberal test, it may be useful to graph the cumulative logits to visually inspect the proportional odds assumption. Cumulative logit plots are graphs of cumulative logits for each predictor variable. If the proportional odds assumption is true, then the slopes of the logits should be parallel. If the plotted lines diverge greatly from parallelism, then you should consider a different modeling approach such as modeling generalized logits. Agresti (2002) also recommends trying a link function for which the response curve is nonsymmetric (in other words, complementary log-log), adding additional parameters such as interactions, and adding dispersion parameters. Cumulative Logit Plots",CD,953,"['score', 'test', 'proportional', 'odds', 'assumption', 'tends', 'reject', 'null', 'hypothesis', 'often', 'warranted', 'many', 'predictor_variable', 'sample_size', 'large', 'test', 'usually', 'produce', 'pvalues', '005', 'allison', '1999', 'given', 'liberal', 'test', 'may', 'useful', 'graph', 'cumulative', 'logits', 'visually', 'inspect', 'proportional', 'odds', 'assumption', 'cumulative', 'logit', 'plot', 'graph', 'cumulative', 'logits', 'predictor_variable', 'proportional', 'odds', 'assumption', 'true', 'slope', 'logits', 'parallel', 'plotted', 'line', 'diverge', 'greatly', 'parallelism', 'consider', 'different', 'modeling', 'approach', 'modeling', 'generalized', 'logits', 'agresti', '2002', 'also', 'recommends', 'trying', 'link', 'function', 'response', 'curve', 'nonsymmetric', 'word', 'complementary', 'loglog', 'adding', 'additional', 'parameter', 'interaction', 'adding', 'dispersion', 'parameter', 'cumulative', 'logit', 'plot']"
991,"The first section of the output describes the data set, the response variable, the number of response levels, the type of model, the algorithm used to obtain the parameter estimates, and the number of observations read and used. The Response Profile table shows the response variable values listed according to their ordered values. By default, PROC LOGISTIC orders the response variable alphanumerically so that it bases the logistic regression model on the probability of the smallest value. Because you used the EVENT=option, in this example, the model is based on the probability of low birth weight (low=1). The Response Profile table also shows the value of the response variable and the frequency. The class level information shows that socio was dummy coded into two design variables. Because you used the PARAM=REF and REF='3' options, this table reflects your choice of socio=3 as the reference level. Model Fit Statistics",CD,932,"['first', 'section', 'output', 'describes', 'data_set', 'response_variable', 'number', 'response', 'level', 'type', 'model', 'algorithm', 'used', 'obtain', 'parameter_estimate', 'number', 'observation', 'read', 'used', 'response', 'profile', 'table', 'show', 'response_variable', 'value', 'listed', 'according', 'ordered', 'value', 'default', 'proc_logistic', 'order', 'response_variable', 'alphanumerically', 'base', 'logistic_regression_model', 'probability', 'smallest', 'value', 'used', 'eventoption', 'example', 'model', 'based', 'probability', 'low', 'birth', 'weight', 'low1', 'response', 'profile', 'table', 'also', 'show', 'value', 'response_variable', 'frequency', 'class', 'level', 'information', 'show', 'socio', 'wa', 'dummy', 'coded', 'two', 'design', 'variable', 'used', 'paramref', 'ref3', 'option', 'table', 'reflects', 'choice', 'socio3', 'reference', 'level', 'model', 'fit', 'statistic']"
992,"When building a model, it is critical that you assess the need to include interaction terms among the predictor variables. One recommendation is to assess only those interactions that are specified a priori based on subject-matter knowledge. To assess the significance of the interaction, compute a likelihood ratio test that compares the model with the interaction to the model with the main effects only. The degrees of freedom would be the difference in the number of variables. If the p-value is below a specified significance level, then you may want to include the interaction term in the final model. However, the final decision as to whether an interaction term should be included in a model should be based on statistical as well as practical considerations. In other words, the interaction term must make sense from a subject-matter point of view (Hosmer and Lemeshow 2000).",CD,884,"['building', 'model', 'critical', 'ass', 'need', 'include', 'interaction', 'term', 'among', 'predictor_variable', 'one', 'recommendation', 'ass', 'interaction', 'specified', 'priori', 'based', 'subjectmatter', 'knowledge', 'ass', 'significance', 'interaction', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'model', 'interaction', 'model', 'main_effect', 'degree', 'freedom', 'would', 'difference', 'number', 'variable', 'pvalue', 'specified', 'significance', 'level', 'may', 'want', 'include', 'interaction', 'term', 'final', 'model', 'however', 'final', 'decision', 'whether', 'interaction', 'term', 'included', 'model', 'based', 'statistical', 'well', 'practical', 'consideration', 'word', 'interaction', 'term', 'must', 'make', 'sense', 'subjectmatter', 'point', 'view', 'hosmer', 'lemeshow', '2000']"
993,The forward selection procedure starts with no variables in the model. At each step the variable with the largest adjusted chi-square statistic is entered into the model if its p-value is lower than the specified significance level. The residual chi-square tests the significance of the variables not in the model. Step 1. Effect prev_pretrm entered: Model Convergence Status,CD,375,"['forward', 'selection', 'procedure', 'start', 'variable', 'model', 'step', 'variable', 'largest', 'adjusted', 'chisquare', 'statistic', 'entered', 'model', 'pvalue', 'lower', 'specified', 'significance', 'level', 'residual', 'chisquare', 'test', 'significance', 'variable', 'model', 'step', '1', 'effect', 'prevpretrm', 'entered', 'model', 'convergence', 'status']"
994,"A key component of exploratory data analysis is to graphically examine the relationship between the response variable and the predictor variables. In linear regression, it is standard practice to examine scatter plots of the response variable and the continuous predictor variables. However, when the response variable is a binary variable, these scatter plots are not very useful. A more enlightening scatter plot for logistic regression is to transform the vertical axis to the logit scale and plot the logit by the continuous predictor variable. In this way you can check the assumption of linearity in the logit (Hosmer and Lemeshow 2000).",CD,643,"['key', 'component', 'exploratory', 'data', 'analysis', 'graphically', 'examine', 'relationship', 'response_variable', 'predictor_variable', 'linear', 'regression', 'standard', 'practice', 'examine', 'scatter', 'plot', 'response_variable', 'continuous', 'predictor_variable', 'however', 'response_variable', 'binary', 'variable', 'scatter', 'plot', 'useful', 'enlightening', 'scatter', 'plot', 'logistic_regression', 'transform', 'vertical', 'axis', 'logit', 'scale', 'plot', 'logit', 'continuous', 'predictor_variable', 'way', 'check', 'assumption', 'linearity', 'logit', 'hosmer', 'lemeshow', '2000']"
995,"Before building a multivariate model, the analyst should perform an exploratory data analysis with contingency tables and logit plots. Contingency table analysis may detect confounders and interactions. Confounders are variables that are associated with both the response variable and a primary predictor variable. When confounding is present, the estimate of the effect of the primary predictor variable to the response is distorted because it is mixed with the effect of the confounder or extraneous variable. Identifying confounders may help the analyst gain an understanding of the relationships among the variables and may help the analyst build a better multivariate model (Rothman 1986). The next two graphs illustrate the concept of confounding. It can be seen that there is a large difference in the log odds of the response between males (Y1) and females (Y2). However, a large portion of this difference may be due to differences in the age of the groups. Therefore, it may not be possible to determine the effect of gender without first eliminating the discrepancy in age.",CD,1084,"['building', 'multivariate', 'model', 'analyst', 'perform', 'exploratory', 'data', 'analysis', 'contingency', 'table', 'logit', 'plot', 'contingency', 'table', 'analysis', 'may', 'detect', 'confounders', 'interaction', 'confounders', 'variable', 'associated', 'response_variable', 'primary', 'predictor_variable', 'confounding', 'present', 'estimate', 'effect', 'primary', 'predictor_variable', 'response', 'distorted', 'mixed', 'effect', 'confounder', 'extraneous', 'variable', 'identifying', 'confounders', 'may', 'help', 'analyst', 'gain', 'understanding', 'relationship', 'among', 'variable', 'may', 'help', 'analyst', 'build', 'better', 'multivariate', 'model', 'rothman', '1986', 'next', 'two', 'graph', 'illustrate', 'concept', 'confounding', 'seen', 'large', 'difference', 'log', 'odds', 'response', 'male', 'y1', 'female', 'y2', 'however', 'large', 'portion', 'difference', 'may', 'due', 'difference', 'age', 'group', 'therefore', 'may', 'possible', 'determine', 'effect', 'gender', 'without', 'first', 'eliminating', 'discrepancy', 'age']"
996,"To assess the significance of the extra terms in the model, you can compute a likelihood ratio test that compares two models. One model would be the full model with all the terms, and the other model would be the reduced model with just a subset of the terms. The difference between the negative 2 log likelihood for the reduced model and the negative 2 log likelihood for the full model is the value of the test statistic for the likelihood ratio test. An alternative way to compute this test statistic is to take the difference between the likelihood ratio chi-square statistic reported for the model with the extra terms and the likelihood ratio chi-square statistic reported for the model without the extra terms. The degrees of freedom would be the difference in the number of terms between the two models. The test statistic along with the corresponding p-value can be computed using ODS. The test statistic for the likelihood ratio test follows a chi-square distribution if the reduced model is a subset of the full model. Therefore, the validity of the test would be compromised if you were comparing two entirely different models. An alternative way to compute likelihood-ratio tests is to use the GENMOD procedure with the TYPE3 option. PROC GENMOD will be shown in a later chapter. Likelihood Ratio Test Statistic",CD,1324,"['ass', 'significance', 'extra', 'term', 'model', 'compute', 'likelihood', 'ratio', 'test', 'compare', 'two', 'model', 'one', 'model', 'would', 'full', 'model', 'term', 'model', 'would', 'reduced', 'model', 'subset', 'term', 'difference', 'negative', '2', 'log', 'likelihood', 'reduced', 'model', 'negative', '2', 'log', 'likelihood', 'full', 'model', 'value', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'alternative', 'way', 'compute', 'test', 'statistic', 'take', 'difference', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'extra', 'term', 'likelihood', 'ratio', 'chisquare', 'statistic', 'reported', 'model', 'without', 'extra', 'term', 'degree', 'freedom', 'would', 'difference', 'number', 'term', 'two', 'model', 'test', 'statistic', 'along', 'corresponding', 'pvalue', 'computed', 'using', 'od', 'test', 'statistic', 'likelihood', 'ratio', 'test', 'follows', 'chisquare', 'distribution', 'reduced', 'model', 'subset', 'full', 'model', 'therefore', 'validity', 'test', 'would', 'compromised', 'comparing', 'two', 'entirely', 'different', 'model', 'alternative', 'way', 'compute', 'likelihoodratio', 'test', 'use', 'genmod', 'procedure', 'type3', 'option', 'proc', 'genmod', 'shown', 'later', 'chapter', 'likelihood', 'ratio', 'test', 'statistic']"
997,"Optimization Technique Newton-Raphson ridge Because the number of parameters is less than 40, the Newton-Raphson with ridging optimization technique is used to obtain the maximum likelihood parameter estimates. Number of Observations Read 112 Number of Observations Used 112",CD,274,"['optimization', 'technique', 'newtonraphson', 'ridge', 'number', 'parameter', 'le', '40', 'newtonraphson', 'ridging', 'optimization', 'technique', 'used', 'obtain', 'maximum', 'likelihood', 'parameter_estimate', 'number', 'observation', 'read', '112', 'number', 'observation', 'used', '112']"
998,"Because the MODELSE option is used, the Analysis Of GEE Parameter Estimates table shows both the empirical standard error estimates and the model-based standard error estimates. The empirical standard error estimates are robust estimates that do not depend on the correctness of the structure imposed on the working correlation matrix. The model-based standard error estimates are based directly on the assumed correlation structure. The model-based standard errors are better estimates if the assumed model for the correlation structure is correct, but worse if the assumed model is incorrect (Allison 1999). Because the sample size is large and the number of repeated measurements is small, the robust standard errors are generally preferred. Notice that smoker is now not significant and age is even more significant. Because smoker is a time-independent variable, the standard error was underestimated (0.1235) in the initial parameter estimates where the standard errors are based on the assumption of independence. The empirical standard error estimate using GEEs is 0.1782, which makes smoker not significant (p-value of 0.1550). This illustrates how ignoring correlated observations can inflate the Type I error rate for time-independent predictor variables. The standard error for age, a time-dependent variable, is estimated at 0.0541 in the initial parameter estimates. The empirical standard error is 0.0442, which lowers the p-value of age (0.036 to 0.0094). This illustrates how ignoring correlated observations can inflate the Type II error rate for time-dependent predictor variables. Score Statistics For Type 3 GEE Analysis",CD,1641,"['modelse', 'option', 'used', 'analysis', 'gee', 'parameter_estimate', 'table', 'show', 'empirical', 'standard_error', 'estimate', 'modelbased', 'standard_error', 'estimate', 'empirical', 'standard_error', 'estimate', 'robust', 'estimate', 'depend', 'correctness', 'structure', 'imposed', 'working', 'correlation', 'matrix', 'modelbased', 'standard_error', 'estimate', 'based', 'directly', 'assumed', 'correlation_structure', 'modelbased', 'standard_error', 'better', 'estimate', 'assumed', 'model', 'correlation_structure', 'correct', 'worse', 'assumed', 'model', 'incorrect', 'allison', '1999', 'sample_size', 'large', 'number', 'repeated', 'measurement', 'small', 'robust', 'standard_error', 'generally', 'preferred', 'notice', 'smoker', 'significant', 'age', 'even', 'significant', 'smoker', 'timeindependent', 'variable', 'standard_error', 'wa', 'underestimated', '01235', 'initial', 'parameter_estimate', 'standard_error', 'based', 'assumption', 'independence', 'empirical', 'standard_error', 'estimate', 'using', 'gee', '01782', 'make', 'smoker', 'significant', 'pvalue', '01550', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'error', 'rate', 'timeindependent', 'predictor_variable', 'standard_error', 'age', 'timedependent', 'variable', 'estimated', '00541', 'initial', 'parameter_estimate', 'empirical', 'standard_error', '00442', 'lower', 'pvalue', 'age', '0036', '00094', 'illustrates', 'ignoring', 'correlated', 'observation', 'inflate', 'type', 'ii', 'error', 'rate', 'timedependent', 'predictor_variable', 'score', 'statistic', 'type', '3', 'gee', 'analysis']"
999,"However, when the model is fit with the main effects and the interaction term, the parameter estimates for the stratification variable and the interaction term along with their associated standard errors increase dramatically. The reason for the model instability is the presence of the 0 cell count when you stratify on the predictor variable. This problem should be detected during the stratified analysis of the predictor variables.",CD,435,"['however', 'model', 'fit', 'main_effect', 'interaction', 'term', 'parameter_estimate', 'stratification', 'variable', 'interaction', 'term', 'along', 'associated', 'standard_error', 'increase', 'dramatically', 'reason', 'model', 'instability', 'presence', '0', 'cell', 'count', 'stratify', 'predictor_variable', 'problem', 'detected', 'stratified', 'analysis', 'predictor_variable']"
1000,"Besides the observations with the large change in the Pearson chi-square statistic, the observations with large circles near the bottom of the cup defined by the quadratic curves should also be examined. These are observations that influenced the parameter estimates to a relatively large extent but are not poorly fitted observations (Hosmer and Lemeshow 2000). Example:	Print the observations with possible outlying covariate patterns. Examine each observation to determine what made the observation influential or an outlier. Establish a cutoff of the 95th percentile for the distribution of DIFDEV, DIFCHISQ, H, and C. ?	Because there are no published statistical cutoffs for the logistic regression diagnostic statistics, these suggested cutoffs are only used to detect possible outliers and influential observations. A more thorough approach would be to examine all of the diagnostic plots to identify all of the unusual observations. /* c2demo11d */ proc logistic data=sasuser.birth noprint; model low(event='1')=mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio mother_age*phy_visit; output out=predict p=pred difdev=difdev difchisq=difchisq h=h c=c dfbetas=dfint dfage dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; run; For the DFBETAS keyword, a list of variable names is specified to correspond to the parameter estimates in the model. The first variable contains the standardized differences in the intercept estimate, the second variable contains the standardized differences in the parameter estimate for the first predictor variable in the MODEL statement, and so on. /* c2demo11e */ proc rank data=predict groups=20 out=bins; var difdev difchisq h c; ranks difdevbin difchisqbin hbin cbin; run; PROC RANK is used to bin the observations into groups. The variable difdevbin is the group identification number for difdev that ranges from 0 (the first group) to 19 (the last group). The variables difchisqbin, hbin, and cbin are the group identification numbers for difchisq, h, and c respectively. /* c2demo11f */ proc print data=bins; where difdevbin=19 or difchisqbin=19 or hbin=19 or cbin=19; var low mother_age phy_visit alcohol uterine_irr hist_hyp mother_wt prev_pretrm socio pred difdev difchisq h c dfint dfvis dfalc dfuter dfhyp dfwt dfpretrm dfsocio dfage_visit; title 'Observations with Possible Outlying Covariate ' 'Patterns'; run;",CD,2400,"['besides', 'observation', 'large', 'change', 'pearson', 'chisquare', 'statistic', 'observation', 'large', 'circle', 'near', 'bottom', 'cup', 'defined', 'quadratic', 'curve', 'also', 'examined', 'observation', 'influenced', 'parameter_estimate', 'relatively', 'large', 'extent', 'poorly', 'fitted', 'observation', 'hosmer', 'lemeshow', '2000', 'example\tprint', 'observation', 'possible', 'outlying', 'covariate', 'pattern', 'examine', 'observation', 'determine', 'made', 'observation', 'influential', 'outlier', 'establish', 'cutoff', '95th', 'percentile', 'distribution', 'difdev', 'difchisq', 'h', 'c', '\tbecause', 'published', 'statistical', 'cutoff', 'logistic_regression', 'diagnostic', 'statistic', 'suggested', 'cutoff', 'used', 'detect', 'possible', 'outlier', 'influential', 'observation', 'thorough', 'approach', 'would', 'examine', 'diagnostic', 'plot', 'identify', 'unusual', 'observation', '', 'c2demo11d', '', 'proc_logistic', 'datasasuserbirth', 'noprint', 'model', 'lowevent1motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'motheragephyvisit', 'output', 'outpredict', 'ppred', 'difdevdifdev', 'difchisqdifchisq', 'hh', 'cc', 'dfbetasdfint', 'dfage', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'run', 'dfbetas', 'keyword', 'list', 'variable', 'name', 'specified', 'correspond', 'parameter_estimate', 'model', 'first', 'variable', 'contains', 'standardized', 'difference', 'intercept', 'estimate', 'second', 'variable', 'contains', 'standardized', 'difference', 'parameter_estimate', 'first', 'predictor_variable', 'model_statement', '', 'c2demo11e', '', 'proc', 'rank', 'datapredict', 'groups20', 'outbins', 'var', 'difdev', 'difchisq', 'h', 'c', 'rank', 'difdevbin', 'difchisqbin', 'hbin', 'cbin', 'run', 'proc', 'rank', 'used', 'bin', 'observation', 'group', 'variable', 'difdevbin', 'group', 'identification', 'number', 'difdev', 'range', '0', 'first', 'group', '19', 'last', 'group', 'variable', 'difchisqbin', 'hbin', 'cbin', 'group', 'identification', 'number', 'difchisq', 'h', 'c', 'respectively', '', 'c2demo11f', '', 'proc', 'print', 'databins', 'difdevbin19', 'difchisqbin19', 'hbin19', 'cbin19', 'var', 'low', 'motherage', 'phyvisit', 'alcohol', 'uterineirr', 'histhyp', 'motherwt', 'prevpretrm', 'socio', 'pred', 'difdev', 'difchisq', 'h', 'c', 'dfint', 'dfvis', 'dfalc', 'dfuter', 'dfhyp', 'dfwt', 'dfpretrm', 'dfsocio', 'dfagevisit', 'title', 'observation', 'possible', 'outlying', 'covariate', '', 'pattern', 'run']"
1001,"The p-value is the probability of getting an equal or less likely statistic. Thus, you would add the probabilities less than or equal to the probability of obtaining the vector of the observed sufficient statistics.",CD,215,"['pvalue', 'probability', 'getting', 'equal', 'le', 'likely', 'statistic', 'thus', 'would', 'add', 'probability', 'le', 'equal', 'probability', 'obtaining', 'vector', 'observed', 'sufficient', 'statistic']"
1002,Complete separation can cause severe bias in the estimates of the odds ratios and poor chi-squared approximations for the goodness-of-fit statistics. You should be concerned about your model when the three goodness-of-fit tests reported in PROC LOGISTIC vary widely. Complete separation should be detected in the univariate analysis of the predictor variables. It should be noted that the modeling strategy that includes all the predictor variables in the model is particularly sensitive to complete separation (Allison 1999).,CD,526,"['complete', 'separation', 'cause', 'severe', 'bias', 'estimate', 'odds_ratio', 'poor', 'chisquared', 'approximation', 'goodnessoffit', 'statistic', 'concerned', 'model', 'three', 'goodnessoffit', 'test', 'reported', 'proc_logistic', 'vary', 'widely', 'complete', 'separation', 'detected', 'univariate', 'analysis', 'predictor_variable', 'noted', 'modeling', 'strategy', 'includes', 'predictor_variable', 'model', 'particularly', 'sensitive', 'complete', 'separation', 'allison', '1999']"
1003,"A useful way to explain significant interactions is to graph them. For example, to visualize the interaction between mother?s age and physician visit, first create a data set that contains the information about the fitted model. Then create a data set with plotting points, which include the median for each predictor variable not involved in the interaction and the 5th, 25th, 50th, 75th, and 95th percentiles of mother?s age and both values of physician visit. Then score the data set in PROC LOGISTIC with the SCORE statement. Finally, plot the predicted logits and the predicted probabilities by the plotting points for the two variables to illustrate how the slope for mother?s age differs by the level of physician visit. Illustrating Interactions",CD,753,"['useful', 'way', 'explain', 'significant', 'interaction', 'graph', 'example', 'visualize', 'interaction', 'mother', 'age', 'physician', 'visit', 'first', 'create', 'data_set', 'contains', 'information', 'fitted', 'model', 'create', 'data_set', 'plotting', 'point', 'include', 'median', 'predictor_variable', 'involved', 'interaction', '5th', '25th', '50th', '75th', '95th', 'percentile', 'mother', 'age', 'value', 'physician', 'visit', 'score', 'data_set', 'proc_logistic', 'score', 'statement', 'finally', 'plot', 'predicted', 'logits', 'predicted', 'probability', 'plotting', 'point', 'two', 'variable', 'illustrate', 'slope', 'mother', 'age', 'differs', 'level', 'physician', 'visit', 'illustrating', 'interaction']"
1004,"To fully appreciate the effect of leverage points and the benefits of regularization transformations, consider the plot above. It shows a standard logistic regression model fit to original and three transformed inputs. The untransformed model appears to show a relatively substantial association between CC_AVG_BAL and INS. In the threshold transformed input, the association largely disappears. For the log and rank transformed inputs, it is seen to be non-existent. Using the %RANK_TRANS Macro",DM,495,"['fully', 'appreciate', 'effect', 'leverage', 'point', 'benefit', 'regularization', 'transformation', 'consider', 'plot', 'show', 'standard', 'logistic_regression_model', 'fit', 'original', 'three', 'transformed', 'input', 'untransformed', 'model', 'appears', 'show', 'relatively', 'substantial', 'association', 'ccavgbal', 'threshold', 'transformed', 'input', 'association', 'largely', 'disappears', 'log', 'rank', 'transformed', 'input', 'seen', 'nonexistent', 'using', 'ranktrans', 'macro']"
1005,Processing by transaction groups requires some minor additions to the Declare and Vector tasks and more substantial additions to the Export task. The most important innovation is the transaction macros use of grouping indicators.,DM,229,"['processing', 'transaction', 'group', 'requires', 'minor', 'addition', 'declare', 'vector', 'task', 'substantial', 'addition', 'export', 'task', 'important', 'innovation', 'transaction', 'macro', 'use', 'grouping', 'indicator']"
1006,"There are several possible transformations you can use to tame extreme distributions. The first is simply truncating the input distribution at some value. This is easy to implement for a given input, but it is difficult to automate because the optimal truncation point usually depends on the distribution. Also, it does not completely solve the problem of leverage because there may be still be considerable mass at the truncation point. Another approach is using a regularization transformation such as the log function. This works well as long as the input is strictly positive. If not, then log(x+a) could be used, as long as an a exists such that x + a > 0 for all x. A more clever transformation is the hyperbolic tangent function, tanh(x). This function controls extreme values such as the log function and admits negative values. Of course, the downside of these transformations is the loss of interpretability of the model coefficients, even for standard regression. A third approach is the use of rank transformation to transform even the most extreme distribution to a uniform one. This eliminates the leverage problem, asymptotes the target response, and maintains a degree of interpretability as most people understand rankings (especially in the form of percentiles). Taming Extreme Distributions",DM,1309,"['several', 'possible', 'transformation', 'use', 'tame', 'extreme', 'distribution', 'first', 'simply', 'truncating', 'input', 'distribution', 'value', 'easy', 'implement', 'given', 'input', 'difficult', 'automate', 'optimal', 'truncation', 'point', 'usually', 'depends', 'distribution', 'also', 'doe', 'completely', 'solve', 'problem', 'leverage', 'may', 'still', 'considerable', 'mass', 'truncation', 'point', 'another', 'approach', 'using', 'regularization', 'transformation', 'log', 'function', 'work', 'well', 'long', 'input', 'strictly', 'positive', 'logxa', 'could', 'used', 'long', 'exists', 'x', '', '', '0', 'x', 'clever', 'transformation', 'hyperbolic', 'tangent', 'function', 'tanhx', 'function', 'control', 'extreme', 'value', 'log', 'function', 'admits', 'negative', 'value', 'course', 'downside', 'transformation', 'loss', 'interpretability', 'model', 'coefficient', 'even', 'standard', 'regression', 'third', 'approach', 'use', 'rank', 'transformation', 'transform', 'even', 'extreme', 'distribution', 'uniform', 'one', 'eliminates', 'leverage', 'problem', 'asymptote', 'target', 'response', 'maintains', 'degree', 'interpretability', 'people', 'understand', 'ranking', 'especially', 'form', 'percentile', 'taming', 'extreme', 'distribution']"
1007,"Any analytic objective involving predictive modeling starts with extraction and transformation of data from remote sources. The level of effort required for this first step is easy to underestimate and is often fraught with difficulties. First, useful data might not exist. For example, a business that wants to predict product failure might collect a large amount of data describing the particulars of defective products, but not record similar information for nondefective products. Even when data exists, it can be impossible to utilize it without violating privacy rules. For example, the Health Insurance Portability and Accountability Act of 1996 prohibits insurance companies from using data used for processing medical claims to underwrite other products, such as life insurance. Assuming that data is available and allowed, useful information is often spread across many disparate sources. Even when data is well organized, the normalized database design disperses information across many tables. For example, a typical marketing data warehouse contains dozens of tables with direct links to dozens more. Because detail tables provide the most insight into customer behavior, they are most valuable for predictive modeling. Yet a single customer can generate thousands of records over the course of a year. Moving these large volumes of data across networks can dramatically slow the data preparation process. Predictive models are often built from a target variable corresponding to a (binary) classification. This classification, in turn, relates to characteristics stored in a database. Success in achieving an analytic objective hinges on a relevant and unambiguous statement of the characteristics corresponding to each class. Without such a statement, it is difficult to extract meaningful modeling data. For example, banks construct risk scores based on the classification of known customers into ?good? and ?bad? credit risks. The precise definition of good and bad risk, however, is somewhat ambiguous and must be agreed upon in advanced. Even when data is available, useable, tractable, and explicable, the largest data extraction challenge remains: drawing an uncontaminated modeling sample. Avoiding the unintentional leakage of target information into the modeling inputs is a recurring theme in this course and the bane of all data mining efforts.",DM,2370,"['analytic', 'objective', 'involving', 'predictive', 'modeling', 'start', 'extraction', 'transformation', 'data', 'remote', 'source', 'level', 'effort', 'required', 'first', 'step', 'easy', 'underestimate', 'often', 'fraught', 'difficulty', 'first', 'useful', 'data', 'might', 'exist', 'example', 'business', 'want', 'predict', 'product', 'failure', 'might', 'collect', 'large', 'amount', 'data', 'describing', 'particular', 'defective', 'product', 'record', 'similar', 'information', 'nondefective', 'product', 'even', 'data', 'exists', 'impossible', 'utilize', 'without', 'violating', 'privacy', 'rule', 'example', 'health', 'insurance', 'portability', 'accountability', 'act', '1996', 'prohibits', 'insurance', 'company', 'using', 'data', 'used', 'processing', 'medical', 'claim', 'underwrite', 'product', 'life', 'insurance', 'assuming', 'data', 'available', 'allowed', 'useful', 'information', 'often', 'spread', 'across', 'many', 'disparate', 'source', 'even', 'data', 'well', 'organized', 'normalized', 'database', 'design', 'disperses', 'information', 'across', 'many', 'table', 'example', 'typical', 'marketing', 'data', 'warehouse', 'contains', 'dozen', 'table', 'direct', 'link', 'dozen', 'detail', 'table', 'provide', 'insight', 'customer', 'behavior', 'valuable', 'predictive', 'modeling', 'yet', 'single', 'customer', 'generate', 'thousand', 'record', 'course', 'year', 'moving', 'large', 'volume', 'data', 'across', 'network', 'dramatically', 'slow', 'data', 'preparation', 'process', 'predictive', 'model', 'often', 'built', 'target', 'variable', 'corresponding', 'binary', 'classification', 'classification', 'turn', 'relates', 'characteristic', 'stored', 'database', 'success', 'achieving', 'analytic', 'objective', 'hinge', 'relevant', 'unambiguous', 'statement', 'characteristic', 'corresponding', 'class', 'without', 'statement', 'difficult', 'extract', 'meaningful', 'modeling', 'data', 'example', 'bank', 'construct', 'risk', 'score', 'based', 'classification', 'known', 'customer', 'good', 'bad', 'credit', 'risk', 'precise', 'definition', 'good', 'bad', 'risk', 'however', 'somewhat', 'ambiguous', 'must', 'agreed', 'upon', 'advanced', 'even', 'data', 'available', 'useable', 'tractable', 'explicable', 'largest', 'data', 'extraction', 'challenge', 'remains', 'drawing', 'uncontaminated', 'modeling', 'sample', 'avoiding', 'unintentional', 'leakage', 'target', 'information', 'modeling', 'input', 'recurring', 'theme', 'course', 'bane', 'data', 'mining', 'effort']"
1008,Transactions data also promotes modeling challenges. The data is often sequestered on inaccessible servers with little opportunity for mass data transfer. The blessing of high detail is also a curse: the sheer volume of data makes it extremely time consuming to obtain and difficult to process.,DM,294,"['transaction', 'data', 'also', 'promotes', 'modeling', 'challenge', 'data', 'often', 'sequestered', 'inaccessible', 'server', 'little', 'opportunity', 'mass', 'data', 'transfer', 'blessing', 'high', 'detail', 'also', 'curse', 'sheer', 'volume', 'data', 'make', 'extremely', 'time', 'consuming', 'obtain', 'difficult', 'process']"
1009,The optional demonstration later in this section details the creation of the report. ?	The %DISTRIBUTION macro can be used on its own to look at the distributions of any variable or set of variables in any SAS data set. The %DISTRIBUTION Macro,DM,243,"['optional', 'demonstration', 'later', 'section', 'detail', 'creation', 'report', '\tthe', 'distribution', 'macro', 'used', 'look', 'distribution', 'variable', 'set', 'variable', 'sa', 'data_set', 'distribution', 'macro']"
1010,The application of the geocoding formats appears somewhat more complicated. The complication arises from the embedded Boolean logic in the assignment statement. data lat_lon_inputs; set dmdp.input_sample_branch;,DM,211,"['application', 'geocoding', 'format', 'appears', 'somewhat', 'complicated', 'complication', 'arises', 'embedded', 'boolean', 'logic', 'assignment', 'statement', 'data', 'latloninputs', 'set', 'dmdpinputsamplebranch']"
1011,"The simulation study shows that, in general, simple dummy coding and simple weight of evidence strategies should be avoided. Better results can be obtained by threshold dummy coding or smoothed weight of evidence approaches.",DM,224,"['simulation', 'study', 'show', 'general', 'simple', 'dummy', 'coding', 'simple', 'weight', 'evidence', 'strategy', 'avoided', 'better', 'result', 'obtained', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'approach']"
1012,"Subsequent chapters detail creation of the input sample, which consists of inputs derived from measurements in the operational data. The inputs provide facts and particulars about the selected cases. Inputs can be numeric, ordinal, nominal, geographic, or textual information.",DM,276,"['subsequent', 'chapter', 'detail', 'creation', 'input', 'sample', 'consists', 'input', 'derived', 'measurement', 'operational', 'data', 'input', 'provide', 'fact', 'particular', 'selected', 'case', 'input', 'numeric', 'ordinal', 'nominal', 'geographic', 'textual', 'information']"
1013,The data must be rearranged to a single row per account for use in predictive modeling. The TRANSPOSE performs such a transformation. *** Transpose Transaction data set; proc transpose data=work.tn_case_inputs out=work.tn_inputs(drop=_NAME_); by CHECKING_ID; var VALUE; id VARNAME; run; The BY statement specifies transposing by checking account ID. The ID statement commands the TRANSPOSE procedure to use the contents of the VARNAME column for column names in the output data set. Browse the TN_INPUTS data set to see the results of the TRANSPOSE procedure.,DM,559,"['data', 'must', 'rearranged', 'single', 'row', 'per', 'account', 'use', 'predictive', 'modeling', 'transpose', 'performs', 'transformation', '', 'transpose', 'transaction', 'data_set', 'proc', 'transpose', 'dataworktncaseinputs', 'outworktninputsdropname', 'checkingid', 'var', 'value', 'id', 'varname', 'run', 'statement', 'specifies', 'transposing', 'checking', 'account', 'id', 'id', 'statement', 'command', 'transpose', 'procedure', 'use', 'content', 'varname', 'column', 'column', 'name', 'output', 'data_set', 'browse', 'tninputs', 'data_set', 'see', 'result', 'transpose', 'procedure']"
1014,"The read task is modified to include reading of the target date data set, which contains the target date and checking account open date. These dates will be incorporated into the transaction processing to establish case-specific relative time scales.",DM,250,"['read', 'task', 'modified', 'include', 'reading', 'target', 'date', 'data_set', 'contains', 'target', 'date', 'checking', 'account', 'open', 'date', 'date', 'incorporated', 'transaction', 'processing', 'establish', 'casespecific', 'relative', 'time', 'scale']"
1015,"Without a suitable operational data warehouse, predictive model becomes at best inefficient and at worst impossible. Necessary data might be relegated to paper records in isolated legacy systems. Even in organizations with good data infrastructures, politics can turn data warehouses into data fortresses or data crypts, inaccessible to all but the select and privileged. Before you can even hope to start building predictive models, such impediments must be removed. As such, this course assumes the raw data to be reasonably well organized in a data warehouse.",DM,562,"['without', 'suitable', 'operational', 'data', 'warehouse', 'predictive', 'model', 'becomes', 'best', 'inefficient', 'worst', 'impossible', 'necessary', 'data', 'might', 'relegated', 'paper', 'record', 'isolated', 'legacy', 'system', 'even', 'organization', 'good', 'data', 'infrastructure', 'politics', 'turn', 'data', 'warehouse', 'data', 'fortress', 'data', 'crypt', 'inaccessible', 'select', 'privileged', 'even', 'hope', 'start', 'building', 'predictive', 'model', 'impediment', 'must', 'removed', 'course', 'assumes', 'raw', 'data', 'reasonably', 'well', 'organized', 'data', 'warehouse']"
1016,"The select and sort step is the easiest to implement, but it typically involves the greatest expenditure of computer resources and time. The simpler first task in this step involves identifying checking accounts belonging to clients in the target sample. To simplify the analysis, qualifications can be placed on the selected accounts to ensure recent account activity or account primacy in the case of multiple checking accounts for a given client. These qualifications, although realistic, will not be invoked here. The second and more onerous task involves selecting every transaction for a client in the specified time range. This often results in the creation of a data set with millions of records. For subsequent processing, the data set must be sorted by checking account ID and checking transaction date, as well as transferred to the analysis server.",DM,860,"['select', 'sort', 'step', 'easiest', 'implement', 'typically', 'involves', 'greatest', 'expenditure', 'computer', 'resource', 'time', 'simpler', 'first', 'task', 'step', 'involves', 'identifying', 'checking', 'account', 'belonging', 'client', 'target', 'sample', 'simplify', 'analysis', 'qualification', 'placed', 'selected', 'account', 'ensure', 'recent', 'account', 'activity', 'account', 'primacy', 'case', 'multiple', 'checking', 'account', 'given', 'client', 'qualification', 'although', 'realistic', 'invoked', 'second', 'onerous', 'task', 'involves', 'selecting', 'every', 'transaction', 'client', 'specified', 'time', 'range', 'often', 'result', 'creation', 'data_set', 'million', 'record', 'subsequent', 'processing', 'data_set', 'must', 'sorted', 'checking', 'account', 'id', 'checking', 'transaction', 'date', 'well', 'transferred', 'analysis', 'server']"
1017,"The institution currently uses 18 branch codes, B1 to B18. Some of the branch codes are sparsely populated. Using threshold-based recoding, these branches will be isolated in a separate branch, coded B0. The first part of the recoding program loads in macros to be used throughout the chapter. The macros automate, to some degree, the tasks described in the demonstrations. The automation process often introduces interesting technical complications orthogonal to the main data preparation concept. Details of these macros are provided in optional demonstrations to follow. *** Include categorical macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""categorical_macros.source"");",DM,699,"['institution', 'currently', 'us', '18', 'branch', 'code', 'b1', 'b18', 'branch', 'code', 'sparsely', 'populated', 'using', 'thresholdbased', 'recoding', 'branch', 'isolated', 'separate', 'branch', 'coded', 'b0', 'first', 'part', 'recoding', 'program', 'load', 'macro', 'used', 'throughout', 'chapter', 'macro', 'automate', 'degree', 'task', 'described', 'demonstration', 'automation', 'process', 'often', 'introduces', 'interesting', 'technical', 'complication', 'orthogonal', 'main', 'data', 'preparation', 'concept', 'detail', 'macro', 'provided', 'optional', 'demonstration', 'follow', '', 'include', 'categorical', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacscategoricalmacrossource']"
1018,"Now the punch line: for large Ni (relative to a and b), the expected value of pi is about what you would obtain using traditional weight of evidence methods. For small values of Ni, the expected value of pi is about equal to the overall target average. Thus, the average target estimates based on sparse level counts are smoothed out and the corresponding bias problems are virtually eliminated.",DM,395,"['punch', 'line', 'large', 'ni', 'relative', 'b', 'expected', 'value', 'pi', 'would', 'obtain', 'using', 'traditional', 'weight', 'evidence', 'method', 'small', 'value', 'ni', 'expected', 'value', 'pi', 'equal', 'overall', 'target', 'average', 'thus', 'average', 'target', 'estimate', 'based', 'sparse', 'level', 'count', 'smoothed', 'corresponding', 'bias', 'problem', 'virtually', 'eliminated']"
1019,"Counter to urban legend, classical regression analysis makes no assumptions about the distribution of inputs. The only assumption is that the expected value of the target (or some function thereof) is a linear combination of input measurements. So why worry about the extreme input distributions? There are at least two compelling reasons. First, in most real-world applications, the relationship between expected target value and input value does not increase without bound. Instead, it typically tapers off to some horizontal asymptote. Standard regression models are unable to accommodate such a relationship. Second, the further a point is from the overall mean of a distribution, the more influence, or leverage, the point has on model fit. Models built on inputs with extreme distributions attempt to optimize fit for the most extreme points at the cost of fit for the bulk of the data, usually near the input mean. The first concern can be addressed by abandoning standard regression models for more flexible modeling methods. This is often done at the cost of model interpretability and, more importantly, failure to address the second concern, leverage.",DM,1162,"['counter', 'urban', 'legend', 'classical', 'regression', 'analysis', 'make', 'assumption', 'distribution', 'input', 'assumption', 'expected', 'value', 'target', 'function', 'thereof', 'linear', 'combination', 'input', 'measurement', 'worry', 'extreme', 'input', 'distribution', 'least', 'two', 'compelling', 'reason', 'first', 'realworld', 'application', 'relationship', 'expected', 'target', 'value', 'input', 'value', 'doe', 'increase', 'without', 'bound', 'instead', 'typically', 'taper', 'horizontal', 'asymptote', 'standard', 'regression_model', 'unable', 'accommodate', 'relationship', 'second', 'point', 'overall', 'mean', 'distribution', 'influence', 'leverage', 'point', 'ha', 'model', 'fit', 'model', 'built', 'input', 'extreme', 'distribution', 'attempt', 'optimize', 'fit', 'extreme', 'point', 'cost', 'fit', 'bulk', 'data', 'usually', 'near', 'input', 'mean', 'first', 'concern', 'addressed', 'abandoning', 'standard', 'regression_model', 'flexible', 'modeling', 'method', 'often', 'done', 'cost', 'model', 'interpretability', 'importantly', 'failure', 'address', 'second', 'concern', 'leverage']"
1020,"The macro code for the %MAX function is similar to that for the count and sum functions. The function scans the transaction array. For each iteration of the DO loop, the output variable is taken to be the maximum of the previously observed maximum value and the current array value.",DM,282,"['macro', 'code', 'max', 'function', 'similar', 'count', 'sum', 'function', 'function', 'scan', 'transaction', 'array', 'iteration', 'loop', 'output', 'variable', 'taken', 'maximum', 'previously', 'observed', 'maximum', 'value', 'current', 'array', 'value']"
1021,"Knowing what an input should look like helps to detect data errors. Typically, the opportunistic data sets used in predictive models are electronically generated, so ?key-punch? errors are much less common than programming errors. Of course, the number of ways that a program can go wrong is incalculable; however, problems can often be detected by scrutinizing the results and asking if the results make sense. An exhaustive list of what can go wrong is impossible to write, but there are some common signs of coding errors. *	The input range should be checked against expectations. Unexpected negative (or positive) numbers are a sign of trouble. *	A large number of missing values can indicate problems with input transformations. *	Examining the smallest and largest observations can help detect coding errors. *	The overall distribution shape should make sense. *	The cardinality of non-numeric inputs should be verified. *	Frequency counts within categorical levels should be reviewed.",DM,991,"['knowing', 'input', 'look', 'like', 'help', 'detect', 'data', 'error', 'typically', 'opportunistic', 'data_set', 'used', 'predictive', 'model', 'electronically', 'generated', 'keypunch', 'error', 'much', 'le', 'common', 'programming', 'error', 'course', 'number', 'way', 'program', 'go', 'wrong', 'incalculable', 'however', 'problem', 'often', 'detected', 'scrutinizing', 'result', 'asking', 'result', 'make', 'sense', 'exhaustive', 'list', 'go', 'wrong', 'impossible', 'write', 'common', 'sign', 'coding', 'error', '\tthe', 'input', 'range', 'checked', 'expectation', 'unexpected', 'negative', 'positive', 'number', 'sign', 'trouble', '\ta', 'large', 'number', 'missing', 'value', 'indicate', 'problem', 'input', 'transformation', '\texamining', 'smallest', 'largest', 'observation', 'help', 'detect', 'coding', 'error', '\tthe', 'overall', 'distribution', 'shape', 'make', 'sense', '\tthe', 'cardinality', 'nonnumeric', 'input', 'verified', '\tfrequency', 'count', 'within', 'categorical', 'level', 'reviewed']"
1022,"This chapter focuses on creation of the target sample, which consists of the ID, target, and target date for cases satisfying the population qualifications of the analytic objective.",DM,182,"['chapter', 'focus', 'creation', 'target', 'sample', 'consists', 'id', 'target', 'target', 'date', 'case', 'satisfying', 'population', 'qualification', 'analytic', 'objective']"
1023,"Creating the rank formats from the RANK procedure is a somewhat subtle and cumbersome process. The five-step process starts by creating a grouped-ranks data set for all specified variables, transposing this data set to a form usable by the MEANS procedure, calculating the minimum and mean values within each rank group for each variable, generating the CNTLIN data set for the FORMAT procedure, and finally applying the FORMAT procedure to the generated CNTLIN data set. The four parameters for the %RANK_TRANS macro are as discussed above. %macro rank_trans(data=,vars=,bins=100,fname=);",DM,589,"['creating', 'rank', 'format', 'rank', 'procedure', 'somewhat', 'subtle', 'cumbersome', 'process', 'fivestep', 'process', 'start', 'creating', 'groupedranks', 'data_set', 'specified', 'variable', 'transposing', 'data_set', 'form', 'usable', 'mean', 'procedure', 'calculating', 'minimum', 'mean', 'value', 'within', 'rank', 'group', 'variable', 'generating', 'cntlin', 'data_set', 'format', 'procedure', 'finally', 'applying', 'format', 'procedure', 'generated', 'cntlin', 'data_set', 'four', 'parameter', 'ranktrans', 'macro', 'discussed', 'macro', 'ranktransdatavarsbins100fname']"
1024,The application of the geocoding formats appears somewhat more complicated. The complication arises from the embedded Boolean logic in the assignment statement. data lat_lon_inputs; set dmdp.input_sample_branch;,DM,211,"['application', 'geocoding', 'format', 'appears', 'somewhat', 'complicated', 'complication', 'arises', 'embedded', 'boolean', 'logic', 'assignment', 'statement', 'data', 'latloninputs', 'set', 'dmdpinputsamplebranch']"
1025,"Transaction data is probably the richest source of information for predictive models. It can capture complex individual behavior in a highly detailed fashion. Because the patterns captured in transaction data often mirror the target event, the data yields inputs with strong target correlation potential.",DM,304,"['transaction', 'data', 'probably', 'richest', 'source', 'information', 'predictive', 'model', 'capture', 'complex', 'individual', 'behavior', 'highly', 'detailed', 'fashion', 'pattern', 'captured', 'transaction', 'data', 'often', 'mirror', 'target', 'event', 'data', 'yield', 'input', 'strong', 'target', 'correlation', 'potential']"
1026,"The select and sort step is the easiest to implement, but it typically involves the greatest expenditure of computer resources and time. The simpler first task in this step involves identifying checking accounts belonging to clients in the target sample. To simplify the analysis, qualifications can be placed on the selected accounts to ensure recent account activity or account primacy in the case of multiple checking accounts for a given client. These qualifications, although realistic, will not be invoked here. The second and more onerous task involves selecting every transaction for a client in the specified time range. This often results in the creation of a data set with millions of records. For subsequent processing, the data set must be sorted by checking account ID and checking transaction date, as well as transferred to the analysis server.",DM,860,"['select', 'sort', 'step', 'easiest', 'implement', 'typically', 'involves', 'greatest', 'expenditure', 'computer', 'resource', 'time', 'simpler', 'first', 'task', 'step', 'involves', 'identifying', 'checking', 'account', 'belonging', 'client', 'target', 'sample', 'simplify', 'analysis', 'qualification', 'placed', 'selected', 'account', 'ensure', 'recent', 'account', 'activity', 'account', 'primacy', 'case', 'multiple', 'checking', 'account', 'given', 'client', 'qualification', 'although', 'realistic', 'invoked', 'second', 'onerous', 'task', 'involves', 'selecting', 'every', 'transaction', 'client', 'specified', 'time', 'range', 'often', 'result', 'creation', 'data_set', 'million', 'record', 'subsequent', 'processing', 'data_set', 'must', 'sorted', 'checking', 'account', 'id', 'checking', 'transaction', 'date', 'well', 'transferred', 'analysis', 'server']"
1027,"Thus far, the target date has been ignored in the input preparation process. Doing so contaminates any created inputs. In this iteration of the analysis, the target dates are read from the data warehouse. Only events that fall in the relevancy period are allowed in the transaction arrays.",DM,289,"['thus', 'far', 'target', 'date', 'ha', 'ignored', 'input', 'preparation', 'process', 'contaminates', 'created', 'input', 'iteration', 'analysis', 'target', 'date', 'read', 'data', 'warehouse', 'event', 'fall', 'relevancy', 'period', 'allowed', 'transaction', 'array']"
1028,"After a case?s period of interest is defined, there are a multitude of input possibilities. Perhaps the simplest are tabulations such as counts and sums derived from period of interest events.",DM,192,"['case', 'period', 'interest', 'defined', 'multitude', 'input', 'possibility', 'perhaps', 'simplest', 'tabulation', 'count', 'sum', 'derived', 'period', 'interest', 'event']"
1029,"The complete list of transaction macro functions can be partitioned into three groups: tabulation functions, distribution (or moment) functions, and order functions.",DM,165,"['complete', 'list', 'transaction', 'macro', 'function', 'partitioned', 'three', 'group', 'tabulation', 'function', 'distribution', 'moment', 'function', 'order', 'function']"
1030,"Type, channel, and method codes can be used to group transactions for stratified analyses. Additions to the augmentation and process steps allow the creation of stratified input variables. These inputs can be used to create an account interaction profile for each client.",DM,271,"['type', 'channel', 'method', 'code', 'used', 'group', 'transaction', 'stratified', 'analysis', 'addition', 'augmentation', 'process', 'step', 'allow', 'creation', 'stratified', 'input', 'variable', 'input', 'used', 'create', 'account', 'interaction', 'profile', 'client']"
1031,"Open the program Transaction Input Creation 5.sas in the program editor. The Declare code adds type, channel, and method transaction arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,235,"['open', 'program', 'transaction', 'input', 'creation', '5sas', 'program', 'editor', 'declare', 'code', 'add', 'type', 'channel', 'method', 'transaction', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1032,"Without a suitable operational data warehouse, predictive model becomes at best inefficient and at worst impossible. Necessary data might be relegated to paper records in isolated legacy systems. Even in organizations with good data infrastructures, politics can turn data warehouses into data fortresses or data crypts, inaccessible to all but the select and privileged. Before you can even hope to start building predictive models, such impediments must be removed. As such, this course assumes the raw data to be reasonably well organized in a data warehouse.",DM,562,"['without', 'suitable', 'operational', 'data', 'warehouse', 'predictive', 'model', 'becomes', 'best', 'inefficient', 'worst', 'impossible', 'necessary', 'data', 'might', 'relegated', 'paper', 'record', 'isolated', 'legacy', 'system', 'even', 'organization', 'good', 'data', 'infrastructure', 'politics', 'turn', 'data', 'warehouse', 'data', 'fortress', 'data', 'crypt', 'inaccessible', 'select', 'privileged', 'even', 'hope', 'start', 'building', 'predictive', 'model', 'impediment', 'must', 'removed', 'course', 'assumes', 'raw', 'data', 'reasonably', 'well', 'organized', 'data', 'warehouse']"
1033,"Open the file Managing Data Pathologies 1.sas in the program editor. This general-purpose program creates a convenient statistical report on any SAS data set and places the report in a PDF file for review and printing. The report includes a CONTENTS procedure summary of the data set columns, statistical summaries and a distribution plot for every numeric variable, a cardinality report for every character variable, and a frequency table for every character variable with cardinality below a specified threshold. The program begins by loading a utility macro file specialized to the needs of this chapter. *** Include pathology macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""pathology_macros.source""); A discussion of the macros used in the report follows in an optional section. Next, the name of the data set to analyze and the location of the analysis report are specified. *** Define data set of interest and report destination; %let data=dmdp.ins_modeling_sample; %let report_name='C:\temp\output.pdf'; The data set DMDP.INS_MODELING_SAMPLE is a merging of all analysis variables created to this point. It also contains input from other data sources related to the INS prediction problem, but not specifically analyzed in the previous chapters. In particular, limited transaction-based inputs from accounts other than checking are attached. In all, the data set contains 89 columns and 2,328 rows. Also, note that none of the census demographic fields from the end of chapter 4 have been appended.",DM,1530,"['open', 'file', 'managing', 'data', 'pathology', '1sas', 'program', 'editor', 'generalpurpose', 'program', 'creates', 'convenient', 'statistical', 'report', 'sa', 'data_set', 'place', 'report', 'pdf', 'file', 'review', 'printing', 'report', 'includes', 'content', 'procedure', 'summary', 'data_set', 'column', 'statistical', 'summary', 'distribution', 'plot', 'every', 'numeric', 'variable', 'cardinality', 'report', 'every', 'character', 'variable', 'frequency', 'table', 'every', 'character', 'variable', 'cardinality', 'specified', 'threshold', 'program', 'begin', 'loading', 'utility', 'macro', 'file', 'specialized', 'need', 'chapter', '', 'include', 'pathology', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacspathologymacrossource', 'discussion', 'macro', 'used', 'report', 'follows', 'optional', 'section', 'next', 'name', 'data_set', 'analyze', 'location', 'analysis', 'report', 'specified', '', 'define', 'data_set', 'interest', 'report', 'destination', 'let', 'datadmdpinsmodelingsample', 'let', 'reportnamectempoutputpdf', 'data_set', 'dmdpinsmodelingsample', 'merging', 'analysis', 'variable', 'created', 'point', 'also', 'contains', 'input', 'data', 'source', 'related', 'prediction', 'problem', 'specifically', 'analyzed', 'previous', 'chapter', 'particular', 'limited', 'transactionbased', 'input', 'account', 'checking', 'attached', 'data_set', 'contains', '89', 'column', '2328', 'row', 'also', 'note', 'none', 'census', 'demographic', 'field', 'end', 'chapter', '4', 'appended']"
1034,"Stratifications can also be used with table statistics, such as counts and sums, to yield profiles. Profiles are extremely useful for identifying patterns of activity in data.",DM,175,"['stratification', 'also', 'used', 'table', 'statistic', 'count', 'sum', 'yield', 'profile', 'profile', 'extremely', 'useful', 'identifying', 'pattern', 'activity', 'data']"
1035,"There are several possible transformations you can use to tame extreme distributions. The first is simply truncating the input distribution at some value. This is easy to implement for a given input, but it is difficult to automate because the optimal truncation point usually depends on the distribution. Also, it does not completely solve the problem of leverage because there may be still be considerable mass at the truncation point. Another approach is using a regularization transformation such as the log function. This works well as long as the input is strictly positive. If not, then log(x+a) could be used, as long as an a exists such that x + a > 0 for all x. A more clever transformation is the hyperbolic tangent function, tanh(x). This function controls extreme values such as the log function and admits negative values. Of course, the downside of these transformations is the loss of interpretability of the model coefficients, even for standard regression. A third approach is the use of rank transformation to transform even the most extreme distribution to a uniform one. This eliminates the leverage problem, asymptotes the target response, and maintains a degree of interpretability as most people understand rankings (especially in the form of percentiles). Taming Extreme Distributions",DM,1309,"['several', 'possible', 'transformation', 'use', 'tame', 'extreme', 'distribution', 'first', 'simply', 'truncating', 'input', 'distribution', 'value', 'easy', 'implement', 'given', 'input', 'difficult', 'automate', 'optimal', 'truncation', 'point', 'usually', 'depends', 'distribution', 'also', 'doe', 'completely', 'solve', 'problem', 'leverage', 'may', 'still', 'considerable', 'mass', 'truncation', 'point', 'another', 'approach', 'using', 'regularization', 'transformation', 'log', 'function', 'work', 'well', 'long', 'input', 'strictly', 'positive', 'logxa', 'could', 'used', 'long', 'exists', 'x', '', '', '0', 'x', 'clever', 'transformation', 'hyperbolic', 'tangent', 'function', 'tanhx', 'function', 'control', 'extreme', 'value', 'log', 'function', 'admits', 'negative', 'value', 'course', 'downside', 'transformation', 'loss', 'interpretability', 'model', 'coefficient', 'even', 'standard', 'regression', 'third', 'approach', 'use', 'rank', 'transformation', 'transform', 'even', 'extreme', 'distribution', 'uniform', 'one', 'eliminates', 'leverage', 'problem', 'asymptote', 'target', 'response', 'maintains', 'degree', 'interpretability', 'people', 'understand', 'ranking', 'especially', 'form', 'percentile', 'taming', 'extreme', 'distribution']"
1036,"The actual %N macro appears relatively straightforward. Some complexity is hidden in the %TN_MACRO_SETUP code, used to initialize this and other transaction macro functions. Introduction to Transaction Macros",DM,208,"['actual', 'n', 'macro', 'appears', 'relatively', 'straightforward', 'complexity', 'hidden', 'tnmacrosetup', 'code', 'used', 'initialize', 'transaction', 'macro', 'function', 'introduction', 'transaction', 'macro']"
1037,Reconciliation of transaction overflows begins with detection. The SQL code lists cases with transaction count in excess of the specified maximum and list observed number of rows. A large number of overflows can be corrected by increasing the max_records_per_case macro variable at the start of the transaction processing code.,DM,327,"['reconciliation', 'transaction', 'overflow', 'begin', 'detection', 'sql', 'code', 'list', 'case', 'transaction', 'count', 'excess', 'specified', 'maximum', 'list', 'observed', 'number', 'row', 'large', 'number', 'overflow', 'corrected', 'increasing', 'maxrecordspercase', 'macro', 'variable', 'start', 'transaction', 'processing', 'code']"
1038,Open the file Extract Relevant Data 1.sas in the SAS program editor. This creates a simple random target sample from the raw operational data stored in the DMDP library. Browse the DMDP.INS_ACCOUNT data set.,DM,207,"['open', 'file', 'extract', 'relevant', 'data', '1sas', 'sa', 'program', 'editor', 'creates', 'simple', 'random', 'target', 'sample', 'raw', 'operational', 'data', 'stored', 'dmdp', 'library', 'browse', 'dmdpinsaccount', 'data_set']"
1039,The data set containing the stratum counts is specified with the N= option. The STRATA statement specifies the name of the stratification variable. Implementing Stratified Separate Sampling,DM,189,"['data_set', 'containing', 'stratum', 'count', 'specified', 'n', 'option', 'stratum', 'statement', 'specifies', 'name', 'stratification', 'variable', 'implementing', 'stratified', 'separate', 'sampling']"
1040,Most predictive modeling tools require a case to be complete (no missing values in any selected input) for inclusion in the model fitting process and for generation of predicted values in model deployment. Even a relatively small proportion of missing values within individual inputs can result in the loss of a substantial fraction of the training data when many inputs are combined in model fitting.,DM,401,"['predictive', 'modeling', 'tool', 'require', 'case', 'complete', 'missing', 'value', 'selected', 'input', 'inclusion', 'model', 'fitting', 'process', 'generation', 'predicted', 'value', 'model', 'deployment', 'even', 'relatively', 'small', 'proportion', 'missing', 'value', 'within', 'individual', 'input', 'result', 'loss', 'substantial', 'fraction', 'training', 'data', 'many', 'input', 'combined', 'model', 'fitting']"
1041,"Processing transaction events can be made easier by encoding commonly used transformations as SAS macros. In this iteration of the process code, the operation of counting the number of transactions is performed by a macro function. This simplifies the Export part of the transaction process.",DM,291,"['processing', 'transaction', 'event', 'made', 'easier', 'encoding', 'commonly', 'used', 'transformation', 'sa', 'macro', 'iteration', 'process', 'code', 'operation', 'counting', 'number', 'transaction', 'performed', 'macro', 'function', 'simplifies', 'export', 'part', 'transaction', 'process']"
1042,"?	Because non-INS clients do not have an INS account, there is no account open date column. This lack of target date for nonresponse cases is a common source of data contamination and must be dealt with carefully. A method for establishing a target date for nonresponse cases is discussed in the last section of this chapter. The final task is to join the INS and non-INS qualified client tables. create table joined_sample as 	select *, 1 as INS from ins_clients_qualified 	outer union corresponding select *, 0 as INS from non_ins_clients_qualified; The outer union corresponding function joins the two tables and consolidates identical columns. This can be seen if you browse the JOINED_SAMPLE data set. Note the addition of a column INS to the joined sample. This column will ultimately serve as the predictive modeling target.",DM,831,"['\tbecause', 'nonins', 'client', 'account', 'account', 'open', 'date', 'column', 'lack', 'target', 'date', 'nonresponse', 'case', 'common', 'source', 'data', 'contamination', 'must', 'dealt', 'carefully', 'method', 'establishing', 'target', 'date', 'nonresponse', 'case', 'discussed', 'last', 'section', 'chapter', 'final', 'task', 'join', 'nonins', 'qualified', 'client', 'table', 'create', 'table', 'joinedsample', '\tselect', '', '1', 'insclientsqualified', '\touter', 'union', 'corresponding', 'select', '', '0', 'noninsclientsqualified', 'outer', 'union', 'corresponding', 'function', 'join', 'two', 'table', 'consolidates', 'identical', 'column', 'seen', 'browse', 'joinedsample', 'data_set', 'note', 'addition', 'column', 'joined', 'sample', 'column', 'ultimately', 'serve', 'predictive', 'modeling', 'target']"
1043,A stratified sample is drawn from the non-INS clients. PROC SURVEYSELECT procedure requires the raw data to be sorted by stratification variable. proc sort data=non_ins_clients_qualified; by STRATUM CLIENT_ID; run;,DM,214,"['stratified', 'sample', 'drawn', 'nonins', 'client', 'proc', 'surveyselect', 'procedure', 'requires', 'raw', 'data', 'sorted', 'stratification', 'variable', 'proc', 'sort', 'datanoninsclientsqualified', 'stratum', 'clientid', 'run']"
1044,"The location of the point mass in synthetic distribution methods is not arbitrary. Ideally, to allow variable selection processes to operate correctly, the synthesized value should be chosen to have minimal impact on the magnitude of an input?s association with the target. For many modeling methods, this can be achieved by locating the point mass at the input?s mean value. Cases with input values equal to the mean value have no influence on the estimation of that input?s model parameters. Because predicted response can be different for cases with a missing input value, a binary imputation indicator variable should also be added to the input sample to allow the model to adjust its predictions.",DM,701,"['location', 'point', 'mass', 'synthetic', 'distribution', 'method', 'arbitrary', 'ideally', 'allow', 'variable', 'selection', 'process', 'operate', 'correctly', 'synthesized', 'value', 'chosen', 'minimal', 'impact', 'magnitude', 'input', 'association', 'target', 'many', 'modeling', 'method', 'achieved', 'locating', 'point', 'mass', 'input', 'mean', 'value', 'case', 'input', 'value', 'equal', 'mean', 'value', 'influence', 'estimation', 'input', 'model', 'parameter', 'predicted', 'response', 'different', 'case', 'missing', 'input', 'value', 'binary', 'imputation', 'indicator', 'variable', 'also', 'added', 'input', 'sample', 'allow', 'model', 'adjust', 'prediction']"
1045,"Target sample creation for a model with a binary target involves four distinct tasks: *	accessing available data from the operational data repository *	selecting qualified responders, usually the minority target class *	selecting qualified nonresponders, usually the majority target class *	joining the responders and nonresponders to create a model sample, possibly stratified. The first three tasks can involve tens of millions of records from the operational repository and run most efficiently on the relational data base management system (RDBMS) server. The last task involves fewer records and will primarily occur within the SAS environment. 2.2	Simple Random Target Samples",DM,682,"['target', 'sample', 'creation', 'model', 'binary', 'target', 'involves', 'four', 'distinct', 'task', '\taccessing', 'available', 'data', 'operational', 'data', 'repository', '\tselecting', 'qualified', 'responder', 'usually', 'minority', 'target', 'class', '\tselecting', 'qualified', 'nonresponders', 'usually', 'majority', 'target', 'class', '\tjoining', 'responder', 'nonresponders', 'create', 'model', 'sample', 'possibly', 'stratified', 'first', 'three', 'task', 'involve', 'ten', 'million', 'record', 'operational', 'repository', 'run', 'efficiently', 'relational', 'data', 'base', 'management', 'system', 'rdbms', 'server', 'last', 'task', 'involves', 'fewer', 'record', 'primarily', 'occur', 'within', 'sa', 'environment', '22\tsimple', 'random', 'target', 'sample']"
1046,The values of branch will be replaced by 1 of 19 distinct smoothed weights of evidence. The demonstration ends with definition and application of the smoothed weight of evidence format. proc format cntlin=f; run;,DM,212,"['value', 'branch', 'replaced', '1', '19', 'distinct', 'smoothed', 'weight', 'evidence', 'demonstration', 'end', 'definition', 'application', 'smoothed', 'weight', 'evidence', 'format', 'proc', 'format', 'cntlinf', 'run']"
1047,Merging with the target sample allows the creation of a checking account indicator input. The indicator is 1 when checking transaction events are present for a case and zero otherwise. Finalizing the Transaction Input Data Set,DM,226,"['merging', 'target', 'sample', 'allows', 'creation', 'checking', 'account', 'indicator', 'input', 'indicator', '1', 'checking', 'transaction', 'event', 'present', 'case', 'zero', 'otherwise', 'finalizing', 'transaction', 'input', 'data_set']"
1048,Counting the number of transactions in a time period is handled by the macro function %N. This function counts the number of nonmissing values in the vector following the word of. The INTO= keyword parameter specifies the name of the variable for the result. The WHERE= keyword parameter can be used to condition the scope of the macro function.,DM,345,"['counting', 'number', 'transaction', 'time', 'period', 'handled', 'macro', 'function', 'n', 'function', 'count', 'number', 'nonmissing', 'value', 'vector', 'following', 'word', 'keyword', 'parameter', 'specifies', 'name', 'variable', 'result', 'keyword', 'parameter', 'used', 'condition', 'scope', 'macro', 'function']"
1049,"Simply knowing latitude and longitude of a case will probably not yield more predictive models. But when position is known, other quantities can also be calculated. One extremely useful quantity is proximity. The next two demonstrations show an effective technique for converting latitude and longitude measures to distance. The distance is calculated using the haversine function, an obscure but highly accurate throwback to the times of trigonometric tables. Combined with the zip code conversion macros, you will have a DATA step function that determines the approximate distance of any two locations (to five- digit zip code resolution). Calculating Distances",DM,663,"['simply', 'knowing', 'latitude', 'longitude', 'case', 'probably', 'yield', 'predictive', 'model', 'position', 'known', 'quantity', 'also', 'calculated', 'one', 'extremely', 'useful', 'quantity', 'proximity', 'next', 'two', 'demonstration', 'show', 'effective', 'technique', 'converting', 'latitude', 'longitude', 'measure', 'distance', 'distance', 'calculated', 'using', 'haversine', 'function', 'obscure', 'highly', 'accurate', 'throwback', 'time', 'trigonometric', 'table', 'combined', 'zip', 'code', 'conversion', 'macro', 'data', 'step', 'function', 'determines', 'approximate', 'distance', 'two', 'location', 'five', 'digit', 'zip', 'code', 'resolution', 'calculating', 'distance']"
1050,"The simulation study shows that, in general, simple dummy coding and simple weight of evidence strategies should be avoided. Better results can be obtained by threshold dummy coding or smoothed weight of evidence approaches.",DM,224,"['simulation', 'study', 'show', 'general', 'simple', 'dummy', 'coding', 'simple', 'weight', 'evidence', 'strategy', 'avoided', 'better', 'result', 'obtained', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'approach']"
1051,"The data set contains facts describing the insurance account. To minimize disk space, the facts are limited to account ID and account open date. In practice, the data set would contain other fields, such as rates, maturity dates, and initial deposit amount. Browse the DMDP.CLIENT_INS_ACCOUNT data set.",DM,302,"['data_set', 'contains', 'fact', 'describing', 'insurance', 'account', 'minimize', 'disk', 'space', 'fact', 'limited', 'account', 'id', 'account', 'open', 'date', 'practice', 'data_set', 'would', 'contain', 'field', 'rate', 'maturity', 'date', 'initial', 'deposit', 'amount', 'browse', 'dmdpclientinsaccount', 'data_set']"
1052,"To calculate the number of non-INS clients in each stratum, the number of INS clients within each stratum is determined and multiplied by the desired N0:N1 ratio. The SURVEYSELECT procedure requires this count to be named _NSIZE_.",DM,230,"['calculate', 'number', 'nonins', 'client', 'stratum', 'number', 'client', 'within', 'stratum', 'determined', 'multiplied', 'desired', 'n0n1', 'ratio', 'surveyselect', 'procedure', 'requires', 'count', 'named', 'nsize']"
1053,"Three types of expertise are required to achieve this (or any) analytic objective. The domain expert thoroughly understands the business aspects of the problem and is usually the ?owner? of the objective. He or she knows the approaches that have been attempted in the past to achieve the objective and their level of success. The data expert specializes in the raw materials of any predictive modeling endeavor. He or she knows where and how historical information is kept and can provide insight into the definitions of the data elements. The analytical methods expert knows the tools of predictive modeling. Ideally, the analytical methods expert prepares the analysis data or, at a minimum, closely supervises the data expert in the task. Each expert checks and influences the others. The analytic and data experts guide the domain expert as to the feasibility of analysis goals. The domain and analytic experts provide meaning and structural requirements to the data expert during data extraction. The domain and data experts offer reality checks on the analytic expert?s results and model implementation plans.",DM,1115,"['three', 'type', 'expertise', 'required', 'achieve', 'analytic', 'objective', 'domain', 'expert', 'thoroughly', 'understands', 'business', 'aspect', 'problem', 'usually', 'owner', 'objective', 'know', 'approach', 'attempted', 'past', 'achieve', 'objective', 'level', 'success', 'data', 'expert', 'specializes', 'raw', 'material', 'predictive', 'modeling', 'endeavor', 'know', 'historical', 'information', 'kept', 'provide', 'insight', 'definition', 'data', 'element', 'analytical', 'method', 'expert', 'know', 'tool', 'predictive', 'modeling', 'ideally', 'analytical', 'method', 'expert', 'prepares', 'analysis', 'data', 'minimum', 'closely', 'supervises', 'data', 'expert', 'task', 'expert', 'check', 'influence', 'others', 'analytic', 'data', 'expert', 'guide', 'domain', 'expert', 'feasibility', 'analysis', 'goal', 'domain', 'analytic', 'expert', 'provide', 'meaning', 'structural', 'requirement', 'data', 'expert', 'data', 'extraction', 'domain', 'data', 'expert', 'offer', 'reality', 'check', 'analytic', 'expert', 'result', 'model', 'implementation', 'plan']"
1054,Merging with the target sample allows the creation of a checking account indicator input. The indicator is 1 when checking transaction events are present for a case and zero otherwise. Finalizing the Transaction Input Data Set,DM,226,"['merging', 'target', 'sample', 'allows', 'creation', 'checking', 'account', 'indicator', 'input', 'indicator', '1', 'checking', 'transaction', 'event', 'present', 'case', 'zero', 'otherwise', 'finalizing', 'transaction', 'input', 'data_set']"
1055,"Counting the number of events in each group code is the first stratified analysis. The %N macro function performs the calculation. Notice that the INTO= keyword is set equal to the code array and that a new keyword parameter, GROUP=, is introduced. The presence of the group keyword instructs the macro function to stratify by the grouping variable (the group variable must be a positive integer). The results are placed in the CODE array whose dimension must match the number of distinct group indices. After applying the counting function, the results must be exported. The DO loop creates an input named TN_CNT_xxx, where xxx is the group code. Any transactions with group code EXD are excluded from the count.",DM,713,"['counting', 'number', 'event', 'group', 'code', 'first', 'stratified', 'analysis', 'n', 'macro', 'function', 'performs', 'calculation', 'notice', 'keyword', 'set', 'equal', 'code', 'array', 'new', 'keyword', 'parameter', 'group', 'introduced', 'presence', 'group', 'keyword', 'instructs', 'macro', 'function', 'stratify', 'grouping', 'variable', 'group', 'variable', 'must', 'positive', 'integer', 'result', 'placed', 'code', 'array', 'whose', 'dimension', 'must', 'match', 'number', 'distinct', 'group', 'index', 'applying', 'counting', 'function', 'result', 'must', 'exported', 'loop', 'creates', 'input', 'named', 'tncntxxx', 'xxx', 'group', 'code', 'transaction', 'group', 'code', 'exd', 'excluded', 'count']"
1056,"A simulation study helps to illustrate the consequences of separate sampling. The details of the simulation are presented above. The results presented are standard logistic regression models with two inputs. The models were correctly specified, so it was possible to achieve an MSB extremely close to zero. The simulation was also run for other input counts and for improperly specified models with similar results.",DM,415,"['simulation', 'study', 'help', 'illustrate', 'consequence', 'separate', 'sampling', 'detail', 'simulation', 'presented', 'result', 'presented', 'standard', 'logistic_regression_model', 'two', 'input', 'model', 'correctly', 'specified', 'wa', 'possible', 'achieve', 'msb', 'extremely', 'close', 'zero', 'simulation', 'wa', 'also', 'run', 'input', 'count', 'improperly', 'specified', 'model', 'similar', 'result']"
1057,"To aid discussion of transaction data, several terms and concepts are now introduced. The analytic objective usually restricts transaction data to a particular time range. Records in this time range are called events.",DM,217,"['aid', 'discussion', 'transaction', 'data', 'several', 'term', 'concept', 'introduced', 'analytic', 'objective', 'usually', 'restricts', 'transaction', 'data', 'particular', 'time', 'range', 'record', 'time', 'range', 'called', 'event']"
1058,"To calculate the number of non-INS clients in each stratum, the number of INS clients within each stratum is determined and multiplied by the desired N0:N1 ratio. The SURVEYSELECT procedure requires this count to be named _NSIZE_.",DM,230,"['calculate', 'number', 'nonins', 'client', 'stratum', 'number', 'client', 'within', 'stratum', 'determined', 'multiplied', 'desired', 'n0n1', 'ratio', 'surveyselect', 'procedure', 'requires', 'count', 'named', 'nsize']"
1059,Adding debits and subtracting credits to END_BAL for events in the latency period and beyond is used to undo the checking account activities and establish the ending balance at relative time 0.,DM,193,"['adding', 'debit', 'subtracting', 'credit', 'endbal', 'event', 'latency', 'period', 'beyond', 'used', 'undo', 'checking', 'account', 'activity', 'establish', 'ending', 'balance', 'relative', 'time', '0']"
1060,Counting the number of transactions in a time period is handled by the macro function %N. This function counts the number of nonmissing values in the vector following the word of. The INTO= keyword parameter specifies the name of the variable for the result. The WHERE= keyword parameter can be used to condition the scope of the macro function.,DM,345,"['counting', 'number', 'transaction', 'time', 'period', 'handled', 'macro', 'function', 'n', 'function', 'count', 'number', 'nonmissing', 'value', 'vector', 'following', 'word', 'keyword', 'parameter', 'specifies', 'name', 'variable', 'result', 'keyword', 'parameter', 'used', 'condition', 'scope', 'macro', 'function']"
1061,"To implement stratified separate sampling, you must add stratification variables to the INS and non-INS client data sets. This involves rerunning the initial queries into the operational data warehouse. Continuous stratification variables must be binned to an appropriate degree (analysis dependent). The desired sample size within each bin must be calculated.",DM,360,"['implement', 'stratified', 'separate', 'sampling', 'must', 'add', 'stratification', 'variable', 'nonins', 'client', 'data_set', 'involves', 'rerunning', 'initial', 'query', 'operational', 'data', 'warehouse', 'continuous', 'stratification', 'variable', 'must', 'binned', 'appropriate', 'degree', 'analysis', 'dependent', 'desired', 'sample_size', 'within', 'bin', 'must', 'calculated']"
1062,"Missing value replacement strategies fall into one of two categories. Estimation methods attempt to provide a reasonable guess as to what the missing value should have been were it not missing. This approach is compatible with missing values resulting from a lack of knowledge (for example, no match or non-disclosure), and not with missing values resulting from the lack of applicability of the inputs. Estimation methods usually closely connected with model building and are outside the scope of this course. Synthetic distribution methods simply modify the distribution in an input to include a point mass at a specific value for cases whose input value is otherwise not known.",DM,680,"['missing', 'value', 'replacement', 'strategy', 'fall', 'one', 'two', 'category', 'estimation', 'method', 'attempt', 'provide', 'reasonable', 'guess', 'missing', 'value', 'missing', 'approach', 'compatible', 'missing', 'value', 'resulting', 'lack', 'knowledge', 'example', 'match', 'nondisclosure', 'missing', 'value', 'resulting', 'lack', 'applicability', 'input', 'estimation', 'method', 'usually', 'closely', 'connected', 'model', 'building', 'outside', 'scope', 'course', 'synthetic', 'distribution', 'method', 'simply', 'modify', 'distribution', 'input', 'include', 'point', 'mass', 'specific', 'value', 'case', 'whose', 'input', 'value', 'otherwise', 'known']"
1063,"As introduced in Chapter 2, the date corresponding to the measurement of the target variable defines the target date. The target date subsets the time range into interest and latency periods. Model inputs are built from events in the interest period. To avoid input contamination, events in the latency period are excluded.",DM,323,"['introduced', 'chapter', '2', 'date', 'corresponding', 'measurement', 'target', 'variable', 'defines', 'target', 'date', 'target', 'date', 'subset', 'time', 'range', 'interest', 'latency', 'period', 'model', 'input', 'built', 'event', 'interest', 'period', 'avoid', 'input', 'contamination', 'event', 'latency', 'period', 'excluded']"
1064,Another skewness reduction transformation involves using the RANK procedure to substitute percentiles or other rank-based values for the original input. proc rank data=transformed out=transformed groups=100; var CC_BAL_AVG; ranks R_CC_BAL_AVG; run;,DM,248,"['another', 'skewness', 'reduction', 'transformation', 'involves', 'using', 'rank', 'procedure', 'substitute', 'percentile', 'rankbased', 'value', 'original', 'input', 'proc', 'rank', 'datatransformed', 'outtransformed', 'groups100', 'var', 'ccbalavg', 'rank', 'rccbalavg', 'run']"
1065,"Open the file Managing Data Pathologies 2.sas in the program editor. This program demonstrates the three techniques for regularizing extreme distributions. As seen in a distribution plot, the variable CC_BAL_AVG is moderately skewed. There are several ways to compensate for this skewness. %distribution(vars=CC_BAL_AVG,data=dmdp.ins_modeling_sample );",DM,352,"['open', 'file', 'managing', 'data', 'pathology', '2sas', 'program', 'editor', 'program', 'demonstrates', 'three', 'technique', 'regularizing', 'extreme', 'distribution', 'seen', 'distribution', 'plot', 'variable', 'ccbalavg', 'moderately', 'skewed', 'several', 'way', 'compensate', 'skewness', 'distributionvarsccbalavgdatadmdpinsmodelingsample', '']"
1066,"Lastly, the non-numeric frequency distributions show the levels and case counts for all non-numeric variables with the number of levels less than the specified maximum. By default, the levels of the non-numeric variables are ordered by frequency, from highest to lowest frequency count. ?	The order of the levels can be changed to alphabetical by specifying the keyword option FREQ_LEVELS=N in the %DISTRIBUTION macro invocation.",DM,429,"['lastly', 'nonnumeric', 'frequency', 'distribution', 'show', 'level', 'case', 'count', 'nonnumeric', 'variable', 'number', 'level', 'le', 'specified', 'maximum', 'default', 'level', 'nonnumeric', 'variable', 'ordered', 'frequency', 'highest', 'lowest', 'frequency', 'count', '\tthe', 'order', 'level', 'changed', 'alphabetical', 'specifying', 'keyword', 'option', 'freqlevelsn', 'distribution', 'macro', 'invocation']"
1067,"The additional transaction arrays combined with the transaction macros allow the creation of stratified inputs. For example, CR_SUM measures the total deposits per month.",DM,170,"['additional', 'transaction', 'array', 'combined', 'transaction', 'macro', 'allow', 'creation', 'stratified', 'input', 'example', 'crsum', 'measure', 'total', 'deposit', 'per', 'month']"
1068,"Open the file Managing Data Pathologies 1.sas in the program editor. This general-purpose program creates a convenient statistical report on any SAS data set and places the report in a PDF file for review and printing. The report includes a CONTENTS procedure summary of the data set columns, statistical summaries and a distribution plot for every numeric variable, a cardinality report for every character variable, and a frequency table for every character variable with cardinality below a specified threshold. The program begins by loading a utility macro file specialized to the needs of this chapter. *** Include pathology macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""pathology_macros.source""); A discussion of the macros used in the report follows in an optional section. Next, the name of the data set to analyze and the location of the analysis report are specified. *** Define data set of interest and report destination; %let data=dmdp.ins_modeling_sample; %let report_name='C:\temp\output.pdf'; The data set DMDP.INS_MODELING_SAMPLE is a merging of all analysis variables created to this point. It also contains input from other data sources related to the INS prediction problem, but not specifically analyzed in the previous chapters. In particular, limited transaction-based inputs from accounts other than checking are attached. In all, the data set contains 89 columns and 2,328 rows. Also, note that none of the census demographic fields from the end of chapter 4 have been appended.",DM,1530,"['open', 'file', 'managing', 'data', 'pathology', '1sas', 'program', 'editor', 'generalpurpose', 'program', 'creates', 'convenient', 'statistical', 'report', 'sa', 'data_set', 'place', 'report', 'pdf', 'file', 'review', 'printing', 'report', 'includes', 'content', 'procedure', 'summary', 'data_set', 'column', 'statistical', 'summary', 'distribution', 'plot', 'every', 'numeric', 'variable', 'cardinality', 'report', 'every', 'character', 'variable', 'frequency', 'table', 'every', 'character', 'variable', 'cardinality', 'specified', 'threshold', 'program', 'begin', 'loading', 'utility', 'macro', 'file', 'specialized', 'need', 'chapter', '', 'include', 'pathology', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacspathologymacrossource', 'discussion', 'macro', 'used', 'report', 'follows', 'optional', 'section', 'next', 'name', 'data_set', 'analyze', 'location', 'analysis', 'report', 'specified', '', 'define', 'data_set', 'interest', 'report', 'destination', 'let', 'datadmdpinsmodelingsample', 'let', 'reportnamectempoutputpdf', 'data_set', 'dmdpinsmodelingsample', 'merging', 'analysis', 'variable', 'created', 'point', 'also', 'contains', 'input', 'data', 'source', 'related', 'prediction', 'problem', 'specifically', 'analyzed', 'previous', 'chapter', 'particular', 'limited', 'transactionbased', 'input', 'account', 'checking', 'attached', 'data_set', 'contains', '89', 'column', '2328', 'row', 'also', 'note', 'none', 'census', 'demographic', 'field', 'end', 'chapter', '4', 'appended']"
1069,Event times in the interest period are recalibrated to a scale measuring time from the start of the latency period. Events with small relative times occur closest to the target date.,DM,182,"['event', 'time', 'interest', 'period', 'recalibrated', 'scale', 'measuring', 'time', 'start', 'latency', 'period', 'event', 'small', 'relative', 'time', 'occur', 'closest', 'target', 'date']"
1070,"As introduced in Chapter 2, the date corresponding to the measurement of the target variable defines the target date. The target date subsets the time range into interest and latency periods. Model inputs are built from events in the interest period. To avoid input contamination, events in the latency period are excluded.",DM,323,"['introduced', 'chapter', '2', 'date', 'corresponding', 'measurement', 'target', 'variable', 'defines', 'target', 'date', 'target', 'date', 'subset', 'time', 'range', 'interest', 'latency', 'period', 'model', 'input', 'built', 'event', 'interest', 'period', 'avoid', 'input', 'contamination', 'event', 'latency', 'period', 'excluded']"
1071,"The DATA step underlying the event processing can be conceptually divided into five tasks labeled Declare, Read, Initialize, Vector, and Export (mnemonic: DRIVE).",DM,162,"['data', 'step', 'underlying', 'event', 'processing', 'conceptually', 'divided', 'five', 'task', 'labeled', 'declare', 'read', 'initialize', 'vector', 'export', 'mnemonic', 'drive']"
1072,A specific data preparation challenge is the target date possibly establishing a unique relative time scale for every case in the data set. This makes SQL processing of the data virtually impossible and necessitates the use of the SAS DATA step. Processing with the DATA step implies that the data must reside on the analysis server and not the warehouse server. Site-specific strategies must be adopted to make this transfer possible.,DM,435,"['specific', 'data', 'preparation', 'challenge', 'target', 'date', 'possibly', 'establishing', 'unique', 'relative', 'time', 'scale', 'every', 'case', 'data_set', 'make', 'sql', 'processing', 'data', 'virtually', 'impossible', 'necessitates', 'use', 'sa', 'data', 'step', 'processing', 'data', 'step', 'implies', 'data', 'must', 'reside', 'analysis', 'server', 'warehouse', 'server', 'sitespecific', 'strategy', 'must', 'adopted', 'make', 'transfer', 'possible']"
1073,The data must be rearranged to a single row per account for use in predictive modeling. The TRANSPOSE performs such a transformation. *** Transpose Transaction data set; proc transpose data=work.tn_case_inputs out=work.tn_inputs(drop=_NAME_); by CHECKING_ID; var VALUE; id VARNAME; run; The BY statement specifies transposing by checking account ID. The ID statement commands the TRANSPOSE procedure to use the contents of the VARNAME column for column names in the output data set. Browse the TN_INPUTS data set to see the results of the TRANSPOSE procedure.,DM,559,"['data', 'must', 'rearranged', 'single', 'row', 'per', 'account', 'use', 'predictive', 'modeling', 'transpose', 'performs', 'transformation', '', 'transpose', 'transaction', 'data_set', 'proc', 'transpose', 'dataworktncaseinputs', 'outworktninputsdropname', 'checkingid', 'var', 'value', 'id', 'varname', 'run', 'statement', 'specifies', 'transposing', 'checking', 'account', 'id', 'id', 'statement', 'command', 'transpose', 'procedure', 'use', 'content', 'varname', 'column', 'column', 'name', 'output', 'data_set', 'browse', 'tninputs', 'data_set', 'see', 'result', 'transpose', 'procedure']"
1074,"The technique employed for reducing the size of the target sample is called separate sampling, although it is known by various other names including case- control sampling, choice-based sampling, biased sampling, y-conditional sampling, outcome-dependent sampling, and oversampling. When the number of nonresponders to responders, the N0:N1 ratio, is large, the usual practice is to take every responder available and an integer multiple of nonresponders for each responder. In the example above, for every INS client, two non-INS clients are selected. This creates a separately sampled target sample with a N0:N1 ratio of 2:1.",DM,627,"['technique', 'employed', 'reducing', 'size', 'target', 'sample', 'called', 'separate', 'sampling', 'although', 'known', 'various', 'name', 'including', 'case', 'control', 'sampling', 'choicebased', 'sampling', 'biased', 'sampling', 'yconditional', 'sampling', 'outcomedependent', 'sampling', 'oversampling', 'number', 'nonresponders', 'responder', 'n0n1', 'ratio', 'large', 'usual', 'practice', 'take', 'every', 'responder', 'available', 'integer', 'multiple', 'nonresponders', 'responder', 'example', 'every', 'client', 'two', 'nonins', 'client', 'selected', 'creates', 'separately', 'sampled', 'target', 'sample', 'n0n1', 'ratio', '21']"
1075,"For predictive models, an analysis data set must contain a collection of independent cases with fields corresponding to the inputs, the target, and, usually, a cases identifier. These fields are usually created from data collected in the operations of an organization. In an ideal situation, the operations data is well organized in a data warehouse that is easy to access. While establishing such a warehouse can be an expensive undertaking, doing so avoids a lengthy data acquisition process, ultimately saving time and money for the organization.",DM,549,"['predictive', 'model', 'analysis', 'data_set', 'must', 'contain', 'collection', 'independent', 'case', 'field', 'corresponding', 'input', 'target', 'usually', 'case', 'identifier', 'field', 'usually', 'created', 'data', 'collected', 'operation', 'organization', 'ideal', 'situation', 'operation', 'data', 'well', 'organized', 'data', 'warehouse', 'easy', 'access', 'establishing', 'warehouse', 'expensive', 'undertaking', 'avoids', 'lengthy', 'data', 'acquisition', 'process', 'ultimately', 'saving', 'time', 'money', 'organization']"
1076,This demonstration continues the application of the Transaction Input Creation 1.sas program. The finalization step is examined here. The goal is to create a transactions input sample for use in predictive modeling. The transaction case input data set contains three rows per checking account.,DM,293,"['demonstration', 'continues', 'application', 'transaction', 'input', 'creation', '1sas', 'program', 'finalization', 'step', 'examined', 'goal', 'create', 'transaction', 'input', 'sample', 'use', 'predictive', 'modeling', 'transaction', 'case', 'input', 'data_set', 'contains', 'three', 'row', 'per', 'checking', 'account']"
1077,"Introduction of the transaction macros enables the transaction processing to begin in earnest. Additional transaction arrays are declared, corresponding to type, channel, and method fields in the transaction data.",DM,213,"['introduction', 'transaction', 'macro', 'enables', 'transaction', 'processing', 'begin', 'earnest', 'additional', 'transaction', 'array', 'declared', 'corresponding', 'type', 'channel', 'method', 'field', 'transaction', 'data']"
1078,"The standard deviation macro function is somewhat more complex than the count or sum functions. Three pieces of information are required to calculate the standard deviation: the number of observations, the sum of the observations, and the sum of the squares of the observations. The first loop in the macro code calculates these quantities and places the results in so-called scratch arrays (see the next slide). If the number of observations is greater than or equal to 2, then the standard deviation is calculated using the usual formula. Discussion of the group macro variable is deferred to the next section.",DM,612,"['standard', 'deviation', 'macro', 'function', 'somewhat', 'complex', 'count', 'sum', 'function', 'three', 'piece', 'information', 'required', 'calculate', 'standard', 'deviation', 'number', 'observation', 'sum', 'observation', 'sum', 'square', 'observation', 'first', 'loop', 'macro', 'code', 'calculates', 'quantity', 'place', 'result', 'socalled', 'scratch', 'array', 'see', 'next', 'slide', 'number', 'observation', 'greater', 'equal', '2', 'standard', 'deviation', 'calculated', 'using', 'usual', 'formula', 'discussion', 'group', 'macro', 'variable', 'deferred', 'next', 'section']"
1079,A specific data preparation challenge is the target date possibly establishing a unique relative time scale for every case in the data set. This makes SQL processing of the data virtually impossible and necessitates the use of the SAS DATA step. Processing with the DATA step implies that the data must reside on the analysis server and not the warehouse server. Site-specific strategies must be adopted to make this transfer possible.,DM,435,"['specific', 'data', 'preparation', 'challenge', 'target', 'date', 'possibly', 'establishing', 'unique', 'relative', 'time', 'scale', 'every', 'case', 'data_set', 'make', 'sql', 'processing', 'data', 'virtually', 'impossible', 'necessitates', 'use', 'sa', 'data', 'step', 'processing', 'data', 'step', 'implies', 'data', 'must', 'reside', 'analysis', 'server', 'warehouse', 'server', 'sitespecific', 'strategy', 'must', 'adopted', 'make', 'transfer', 'possible']"
1080,"The complete list of transaction macro functions can be partitioned into three groups: tabulation functions, distribution (or moment) functions, and order functions.",DM,165,"['complete', 'list', 'transaction', 'macro', 'function', 'partitioned', 'three', 'group', 'tabulation', 'function', 'distribution', 'moment', 'function', 'order', 'function']"
1081,"The temporary transaction arrays are containers for the complete event history of a given case. The maximum records per case macro variable, defined at the start of the transaction transformation process, must be larger than the maximum number of events for each case.",DM,268,"['temporary', 'transaction', 'array', 'container', 'complete', 'event', 'history', 'given', 'case', 'maximum', 'record', 'per', 'case', 'macro', 'variable', 'defined', 'start', 'transaction', 'transformation', 'process', 'must', 'larger', 'maximum', 'number', 'event', 'case']"
1082,"The %DISTRIBUTION macro has two main components: one for numeric variables and one for non-numeric variables. The numeric component centers on the UNIVARITATE procedure, and the non-numeric component centers on the FREQ procedure. The macro has one required keyword parameter, DATA=, and six optional keyword parameters: VARS=, CATVARS=, OUT=, CONTENTS=, FREQ_LEVELS=, and MAX_LEVELS=. %macro distribution(vars=,catvars=,data=, out=LISTING, contents=NO, freq_levels=Y, max_levels=100); DATA=, the lone required parameter, specifies the name of the source data containing the variables of interest. VARS= specifies the variables to analyze from DATA=. Omitting a value for VARS= results in a distribution report for all variables. CATVARS= specifies the names of numeric variables that should be subject to non-numeric analysis. Omission of CATVARS= results in character variables being treated as non-numeric variables. OUT= specifies the destination of the analysis. The destination can be a quoted pdf file location or OUTPUT (the default value). Specifying OUTPUT as the destination results in result table being directed to the Output window and distribution plots being directed to the Graph window. FREQ_LEVELS= specifies the order of levels presented in non-numeric distribution tables. The default value, Y, causes the levels to be ordered by frequency counts (from highest to lowest). A value of N causes the levels to be ordered alphabetically. MAX_LEVELS= specifies the maximum cardinality for distribution summaries. Variables with cardinality higher than the specified value are omitted from the distribution analysis. Details The macro opens with a specification of landscape orientation. options orientation=landscape;",DM,1733,"['distribution', 'macro', 'ha', 'two', 'main', 'component', 'one', 'numeric', 'variable', 'one', 'nonnumeric', 'variable', 'numeric', 'component', 'center', 'univaritate', 'procedure', 'nonnumeric', 'component', 'center', 'freq', 'procedure', 'macro', 'ha', 'one', 'required', 'keyword', 'parameter', 'data', 'six', 'optional', 'keyword', 'parameter', 'var', 'catvars', 'content', 'freqlevels', 'maxlevels', 'macro', 'distributionvarscatvarsdata', 'outlisting', 'contentsno', 'freqlevelsy', 'maxlevels100', 'data', 'lone', 'required', 'parameter', 'specifies', 'name', 'source', 'data', 'containing', 'variable', 'interest', 'var', 'specifies', 'variable', 'analyze', 'data', 'omitting', 'value', 'var', 'result', 'distribution', 'report', 'variable', 'catvars', 'specifies', 'name', 'numeric', 'variable', 'subject', 'nonnumeric', 'analysis', 'omission', 'catvars', 'result', 'character', 'variable', 'treated', 'nonnumeric', 'variable', 'specifies', 'destination', 'analysis', 'destination', 'quoted', 'pdf', 'file', 'location', 'output', 'default', 'value', 'specifying', 'output', 'destination', 'result', 'result', 'table', 'directed', 'output', 'window', 'distribution', 'plot', 'directed', 'graph', 'window', 'freqlevels', 'specifies', 'order', 'level', 'presented', 'nonnumeric', 'distribution', 'table', 'default', 'value', 'cause', 'level', 'ordered', 'frequency', 'count', 'highest', 'lowest', 'value', 'n', 'cause', 'level', 'ordered', 'alphabetically', 'maxlevels', 'specifies', 'maximum', 'cardinality', 'distribution', 'summary', 'variable', 'cardinality', 'higher', 'specified', 'value', 'omitted', 'distribution', 'analysis', 'detail', 'macro', 'open', 'specification', 'landscape', 'orientation', 'option', 'orientationlandscape']"
1083,Much of the course discussion centers on the analytic objective stated above. Financial institutions usually possess highly detailed data that is challenging to transform into a structure suitable for predictive modeling. The approaches used to overcome the challenges are applicable to many domains.,DM,300,"['much', 'course', 'discussion', 'center', 'analytic', 'objective', 'stated', 'financial', 'institution', 'usually', 'posse', 'highly', 'detailed', 'data', 'challenging', 'transform', 'structure', 'suitable', 'predictive', 'modeling', 'approach', 'used', 'overcome', 'challenge', 'applicable', 'many', 'domain']"
1084,"The task of predictive modeling does not stand by itself. To build a successful predictive model you must first?unambiguously?define an analytic objective. The predictive model serves as a means of fulfilling the analytic objective. The predictive modeling effort is surrounded by two other tasks. Before modeling begins, data must be assembled, often from a variety of sources, and arranged in a format suitable for model building. After the modeling is complete, the resulting model (and the modeling results) must be integrated into the business environment that originally motivated the modeling. These tasks often require more effort than the modeling itself. This course focuses on the first of the three tasks: data preparation. Note that while the data preparation task comes before model building, this data preparation course is designed to be taken after a suitable predictive modeling course. With the background gained in a predictive modeling course, students gain insight into the reasons behind the data preparation activities.",DM,1043,"['task', 'predictive', 'modeling', 'doe', 'stand', 'build', 'successful', 'predictive', 'model', 'must', 'firstunambiguouslydefine', 'analytic', 'objective', 'predictive', 'model', 'serf', 'mean', 'fulfilling', 'analytic', 'objective', 'predictive', 'modeling', 'effort', 'surrounded', 'two', 'task', 'modeling', 'begin', 'data', 'must', 'assembled', 'often', 'variety', 'source', 'arranged', 'format', 'suitable', 'model', 'building', 'modeling', 'complete', 'resulting', 'model', 'modeling', 'result', 'must', 'integrated', 'business', 'environment', 'originally', 'motivated', 'modeling', 'task', 'often', 'require', 'effort', 'modeling', 'course', 'focus', 'first', 'three', 'task', 'data', 'preparation', 'note', 'data', 'preparation', 'task', 'come', 'model', 'building', 'data', 'preparation', 'course', 'designed', 'taken', 'suitable', 'predictive', 'modeling', 'course', 'background', 'gained', 'predictive', 'modeling', 'course', 'student', 'gain', 'insight', 'reason', 'behind', 'data', 'preparation', 'activity']"
1085,"This chapter focuses on creation of the target sample, which consists of the ID, target, and target date for cases satisfying the population qualifications of the analytic objective.",DM,182,"['chapter', 'focus', 'creation', 'target', 'sample', 'consists', 'id', 'target', 'target', 'date', 'case', 'satisfying', 'population', 'qualification', 'analytic', 'objective']"
1086,"In general, tabulation functions are the fastest, followed by distributional functions, and finally order statistics (exceptions are the %MIN and %MAX functions, which are in fact the fastest of all the transaction macros). Using Transaction Macros",DM,248,"['general', 'tabulation', 'function', 'fastest', 'followed', 'distributional', 'function', 'finally', 'order', 'statistic', 'exception', 'min', 'max', 'function', 'fact', 'fastest', 'transaction', 'macro', 'using', 'transaction', 'macro']"
1087,"In this iteration of the process step, only three inputs are generated per case. The first indicates the presence of a checking account. The second indicates a transaction overflow, in which the observed transaction count exceeds the maximum allowed per case. The third gives the observed transaction count. The transaction case input data must now be transposed to a single row per case and merged with the client ID data set.",DM,427,"['iteration', 'process', 'step', 'three', 'input', 'generated', 'per', 'case', 'first', 'indicates', 'presence', 'checking', 'account', 'second', 'indicates', 'transaction', 'overflow', 'observed', 'transaction', 'count', 'exceeds', 'maximum', 'allowed', 'per', 'case', 'third', 'give', 'observed', 'transaction', 'count', 'transaction', 'case', 'input', 'data', 'must', 'transposed', 'single', 'row', 'per', 'case', 'merged', 'client', 'id', 'data_set']"
1088,The DATASETS procedure deletes any previous version of the COUNTS data set. The COUNTS data set will contain the cardinality of each non-numeric variable. proc datasets library=work nodetails nolist; delete counts; run;,DM,219,"['datasets', 'procedure', 'deletes', 'previous', 'version', 'count', 'data_set', 'count', 'data_set', 'contain', 'cardinality', 'nonnumeric', 'variable', 'proc', 'datasets', 'librarywork', 'nodetails', 'nolist', 'delete', 'count', 'run']"
1089,This demonstration continues the application of the Transaction Input Creation 1.sas program. The finalization step is examined here. The goal is to create a transactions input sample for use in predictive modeling. The transaction case input data set contains three rows per checking account.,DM,293,"['demonstration', 'continues', 'application', 'transaction', 'input', 'creation', '1sas', 'program', 'finalization', 'step', 'examined', 'goal', 'create', 'transaction', 'input', 'sample', 'use', 'predictive', 'modeling', 'transaction', 'case', 'input', 'data_set', 'contains', 'three', 'row', 'per', 'checking', 'account']"
1090,"There are many challenges to be faced in the data preparation process. Six of the most important are listed above, in informal terms. Clarification follows on the next slide.",DM,174,"['many', 'challenge', 'faced', 'data', 'preparation', 'process', 'six', 'important', 'listed', 'informal', 'term', 'clarification', 'follows', 'next', 'slide']"
1091,"Open the program Transaction Input Creation 5.sas in the program editor. The Declare code adds type, channel, and method transaction arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,235,"['open', 'program', 'transaction', 'input', 'creation', '5sas', 'program', 'editor', 'declare', 'code', 'add', 'type', 'channel', 'method', 'transaction', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1092,"A simple but effective remedy for overgeneralization is thresholding?that is, requiring a minimum number of cases in a level before creating a dummy code input. Any level failing to meet this minimum threshold is relegated to a new level called OTHER. By reducing the number of inputs available to a model, thresholding limits the model?s ability to ?discover? spurious input-target associations.",DM,396,"['simple', 'effective', 'remedy', 'overgeneralization', 'thresholdingthat', 'requiring', 'minimum', 'number', 'case', 'level', 'creating', 'dummy', 'code', 'input', 'level', 'failing', 'meet', 'minimum', 'threshold', 'relegated', 'new', 'level', 'called', 'reducing', 'number', 'input', 'available', 'model', 'thresholding', 'limit', 'model', 'ability', 'discover', 'spurious', 'inputtarget', 'association']"
1093,"In this analysis, stratification will occur on the tenure of a client with the financial institution. Tenure is defined as the number of months elapsed since the customer origination date. Because tenure is a continuous quantity, it will be binned using a so-called dilated time format. Using tenure addresses concerns about the exogenous correlation of time factors (such as the economy) with account acquisition. The strategy matches clients that arrive at the financial institution at about the same time. Some acquire the INS account, and some do not. Any observed differences will not result from factors related when the client originates. The bin sizes in the dilated time format increase with increasing number of months since event. Events within the last year are binned by month. Events between one and two years ago are grouped by quarter. Events 2-3 years ago are grouped by half-year. Events 3-8 years ago are grouped by year. Events more than 8 years ago are consolidated into a single bin representing ?the distant past.?",DM,1037,"['analysis', 'stratification', 'occur', 'tenure', 'client', 'financial', 'institution', 'tenure', 'defined', 'number', 'month', 'elapsed', 'since', 'customer', 'origination', 'date', 'tenure', 'continuous', 'quantity', 'binned', 'using', 'socalled', 'dilated', 'time', 'format', 'using', 'tenure', 'address', 'concern', 'exogenous', 'correlation', 'time', 'factor', 'economy', 'account', 'acquisition', 'strategy', 'match', 'client', 'arrive', 'financial', 'institution', 'time', 'acquire', 'account', 'observed', 'difference', 'result', 'factor', 'related', 'client', 'originates', 'bin', 'size', 'dilated', 'time', 'format', 'increase', 'increasing', 'number', 'month', 'since', 'event', 'event', 'within', 'last', 'year', 'binned', 'month', 'event', 'one', 'two', 'year', 'ago', 'grouped', 'quarter', 'event', '23', 'year', 'ago', 'grouped', 'halfyear', 'event', '38', 'year', 'ago', 'grouped', 'year', 'event', '8', 'year', 'ago', 'consolidated', 'single', 'bin', 'representing', 'distant', 'past']"
1094,"To implement stratified separate sampling, you must add stratification variables to the INS and non-INS client data sets. This involves rerunning the initial queries into the operational data warehouse. Continuous stratification variables must be binned to an appropriate degree (analysis dependent). The desired sample size within each bin must be calculated.",DM,360,"['implement', 'stratified', 'separate', 'sampling', 'must', 'add', 'stratification', 'variable', 'nonins', 'client', 'data_set', 'involves', 'rerunning', 'initial', 'query', 'operational', 'data', 'warehouse', 'continuous', 'stratification', 'variable', 'must', 'binned', 'appropriate', 'degree', 'analysis', 'dependent', 'desired', 'sample_size', 'within', 'bin', 'must', 'calculated']"
1095,This demonstration continues the use of the Transaction Input Creation 1.sas program. Here the process by ID step is examined. The goal is to transform the raw transactions into a so-called case input data set. Each row of the case input data set is the value of an input for a case. The raw data for this process step is the transaction extract TN_EXTRACT created in the previous demonstration.,DM,395,"['demonstration', 'continues', 'use', 'transaction', 'input', 'creation', '1sas', 'program', 'process', 'id', 'step', 'examined', 'goal', 'transform', 'raw', 'transaction', 'socalled', 'case', 'input', 'data_set', 'row', 'case', 'input', 'data_set', 'value', 'input', 'case', 'raw', 'data', 'process', 'step', 'transaction', 'extract', 'tnextract', 'created', 'previous', 'demonstration']"
1096,"In practice, analysts typically use a slight variation of this recoding method. Instead of representing the levels with integers, they employ the actual target average (or a model-appropriate transformation) to represent the level. Because their encoding is nearly identical, levels with identical expected response are effectively merged. A common name for this approach is the weight of evidence recoding. Weight of evidence recoding works reasonably well when the number of cases in a level is large enough to get stable target average estimates. However, like dummy coding, when the number of levels is large (so that the number of cases in a level is small), weight of evidence recoding results in models with poor generalization.",DM,735,"['practice', 'analyst', 'typically', 'use', 'slight', 'variation', 'recoding', 'method', 'instead', 'representing', 'level', 'integer', 'employ', 'actual', 'target', 'average', 'modelappropriate', 'transformation', 'represent', 'level', 'encoding', 'nearly', 'identical', 'level', 'identical', 'expected', 'response', 'effectively', 'merged', 'common', 'name', 'approach', 'weight', 'evidence', 'recoding', 'weight', 'evidence', 'recoding', 'work', 'reasonably', 'well', 'number', 'case', 'level', 'large', 'enough', 'get', 'stable', 'target', 'average', 'estimate', 'however', 'like', 'dummy', 'coding', 'number', 'level', 'large', 'number', 'case', 'level', 'small', 'weight', 'evidence', 'recoding', 'result', 'model', 'poor', 'generalization']"
1097,"The macro code for the %MAX function is similar to that for the count and sum functions. The function scans the transaction array. For each iteration of the DO loop, the output variable is taken to be the maximum of the previously observed maximum value and the current array value.",DM,282,"['macro', 'code', 'max', 'function', 'similar', 'count', 'sum', 'function', 'function', 'scan', 'transaction', 'array', 'iteration', 'loop', 'output', 'variable', 'taken', 'maximum', 'previously', 'observed', 'maximum', 'value', 'current', 'array', 'value']"
1098,"The resulting distributions were obtained from over 100 simulations per strategy. Threshold dummy coding and the smoothed weight of evidence strategies performed comparably on the presented configuration. In further simulations, it was found that higher cardinality inputs favored the smoothed weight of evidence slightly. A more complete discussion of the results is found in a forthcoming paper by the author.",DM,411,"['resulting', 'distribution', 'obtained', '100', 'simulation', 'per', 'strategy', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'strategy', 'performed', 'comparably', 'presented', 'configuration', 'simulation', 'wa', 'found', 'higher', 'cardinality', 'input', 'favored', 'smoothed', 'weight', 'evidence', 'slightly', 'complete', 'discussion', 'result', 'found', 'forthcoming', 'paper', 'author']"
1099,The DATASETS procedure deletes any previous version of the COUNTS data set. The COUNTS data set will contain the cardinality of each non-numeric variable. proc datasets library=work nodetails nolist; delete counts; run;,DM,219,"['datasets', 'procedure', 'deletes', 'previous', 'version', 'count', 'data_set', 'count', 'data_set', 'contain', 'cardinality', 'nonnumeric', 'variable', 'proc', 'datasets', 'librarywork', 'nodetails', 'nolist', 'delete', 'count', 'run']"
1100,Most predictive modeling tools require a case to be complete (no missing values in any selected input) for inclusion in the model fitting process and for generation of predicted values in model deployment. Even a relatively small proportion of missing values within individual inputs can result in the loss of a substantial fraction of the training data when many inputs are combined in model fitting.,DM,401,"['predictive', 'modeling', 'tool', 'require', 'case', 'complete', 'missing', 'value', 'selected', 'input', 'inclusion', 'model', 'fitting', 'process', 'generation', 'predicted', 'value', 'model', 'deployment', 'even', 'relatively', 'small', 'proportion', 'missing', 'value', 'within', 'individual', 'input', 'result', 'loss', 'substantial', 'fraction', 'training', 'data', 'many', 'input', 'combined', 'model', 'fitting']"
1101,"The method you use to access the raw operational data depends on the data?s format and the tools at your disposal. Accessing data in a text or binary file independent of a RDBMS system is often performed by DATA step programming or, in the case of certain file formats, the IMPORT procedure. When the raw operational data is contained within a RDBMS system, you can use SAS/ACCESS products to read and operate on the data as if it were a SAS data set. SAS/ACCESS products also enable you to pass through RDBMS- specific queries that operate completely on the RDDMS server and might utilize functions not available in SAS.",DM,621,"['method', 'use', 'access', 'raw', 'operational', 'data', 'depends', 'data', 'format', 'tool', 'disposal', 'accessing', 'data', 'text', 'binary', 'file', 'independent', 'rdbms', 'system', 'often', 'performed', 'data', 'step', 'programming', 'case', 'certain', 'file', 'format', 'import', 'procedure', 'raw', 'operational', 'data', 'contained', 'within', 'rdbms', 'system', 'use', 'sasaccess', 'product', 'read', 'operate', 'data', 'sa', 'data_set', 'sasaccess', 'product', 'also', 'enable', 'pas', 'rdbms', 'specific', 'query', 'operate', 'completely', 'rddms', 'server', 'might', 'utilize', 'function', 'available', 'sa']"
1102,The events in the period of interest can be thought of as measurements of a random variable. All manner of statistics to describe the distribution of this random variable can be used as model inputs.,DM,199,"['event', 'period', 'interest', 'thought', 'measurement', 'random', 'variable', 'manner', 'statistic', 'describe', 'distribution', 'random', 'variable', 'used', 'model', 'input']"
1103,"The complete list of transaction macro functions can be partitioned into three groups: tabulation functions, distribution (or moment) functions, and order functions.",DM,165,"['complete', 'list', 'transaction', 'macro', 'function', 'partitioned', 'three', 'group', 'tabulation', 'function', 'distribution', 'moment', 'function', 'order', 'function']"
1104,"The select and sort step is the easiest to implement, but it typically involves the greatest expenditure of computer resources and time. The simpler first task in this step involves identifying checking accounts belonging to clients in the target sample. To simplify the analysis, qualifications can be placed on the selected accounts to ensure recent account activity or account primacy in the case of multiple checking accounts for a given client. These qualifications, although realistic, will not be invoked here. The second and more onerous task involves selecting every transaction for a client in the specified time range. This often results in the creation of a data set with millions of records. For subsequent processing, the data set must be sorted by checking account ID and checking transaction date, as well as transferred to the analysis server.",DM,860,"['select', 'sort', 'step', 'easiest', 'implement', 'typically', 'involves', 'greatest', 'expenditure', 'computer', 'resource', 'time', 'simpler', 'first', 'task', 'step', 'involves', 'identifying', 'checking', 'account', 'belonging', 'client', 'target', 'sample', 'simplify', 'analysis', 'qualification', 'placed', 'selected', 'account', 'ensure', 'recent', 'account', 'activity', 'account', 'primacy', 'case', 'multiple', 'checking', 'account', 'given', 'client', 'qualification', 'although', 'realistic', 'invoked', 'second', 'onerous', 'task', 'involves', 'selecting', 'every', 'transaction', 'client', 'specified', 'time', 'range', 'often', 'result', 'creation', 'data_set', 'million', 'record', 'subsequent', 'processing', 'data_set', 'must', 'sorted', 'checking', 'account', 'id', 'checking', 'transaction', 'date', 'well', 'transferred', 'analysis', 'server']"
1105,*	transposing the transaction case input data just created *	reconciling transaction overflows *	appending client IDs to the transaction based input sample *	merging the transaction input sample to the target sample.,DM,216,"['\ttransposing', 'transaction', 'case', 'input', 'data', 'created', '\treconciling', 'transaction', 'overflow', '\tappending', 'client', 'id', 'transaction', 'based', 'input', 'sample', '\tmerging', 'transaction', 'input', 'sample', 'target', 'sample']"
1106,"Open the file Transaction Input Creation 1.sas in the SAS program editor. This program performs the four steps of transaction transformation. This demonstration focuses on the selecting and sorting step. The program begins by including a set of macros used for input creation throughout the course. The macros are studied in some detail later in the chapter. *** Include transaction macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""transaction_macros.source"");",DM,484,"['open', 'file', 'transaction', 'input', 'creation', '1sas', 'sa', 'program', 'editor', 'program', 'performs', 'four', 'step', 'transaction', 'transformation', 'demonstration', 'focus', 'selecting', 'sorting', 'step', 'program', 'begin', 'including', 'set', 'macro', 'used', 'input', 'creation', 'throughout', 'course', 'macro', 'studied', 'detail', 'later', 'chapter', '', 'include', 'transaction', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacstransactionmacrossource']"
1107,"The key is knowing the location corresponding to the postal codes. There are many public tabulations of this data available. In fact, one tabulation is found in the SASHELP library. The tabulations, known as ZIP code centroid tables, match postal codes to latitude and longitude locations. Combining the centroid tables with the SAS formats makes it trivial to instantly translate a postal code to latitude and longitude values. Translating Zip Codes to Latitude/Longitude Values Open the file Using Non-Numeric Data 3.sas in the SAS program editor. This program creates formats for translating zip codes to latitude and longitude. Open the data set DMDP.ZIP_CENTROIDS.",DM,669,"['key', 'knowing', 'location', 'corresponding', 'postal', 'code', 'many', 'public', 'tabulation', 'data', 'available', 'fact', 'one', 'tabulation', 'found', 'sashelp', 'library', 'tabulation', 'known', 'zip', 'code', 'centroid', 'table', 'match', 'postal', 'code', 'latitude', 'longitude', 'location', 'combining', 'centroid', 'table', 'sa', 'format', 'make', 'trivial', 'instantly', 'translate', 'postal', 'code', 'latitude', 'longitude', 'value', 'translating', 'zip', 'code', 'latitudelongitude', 'value', 'open', 'file', 'using', 'nonnumeric', 'data', '3sas', 'sa', 'program', 'editor', 'program', 'creates', 'format', 'translating', 'zip', 'code', 'latitude', 'longitude', 'open', 'data_set', 'dmdpzipcentroids']"
1108,"Subsequent chapters detail creation of the input sample, which consists of inputs derived from measurements in the operational data. The inputs provide facts and particulars about the selected cases. Inputs can be numeric, ordinal, nominal, geographic, or textual information.",DM,276,"['subsequent', 'chapter', 'detail', 'creation', 'input', 'sample', 'consists', 'input', 'derived', 'measurement', 'operational', 'data', 'input', 'provide', 'fact', 'particular', 'selected', 'case', 'input', 'numeric', 'ordinal', 'nominal', 'geographic', 'textual', 'information']"
1109,Open the file Transaction Input Creation 2.sas in the SAS program editor. The code focuses on the process by ID step in the transaction input creation exercise. The only change in the program occurs in the execute step.,DM,219,"['open', 'file', 'transaction', 'input', 'creation', '2sas', 'sa', 'program', 'editor', 'code', 'focus', 'process', 'id', 'step', 'transaction', 'input', 'creation', 'exercise', 'change', 'program', 'occurs', 'execute', 'step']"
1110,"The augment step creates a data set containing the target date and the checking account open date. The target dates are obtained from the target sample, and the checking account open dates are obtained from the checking account table. The created table is ordered by checking ID for inclusion in subsequent transaction processing.",DM,330,"['augment', 'step', 'creates', 'data_set', 'containing', 'target', 'date', 'checking', 'account', 'open', 'date', 'target', 'date', 'obtained', 'target', 'sample', 'checking', 'account', 'open', 'date', 'obtained', 'checking', 'account', 'table', 'created', 'table', 'ordered', 'checking', 'id', 'inclusion', 'subsequent', 'transaction', 'processing']"
1111,"Most strategies for representing non-numeric data in predictive models involve some form of recoding or transformation of the non-numeric data to numeric data into numeric data. The approaches taken depend mostly on the degree of cardinality. Low cardinality inputs (fewer than 10 distinct levels) are acceptable to most modeling techniques and need no additional processing (although several low cardinality inputs actually look like a single high cardinality input to a statistical model). When the input cardinality is in the range of ten to several hundred, the techniques built in to many statistical models are not sufficient to avoid overgeneralization. Some form of external recoding is usually deployed. Recoding strategies are discussed in the next section. When the cardinality exceeds several hundred, approaches other than recoding are needed. Many of the approaches involve a transformation dependent on the intrinsic or extrinsic properties of the non-numeric input. For example the intrinsic meaning of a non-numeric field such as postal code (location) enables transformations to numeric inputs (latitude and longitude). Location can be used to create or access a variety of valuable modeling inputs. Section 4.3 discusses geocoding, the transformation of postal code to latitude and longitude. Non-numeric variables also possess extrinsic properties in that they often serve as links to other data sources. Section 4.4 describes how linking can be used to transform a single non-numeric input into hundreds of new, independent, and informative inputs. At the highest end of the cardinality scale are the variables with unbounded cardinality. Free-form text fields are one example. The emerging field of text mining focuses on these extreme cardinality inputs. The techniques are of sufficient complexity to justify a separate course.",DM,1851,"['strategy', 'representing', 'nonnumeric', 'data', 'predictive', 'model', 'involve', 'form', 'recoding', 'transformation', 'nonnumeric', 'data', 'numeric', 'data', 'numeric', 'data', 'approach', 'taken', 'depend', 'mostly', 'degree', 'cardinality', 'low', 'cardinality', 'input', 'fewer', '10', 'distinct', 'level', 'acceptable', 'modeling', 'technique', 'need', 'additional', 'processing', 'although', 'several', 'low', 'cardinality', 'input', 'actually', 'look', 'like', 'single', 'high', 'cardinality', 'input', 'statistical', 'model', 'input', 'cardinality', 'range', 'ten', 'several', 'hundred', 'technique', 'built', 'many', 'statistical', 'model', 'sufficient', 'avoid', 'overgeneralization', 'form', 'external', 'recoding', 'usually', 'deployed', 'recoding', 'strategy', 'discussed', 'next', 'section', 'cardinality', 'exceeds', 'several', 'hundred', 'approach', 'recoding', 'needed', 'many', 'approach', 'involve', 'transformation', 'dependent', 'intrinsic', 'extrinsic', 'property', 'nonnumeric', 'input', 'example', 'intrinsic', 'meaning', 'nonnumeric', 'field', 'postal', 'code', 'location', 'enables', 'transformation', 'numeric', 'input', 'latitude', 'longitude', 'location', 'used', 'create', 'access', 'variety', 'valuable', 'modeling', 'input', 'section', '43', 'discus', 'geocoding', 'transformation', 'postal', 'code', 'latitude', 'longitude', 'nonnumeric', 'variable', 'also', 'posse', 'extrinsic', 'property', 'often', 'serve', 'link', 'data', 'source', 'section', '44', 'describes', 'linking', 'used', 'transform', 'single', 'nonnumeric', 'input', 'hundred', 'new', 'independent', 'informative', 'input', 'highest', 'end', 'cardinality', 'scale', 'variable', 'unbounded', 'cardinality', 'freeform', 'text', 'field', 'one', 'example', 'emerging', 'field', 'text', 'mining', 'focus', 'extreme', 'cardinality', 'input', 'technique', 'sufficient', 'complexity', 'justify', 'separate', 'course']"
1112,"After a case?s period of interest is defined, there are a multitude of input possibilities. Perhaps the simplest are tabulations such as counts and sums derived from period of interest events.",DM,192,"['case', 'period', 'interest', 'defined', 'multitude', 'input', 'possibility', 'perhaps', 'simplest', 'tabulation', 'count', 'sum', 'derived', 'period', 'interest', 'event']"
1113,"Stratifications can also be used with table statistics, such as counts and sums, to yield profiles. Profiles are extremely useful for identifying patterns of activity in data.",DM,175,"['stratification', 'also', 'used', 'table', 'statistic', 'count', 'sum', 'yield', 'profile', 'profile', 'extremely', 'useful', 'identifying', 'pattern', 'activity', 'data']"
1114,"Open the program Transaction Input Creation 5.sas in the program editor. The Declare code adds type, channel, and method transaction arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,235,"['open', 'program', 'transaction', 'input', 'creation', '5sas', 'program', 'editor', 'declare', 'code', 'add', 'type', 'channel', 'method', 'transaction', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1115,"A new process variable, R_OPEN_DT, is declared and retained. R_OPEN_DT will give the checking account open date in relative time. A negative value indicates a checking account open date after the target date minus latency.",DM,222,"['new', 'process', 'variable', 'ropendt', 'declared', 'retained', 'ropendt', 'give', 'checking', 'account', 'open', 'date', 'relative', 'time', 'negative', 'value', 'indicates', 'checking', 'account', 'open', 'date', 'target', 'date', 'minus', 'latency']"
1116,"Open the file Using Non-Numeric Data 1.sas in the SAS program editor. This program demonstrates one way to implement threshold-based recoding. The financial institution groups its client by branch region based on the client?s home postal code. The data set DMDP.INPUT_SAMPLE_BRANCH describes each client?s branch region affiliation, five-digit postal code, and target value. ?	To avoid contamination, these values should correspond to measurements taken before the target date.",DM,477,"['open', 'file', 'using', 'nonnumeric', 'data', '1sas', 'sa', 'program', 'editor', 'program', 'demonstrates', 'one', 'way', 'implement', 'thresholdbased', 'recoding', 'financial', 'institution', 'group', 'client', 'branch', 'region', 'based', 'client', 'home', 'postal', 'code', 'data_set', 'dmdpinputsamplebranch', 'describes', 'client', 'branch', 'region', 'affiliation', 'fivedigit', 'postal', 'code', 'target', 'value', '\tto', 'avoid', 'contamination', 'value', 'correspond', 'measurement', 'taken', 'target', 'date']"
1117,"Weight of evidence recoding is sometimes combined with dummy coding approaches. In this hybrid approach, the weights of evidence are used to cluster variable levels. The number of levels after clustering is usually small enough to dummy code. There are close connections between this approach and decision tree models.",DM,318,"['weight', 'evidence', 'recoding', 'sometimes', 'combined', 'dummy', 'coding', 'approach', 'hybrid', 'approach', 'weight', 'evidence', 'used', 'cluster', 'variable', 'level', 'number', 'level', 'clustering', 'usually', 'small', 'enough', 'dummy', 'code', 'close', 'connection', 'approach', 'decision', 'tree', 'model']"
1118,"The data set contains facts describing the insurance account. To minimize disk space, the facts are limited to account ID and account open date. In practice, the data set would contain other fields, such as rates, maturity dates, and initial deposit amount. Browse the DMDP.CLIENT_INS_ACCOUNT data set.",DM,302,"['data_set', 'contains', 'fact', 'describing', 'insurance', 'account', 'minimize', 'disk', 'space', 'fact', 'limited', 'account', 'id', 'account', 'open', 'date', 'practice', 'data_set', 'would', 'contain', 'field', 'rate', 'maturity', 'date', 'initial', 'deposit', 'amount', 'browse', 'dmdpclientinsaccount', 'data_set']"
1119,The data set containing the stratum counts is specified with the N= option. The STRATA statement specifies the name of the stratification variable. Implementing Stratified Separate Sampling,DM,189,"['data_set', 'containing', 'stratum', 'count', 'specified', 'n', 'option', 'stratum', 'statement', 'specifies', 'name', 'stratification', 'variable', 'implementing', 'stratified', 'separate', 'sampling']"
1120,"With the events extracted and sorted, the transaction transformation moves on to actual processing of individual events by case ID. For clarity, the augmentation of data is deferred until later. The processing step creates a data set, TN_CASE_INPUT, with one row per input per case. As such, the data set must be transposed for use as an input sample. The transposition occurs in the finalize step. The case input structure allows for the addition of an arbitrarily large number of inputs, without the added step of including each input in a keep list. It also facilitates the creation of stratified input variables because stratification levels are easily incorporated into input names.",DM,687,"['event', 'extracted', 'sorted', 'transaction', 'transformation', 'move', 'actual', 'processing', 'individual', 'event', 'case', 'id', 'clarity', 'augmentation', 'data', 'deferred', 'later', 'processing', 'step', 'creates', 'data_set', 'tncaseinput', 'one', 'row', 'per', 'input', 'per', 'case', 'data_set', 'must', 'transposed', 'use', 'input', 'sample', 'transposition', 'occurs', 'finalize', 'step', 'case', 'input', 'structure', 'allows', 'addition', 'arbitrarily', 'large', 'number', 'input', 'without', 'added', 'step', 'including', 'input', 'keep', 'list', 'also', 'facilitates', 'creation', 'stratified', 'input', 'variable', 'stratification', 'level', 'easily', 'incorporated', 'input', 'name']"
1121,"The institution currently uses 18 branch codes, B1 to B18. Some of the branch codes are sparsely populated. Using threshold-based recoding, these branches will be isolated in a separate branch, coded B0. The first part of the recoding program loads in macros to be used throughout the chapter. The macros automate, to some degree, the tasks described in the demonstrations. The automation process often introduces interesting technical complications orthogonal to the main data preparation concept. Details of these macros are provided in optional demonstrations to follow. *** Include categorical macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""categorical_macros.source"");",DM,699,"['institution', 'currently', 'us', '18', 'branch', 'code', 'b1', 'b18', 'branch', 'code', 'sparsely', 'populated', 'using', 'thresholdbased', 'recoding', 'branch', 'isolated', 'separate', 'branch', 'coded', 'b0', 'first', 'part', 'recoding', 'program', 'load', 'macro', 'used', 'throughout', 'chapter', 'macro', 'automate', 'degree', 'task', 'described', 'demonstration', 'automation', 'process', 'often', 'introduces', 'interesting', 'technical', 'complication', 'orthogonal', 'main', 'data', 'preparation', 'concept', 'detail', 'macro', 'provided', 'optional', 'demonstration', 'follow', '', 'include', 'categorical', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacscategoricalmacrossource']"
1122,The values of branch will be replaced by 1 of 19 distinct smoothed weights of evidence. The demonstration ends with definition and application of the smoothed weight of evidence format. proc format cntlin=f; run;,DM,212,"['value', 'branch', 'replaced', '1', '19', 'distinct', 'smoothed', 'weight', 'evidence', 'demonstration', 'end', 'definition', 'application', 'smoothed', 'weight', 'evidence', 'format', 'proc', 'format', 'cntlinf', 'run']"
1123,"A different modification to the basic weight of evidence approach (inspired by Bayesian statistical methods) assumes a priori distributions for the target average within level. These so-called prior distributions reflect the analyst?s state of knowledge about the expect value of the target within level. Observations from the training data are then combined with the prior data to form updated estimates of the target average distribution. The expected value of this a posteriori distribution serves as the estimated target value within level. These so-called posterior estimates show substantial reduction prediction bias compared to the basic weight of evidence approach, especially in non-numeric inputs with tens to hundreds of levels.",DM,740,"['different', 'modification', 'basic', 'weight', 'evidence', 'approach', 'inspired', 'bayesian', 'statistical', 'method', 'assumes', 'priori', 'distribution', 'target', 'average', 'within', 'level', 'socalled', 'prior', 'distribution', 'reflect', 'analyst', 'state', 'knowledge', 'expect', 'value', 'target', 'within', 'level', 'observation', 'training', 'data', 'combined', 'prior', 'data', 'form', 'updated', 'estimate', 'target', 'average', 'distribution', 'expected', 'value', 'posteriori', 'distribution', 'serf', 'estimated', 'target', 'value', 'within', 'level', 'socalled', 'posterior', 'estimate', 'show', 'substantial', 'reduction', 'prediction', 'bias', 'compared', 'basic', 'weight', 'evidence', 'approach', 'especially', 'nonnumeric', 'input', 'ten', 'hundred', 'level']"
1124,"The augment step creates a data set containing the target date and the checking account open date. The target dates are obtained from the target sample, and the checking account open dates are obtained from the checking account table. The created table is ordered by checking ID for inclusion in subsequent transaction processing.",DM,330,"['augment', 'step', 'creates', 'data_set', 'containing', 'target', 'date', 'checking', 'account', 'open', 'date', 'target', 'date', 'obtained', 'target', 'sample', 'checking', 'account', 'open', 'date', 'obtained', 'checking', 'account', 'table', 'created', 'table', 'ordered', 'checking', 'id', 'inclusion', 'subsequent', 'transaction', 'processing']"
1125,Transactions data also promotes modeling challenges. The data is often sequestered on inaccessible servers with little opportunity for mass data transfer. The blessing of high detail is also a curse: the sheer volume of data makes it extremely time consuming to obtain and difficult to process.,DM,294,"['transaction', 'data', 'also', 'promotes', 'modeling', 'challenge', 'data', 'often', 'sequestered', 'inaccessible', 'server', 'little', 'opportunity', 'mass', 'data', 'transfer', 'blessing', 'high', 'detail', 'also', 'curse', 'sheer', 'volume', 'data', 'make', 'extremely', 'time', 'consuming', 'obtain', 'difficult', 'process']"
1126,"The actual %N macro appears relatively straightforward. Some complexity is hidden in the %TN_MACRO_SETUP code, used to initialize this and other transaction macro functions. Introduction to Transaction Macros",DM,208,"['actual', 'n', 'macro', 'appears', 'relatively', 'straightforward', 'complexity', 'hidden', 'tnmacrosetup', 'code', 'used', 'initialize', 'transaction', 'macro', 'function', 'introduction', 'transaction', 'macro']"
1127,"The standard deviation macro function is somewhat more complex than the count or sum functions. Three pieces of information are required to calculate the standard deviation: the number of observations, the sum of the observations, and the sum of the squares of the observations. The first loop in the macro code calculates these quantities and places the results in so-called scratch arrays (see the next slide). If the number of observations is greater than or equal to 2, then the standard deviation is calculated using the usual formula. Discussion of the group macro variable is deferred to the next section.",DM,612,"['standard', 'deviation', 'macro', 'function', 'somewhat', 'complex', 'count', 'sum', 'function', 'three', 'piece', 'information', 'required', 'calculate', 'standard', 'deviation', 'number', 'observation', 'sum', 'observation', 'sum', 'square', 'observation', 'first', 'loop', 'macro', 'code', 'calculates', 'quantity', 'place', 'result', 'socalled', 'scratch', 'array', 'see', 'next', 'slide', 'number', 'observation', 'greater', 'equal', '2', 'standard', 'deviation', 'calculated', 'using', 'usual', 'formula', 'discussion', 'group', 'macro', 'variable', 'deferred', 'next', 'section']"
1128,The names of all selected non-numeric variables with a cardinality less than MAX_LEVELS are placed in macro variable CHARVARS. proc sql noprint; select var into :charvars separated by ' ' from counts where levels<&max_levels; quit;,DM,231,"['name', 'selected', 'nonnumeric', 'variable', 'cardinality', 'le', 'maxlevels', 'placed', 'macro', 'variable', 'charvars', 'proc', 'sql', 'noprint', 'select', 'var', 'charvars', 'separated', '', '', 'count', 'levelsmaxlevels', 'quit']"
1129,"Ideally, you will have access to a private database closely tied to the RDBMS server that contains the operational data. This database will contain views to the operational data as well as large intermediate tables generated by the SAS/ACCESS Pass-Through facility. Subsets of these intermediate tables will be transferred to the SAS analysis server for processing by SAS. In this way, transfer of data through the network is limited to small amounts of data and occurs only when necessary.",DM,490,"['ideally', 'access', 'private', 'database', 'closely', 'tied', 'rdbms', 'server', 'contains', 'operational', 'data', 'database', 'contain', 'view', 'operational', 'data', 'well', 'large', 'intermediate', 'table', 'generated', 'sasaccess', 'passthrough', 'facility', 'subset', 'intermediate', 'table', 'transferred', 'sa', 'analysis', 'server', 'processing', 'sa', 'way', 'transfer', 'data', 'network', 'limited', 'small', 'amount', 'data', 'occurs', 'necessary']"
1130,"Processing transaction events can be made easier by encoding commonly used transformations as SAS macros. In this iteration of the process code, the operation of counting the number of transactions is performed by a macro function. This simplifies the Export part of the transaction process.",DM,291,"['processing', 'transaction', 'event', 'made', 'easier', 'encoding', 'commonly', 'used', 'transformation', 'sa', 'macro', 'iteration', 'process', 'code', 'operation', 'counting', 'number', 'transaction', 'performed', 'macro', 'function', 'simplifies', 'export', 'part', 'transaction', 'process']"
1131,The events in the period of interest can be thought of as measurements of a random variable. All manner of statistics to describe the distribution of this random variable can be used as model inputs.,DM,199,"['event', 'period', 'interest', 'thought', 'measurement', 'random', 'variable', 'manner', 'statistic', 'describe', 'distribution', 'random', 'variable', 'used', 'model', 'input']"
1132,"Potential predictive pitfalls can lurk in data sets with many cleverly crafted inputs. Data pathologies?input miscodings, extreme or outlying cases, highly skewed distributions, and missing values?can all seriously diminish model performance. This chapter offers a three-step regimen for countering these pathologies. Section 5.2 presents methods for finding potential problems in an input sample. Section 5.3 suggests transformations to avoid the debilitating effects of highly skewed inputs. Section 5.4 compares strategies for missing value imputation.",DM,555,"['potential', 'predictive', 'pitfall', 'lurk', 'data_set', 'many', 'cleverly', 'crafted', 'input', 'data', 'pathologiesinput', 'miscodings', 'extreme', 'outlying', 'case', 'highly', 'skewed', 'distribution', 'missing', 'valuescan', 'seriously', 'diminish', 'model', 'performance', 'chapter', 'offer', 'threestep', 'regimen', 'countering', 'pathology', 'section', '52', 'present', 'method', 'finding', 'potential', 'problem', 'input', 'sample', 'section', '53', 'suggests', 'transformation', 'avoid', 'debilitating', 'effect', 'highly', 'skewed', 'input', 'section', '54', 'compare', 'strategy', 'missing', 'value', 'imputation']"
1133,The scratch array is a two-dimensional array used by the transaction macro functions to store intermediate results. Any DATA step that uses the transaction processing macros must include a scratch array definition. The temporary array?s dimensions are 0 to the maximum number records per case in one dimension and 0 to 5 in the other dimension.,DM,344,"['scratch', 'array', 'twodimensional', 'array', 'used', 'transaction', 'macro', 'function', 'store', 'intermediate', 'result', 'data', 'step', 'us', 'transaction', 'processing', 'macro', 'must', 'include', 'scratch', 'array', 'definition', 'temporary', 'array', 'dimension', '0', 'maximum', 'number', 'record', 'per', 'case', 'one', 'dimension', '0', '5', 'dimension']"
1134,"The most important difference between access methods is the time required for their completion. Writing DATA step code to translate raw data into SAS data sets is time consuming. If the raw data is in a specific file format (such as a delimited file with column header information), the IMPORT procedure automates some of the DATA step code generation, although some code editing could be required to obtain the desired results. Using SAS/ACCESS products, the raw data appears to SAS as a SAS data set. This trims hours from the time required to read the raw data. Unfortunately, the raw data may need to be pulled across a network for SAS to operate on the data. Performance is then limited by network speed. The most efficient approach utilizes the SAS/ACCESS Pass-Through facility. Queries are then sent and executed directly to the RDBMS server. By limiting the transfer of data across the network, data access time is reduced to seconds even for large queries.",DM,965,"['important', 'difference', 'access', 'method', 'time', 'required', 'completion', 'writing', 'data', 'step', 'code', 'translate', 'raw', 'data', 'sa', 'data_set', 'time', 'consuming', 'raw', 'data', 'specific', 'file', 'format', 'delimited', 'file', 'column', 'header', 'information', 'import', 'procedure', 'automates', 'data', 'step', 'code', 'generation', 'although', 'code', 'editing', 'could', 'required', 'obtain', 'desired', 'result', 'using', 'sasaccess', 'product', 'raw', 'data', 'appears', 'sa', 'sa', 'data_set', 'trim', 'hour', 'time', 'required', 'read', 'raw', 'data', 'unfortunately', 'raw', 'data', 'may', 'need', 'pulled', 'across', 'network', 'sa', 'operate', 'data', 'performance', 'limited', 'network', 'speed', 'efficient', 'approach', 'utilizes', 'sasaccess', 'passthrough', 'facility', 'query', 'sent', 'executed', 'directly', 'rdbms', 'server', 'limiting', 'transfer', 'data', 'across', 'network', 'data', 'access', 'time', 'reduced', 'second', 'even', 'large', 'query']"
1135,This demonstration continues the use of the Transaction Input Creation 1.sas program. Here the process by ID step is examined. The goal is to transform the raw transactions into a so-called case input data set. Each row of the case input data set is the value of an input for a case. The raw data for this process step is the transaction extract TN_EXTRACT created in the previous demonstration.,DM,395,"['demonstration', 'continues', 'use', 'transaction', 'input', 'creation', '1sas', 'program', 'process', 'id', 'step', 'examined', 'goal', 'transform', 'raw', 'transaction', 'socalled', 'case', 'input', 'data_set', 'row', 'case', 'input', 'data_set', 'value', 'input', 'case', 'raw', 'data', 'process', 'step', 'transaction', 'extract', 'tnextract', 'created', 'previous', 'demonstration']"
1136,"There are many techniques used to recode non-numeric inputs. The most obvious?random enumeration of the levels?is usually the worst of them (for predictive modeling). Most models assume a continuous association between input and target: small changes in input value should imply small changes in expected target value. With a random enumeration, two adjacent levels can have completely different response behavior, violating the model?s continuity assumption. More reasonable approaches involve dummy coding or target-based enumerations.",DM,537,"['many', 'technique', 'used', 'recode', 'nonnumeric', 'input', 'obviousrandom', 'enumeration', 'levelsis', 'usually', 'worst', 'predictive', 'modeling', 'model', 'assume', 'continuous', 'association', 'input', 'target', 'small', 'change', 'input', 'value', 'imply', 'small', 'change', 'expected', 'target', 'value', 'random', 'enumeration', 'two', 'adjacent', 'level', 'completely', 'different', 'response', 'behavior', 'violating', 'model', 'continuity', 'assumption', 'reasonable', 'approach', 'involve', 'dummy', 'coding', 'targetbased', 'enumeration']"
1137,Event times in the interest period are recalibrated to a scale measuring time from the start of the latency period. Events with small relative times occur closest to the target date.,DM,182,"['event', 'time', 'interest', 'period', 'recalibrated', 'scale', 'measuring', 'time', 'start', 'latency', 'period', 'event', 'small', 'relative', 'time', 'occur', 'closest', 'target', 'date']"
1138,"The Export task commences upon reading the last transaction record for a given case. The first input created an account ownership indicator. Only accounts with transactions will have a checking account indicator variable (set equal to 1, that is). This fact will be useful during the finalize step.",DM,298,"['export', 'task', 'commences', 'upon', 'reading', 'last', 'transaction', 'record', 'given', 'case', 'first', 'input', 'created', 'account', 'ownership', 'indicator', 'account', 'transaction', 'checking', 'account', 'indicator', 'variable', 'set', 'equal', '1', 'fact', 'useful', 'finalize', 'step']"
1139,"The checking account IDs of clients in the target sample are placed in a data set named SAMPLE_CHECKING_ACCOUNTS. As mentioned above, in practice, several checking account qualifications might be invoked at this point. *** Access Transaction Data from Warehouse; proc sql; create table sample_checking_accounts as select CLIENT_ID, CHECKING_ID from dmdp.client_checking_account where CLIENT_ID in (select CLIENT_ID from dmdp.target_sample);",DM,440,"['checking', 'account', 'id', 'client', 'target', 'sample', 'placed', 'data_set', 'named', 'samplecheckingaccounts', 'mentioned', 'practice', 'several', 'checking', 'account', 'qualification', 'might', 'invoked', 'point', '', 'access', 'transaction', 'data', 'warehouse', 'proc', 'sql', 'create', 'table', 'samplecheckingaccounts', 'select', 'clientid', 'checkingid', 'dmdpclientcheckingaccount', 'clientid', 'select', 'clientid', 'dmdptargetsample']"
1140,"With the account balance known at the end date, it is possible to use the values of the transaction events to determine the account balance at any point in time.",DM,161,"['account', 'balance', 'known', 'end', 'date', 'possible', 'use', 'value', 'transaction', 'event', 'determine', 'account', 'balance', 'point', 'time']"
1141,"A second input created is a transaction account overflow flag. This flag is zero unless the observed number of events for a case exceeds the assumed maximum. In this case, it is equal to the observed number of events.",DM,217,"['second', 'input', 'created', 'transaction', 'account', 'overflow', 'flag', 'flag', 'zero', 'unless', 'observed', 'number', 'event', 'case', 'exceeds', 'assumed', 'maximum', 'case', 'equal', 'observed', 'number', 'event']"
1142,The TN_CODE_IDX array is used to capture the grouping code indices of each transaction event. The transaction code indices are generated by translating the raw profile to a grouping code and the grouping code to an index.,DM,221,"['tncodeidx', 'array', 'used', 'capture', 'grouping', 'code', 'index', 'transaction', 'event', 'transaction', 'code', 'index', 'generated', 'translating', 'raw', 'profile', 'grouping', 'code', 'grouping', 'code', 'index']"
1143,"Open the file Transaction Input Creation 1.sas in the SAS program editor. This program performs the four steps of transaction transformation. This demonstration focuses on the selecting and sorting step. The program begins by including a set of macros used for input creation throughout the course. The macros are studied in some detail later in the chapter. *** Include transaction macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""transaction_macros.source"");",DM,484,"['open', 'file', 'transaction', 'input', 'creation', '1sas', 'sa', 'program', 'editor', 'program', 'performs', 'four', 'step', 'transaction', 'transformation', 'demonstration', 'focus', 'selecting', 'sorting', 'step', 'program', 'begin', 'including', 'set', 'macro', 'used', 'input', 'creation', 'throughout', 'course', 'macro', 'studied', 'detail', 'later', 'chapter', '', 'include', 'transaction', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacstransactionmacrossource']"
1144,"In the previous section, the inherent meaning of non-numeric variables allowed transformations to useful numeric inputs. In this section, their relationships to other (extrinsic) data is leveraged. It is often possible to think of high cardinality variables as indices to other data sources. For example, a table summarizing the frequency distribution of names by gender can be linked to the first names in the target sample. Bayes? theorem can be employed to translate these gender-specific frequency distributions into probability statements about a specific individual?s gender. As a second example, many demographic data sets are summarized at the postal code level. Linking these demographic summaries to individuals via postal code makes a tremendous amount of (summarized) information available to predictive models. This summarized data can provide hints about race, wealth, employment, education, and lifestyle. Commercial data provides such as Acxiom, Claritas, Experian, and Equifax use even higher cardinality variables such as name, address, and social security number as links to their vast data stores. By using higher cardinality links, the commercial data can provide more accurate information to the predictive model.",DM,1235,"['previous', 'section', 'inherent', 'meaning', 'nonnumeric', 'variable', 'allowed', 'transformation', 'useful', 'numeric', 'input', 'section', 'relationship', 'extrinsic', 'data', 'leveraged', 'often', 'possible', 'think', 'high', 'cardinality', 'variable', 'index', 'data', 'source', 'example', 'table', 'summarizing', 'frequency', 'distribution', 'name', 'gender', 'linked', 'first', 'name', 'target', 'sample', 'bayes', 'theorem', 'employed', 'translate', 'genderspecific', 'frequency', 'distribution', 'probability', 'statement', 'specific', 'individual', 'gender', 'second', 'example', 'many', 'demographic', 'data_set', 'summarized', 'postal', 'code', 'level', 'linking', 'demographic', 'summary', 'individual', 'via', 'postal', 'code', 'make', 'tremendous', 'amount', 'summarized', 'information', 'available', 'predictive', 'model', 'summarized', 'data', 'provide', 'hint', 'race', 'wealth', 'employment', 'education', 'lifestyle', 'commercial', 'data', 'provides', 'acxiom', 'claritas', 'experian', 'equifax', 'use', 'even', 'higher', 'cardinality', 'variable', 'name', 'address', 'social', 'security', 'number', 'link', 'vast', 'data', 'store', 'using', 'higher', 'cardinality', 'link', 'commercial', 'data', 'provide', 'accurate', 'information', 'predictive', 'model']"
1145,"In a simple random target sample, the non-INS clients outnumber the INS clients by approximately 46 to 1. By using separate sampling techniques, it is possible to substantially reduce the number of clients selected for modeling, without significantly reducing predictive modeling performance. In fact, by using the stratification techniques discussed in Section 2.4, it is possible to obtain a modeling sample that controls for potential non-stationarities in the data and thereby improves predictive model performance.",DM,519,"['simple', 'random', 'target', 'sample', 'nonins', 'client', 'outnumber', 'client', 'approximately', '46', '1', 'using', 'separate', 'sampling', 'technique', 'possible', 'substantially', 'reduce', 'number', 'client', 'selected', 'modeling', 'without', 'significantly', 'reducing', 'predictive', 'modeling', 'performance', 'fact', 'using', 'stratification', 'technique', 'discussed', 'section', '24', 'possible', 'obtain', 'modeling', 'sample', 'control', 'potential', 'nonstationarities', 'data', 'thereby', 'improves', 'predictive', 'model', 'performance']"
1146,"A different modification to the basic weight of evidence approach (inspired by Bayesian statistical methods) assumes a priori distributions for the target average within level. These so-called prior distributions reflect the analyst?s state of knowledge about the expect value of the target within level. Observations from the training data are then combined with the prior data to form updated estimates of the target average distribution. The expected value of this a posteriori distribution serves as the estimated target value within level. These so-called posterior estimates show substantial reduction prediction bias compared to the basic weight of evidence approach, especially in non-numeric inputs with tens to hundreds of levels.",DM,740,"['different', 'modification', 'basic', 'weight', 'evidence', 'approach', 'inspired', 'bayesian', 'statistical', 'method', 'assumes', 'priori', 'distribution', 'target', 'average', 'within', 'level', 'socalled', 'prior', 'distribution', 'reflect', 'analyst', 'state', 'knowledge', 'expect', 'value', 'target', 'within', 'level', 'observation', 'training', 'data', 'combined', 'prior', 'data', 'form', 'updated', 'estimate', 'target', 'average', 'distribution', 'expected', 'value', 'posteriori', 'distribution', 'serf', 'estimated', 'target', 'value', 'within', 'level', 'socalled', 'posterior', 'estimate', 'show', 'substantial', 'reduction', 'prediction', 'bias', 'compared', 'basic', 'weight', 'evidence', 'approach', 'especially', 'nonnumeric', 'input', 'ten', 'hundred', 'level']"
1147,The program Extracting Relevant Data 4.sas demonstrates assigning target dates to cases in the INS example. The data is sorted by origination date in descending order. proc sort data=ins_clients_qualified; by descending ORIG_DT; run;,DM,233,"['program', 'extracting', 'relevant', 'data', '4sas', 'demonstrates', 'assigning', 'target', 'date', 'case', 'example', 'data', 'sorted', 'origination', 'date', 'descending', 'order', 'proc', 'sort', 'datainsclientsqualified', 'descending', 'origdt', 'run']"
1148,"The most straightforward implementation of separate sampling involves transferring the INS and non-INS qualified client data sets from the warehouse server to the SAS analysis server. Transfer can be accomplished by defining a SAS/ACCESS library reference to the server and copying the data with a DATA step. ?	While most major RDBMS engines (Oracle, DB2, and SQLServer) have functions for implementing separate sampling, the functions are specific to the RDBMS engine and beyond the scope of this course.",DM,505,"['straightforward', 'implementation', 'separate', 'sampling', 'involves', 'transferring', 'nonins', 'qualified', 'client', 'data_set', 'warehouse', 'server', 'sa', 'analysis', 'server', 'transfer', 'accomplished', 'defining', 'sasaccess', 'library', 'reference', 'server', 'copying', 'data', 'data', 'step', '\twhile', 'major', 'rdbms', 'engine', 'oracle', 'db2', 'sqlserver', 'function', 'implementing', 'separate', 'sampling', 'function', 'specific', 'rdbms', 'engine', 'beyond', 'scope', 'course']"
1149,"Processing transaction events can be made easier by encoding commonly used transformations as SAS macros. In this iteration of the process code, the operation of counting the number of transactions is performed by a macro function. This simplifies the Export part of the transaction process.",DM,291,"['processing', 'transaction', 'event', 'made', 'easier', 'encoding', 'commonly', 'used', 'transformation', 'sa', 'macro', 'iteration', 'process', 'code', 'operation', 'counting', 'number', 'transaction', 'performed', 'macro', 'function', 'simplifies', 'export', 'part', 'transaction', 'process']"
1150,The DESCRIPTIVE data set is in a most inconvenient form: one row and many columns. The TRANSPOSE procedure reverses this arrangement. *** make descriptive statistics inset data; proc transpose data=descriptive out=descriptive; run;,DM,231,"['descriptive', 'data_set', 'inconvenient', 'form', 'one', 'row', 'many', 'column', 'transpose', 'procedure', 'revers', 'arrangement', '', 'make', 'descriptive', 'statistic', 'inset', 'data', 'proc', 'transpose', 'datadescriptive', 'outdescriptive', 'run']"
1151,"There are many techniques used to recode non-numeric inputs. The most obvious?random enumeration of the levels?is usually the worst of them (for predictive modeling). Most models assume a continuous association between input and target: small changes in input value should imply small changes in expected target value. With a random enumeration, two adjacent levels can have completely different response behavior, violating the model?s continuity assumption. More reasonable approaches involve dummy coding or target-based enumerations.",DM,537,"['many', 'technique', 'used', 'recode', 'nonnumeric', 'input', 'obviousrandom', 'enumeration', 'levelsis', 'usually', 'worst', 'predictive', 'modeling', 'model', 'assume', 'continuous', 'association', 'input', 'target', 'small', 'change', 'input', 'value', 'imply', 'small', 'change', 'expected', 'target', 'value', 'random', 'enumeration', 'two', 'adjacent', 'level', 'completely', 'different', 'response', 'behavior', 'violating', 'model', 'continuity', 'assumption', 'reasonable', 'approach', 'involve', 'dummy', 'coding', 'targetbased', 'enumeration']"
1152,"Postal codes are non-numeric inputs with cardinalities several orders of magnitude greater than those considered in the previous section. As such, they are ill suited for the recoding techniques discussed there and are often ignored in predictive modeling applications. Because the codes have a meaning transcendent of the data, namely location, it is possible to make a meaning transformation of the codes to useful inputs.",DM,424,"['postal', 'code', 'nonnumeric', 'input', 'cardinality', 'several', 'order', 'magnitude', 'greater', 'considered', 'previous', 'section', 'ill', 'suited', 'recoding', 'technique', 'discussed', 'often', 'ignored', 'predictive', 'modeling', 'application', 'code', 'meaning', 'transcendent', 'data', 'namely', 'location', 'possible', 'make', 'meaning', 'transformation', 'code', 'useful', 'input']"
1153,"The method you use to access the raw operational data depends on the data?s format and the tools at your disposal. Accessing data in a text or binary file independent of a RDBMS system is often performed by DATA step programming or, in the case of certain file formats, the IMPORT procedure. When the raw operational data is contained within a RDBMS system, you can use SAS/ACCESS products to read and operate on the data as if it were a SAS data set. SAS/ACCESS products also enable you to pass through RDBMS- specific queries that operate completely on the RDDMS server and might utilize functions not available in SAS.",DM,621,"['method', 'use', 'access', 'raw', 'operational', 'data', 'depends', 'data', 'format', 'tool', 'disposal', 'accessing', 'data', 'text', 'binary', 'file', 'independent', 'rdbms', 'system', 'often', 'performed', 'data', 'step', 'programming', 'case', 'certain', 'file', 'format', 'import', 'procedure', 'raw', 'operational', 'data', 'contained', 'within', 'rdbms', 'system', 'use', 'sasaccess', 'product', 'read', 'operate', 'data', 'sa', 'data_set', 'sasaccess', 'product', 'also', 'enable', 'pas', 'rdbms', 'specific', 'query', 'operate', 'completely', 'rddms', 'server', 'might', 'utilize', 'function', 'available', 'sa']"
1154,"A simpler, and arguably more effective, approach is to transform offending inputs to less extreme forms and build models on these transformed inputs. This not only reduces the influence of extreme cases, but it also creates an asymptotic association between input and target on the original input scale.",DM,303,"['simpler', 'arguably', 'effective', 'approach', 'transform', 'offending', 'input', 'le', 'extreme', 'form', 'build', 'model', 'transformed', 'input', 'reduces', 'influence', 'extreme', 'case', 'also', 'creates', 'asymptotic', 'association', 'input', 'target', 'original', 'input', 'scale']"
1155,"Missing value replacement strategies fall into one of two categories. Estimation methods attempt to provide a reasonable guess as to what the missing value should have been were it not missing. This approach is compatible with missing values resulting from a lack of knowledge (for example, no match or non-disclosure), and not with missing values resulting from the lack of applicability of the inputs. Estimation methods usually closely connected with model building and are outside the scope of this course. Synthetic distribution methods simply modify the distribution in an input to include a point mass at a specific value for cases whose input value is otherwise not known.",DM,680,"['missing', 'value', 'replacement', 'strategy', 'fall', 'one', 'two', 'category', 'estimation', 'method', 'attempt', 'provide', 'reasonable', 'guess', 'missing', 'value', 'missing', 'approach', 'compatible', 'missing', 'value', 'resulting', 'lack', 'knowledge', 'example', 'match', 'nondisclosure', 'missing', 'value', 'resulting', 'lack', 'applicability', 'input', 'estimation', 'method', 'usually', 'closely', 'connected', 'model', 'building', 'outside', 'scope', 'course', 'synthetic', 'distribution', 'method', 'simply', 'modify', 'distribution', 'input', 'include', 'point', 'mass', 'specific', 'value', 'case', 'whose', 'input', 'value', 'otherwise', 'known']"
1156,The rank transformation is attractive in that it completely eliminates input skewness by transforming any numeric input to an almost uniform distribution. (The spike in the 10th percentile is caused by the set of cases with CC_BAL_AVG=0.),DM,238,"['rank', 'transformation', 'attractive', 'completely', 'eliminates', 'input', 'skewness', 'transforming', 'numeric', 'input', 'almost', 'uniform', 'distribution', 'spike', '10th', 'percentile', 'caused', 'set', 'case', 'ccbalavg0']"
1157,"Most strategies for representing non-numeric data in predictive models involve some form of recoding or transformation of the non-numeric data to numeric data into numeric data. The approaches taken depend mostly on the degree of cardinality. Low cardinality inputs (fewer than 10 distinct levels) are acceptable to most modeling techniques and need no additional processing (although several low cardinality inputs actually look like a single high cardinality input to a statistical model). When the input cardinality is in the range of ten to several hundred, the techniques built in to many statistical models are not sufficient to avoid overgeneralization. Some form of external recoding is usually deployed. Recoding strategies are discussed in the next section. When the cardinality exceeds several hundred, approaches other than recoding are needed. Many of the approaches involve a transformation dependent on the intrinsic or extrinsic properties of the non-numeric input. For example the intrinsic meaning of a non-numeric field such as postal code (location) enables transformations to numeric inputs (latitude and longitude). Location can be used to create or access a variety of valuable modeling inputs. Section 4.3 discusses geocoding, the transformation of postal code to latitude and longitude. Non-numeric variables also possess extrinsic properties in that they often serve as links to other data sources. Section 4.4 describes how linking can be used to transform a single non-numeric input into hundreds of new, independent, and informative inputs. At the highest end of the cardinality scale are the variables with unbounded cardinality. Free-form text fields are one example. The emerging field of text mining focuses on these extreme cardinality inputs. The techniques are of sufficient complexity to justify a separate course.",DM,1851,"['strategy', 'representing', 'nonnumeric', 'data', 'predictive', 'model', 'involve', 'form', 'recoding', 'transformation', 'nonnumeric', 'data', 'numeric', 'data', 'numeric', 'data', 'approach', 'taken', 'depend', 'mostly', 'degree', 'cardinality', 'low', 'cardinality', 'input', 'fewer', '10', 'distinct', 'level', 'acceptable', 'modeling', 'technique', 'need', 'additional', 'processing', 'although', 'several', 'low', 'cardinality', 'input', 'actually', 'look', 'like', 'single', 'high', 'cardinality', 'input', 'statistical', 'model', 'input', 'cardinality', 'range', 'ten', 'several', 'hundred', 'technique', 'built', 'many', 'statistical', 'model', 'sufficient', 'avoid', 'overgeneralization', 'form', 'external', 'recoding', 'usually', 'deployed', 'recoding', 'strategy', 'discussed', 'next', 'section', 'cardinality', 'exceeds', 'several', 'hundred', 'approach', 'recoding', 'needed', 'many', 'approach', 'involve', 'transformation', 'dependent', 'intrinsic', 'extrinsic', 'property', 'nonnumeric', 'input', 'example', 'intrinsic', 'meaning', 'nonnumeric', 'field', 'postal', 'code', 'location', 'enables', 'transformation', 'numeric', 'input', 'latitude', 'longitude', 'location', 'used', 'create', 'access', 'variety', 'valuable', 'modeling', 'input', 'section', '43', 'discus', 'geocoding', 'transformation', 'postal', 'code', 'latitude', 'longitude', 'nonnumeric', 'variable', 'also', 'posse', 'extrinsic', 'property', 'often', 'serve', 'link', 'data', 'source', 'section', '44', 'describes', 'linking', 'used', 'transform', 'single', 'nonnumeric', 'input', 'hundred', 'new', 'independent', 'informative', 'input', 'highest', 'end', 'cardinality', 'scale', 'variable', 'unbounded', 'cardinality', 'freeform', 'text', 'field', 'one', 'example', 'emerging', 'field', 'text', 'mining', 'focus', 'extreme', 'cardinality', 'input', 'technique', 'sufficient', 'complexity', 'justify', 'separate', 'course']"
1158,The data must be rearranged to a single row per account for use in predictive modeling. The TRANSPOSE performs such a transformation. *** Transpose Transaction data set; proc transpose data=work.tn_case_inputs out=work.tn_inputs(drop=_NAME_); by CHECKING_ID; var VALUE; id VARNAME; run; The BY statement specifies transposing by checking account ID. The ID statement commands the TRANSPOSE procedure to use the contents of the VARNAME column for column names in the output data set. Browse the TN_INPUTS data set to see the results of the TRANSPOSE procedure.,DM,559,"['data', 'must', 'rearranged', 'single', 'row', 'per', 'account', 'use', 'predictive', 'modeling', 'transpose', 'performs', 'transformation', '', 'transpose', 'transaction', 'data_set', 'proc', 'transpose', 'dataworktncaseinputs', 'outworktninputsdropname', 'checkingid', 'var', 'value', 'id', 'varname', 'run', 'statement', 'specifies', 'transposing', 'checking', 'account', 'id', 'id', 'statement', 'command', 'transpose', 'procedure', 'use', 'content', 'varname', 'column', 'column', 'name', 'output', 'data_set', 'browse', 'tninputs', 'data_set', 'see', 'result', 'transpose', 'procedure']"
1159,"To avoid input sample contamination, a target date should be included in the target sample. This ensures that all input measurements are made before the target event, avoiding temporal infidelity. For INS clients the target date is obviously the account open date. For non-INS clients this date is undefined. This section demonstrates a method by which a meaningful target date can be established for non-INS clients.",DM,417,"['avoid', 'input', 'sample', 'contamination', 'target', 'date', 'included', 'target', 'sample', 'ensures', 'input', 'measurement', 'made', 'target', 'event', 'avoiding', 'temporal', 'infidelity', 'client', 'target', 'date', 'obviously', 'account', 'open', 'date', 'nonins', 'client', 'date', 'undefined', 'section', 'demonstrates', 'method', 'meaningful', 'target', 'date', 'established', 'nonins', 'client']"
1160,"Creating the rank formats from the RANK procedure is a somewhat subtle and cumbersome process. The five-step process starts by creating a grouped-ranks data set for all specified variables, transposing this data set to a form usable by the MEANS procedure, calculating the minimum and mean values within each rank group for each variable, generating the CNTLIN data set for the FORMAT procedure, and finally applying the FORMAT procedure to the generated CNTLIN data set. The four parameters for the %RANK_TRANS macro are as discussed above. %macro rank_trans(data=,vars=,bins=100,fname=);",DM,589,"['creating', 'rank', 'format', 'rank', 'procedure', 'somewhat', 'subtle', 'cumbersome', 'process', 'fivestep', 'process', 'start', 'creating', 'groupedranks', 'data_set', 'specified', 'variable', 'transposing', 'data_set', 'form', 'usable', 'mean', 'procedure', 'calculating', 'minimum', 'mean', 'value', 'within', 'rank', 'group', 'variable', 'generating', 'cntlin', 'data_set', 'format', 'procedure', 'finally', 'applying', 'format', 'procedure', 'generated', 'cntlin', 'data_set', 'four', 'parameter', 'ranktrans', 'macro', 'discussed', 'macro', 'ranktransdatavarsbins100fname']"
1161,"A small addition to the execute task of the process by ID step generates an input that counts the number of events occurring between day zero and day 30 in relative time. A new variable, TN_LIMIT, is calculated to prevent reading past the limits of the transaction array.",DM,271,"['small', 'addition', 'execute', 'task', 'process', 'id', 'step', 'generates', 'input', 'count', 'number', 'event', 'occurring', 'day', 'zero', 'day', '30', 'relative', 'time', 'new', 'variable', 'tnlimit', 'calculated', 'prevent', 'reading', 'past', 'limit', 'transaction', 'array']"
1162,"Transaction data is probably the richest source of information for predictive models. It can capture complex individual behavior in a highly detailed fashion. Because the patterns captured in transaction data often mirror the target event, the data yields inputs with strong target correlation potential.",DM,304,"['transaction', 'data', 'probably', 'richest', 'source', 'information', 'predictive', 'model', 'capture', 'complex', 'individual', 'behavior', 'highly', 'detailed', 'fashion', 'pattern', 'captured', 'transaction', 'data', 'often', 'mirror', 'target', 'event', 'data', 'yield', 'input', 'strong', 'target', 'correlation', 'potential']"
1163,"In general, tabulation functions are the fastest, followed by distributional functions, and finally order statistics (exceptions are the %MIN and %MAX functions, which are in fact the fastest of all the transaction macros). Using Transaction Macros",DM,248,"['general', 'tabulation', 'function', 'fastest', 'followed', 'distributional', 'function', 'finally', 'order', 'statistic', 'exception', 'min', 'max', 'function', 'fact', 'fastest', 'transaction', 'macro', 'using', 'transaction', 'macro']"
1164,"The key is knowing the location corresponding to the postal codes. There are many public tabulations of this data available. In fact, one tabulation is found in the SASHELP library. The tabulations, known as ZIP code centroid tables, match postal codes to latitude and longitude locations. Combining the centroid tables with the SAS formats makes it trivial to instantly translate a postal code to latitude and longitude values. Translating Zip Codes to Latitude/Longitude Values Open the file Using Non-Numeric Data 3.sas in the SAS program editor. This program creates formats for translating zip codes to latitude and longitude. Open the data set DMDP.ZIP_CENTROIDS.",DM,669,"['key', 'knowing', 'location', 'corresponding', 'postal', 'code', 'many', 'public', 'tabulation', 'data', 'available', 'fact', 'one', 'tabulation', 'found', 'sashelp', 'library', 'tabulation', 'known', 'zip', 'code', 'centroid', 'table', 'match', 'postal', 'code', 'latitude', 'longitude', 'location', 'combining', 'centroid', 'table', 'sa', 'format', 'make', 'trivial', 'instantly', 'translate', 'postal', 'code', 'latitude', 'longitude', 'value', 'translating', 'zip', 'code', 'latitudelongitude', 'value', 'open', 'file', 'using', 'nonnumeric', 'data', '3sas', 'sa', 'program', 'editor', 'program', 'creates', 'format', 'translating', 'zip', 'code', 'latitude', 'longitude', 'open', 'data_set', 'dmdpzipcentroids']"
1165,"Open the file Managing Data Pathologies 2.sas in the program editor. This program demonstrates the three techniques for regularizing extreme distributions. As seen in a distribution plot, the variable CC_BAL_AVG is moderately skewed. There are several ways to compensate for this skewness. %distribution(vars=CC_BAL_AVG,data=dmdp.ins_modeling_sample );",DM,352,"['open', 'file', 'managing', 'data', 'pathology', '2sas', 'program', 'editor', 'program', 'demonstrates', 'three', 'technique', 'regularizing', 'extreme', 'distribution', 'seen', 'distribution', 'plot', 'variable', 'ccbalavg', 'moderately', 'skewed', 'several', 'way', 'compensate', 'skewness', 'distributionvarsccbalavgdatadmdpinsmodelingsample', '']"
1166,"In the previous section, the inherent meaning of non-numeric variables allowed transformations to useful numeric inputs. In this section, their relationships to other (extrinsic) data is leveraged. It is often possible to think of high cardinality variables as indices to other data sources. For example, a table summarizing the frequency distribution of names by gender can be linked to the first names in the target sample. Bayes? theorem can be employed to translate these gender-specific frequency distributions into probability statements about a specific individual?s gender. As a second example, many demographic data sets are summarized at the postal code level. Linking these demographic summaries to individuals via postal code makes a tremendous amount of (summarized) information available to predictive models. This summarized data can provide hints about race, wealth, employment, education, and lifestyle. Commercial data provides such as Acxiom, Claritas, Experian, and Equifax use even higher cardinality variables such as name, address, and social security number as links to their vast data stores. By using higher cardinality links, the commercial data can provide more accurate information to the predictive model.",DM,1235,"['previous', 'section', 'inherent', 'meaning', 'nonnumeric', 'variable', 'allowed', 'transformation', 'useful', 'numeric', 'input', 'section', 'relationship', 'extrinsic', 'data', 'leveraged', 'often', 'possible', 'think', 'high', 'cardinality', 'variable', 'index', 'data', 'source', 'example', 'table', 'summarizing', 'frequency', 'distribution', 'name', 'gender', 'linked', 'first', 'name', 'target', 'sample', 'bayes', 'theorem', 'employed', 'translate', 'genderspecific', 'frequency', 'distribution', 'probability', 'statement', 'specific', 'individual', 'gender', 'second', 'example', 'many', 'demographic', 'data_set', 'summarized', 'postal', 'code', 'level', 'linking', 'demographic', 'summary', 'individual', 'via', 'postal', 'code', 'make', 'tremendous', 'amount', 'summarized', 'information', 'available', 'predictive', 'model', 'summarized', 'data', 'provide', 'hint', 'race', 'wealth', 'employment', 'education', 'lifestyle', 'commercial', 'data', 'provides', 'acxiom', 'claritas', 'experian', 'equifax', 'use', 'even', 'higher', 'cardinality', 'variable', 'name', 'address', 'social', 'security', 'number', 'link', 'vast', 'data', 'store', 'using', 'higher', 'cardinality', 'link', 'commercial', 'data', 'provide', 'accurate', 'information', 'predictive', 'model']"
1167,"Creating the rank formats from the RANK procedure is a somewhat subtle and cumbersome process. The five-step process starts by creating a grouped-ranks data set for all specified variables, transposing this data set to a form usable by the MEANS procedure, calculating the minimum and mean values within each rank group for each variable, generating the CNTLIN data set for the FORMAT procedure, and finally applying the FORMAT procedure to the generated CNTLIN data set. The four parameters for the %RANK_TRANS macro are as discussed above. %macro rank_trans(data=,vars=,bins=100,fname=);",DM,589,"['creating', 'rank', 'format', 'rank', 'procedure', 'somewhat', 'subtle', 'cumbersome', 'process', 'fivestep', 'process', 'start', 'creating', 'groupedranks', 'data_set', 'specified', 'variable', 'transposing', 'data_set', 'form', 'usable', 'mean', 'procedure', 'calculating', 'minimum', 'mean', 'value', 'within', 'rank', 'group', 'variable', 'generating', 'cntlin', 'data_set', 'format', 'procedure', 'finally', 'applying', 'format', 'procedure', 'generated', 'cntlin', 'data_set', 'four', 'parameter', 'ranktrans', 'macro', 'discussed', 'macro', 'ranktransdatavarsbins100fname']"
1168,"A second input created is a transaction account overflow flag. This flag is zero unless the observed number of events for a case exceeds the assumed maximum. In this case, it is equal to the observed number of events.",DM,217,"['second', 'input', 'created', 'transaction', 'account', 'overflow', 'flag', 'flag', 'zero', 'unless', 'observed', 'number', 'event', 'case', 'exceeds', 'assumed', 'maximum', 'case', 'equal', 'observed', 'number', 'event']"
1169,"To fully appreciate the effect of leverage points and the benefits of regularization transformations, consider the plot above. It shows a standard logistic regression model fit to original and three transformed inputs. The untransformed model appears to show a relatively substantial association between CC_AVG_BAL and INS. In the threshold transformed input, the association largely disappears. For the log and rank transformed inputs, it is seen to be non-existent. Using the %RANK_TRANS Macro",DM,495,"['fully', 'appreciate', 'effect', 'leverage', 'point', 'benefit', 'regularization', 'transformation', 'consider', 'plot', 'show', 'standard', 'logistic_regression_model', 'fit', 'original', 'three', 'transformed', 'input', 'untransformed', 'model', 'appears', 'show', 'relatively', 'substantial', 'association', 'ccavgbal', 'threshold', 'transformed', 'input', 'association', 'largely', 'disappears', 'log', 'rank', 'transformed', 'input', 'seen', 'nonexistent', 'using', 'ranktrans', 'macro']"
1170,"Introduction of the transaction macros enables the transaction processing to begin in earnest. Additional transaction arrays are declared, corresponding to type, channel, and method fields in the transaction data.",DM,213,"['introduction', 'transaction', 'macro', 'enables', 'transaction', 'processing', 'begin', 'earnest', 'additional', 'transaction', 'array', 'declared', 'corresponding', 'type', 'channel', 'method', 'field', 'transaction', 'data']"
1171,"With the BALANCE array containing the actual daily balance of the account, it is easy to generate statistic describing the balance distribution. For example, the %MEAN macro function yields the average daily balance.",DM,216,"['balance', 'array', 'containing', 'actual', 'daily', 'balance', 'account', 'easy', 'generate', 'statistic', 'describing', 'balance', 'distribution', 'example', 'mean', 'macro', 'function', 'yield', 'average', 'daily', 'balance']"
1172,"The institution currently uses 18 branch codes, B1 to B18. Some of the branch codes are sparsely populated. Using threshold-based recoding, these branches will be isolated in a separate branch, coded B0. The first part of the recoding program loads in macros to be used throughout the chapter. The macros automate, to some degree, the tasks described in the demonstrations. The automation process often introduces interesting technical complications orthogonal to the main data preparation concept. Details of these macros are provided in optional demonstrations to follow. *** Include categorical macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""categorical_macros.source"");",DM,699,"['institution', 'currently', 'us', '18', 'branch', 'code', 'b1', 'b18', 'branch', 'code', 'sparsely', 'populated', 'using', 'thresholdbased', 'recoding', 'branch', 'isolated', 'separate', 'branch', 'coded', 'b0', 'first', 'part', 'recoding', 'program', 'load', 'macro', 'used', 'throughout', 'chapter', 'macro', 'automate', 'degree', 'task', 'described', 'demonstration', 'automation', 'process', 'often', 'introduces', 'interesting', 'technical', 'complication', 'orthogonal', 'main', 'data', 'preparation', 'concept', 'detail', 'macro', 'provided', 'optional', 'demonstration', 'follow', '', 'include', 'categorical', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacscategoricalmacrossource']"
1173,The rank transformation is attractive in that it completely eliminates input skewness by transforming any numeric input to an almost uniform distribution. (The spike in the 10th percentile is caused by the set of cases with CC_BAL_AVG=0.),DM,238,"['rank', 'transformation', 'attractive', 'completely', 'eliminates', 'input', 'skewness', 'transforming', 'numeric', 'input', 'almost', 'uniform', 'distribution', 'spike', '10th', 'percentile', 'caused', 'set', 'case', 'ccbalavg0']"
1174,"The standard deviation macro function is somewhat more complex than the count or sum functions. Three pieces of information are required to calculate the standard deviation: the number of observations, the sum of the observations, and the sum of the squares of the observations. The first loop in the macro code calculates these quantities and places the results in so-called scratch arrays (see the next slide). If the number of observations is greater than or equal to 2, then the standard deviation is calculated using the usual formula. Discussion of the group macro variable is deferred to the next section.",DM,612,"['standard', 'deviation', 'macro', 'function', 'somewhat', 'complex', 'count', 'sum', 'function', 'three', 'piece', 'information', 'required', 'calculate', 'standard', 'deviation', 'number', 'observation', 'sum', 'observation', 'sum', 'square', 'observation', 'first', 'loop', 'macro', 'code', 'calculates', 'quantity', 'place', 'result', 'socalled', 'scratch', 'array', 'see', 'next', 'slide', 'number', 'observation', 'greater', 'equal', '2', 'standard', 'deviation', 'calculated', 'using', 'usual', 'formula', 'discussion', 'group', 'macro', 'variable', 'deferred', 'next', 'section']"
1175,The application of the geocoding formats appears somewhat more complicated. The complication arises from the embedded Boolean logic in the assignment statement. data lat_lon_inputs; set dmdp.input_sample_branch;,DM,211,"['application', 'geocoding', 'format', 'appears', 'somewhat', 'complicated', 'complication', 'arises', 'embedded', 'boolean', 'logic', 'assignment', 'statement', 'data', 'latloninputs', 'set', 'dmdpinputsamplebranch']"
1176,"The key is knowing the location corresponding to the postal codes. There are many public tabulations of this data available. In fact, one tabulation is found in the SASHELP library. The tabulations, known as ZIP code centroid tables, match postal codes to latitude and longitude locations. Combining the centroid tables with the SAS formats makes it trivial to instantly translate a postal code to latitude and longitude values. Translating Zip Codes to Latitude/Longitude Values Open the file Using Non-Numeric Data 3.sas in the SAS program editor. This program creates formats for translating zip codes to latitude and longitude. Open the data set DMDP.ZIP_CENTROIDS.",DM,669,"['key', 'knowing', 'location', 'corresponding', 'postal', 'code', 'many', 'public', 'tabulation', 'data', 'available', 'fact', 'one', 'tabulation', 'found', 'sashelp', 'library', 'tabulation', 'known', 'zip', 'code', 'centroid', 'table', 'match', 'postal', 'code', 'latitude', 'longitude', 'location', 'combining', 'centroid', 'table', 'sa', 'format', 'make', 'trivial', 'instantly', 'translate', 'postal', 'code', 'latitude', 'longitude', 'value', 'translating', 'zip', 'code', 'latitudelongitude', 'value', 'open', 'file', 'using', 'nonnumeric', 'data', '3sas', 'sa', 'program', 'editor', 'program', 'creates', 'format', 'translating', 'zip', 'code', 'latitude', 'longitude', 'open', 'data_set', 'dmdpzipcentroids']"
1177,"Thus far, the target date has been ignored in the input preparation process. Doing so contaminates any created inputs. In this iteration of the analysis, the target dates are read from the data warehouse. Only events that fall in the relevancy period are allowed in the transaction arrays.",DM,289,"['thus', 'far', 'target', 'date', 'ha', 'ignored', 'input', 'preparation', 'process', 'contaminates', 'created', 'input', 'iteration', 'analysis', 'target', 'date', 'read', 'data', 'warehouse', 'event', 'fall', 'relevancy', 'period', 'allowed', 'transaction', 'array']"
1178,"The Export task commences upon reading the last transaction record for a given case. The first input created an account ownership indicator. Only accounts with transactions will have a checking account indicator variable (set equal to 1, that is). This fact will be useful during the finalize step.",DM,298,"['export', 'task', 'commences', 'upon', 'reading', 'last', 'transaction', 'record', 'given', 'case', 'first', 'input', 'created', 'account', 'ownership', 'indicator', 'account', 'transaction', 'checking', 'account', 'indicator', 'variable', 'set', 'equal', '1', 'fact', 'useful', 'finalize', 'step']"
1179,"The additional transaction arrays combined with the transaction macros allow the creation of stratified inputs. For example, CR_SUM measures the total deposits per month.",DM,170,"['additional', 'transaction', 'array', 'combined', 'transaction', 'macro', 'allow', 'creation', 'stratified', 'input', 'example', 'crsum', 'measure', 'total', 'deposit', 'per', 'month']"
1180,Much of the course discussion centers on the analytic objective stated above. Financial institutions usually possess highly detailed data that is challenging to transform into a structure suitable for predictive modeling. The approaches used to overcome the challenges are applicable to many domains.,DM,300,"['much', 'course', 'discussion', 'center', 'analytic', 'objective', 'stated', 'financial', 'institution', 'usually', 'posse', 'highly', 'detailed', 'data', 'challenging', 'transform', 'structure', 'suitable', 'predictive', 'modeling', 'approach', 'used', 'overcome', 'challenge', 'applicable', 'many', 'domain']"
1181,"Counting the number of events in each group code is the first stratified analysis. The %N macro function performs the calculation. Notice that the INTO= keyword is set equal to the code array and that a new keyword parameter, GROUP=, is introduced. The presence of the group keyword instructs the macro function to stratify by the grouping variable (the group variable must be a positive integer). The results are placed in the CODE array whose dimension must match the number of distinct group indices. After applying the counting function, the results must be exported. The DO loop creates an input named TN_CNT_xxx, where xxx is the group code. Any transactions with group code EXD are excluded from the count.",DM,713,"['counting', 'number', 'event', 'group', 'code', 'first', 'stratified', 'analysis', 'n', 'macro', 'function', 'performs', 'calculation', 'notice', 'keyword', 'set', 'equal', 'code', 'array', 'new', 'keyword', 'parameter', 'group', 'introduced', 'presence', 'group', 'keyword', 'instructs', 'macro', 'function', 'stratify', 'grouping', 'variable', 'group', 'variable', 'must', 'positive', 'integer', 'result', 'placed', 'code', 'array', 'whose', 'dimension', 'must', 'match', 'number', 'distinct', 'group', 'index', 'applying', 'counting', 'function', 'result', 'must', 'exported', 'loop', 'creates', 'input', 'named', 'tncntxxx', 'xxx', 'group', 'code', 'transaction', 'group', 'code', 'exd', 'excluded', 'count']"
1182,"If the relative event date is less than 365 days from the origin, the event is added to the transaction array. The code is similar to previous versions. However, the transaction date is now recorded in relative time. Processing Time-Dependent Data",DM,247,"['relative', 'event', 'date', 'le', '365', 'day', 'origin', 'event', 'added', 'transaction', 'array', 'code', 'similar', 'previous', 'version', 'however', 'transaction', 'date', 'recorded', 'relative', 'time', 'processing', 'timedependent', 'data']"
1183,"There are several possible transformations you can use to tame extreme distributions. The first is simply truncating the input distribution at some value. This is easy to implement for a given input, but it is difficult to automate because the optimal truncation point usually depends on the distribution. Also, it does not completely solve the problem of leverage because there may be still be considerable mass at the truncation point. Another approach is using a regularization transformation such as the log function. This works well as long as the input is strictly positive. If not, then log(x+a) could be used, as long as an a exists such that x + a > 0 for all x. A more clever transformation is the hyperbolic tangent function, tanh(x). This function controls extreme values such as the log function and admits negative values. Of course, the downside of these transformations is the loss of interpretability of the model coefficients, even for standard regression. A third approach is the use of rank transformation to transform even the most extreme distribution to a uniform one. This eliminates the leverage problem, asymptotes the target response, and maintains a degree of interpretability as most people understand rankings (especially in the form of percentiles). Taming Extreme Distributions",DM,1309,"['several', 'possible', 'transformation', 'use', 'tame', 'extreme', 'distribution', 'first', 'simply', 'truncating', 'input', 'distribution', 'value', 'easy', 'implement', 'given', 'input', 'difficult', 'automate', 'optimal', 'truncation', 'point', 'usually', 'depends', 'distribution', 'also', 'doe', 'completely', 'solve', 'problem', 'leverage', 'may', 'still', 'considerable', 'mass', 'truncation', 'point', 'another', 'approach', 'using', 'regularization', 'transformation', 'log', 'function', 'work', 'well', 'long', 'input', 'strictly', 'positive', 'logxa', 'could', 'used', 'long', 'exists', 'x', '', '', '0', 'x', 'clever', 'transformation', 'hyperbolic', 'tangent', 'function', 'tanhx', 'function', 'control', 'extreme', 'value', 'log', 'function', 'admits', 'negative', 'value', 'course', 'downside', 'transformation', 'loss', 'interpretability', 'model', 'coefficient', 'even', 'standard', 'regression', 'third', 'approach', 'use', 'rank', 'transformation', 'transform', 'even', 'extreme', 'distribution', 'uniform', 'one', 'eliminates', 'leverage', 'problem', 'asymptote', 'target', 'response', 'maintains', 'degree', 'interpretability', 'people', 'understand', 'ranking', 'especially', 'form', 'percentile', 'taming', 'extreme', 'distribution']"
1184,"Pathology detection is a combination of knowing what an input should look like and knowing what can harm a predictive model. Because predictive modeling data sets are quite large, analyzing every record is out of the question. However, well- considered descriptive statistics, distributions plots, and frequency tables should provide enough detail for you to know when intervention is needed.",DM,392,"['pathology', 'detection', 'combination', 'knowing', 'input', 'look', 'like', 'knowing', 'harm', 'predictive', 'model', 'predictive', 'modeling', 'data_set', 'quite', 'large', 'analyzing', 'every', 'record', 'question', 'however', 'well', 'considered', 'descriptive', 'statistic', 'distribution', 'plot', 'frequency', 'table', 'provide', 'enough', 'detail', 'know', 'intervention', 'needed']"
1185,"Open the file Using Non-Numeric Data 1.sas in the SAS program editor. This program demonstrates one way to implement threshold-based recoding. The financial institution groups its client by branch region based on the client?s home postal code. The data set DMDP.INPUT_SAMPLE_BRANCH describes each client?s branch region affiliation, five-digit postal code, and target value. ?	To avoid contamination, these values should correspond to measurements taken before the target date.",DM,477,"['open', 'file', 'using', 'nonnumeric', 'data', '1sas', 'sa', 'program', 'editor', 'program', 'demonstrates', 'one', 'way', 'implement', 'thresholdbased', 'recoding', 'financial', 'institution', 'group', 'client', 'branch', 'region', 'based', 'client', 'home', 'postal', 'code', 'data_set', 'dmdpinputsamplebranch', 'describes', 'client', 'branch', 'region', 'affiliation', 'fivedigit', 'postal', 'code', 'target', 'value', '\tto', 'avoid', 'contamination', 'value', 'correspond', 'measurement', 'taken', 'target', 'date']"
1186,"Counting the number of events in each group code is the first stratified analysis. The %N macro function performs the calculation. Notice that the INTO= keyword is set equal to the code array and that a new keyword parameter, GROUP=, is introduced. The presence of the group keyword instructs the macro function to stratify by the grouping variable (the group variable must be a positive integer). The results are placed in the CODE array whose dimension must match the number of distinct group indices. After applying the counting function, the results must be exported. The DO loop creates an input named TN_CNT_xxx, where xxx is the group code. Any transactions with group code EXD are excluded from the count.",DM,713,"['counting', 'number', 'event', 'group', 'code', 'first', 'stratified', 'analysis', 'n', 'macro', 'function', 'performs', 'calculation', 'notice', 'keyword', 'set', 'equal', 'code', 'array', 'new', 'keyword', 'parameter', 'group', 'introduced', 'presence', 'group', 'keyword', 'instructs', 'macro', 'function', 'stratify', 'grouping', 'variable', 'group', 'variable', 'must', 'positive', 'integer', 'result', 'placed', 'code', 'array', 'whose', 'dimension', 'must', 'match', 'number', 'distinct', 'group', 'index', 'applying', 'counting', 'function', 'result', 'must', 'exported', 'loop', 'creates', 'input', 'named', 'tncntxxx', 'xxx', 'group', 'code', 'transaction', 'group', 'code', 'exd', 'excluded', 'count']"
1187,"The augment step creates a data set containing the target date and the checking account open date. The target dates are obtained from the target sample, and the checking account open dates are obtained from the checking account table. The created table is ordered by checking ID for inclusion in subsequent transaction processing.",DM,330,"['augment', 'step', 'creates', 'data_set', 'containing', 'target', 'date', 'checking', 'account', 'open', 'date', 'target', 'date', 'obtained', 'target', 'sample', 'checking', 'account', 'open', 'date', 'obtained', 'checking', 'account', 'table', 'created', 'table', 'ordered', 'checking', 'id', 'inclusion', 'subsequent', 'transaction', 'processing']"
1188,"The next task after settling upon a data access method is selecting qualified responders. In the example, the responders are individuals who have already acquired the insurance product and are henceforth called INS clients. The INS clients are subject to a variety of qualification constraints involving recency of account acquisition, bank tenure, client age, and financial maturity. As the constraints are spread across multiple tables in the marketing warehouse, selecting the INS clients will require creating intermediate tables, preferably close to the RDBMS server.",DM,572,"['next', 'task', 'settling', 'upon', 'data', 'access', 'method', 'selecting', 'qualified', 'responder', 'example', 'responder', 'individual', 'already', 'acquired', 'insurance', 'product', 'henceforth', 'called', 'client', 'client', 'subject', 'variety', 'qualification', 'constraint', 'involving', 'recency', 'account', 'acquisition', 'bank', 'tenure', 'client', 'age', 'financial', 'maturity', 'constraint', 'spread', 'across', 'multiple', 'table', 'marketing', 'warehouse', 'selecting', 'client', 'require', 'creating', 'intermediate', 'table', 'preferably', 'close', 'rdbms', 'server']"
1189,"It is extremely easy to underestimate the scope of the data preparation task. When starting a project, many analysts anticipate ample time to explore a variety of predictive modeling techniques. They are often dismayed to discover that the data preparation activities require a majority of the time allotted. In the worst cases, much of the time is spent acquiring the analysis data from disparate and disorganized sources. Natural projects must be organized to allow ample time for both data preparation and data analysis.",DM,523,"['extremely', 'easy', 'underestimate', 'scope', 'data', 'preparation', 'task', 'starting', 'project', 'many', 'analyst', 'anticipate', 'ample', 'time', 'explore', 'variety', 'predictive', 'modeling', 'technique', 'often', 'dismayed', 'discover', 'data', 'preparation', 'activity', 'require', 'majority', 'time', 'allotted', 'worst', 'case', 'much', 'time', 'spent', 'acquiring', 'analysis', 'data', 'disparate', 'disorganized', 'source', 'natural', 'project', 'must', 'organized', 'allow', 'ample', 'time', 'data', 'preparation', 'data', 'analysis']"
1190,"Knowing what an input should look like helps to detect data errors. Typically, the opportunistic data sets used in predictive models are electronically generated, so ?key-punch? errors are much less common than programming errors. Of course, the number of ways that a program can go wrong is incalculable; however, problems can often be detected by scrutinizing the results and asking if the results make sense. An exhaustive list of what can go wrong is impossible to write, but there are some common signs of coding errors. *	The input range should be checked against expectations. Unexpected negative (or positive) numbers are a sign of trouble. *	A large number of missing values can indicate problems with input transformations. *	Examining the smallest and largest observations can help detect coding errors. *	The overall distribution shape should make sense. *	The cardinality of non-numeric inputs should be verified. *	Frequency counts within categorical levels should be reviewed.",DM,991,"['knowing', 'input', 'look', 'like', 'help', 'detect', 'data', 'error', 'typically', 'opportunistic', 'data_set', 'used', 'predictive', 'model', 'electronically', 'generated', 'keypunch', 'error', 'much', 'le', 'common', 'programming', 'error', 'course', 'number', 'way', 'program', 'go', 'wrong', 'incalculable', 'however', 'problem', 'often', 'detected', 'scrutinizing', 'result', 'asking', 'result', 'make', 'sense', 'exhaustive', 'list', 'go', 'wrong', 'impossible', 'write', 'common', 'sign', 'coding', 'error', '\tthe', 'input', 'range', 'checked', 'expectation', 'unexpected', 'negative', 'positive', 'number', 'sign', 'trouble', '\ta', 'large', 'number', 'missing', 'value', 'indicate', 'problem', 'input', 'transformation', '\texamining', 'smallest', 'largest', 'observation', 'help', 'detect', 'coding', 'error', '\tthe', 'overall', 'distribution', 'shape', 'make', 'sense', '\tthe', 'cardinality', 'nonnumeric', 'input', 'verified', '\tfrequency', 'count', 'within', 'categorical', 'level', 'reviewed']"
1191,Summing the value of events in each group code is the second stratified analysis application. The syntax is virtually identical to the stratified counting example above.,DM,169,"['summing', 'value', 'event', 'group', 'code', 'second', 'stratified', 'analysis', 'application', 'syntax', 'virtually', 'identical', 'stratified', 'counting', 'example']"
1192,"As introduced in Chapter 2, the date corresponding to the measurement of the target variable defines the target date. The target date subsets the time range into interest and latency periods. Model inputs are built from events in the interest period. To avoid input contamination, events in the latency period are excluded.",DM,323,"['introduced', 'chapter', '2', 'date', 'corresponding', 'measurement', 'target', 'variable', 'defines', 'target', 'date', 'target', 'date', 'subset', 'time', 'range', 'interest', 'latency', 'period', 'model', 'input', 'built', 'event', 'interest', 'period', 'avoid', 'input', 'contamination', 'event', 'latency', 'period', 'excluded']"
1193,Merging with the target sample allows the creation of a checking account indicator input. The indicator is 1 when checking transaction events are present for a case and zero otherwise. Finalizing the Transaction Input Data Set,DM,226,"['merging', 'target', 'sample', 'allows', 'creation', 'checking', 'account', 'indicator', 'input', 'indicator', '1', 'checking', 'transaction', 'event', 'present', 'case', 'zero', 'otherwise', 'finalizing', 'transaction', 'input', 'data_set']"
1194,This demonstration continues the application of the Transaction Input Creation 1.sas program. The finalization step is examined here. The goal is to create a transactions input sample for use in predictive modeling. The transaction case input data set contains three rows per checking account.,DM,293,"['demonstration', 'continues', 'application', 'transaction', 'input', 'creation', '1sas', 'program', 'finalization', 'step', 'examined', 'goal', 'create', 'transaction', 'input', 'sample', 'use', 'predictive', 'modeling', 'transaction', 'case', 'input', 'data_set', 'contains', 'three', 'row', 'per', 'checking', 'account']"
1195,"The GENERATE_GROUPING macro is used to create a set of grouping formats. These formats are applied in the process step to facilitate stratified analyses. Three keyword parameters must be specified: FROM=, which indicates the class/group correspondence data set; VALUE=, which indicates the source profile; and GROUP=, which indicates the group code.",DM,349,"['generategrouping', 'macro', 'used', 'create', 'set', 'grouping', 'format', 'format', 'applied', 'process', 'step', 'facilitate', 'stratified', 'analysis', 'three', 'keyword', 'parameter', 'must', 'specified', 'indicates', 'classgroup', 'correspondence', 'data_set', 'value', 'indicates', 'source', 'profile', 'group', 'indicates', 'group', 'code']"
1196,Many of the records have missing values corresponding to unknown zip codes. Remedying these missing values requires taking advantage of another property of zip codes: hierarchy. Imputing Missing Geocode Values,DM,209,"['many', 'record', 'missing', 'value', 'corresponding', 'unknown', 'zip', 'code', 'remedying', 'missing', 'value', 'requires', 'taking', 'advantage', 'another', 'property', 'zip', 'code', 'hierarchy', 'imputing', 'missing', 'geocode', 'value']"
1197,"The read task is modified to include reading of the target date data set, which contains the target date and checking account open date. These dates will be incorporated into the transaction processing to establish case-specific relative time scales.",DM,250,"['read', 'task', 'modified', 'include', 'reading', 'target', 'date', 'data_set', 'contains', 'target', 'date', 'checking', 'account', 'open', 'date', 'date', 'incorporated', 'transaction', 'processing', 'establish', 'casespecific', 'relative', 'time', 'scale']"
1198,"The location of the point mass in synthetic distribution methods is not arbitrary. Ideally, to allow variable selection processes to operate correctly, the synthesized value should be chosen to have minimal impact on the magnitude of an input?s association with the target. For many modeling methods, this can be achieved by locating the point mass at the input?s mean value. Cases with input values equal to the mean value have no influence on the estimation of that input?s model parameters. Because predicted response can be different for cases with a missing input value, a binary imputation indicator variable should also be added to the input sample to allow the model to adjust its predictions.",DM,701,"['location', 'point', 'mass', 'synthetic', 'distribution', 'method', 'arbitrary', 'ideally', 'allow', 'variable', 'selection', 'process', 'operate', 'correctly', 'synthesized', 'value', 'chosen', 'minimal', 'impact', 'magnitude', 'input', 'association', 'target', 'many', 'modeling', 'method', 'achieved', 'locating', 'point', 'mass', 'input', 'mean', 'value', 'case', 'input', 'value', 'equal', 'mean', 'value', 'influence', 'estimation', 'input', 'model', 'parameter', 'predicted', 'response', 'different', 'case', 'missing', 'input', 'value', 'binary', 'imputation', 'indicator', 'variable', 'also', 'added', 'input', 'sample', 'allow', 'model', 'adjust', 'prediction']"
1199,"%generate_grouping(from=work.profile_codes,value=PROFILE,group=CODE); There are seven distinct grouping codes of interest generated from ten profile combinations. All other profile combinations are accommodated by the OTHER profile, which maps to the EXD grouping code. The next block of code includes the declaration of the transaction code index and code arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,459,"['generategroupingfromworkprofilecodesvalueprofilegroupcode', 'seven', 'distinct', 'grouping', 'code', 'interest', 'generated', 'ten', 'profile', 'combination', 'profile', 'combination', 'accommodated', 'profile', 'map', 'exd', 'grouping', 'code', 'next', 'block', 'code', 'includes', 'declaration', 'transaction', 'code', 'index', 'code', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1200,"Lastly, the non-numeric frequency distributions show the levels and case counts for all non-numeric variables with the number of levels less than the specified maximum. By default, the levels of the non-numeric variables are ordered by frequency, from highest to lowest frequency count. ?	The order of the levels can be changed to alphabetical by specifying the keyword option FREQ_LEVELS=N in the %DISTRIBUTION macro invocation.",DM,429,"['lastly', 'nonnumeric', 'frequency', 'distribution', 'show', 'level', 'case', 'count', 'nonnumeric', 'variable', 'number', 'level', 'le', 'specified', 'maximum', 'default', 'level', 'nonnumeric', 'variable', 'ordered', 'frequency', 'highest', 'lowest', 'frequency', 'count', '\tthe', 'order', 'level', 'changed', 'alphabetical', 'specifying', 'keyword', 'option', 'freqlevelsn', 'distribution', 'macro', 'invocation']"
1201,"Examples of non-numeric data abound in predictive modeling applications. The focus is capturing the qualities of an entity rather than quantities. Ironically, from a modeling perspective the most important quality of non-numeric data is, in fact, a quantity: cardinality. Here, cardinality refers to the number of distinct levels of a non-numeric variable. Using non-numeric data in predictive models increases in difficulty with the cardinality. This chapter introduces strategies for overcoming some of these difficulties.",DM,524,"['example', 'nonnumeric', 'data', 'abound', 'predictive', 'modeling', 'application', 'focus', 'capturing', 'quality', 'entity', 'rather', 'quantity', 'ironically', 'modeling', 'perspective', 'important', 'quality', 'nonnumeric', 'data', 'fact', 'quantity', 'cardinality', 'cardinality', 'refers', 'number', 'distinct', 'level', 'nonnumeric', 'variable', 'using', 'nonnumeric', 'data', 'predictive', 'model', 'increase', 'difficulty', 'cardinality', 'chapter', 'introduces', 'strategy', 'overcoming', 'difficulty']"
1202,"A simple but effective remedy for overgeneralization is thresholding?that is, requiring a minimum number of cases in a level before creating a dummy code input. Any level failing to meet this minimum threshold is relegated to a new level called OTHER. By reducing the number of inputs available to a model, thresholding limits the model?s ability to ?discover? spurious input-target associations.",DM,396,"['simple', 'effective', 'remedy', 'overgeneralization', 'thresholdingthat', 'requiring', 'minimum', 'number', 'case', 'level', 'creating', 'dummy', 'code', 'input', 'level', 'failing', 'meet', 'minimum', 'threshold', 'relegated', 'new', 'level', 'called', 'reducing', 'number', 'input', 'available', 'model', 'thresholding', 'limit', 'model', 'ability', 'discover', 'spurious', 'inputtarget', 'association']"
1203,"The temporary transaction arrays are containers for the complete event history of a given case. The maximum records per case macro variable, defined at the start of the transaction transformation process, must be larger than the maximum number of events for each case.",DM,268,"['temporary', 'transaction', 'array', 'container', 'complete', 'event', 'history', 'given', 'case', 'maximum', 'record', 'per', 'case', 'macro', 'variable', 'defined', 'start', 'transaction', 'transformation', 'process', 'must', 'larger', 'maximum', 'number', 'event', 'case']"
1204,"Postal codes are non-numeric inputs with cardinalities several orders of magnitude greater than those considered in the previous section. As such, they are ill suited for the recoding techniques discussed there and are often ignored in predictive modeling applications. Because the codes have a meaning transcendent of the data, namely location, it is possible to make a meaning transformation of the codes to useful inputs.",DM,424,"['postal', 'code', 'nonnumeric', 'input', 'cardinality', 'several', 'order', 'magnitude', 'greater', 'considered', 'previous', 'section', 'ill', 'suited', 'recoding', 'technique', 'discussed', 'often', 'ignored', 'predictive', 'modeling', 'application', 'code', 'meaning', 'transcendent', 'data', 'namely', 'location', 'possible', 'make', 'meaning', 'transformation', 'code', 'useful', 'input']"
1205,"In general, tabulation functions are the fastest, followed by distributional functions, and finally order statistics (exceptions are the %MIN and %MAX functions, which are in fact the fastest of all the transaction macros). Using Transaction Macros",DM,248,"['general', 'tabulation', 'function', 'fastest', 'followed', 'distributional', 'function', 'finally', 'order', 'statistic', 'exception', 'min', 'max', 'function', 'fact', 'fastest', 'transaction', 'macro', 'using', 'transaction', 'macro']"
1206,Summing the value of events in each group code is the second stratified analysis application. The syntax is virtually identical to the stratified counting example above.,DM,169,"['summing', 'value', 'event', 'group', 'code', 'second', 'stratified', 'analysis', 'application', 'syntax', 'virtually', 'identical', 'stratified', 'counting', 'example']"
1207,"The method you use to access the raw operational data depends on the data?s format and the tools at your disposal. Accessing data in a text or binary file independent of a RDBMS system is often performed by DATA step programming or, in the case of certain file formats, the IMPORT procedure. When the raw operational data is contained within a RDBMS system, you can use SAS/ACCESS products to read and operate on the data as if it were a SAS data set. SAS/ACCESS products also enable you to pass through RDBMS- specific queries that operate completely on the RDDMS server and might utilize functions not available in SAS.",DM,621,"['method', 'use', 'access', 'raw', 'operational', 'data', 'depends', 'data', 'format', 'tool', 'disposal', 'accessing', 'data', 'text', 'binary', 'file', 'independent', 'rdbms', 'system', 'often', 'performed', 'data', 'step', 'programming', 'case', 'certain', 'file', 'format', 'import', 'procedure', 'raw', 'operational', 'data', 'contained', 'within', 'rdbms', 'system', 'use', 'sasaccess', 'product', 'read', 'operate', 'data', 'sa', 'data_set', 'sasaccess', 'product', 'also', 'enable', 'pas', 'rdbms', 'specific', 'query', 'operate', 'completely', 'rddms', 'server', 'might', 'utilize', 'function', 'available', 'sa']"
1208,"The %DISTRIBUTION macro has two main components: one for numeric variables and one for non-numeric variables. The numeric component centers on the UNIVARITATE procedure, and the non-numeric component centers on the FREQ procedure. The macro has one required keyword parameter, DATA=, and six optional keyword parameters: VARS=, CATVARS=, OUT=, CONTENTS=, FREQ_LEVELS=, and MAX_LEVELS=. %macro distribution(vars=,catvars=,data=, out=LISTING, contents=NO, freq_levels=Y, max_levels=100); DATA=, the lone required parameter, specifies the name of the source data containing the variables of interest. VARS= specifies the variables to analyze from DATA=. Omitting a value for VARS= results in a distribution report for all variables. CATVARS= specifies the names of numeric variables that should be subject to non-numeric analysis. Omission of CATVARS= results in character variables being treated as non-numeric variables. OUT= specifies the destination of the analysis. The destination can be a quoted pdf file location or OUTPUT (the default value). Specifying OUTPUT as the destination results in result table being directed to the Output window and distribution plots being directed to the Graph window. FREQ_LEVELS= specifies the order of levels presented in non-numeric distribution tables. The default value, Y, causes the levels to be ordered by frequency counts (from highest to lowest). A value of N causes the levels to be ordered alphabetically. MAX_LEVELS= specifies the maximum cardinality for distribution summaries. Variables with cardinality higher than the specified value are omitted from the distribution analysis. Details The macro opens with a specification of landscape orientation. options orientation=landscape;",DM,1733,"['distribution', 'macro', 'ha', 'two', 'main', 'component', 'one', 'numeric', 'variable', 'one', 'nonnumeric', 'variable', 'numeric', 'component', 'center', 'univaritate', 'procedure', 'nonnumeric', 'component', 'center', 'freq', 'procedure', 'macro', 'ha', 'one', 'required', 'keyword', 'parameter', 'data', 'six', 'optional', 'keyword', 'parameter', 'var', 'catvars', 'content', 'freqlevels', 'maxlevels', 'macro', 'distributionvarscatvarsdata', 'outlisting', 'contentsno', 'freqlevelsy', 'maxlevels100', 'data', 'lone', 'required', 'parameter', 'specifies', 'name', 'source', 'data', 'containing', 'variable', 'interest', 'var', 'specifies', 'variable', 'analyze', 'data', 'omitting', 'value', 'var', 'result', 'distribution', 'report', 'variable', 'catvars', 'specifies', 'name', 'numeric', 'variable', 'subject', 'nonnumeric', 'analysis', 'omission', 'catvars', 'result', 'character', 'variable', 'treated', 'nonnumeric', 'variable', 'specifies', 'destination', 'analysis', 'destination', 'quoted', 'pdf', 'file', 'location', 'output', 'default', 'value', 'specifying', 'output', 'destination', 'result', 'result', 'table', 'directed', 'output', 'window', 'distribution', 'plot', 'directed', 'graph', 'window', 'freqlevels', 'specifies', 'order', 'level', 'presented', 'nonnumeric', 'distribution', 'table', 'default', 'value', 'cause', 'level', 'ordered', 'frequency', 'count', 'highest', 'lowest', 'value', 'n', 'cause', 'level', 'ordered', 'alphabetically', 'maxlevels', 'specifies', 'maximum', 'cardinality', 'distribution', 'summary', 'variable', 'cardinality', 'higher', 'specified', 'value', 'omitted', 'distribution', 'analysis', 'detail', 'macro', 'open', 'specification', 'landscape', 'orientation', 'option', 'orientationlandscape']"
1209,Time trends in transactions are useful for predicting future events. This final modification to the event processing code demonstrates one way in which balance trends can be identified.,DM,185,"['time', 'trend', 'transaction', 'useful', 'predicting', 'future', 'event', 'final', 'modification', 'event', 'processing', 'code', 'demonstrates', 'one', 'way', 'balance', 'trend', 'identified']"
1210,"To aid discussion of transaction data, several terms and concepts are now introduced. The analytic objective usually restricts transaction data to a particular time range. Records in this time range are called events.",DM,217,"['aid', 'discussion', 'transaction', 'data', 'several', 'term', 'concept', 'introduced', 'analytic', 'objective', 'usually', 'restricts', 'transaction', 'data', 'particular', 'time', 'range', 'record', 'time', 'range', 'called', 'event']"
1211,The TN_CODE_IDX array is used to capture the grouping code indices of each transaction event. The transaction code indices are generated by translating the raw profile to a grouping code and the grouping code to an index.,DM,221,"['tncodeidx', 'array', 'used', 'capture', 'grouping', 'code', 'index', 'transaction', 'event', 'transaction', 'code', 'index', 'generated', 'translating', 'raw', 'profile', 'grouping', 'code', 'grouping', 'code', 'index']"
1212,"?	Because non-INS clients do not have an INS account, there is no account open date column. This lack of target date for nonresponse cases is a common source of data contamination and must be dealt with carefully. A method for establishing a target date for nonresponse cases is discussed in the last section of this chapter. The final task is to join the INS and non-INS qualified client tables. create table joined_sample as 	select *, 1 as INS from ins_clients_qualified 	outer union corresponding select *, 0 as INS from non_ins_clients_qualified; The outer union corresponding function joins the two tables and consolidates identical columns. This can be seen if you browse the JOINED_SAMPLE data set. Note the addition of a column INS to the joined sample. This column will ultimately serve as the predictive modeling target.",DM,831,"['\tbecause', 'nonins', 'client', 'account', 'account', 'open', 'date', 'column', 'lack', 'target', 'date', 'nonresponse', 'case', 'common', 'source', 'data', 'contamination', 'must', 'dealt', 'carefully', 'method', 'establishing', 'target', 'date', 'nonresponse', 'case', 'discussed', 'last', 'section', 'chapter', 'final', 'task', 'join', 'nonins', 'qualified', 'client', 'table', 'create', 'table', 'joinedsample', '\tselect', '', '1', 'insclientsqualified', '\touter', 'union', 'corresponding', 'select', '', '0', 'noninsclientsqualified', 'outer', 'union', 'corresponding', 'function', 'join', 'two', 'table', 'consolidates', 'identical', 'column', 'seen', 'browse', 'joinedsample', 'data_set', 'note', 'addition', 'column', 'joined', 'sample', 'column', 'ultimately', 'serve', 'predictive', 'modeling', 'target']"
1213,"A new process variable, R_OPEN_DT, is declared and retained. R_OPEN_DT will give the checking account open date in relative time. A negative value indicates a checking account open date after the target date minus latency.",DM,222,"['new', 'process', 'variable', 'ropendt', 'declared', 'retained', 'ropendt', 'give', 'checking', 'account', 'open', 'date', 'relative', 'time', 'negative', 'value', 'indicates', 'checking', 'account', 'open', 'date', 'target', 'date', 'minus', 'latency']"
1214,The rank transformation is attractive in that it completely eliminates input skewness by transforming any numeric input to an almost uniform distribution. (The spike in the 10th percentile is caused by the set of cases with CC_BAL_AVG=0.),DM,238,"['rank', 'transformation', 'attractive', 'completely', 'eliminates', 'input', 'skewness', 'transforming', 'numeric', 'input', 'almost', 'uniform', 'distribution', 'spike', '10th', 'percentile', 'caused', 'set', 'case', 'ccbalavg0']"
1215,"To fully appreciate the effect of leverage points and the benefits of regularization transformations, consider the plot above. It shows a standard logistic regression model fit to original and three transformed inputs. The untransformed model appears to show a relatively substantial association between CC_AVG_BAL and INS. In the threshold transformed input, the association largely disappears. For the log and rank transformed inputs, it is seen to be non-existent. Using the %RANK_TRANS Macro",DM,495,"['fully', 'appreciate', 'effect', 'leverage', 'point', 'benefit', 'regularization', 'transformation', 'consider', 'plot', 'show', 'standard', 'logistic_regression_model', 'fit', 'original', 'three', 'transformed', 'input', 'untransformed', 'model', 'appears', 'show', 'relatively', 'substantial', 'association', 'ccavgbal', 'threshold', 'transformed', 'input', 'association', 'largely', 'disappears', 'log', 'rank', 'transformed', 'input', 'seen', 'nonexistent', 'using', 'ranktrans', 'macro']"
1216,"All activities in this course center on transforming operational data into a model development data set. A model development data set consists of independent rows of data called modeling cases and four types of columns: IDs, targets, target dates, and inputs. Each modeling case can correspond to hundreds of records in the operational data.",DM,341,"['activity', 'course', 'center', 'transforming', 'operational', 'data', 'model', 'development', 'data_set', 'model', 'development', 'data_set', 'consists', 'independent', 'row', 'data', 'called', 'modeling', 'case', 'four', 'type', 'column', 'id', 'target', 'target', 'date', 'input', 'modeling', 'case', 'correspond', 'hundred', 'record', 'operational', 'data']"
1217,"There are many challenges to be faced in the data preparation process. Six of the most important are listed above, in informal terms. Clarification follows on the next slide.",DM,174,"['many', 'challenge', 'faced', 'data', 'preparation', 'process', 'six', 'important', 'listed', 'informal', 'term', 'clarification', 'follows', 'next', 'slide']"
1218,"%distribution(data=&data,out=&report_name,contents=Y,max_levels=120); The %DISTRIBUTION macro is called with the DATA= parameter pointing to the aforementioned data set. The OUT= parameter specifies the location of the PDF report to be generated by the macro. ?	Omission of a report name?or, more specifically, a quoted path pointing to a *.pdf file?results in the macro sending all output to the Graph and Listing windows. The CONTENTS= parameter requests the macro to produce a CONTENTS procedure summary of the specified data set. The MAX_LEVELS= parameter limits the display of non-numeric distributions to those variables with cardinality less than the specified number. The generated report is partitioned into five sections: 1.	data set attributes. 2.	variable listing. 3.	numeric distributions. 4.	cardinality report. 5.	non-numeric frequency distributions. The data set attributes section is generated by the CONTENTS procedure and gives general facts about the selected data set.",DM,989,"['distributiondatadataoutreportnamecontentsymaxlevels120', 'distribution', 'macro', 'called', 'data', 'parameter', 'pointing', 'aforementioned', 'data_set', 'parameter', 'specifies', 'location', 'pdf', 'report', 'generated', 'macro', '\tomission', 'report', 'nameor', 'specifically', 'quoted', 'path', 'pointing', 'pdf', 'fileresults', 'macro', 'sending', 'output', 'graph', 'listing', 'window', 'content', 'parameter', 'request', 'macro', 'produce', 'content', 'procedure', 'summary', 'specified', 'data_set', 'maxlevels', 'parameter', 'limit', 'display', 'nonnumeric', 'distribution', 'variable', 'cardinality', 'le', 'specified', 'number', 'generated', 'report', 'partitioned', 'five', 'section', '1\tdata', 'set', 'attribute', '2\tvariable', 'listing', '3\tnumeric', 'distribution', '4\tcardinality', 'report', '5\tnonnumeric', 'frequency', 'distribution', 'data_set', 'attribute', 'section', 'generated', 'content', 'procedure', 'give', 'general', 'fact', 'selected', 'data_set']"
1219,"Any analytic objective involving predictive modeling starts with extraction and transformation of data from remote sources. The level of effort required for this first step is easy to underestimate and is often fraught with difficulties. First, useful data might not exist. For example, a business that wants to predict product failure might collect a large amount of data describing the particulars of defective products, but not record similar information for nondefective products. Even when data exists, it can be impossible to utilize it without violating privacy rules. For example, the Health Insurance Portability and Accountability Act of 1996 prohibits insurance companies from using data used for processing medical claims to underwrite other products, such as life insurance. Assuming that data is available and allowed, useful information is often spread across many disparate sources. Even when data is well organized, the normalized database design disperses information across many tables. For example, a typical marketing data warehouse contains dozens of tables with direct links to dozens more. Because detail tables provide the most insight into customer behavior, they are most valuable for predictive modeling. Yet a single customer can generate thousands of records over the course of a year. Moving these large volumes of data across networks can dramatically slow the data preparation process. Predictive models are often built from a target variable corresponding to a (binary) classification. This classification, in turn, relates to characteristics stored in a database. Success in achieving an analytic objective hinges on a relevant and unambiguous statement of the characteristics corresponding to each class. Without such a statement, it is difficult to extract meaningful modeling data. For example, banks construct risk scores based on the classification of known customers into ?good? and ?bad? credit risks. The precise definition of good and bad risk, however, is somewhat ambiguous and must be agreed upon in advanced. Even when data is available, useable, tractable, and explicable, the largest data extraction challenge remains: drawing an uncontaminated modeling sample. Avoiding the unintentional leakage of target information into the modeling inputs is a recurring theme in this course and the bane of all data mining efforts.",DM,2370,"['analytic', 'objective', 'involving', 'predictive', 'modeling', 'start', 'extraction', 'transformation', 'data', 'remote', 'source', 'level', 'effort', 'required', 'first', 'step', 'easy', 'underestimate', 'often', 'fraught', 'difficulty', 'first', 'useful', 'data', 'might', 'exist', 'example', 'business', 'want', 'predict', 'product', 'failure', 'might', 'collect', 'large', 'amount', 'data', 'describing', 'particular', 'defective', 'product', 'record', 'similar', 'information', 'nondefective', 'product', 'even', 'data', 'exists', 'impossible', 'utilize', 'without', 'violating', 'privacy', 'rule', 'example', 'health', 'insurance', 'portability', 'accountability', 'act', '1996', 'prohibits', 'insurance', 'company', 'using', 'data', 'used', 'processing', 'medical', 'claim', 'underwrite', 'product', 'life', 'insurance', 'assuming', 'data', 'available', 'allowed', 'useful', 'information', 'often', 'spread', 'across', 'many', 'disparate', 'source', 'even', 'data', 'well', 'organized', 'normalized', 'database', 'design', 'disperses', 'information', 'across', 'many', 'table', 'example', 'typical', 'marketing', 'data', 'warehouse', 'contains', 'dozen', 'table', 'direct', 'link', 'dozen', 'detail', 'table', 'provide', 'insight', 'customer', 'behavior', 'valuable', 'predictive', 'modeling', 'yet', 'single', 'customer', 'generate', 'thousand', 'record', 'course', 'year', 'moving', 'large', 'volume', 'data', 'across', 'network', 'dramatically', 'slow', 'data', 'preparation', 'process', 'predictive', 'model', 'often', 'built', 'target', 'variable', 'corresponding', 'binary', 'classification', 'classification', 'turn', 'relates', 'characteristic', 'stored', 'database', 'success', 'achieving', 'analytic', 'objective', 'hinge', 'relevant', 'unambiguous', 'statement', 'characteristic', 'corresponding', 'class', 'without', 'statement', 'difficult', 'extract', 'meaningful', 'modeling', 'data', 'example', 'bank', 'construct', 'risk', 'score', 'based', 'classification', 'known', 'customer', 'good', 'bad', 'credit', 'risk', 'precise', 'definition', 'good', 'bad', 'risk', 'however', 'somewhat', 'ambiguous', 'must', 'agreed', 'upon', 'advanced', 'even', 'data', 'available', 'useable', 'tractable', 'explicable', 'largest', 'data', 'extraction', 'challenge', 'remains', 'drawing', 'uncontaminated', 'modeling', 'sample', 'avoiding', 'unintentional', 'leakage', 'target', 'information', 'modeling', 'input', 'recurring', 'theme', 'course', 'bane', 'data', 'mining', 'effort']"
1220,The MEANS procedure is used to find the minimum and mean of each variable and rank group combination. This table will be used to form the rank formats. proc means data=rtranspose noprint; by VARNAME R_VALUE; output out=mrtranspose min=min mean=mean; run;,DM,254,"['mean', 'procedure', 'used', 'find', 'minimum', 'mean', 'variable', 'rank', 'group', 'combination', 'table', 'used', 'form', 'rank', 'format', 'proc', 'mean', 'datartranspose', 'noprint', 'varname', 'rvalue', 'output', 'outmrtranspose', 'minmin', 'meanmean', 'run']"
1221,"The whimsical portrayals translate to issues well known to data miners. As data collection and storage costs decrease, analytic data sets grow larger and larger. When processing the data, it is easy to introduce artificial input/target associations by ignoring the temporal aspects of data. The most useful data describes the actions individuals take, which are recorded as transactions and events. To use this transaction data in a model, it must be transformed and summarized into a single record per case. Nonnumeric data requires specially treatment for inclusion in a model. However, the traditional approach of creating dummy variables for such data, often severely degrades model performance. Inputs with exceptional, extreme, or missing values pose many challenges to model performance. Finally, stationarity, the assumption that the world in which the model will be deployed resembles the world from which the model was built, must constantly guide the data preparation process.",DM,987,"['whimsical', 'portrayal', 'translate', 'issue', 'well', 'known', 'data', 'miner', 'data', 'collection', 'storage', 'cost', 'decrease', 'analytic', 'data_set', 'grow', 'larger', 'larger', 'processing', 'data', 'easy', 'introduce', 'artificial', 'inputtarget', 'association', 'ignoring', 'temporal', 'aspect', 'data', 'useful', 'data', 'describes', 'action', 'individual', 'take', 'recorded', 'transaction', 'event', 'use', 'transaction', 'data', 'model', 'must', 'transformed', 'summarized', 'single', 'record', 'per', 'case', 'nonnumeric', 'data', 'requires', 'specially', 'treatment', 'inclusion', 'model', 'however', 'traditional', 'approach', 'creating', 'dummy', 'variable', 'data', 'often', 'severely', 'degrades', 'model', 'performance', 'input', 'exceptional', 'extreme', 'missing', 'value', 'pose', 'many', 'challenge', 'model', 'performance', 'finally', 'stationarity', 'assumption', 'world', 'model', 'deployed', 'resembles', 'world', 'model', 'wa', 'built', 'must', 'constantly', 'guide', 'data', 'preparation', 'process']"
1222,"To avoid input sample contamination, a target date should be included in the target sample. This ensures that all input measurements are made before the target event, avoiding temporal infidelity. For INS clients the target date is obviously the account open date. For non-INS clients this date is undefined. This section demonstrates a method by which a meaningful target date can be established for non-INS clients.",DM,417,"['avoid', 'input', 'sample', 'contamination', 'target', 'date', 'included', 'target', 'sample', 'ensures', 'input', 'measurement', 'made', 'target', 'event', 'avoiding', 'temporal', 'infidelity', 'client', 'target', 'date', 'obviously', 'account', 'open', 'date', 'nonins', 'client', 'date', 'undefined', 'section', 'demonstrates', 'method', 'meaningful', 'target', 'date', 'established', 'nonins', 'client']"
1223,The events in the period of interest can be stratified by time or transaction class variables. The events within each stratum can be thought of as measurements of a random variable. Descriptive statistics of these random variable distributions generate additional model inputs.,DM,277,"['event', 'period', 'interest', 'stratified', 'time', 'transaction', 'class', 'variable', 'event', 'within', 'stratum', 'thought', 'measurement', 'random', 'variable', 'descriptive', 'statistic', 'random', 'variable', 'distribution', 'generate', 'additional', 'model', 'input']"
1224,"Transaction events often serve as increments to a fixed value such as an account balance. Properties of account balances over time are often of great interest to the modeler. The existing framework can be modified to analyze account balance as a time series. In this way, properties such as average account balance, account volatility, and, later, balance trends can be used as inputs for predictive models.",DM,407,"['transaction', 'event', 'often', 'serve', 'increment', 'fixed', 'value', 'account', 'balance', 'property', 'account', 'balance', 'time', 'often', 'great', 'interest', 'modeler', 'existing', 'framework', 'modified', 'analyze', 'account', 'balance', 'time', 'series', 'way', 'property', 'average', 'account', 'balance', 'account', 'volatility', 'later', 'balance', 'trend', 'used', 'input', 'predictive', 'model']"
1225,"Weight of evidence recoding is sometimes combined with dummy coding approaches. In this hybrid approach, the weights of evidence are used to cluster variable levels. The number of levels after clustering is usually small enough to dummy code. There are close connections between this approach and decision tree models.",DM,318,"['weight', 'evidence', 'recoding', 'sometimes', 'combined', 'dummy', 'coding', 'approach', 'hybrid', 'approach', 'weight', 'evidence', 'used', 'cluster', 'variable', 'level', 'number', 'level', 'clustering', 'usually', 'small', 'enough', 'dummy', 'code', 'close', 'connection', 'approach', 'decision', 'tree', 'model']"
1226,"*	Temporal infidelity occurs when model inputs contain information that will be unavailable at the time the prediction model is deployed. Including an individual?s current credit score in a model to predict a past event like bankruptcy is a case of temporal infidelity. Individual specific data before the event of interest is needed for accurate prediction. *	Hidden or deterministic rules sometimes plague predictive models. For example, a model used to identify customers interested in a credit card protection product could be built from customers with and without the product. However, unbeknownst to the analyst, all credit card customers automatically received the product as part of a special promotion. These customers should be excluded from the analysis, but identifying them can be problematic. *	Temporal factors affect the distribution of modeling data in unaccountable ways. A fundamental assumption of predictive modeling is stationarity?that is, the data from which the models are built looks more or less like the data to which the models will be applied. Macroeconomic factors often cast doubt on such assumptions. For example, a loan prepayment model built from data when interest rates are falling may be of little use when interest rates stabilize or begin to climb. *	Sampling errors, the most insidious problem, can contaminate model data. Creation of modeling data involves the manipulation and transformation of possibly hundreds of data sets. Mistakes at any stage can introduce noise or correlations that corrupt model predictions.",DM,1559,"['\ttemporal', 'infidelity', 'occurs', 'model', 'input', 'contain', 'information', 'unavailable', 'time', 'prediction', 'model', 'deployed', 'including', 'individual', 'current', 'credit', 'score', 'model', 'predict', 'past', 'event', 'like', 'bankruptcy', 'case', 'temporal', 'infidelity', 'individual', 'specific', 'data', 'event', 'interest', 'needed', 'accurate', 'prediction', '\thidden', 'deterministic', 'rule', 'sometimes', 'plague', 'predictive', 'model', 'example', 'model', 'used', 'identify', 'customer', 'interested', 'credit', 'card', 'protection', 'product', 'could', 'built', 'customer', 'without', 'product', 'however', 'unbeknownst', 'analyst', 'credit', 'card', 'customer', 'automatically', 'received', 'product', 'part', 'special', 'promotion', 'customer', 'excluded', 'analysis', 'identifying', 'problematic', '\ttemporal', 'factor', 'affect', 'distribution', 'modeling', 'data', 'unaccountable', 'way', 'fundamental', 'assumption', 'predictive', 'modeling', 'stationaritythat', 'data', 'model', 'built', 'look', 'le', 'like', 'data', 'model', 'applied', 'macroeconomic', 'factor', 'often', 'cast', 'doubt', 'assumption', 'example', 'loan', 'prepayment', 'model', 'built', 'data', 'interest', 'rate', 'falling', 'may', 'little', 'use', 'interest', 'rate', 'stabilize', 'begin', 'climb', '\tsampling', 'error', 'insidious', 'problem', 'contaminate', 'model', 'data', 'creation', 'modeling', 'data', 'involves', 'manipulation', 'transformation', 'possibly', 'hundred', 'data_set', 'mistake', 'stage', 'introduce', 'noise', 'correlation', 'corrupt', 'model', 'prediction']"
1227,A specific data preparation challenge is the target date possibly establishing a unique relative time scale for every case in the data set. This makes SQL processing of the data virtually impossible and necessitates the use of the SAS DATA step. Processing with the DATA step implies that the data must reside on the analysis server and not the warehouse server. Site-specific strategies must be adopted to make this transfer possible.,DM,435,"['specific', 'data', 'preparation', 'challenge', 'target', 'date', 'possibly', 'establishing', 'unique', 'relative', 'time', 'scale', 'every', 'case', 'data_set', 'make', 'sql', 'processing', 'data', 'virtually', 'impossible', 'necessitates', 'use', 'sa', 'data', 'step', 'processing', 'data', 'step', 'implies', 'data', 'must', 'reside', 'analysis', 'server', 'warehouse', 'server', 'sitespecific', 'strategy', 'must', 'adopted', 'make', 'transfer', 'possible']"
1228,"Postal codes are non-numeric inputs with cardinalities several orders of magnitude greater than those considered in the previous section. As such, they are ill suited for the recoding techniques discussed there and are often ignored in predictive modeling applications. Because the codes have a meaning transcendent of the data, namely location, it is possible to make a meaning transformation of the codes to useful inputs.",DM,424,"['postal', 'code', 'nonnumeric', 'input', 'cardinality', 'several', 'order', 'magnitude', 'greater', 'considered', 'previous', 'section', 'ill', 'suited', 'recoding', 'technique', 'discussed', 'often', 'ignored', 'predictive', 'modeling', 'application', 'code', 'meaning', 'transcendent', 'data', 'namely', 'location', 'possible', 'make', 'meaning', 'transformation', 'code', 'useful', 'input']"
1229,Most predictive modeling tools require a case to be complete (no missing values in any selected input) for inclusion in the model fitting process and for generation of predicted values in model deployment. Even a relatively small proportion of missing values within individual inputs can result in the loss of a substantial fraction of the training data when many inputs are combined in model fitting.,DM,401,"['predictive', 'modeling', 'tool', 'require', 'case', 'complete', 'missing', 'value', 'selected', 'input', 'inclusion', 'model', 'fitting', 'process', 'generation', 'predicted', 'value', 'model', 'deployment', 'even', 'relatively', 'small', 'proportion', 'missing', 'value', 'within', 'individual', 'input', 'result', 'loss', 'substantial', 'fraction', 'training', 'data', 'many', 'input', 'combined', 'model', 'fitting']"
1230,"Of course, the events occur across time, which immediately suggests time series analysis. Time averages and trends are excellent summaries of case behavior, as are measures of time series variability. The demonstrations in the chapter illustrate creation of each of these types of inputs. Macro functions are provided to allow for straightforward (if not easy) implementation of these techniques on your own data.",DM,413,"['course', 'event', 'occur', 'across', 'time', 'immediately', 'suggests', 'time', 'series', 'analysis', 'time', 'average', 'trend', 'excellent', 'summary', 'case', 'behavior', 'measure', 'time', 'series', 'variability', 'demonstration', 'chapter', 'illustrate', 'creation', 'type', 'input', 'macro', 'function', 'provided', 'allow', 'straightforward', 'easy', 'implementation', 'technique', 'data']"
1231,"Weight of evidence recoding is sometimes combined with dummy coding approaches. In this hybrid approach, the weights of evidence are used to cluster variable levels. The number of levels after clustering is usually small enough to dummy code. There are close connections between this approach and decision tree models.",DM,318,"['weight', 'evidence', 'recoding', 'sometimes', 'combined', 'dummy', 'coding', 'approach', 'hybrid', 'approach', 'weight', 'evidence', 'used', 'cluster', 'variable', 'level', 'number', 'level', 'clustering', 'usually', 'small', 'enough', 'dummy', 'code', 'close', 'connection', 'approach', 'decision', 'tree', 'model']"
1232,The TRANSPOSE procedure completes the first finalization task by rearranging the transaction case input data set. The output data set has a single row per case with the transaction inputs defining the columns.,DM,209,"['transpose', 'procedure', 'completes', 'first', 'finalization', 'task', 'rearranging', 'transaction', 'case', 'input', 'data_set', 'output', 'data_set', 'ha', 'single', 'row', 'per', 'case', 'transaction', 'input', 'defining', 'column']"
1233,"A simpler, and arguably more effective, approach is to transform offending inputs to less extreme forms and build models on these transformed inputs. This not only reduces the influence of extreme cases, but it also creates an asymptotic association between input and target on the original input scale.",DM,303,"['simpler', 'arguably', 'effective', 'approach', 'transform', 'offending', 'input', 'le', 'extreme', 'form', 'build', 'model', 'transformed', 'input', 'reduces', 'influence', 'extreme', 'case', 'also', 'creates', 'asymptotic', 'association', 'input', 'target', 'original', 'input', 'scale']"
1234,"The %DISTRIBUTION macro has two main components: one for numeric variables and one for non-numeric variables. The numeric component centers on the UNIVARITATE procedure, and the non-numeric component centers on the FREQ procedure. The macro has one required keyword parameter, DATA=, and six optional keyword parameters: VARS=, CATVARS=, OUT=, CONTENTS=, FREQ_LEVELS=, and MAX_LEVELS=. %macro distribution(vars=,catvars=,data=, out=LISTING, contents=NO, freq_levels=Y, max_levels=100); DATA=, the lone required parameter, specifies the name of the source data containing the variables of interest. VARS= specifies the variables to analyze from DATA=. Omitting a value for VARS= results in a distribution report for all variables. CATVARS= specifies the names of numeric variables that should be subject to non-numeric analysis. Omission of CATVARS= results in character variables being treated as non-numeric variables. OUT= specifies the destination of the analysis. The destination can be a quoted pdf file location or OUTPUT (the default value). Specifying OUTPUT as the destination results in result table being directed to the Output window and distribution plots being directed to the Graph window. FREQ_LEVELS= specifies the order of levels presented in non-numeric distribution tables. The default value, Y, causes the levels to be ordered by frequency counts (from highest to lowest). A value of N causes the levels to be ordered alphabetically. MAX_LEVELS= specifies the maximum cardinality for distribution summaries. Variables with cardinality higher than the specified value are omitted from the distribution analysis. Details The macro opens with a specification of landscape orientation. options orientation=landscape;",DM,1733,"['distribution', 'macro', 'ha', 'two', 'main', 'component', 'one', 'numeric', 'variable', 'one', 'nonnumeric', 'variable', 'numeric', 'component', 'center', 'univaritate', 'procedure', 'nonnumeric', 'component', 'center', 'freq', 'procedure', 'macro', 'ha', 'one', 'required', 'keyword', 'parameter', 'data', 'six', 'optional', 'keyword', 'parameter', 'var', 'catvars', 'content', 'freqlevels', 'maxlevels', 'macro', 'distributionvarscatvarsdata', 'outlisting', 'contentsno', 'freqlevelsy', 'maxlevels100', 'data', 'lone', 'required', 'parameter', 'specifies', 'name', 'source', 'data', 'containing', 'variable', 'interest', 'var', 'specifies', 'variable', 'analyze', 'data', 'omitting', 'value', 'var', 'result', 'distribution', 'report', 'variable', 'catvars', 'specifies', 'name', 'numeric', 'variable', 'subject', 'nonnumeric', 'analysis', 'omission', 'catvars', 'result', 'character', 'variable', 'treated', 'nonnumeric', 'variable', 'specifies', 'destination', 'analysis', 'destination', 'quoted', 'pdf', 'file', 'location', 'output', 'default', 'value', 'specifying', 'output', 'destination', 'result', 'result', 'table', 'directed', 'output', 'window', 'distribution', 'plot', 'directed', 'graph', 'window', 'freqlevels', 'specifies', 'order', 'level', 'presented', 'nonnumeric', 'distribution', 'table', 'default', 'value', 'cause', 'level', 'ordered', 'frequency', 'count', 'highest', 'lowest', 'value', 'n', 'cause', 'level', 'ordered', 'alphabetically', 'maxlevels', 'specifies', 'maximum', 'cardinality', 'distribution', 'summary', 'variable', 'cardinality', 'higher', 'specified', 'value', 'omitted', 'distribution', 'analysis', 'detail', 'macro', 'open', 'specification', 'landscape', 'orientation', 'option', 'orientationlandscape']"
1235,The events in the period of interest can be stratified by time or transaction class variables. The events within each stratum can be thought of as measurements of a random variable. Descriptive statistics of these random variable distributions generate additional model inputs.,DM,277,"['event', 'period', 'interest', 'stratified', 'time', 'transaction', 'class', 'variable', 'event', 'within', 'stratum', 'thought', 'measurement', 'random', 'variable', 'descriptive', 'statistic', 'random', 'variable', 'distribution', 'generate', 'additional', 'model', 'input']"
1236,*	transposing the transaction case input data just created *	reconciling transaction overflows *	appending client IDs to the transaction based input sample *	merging the transaction input sample to the target sample.,DM,216,"['\ttransposing', 'transaction', 'case', 'input', 'data', 'created', '\treconciling', 'transaction', 'overflow', '\tappending', 'client', 'id', 'transaction', 'based', 'input', 'sample', '\tmerging', 'transaction', 'input', 'sample', 'target', 'sample']"
1237,The names of all selected non-numeric variables with a cardinality less than MAX_LEVELS are placed in macro variable CHARVARS. proc sql noprint; select var into :charvars separated by ' ' from counts where levels<&max_levels; quit;,DM,231,"['name', 'selected', 'nonnumeric', 'variable', 'cardinality', 'le', 'maxlevels', 'placed', 'macro', 'variable', 'charvars', 'proc', 'sql', 'noprint', 'select', 'var', 'charvars', 'separated', '', '', 'count', 'levelsmaxlevels', 'quit']"
1238,"To calculate the number of non-INS clients in each stratum, the number of INS clients within each stratum is determined and multiplied by the desired N0:N1 ratio. The SURVEYSELECT procedure requires this count to be named _NSIZE_.",DM,230,"['calculate', 'number', 'nonins', 'client', 'stratum', 'number', 'client', 'within', 'stratum', 'determined', 'multiplied', 'desired', 'n0n1', 'ratio', 'surveyselect', 'procedure', 'requires', 'count', 'named', 'nsize']"
1239,The values of branch will be replaced by 1 of 19 distinct smoothed weights of evidence. The demonstration ends with definition and application of the smoothed weight of evidence format. proc format cntlin=f; run;,DM,212,"['value', 'branch', 'replaced', '1', '19', 'distinct', 'smoothed', 'weight', 'evidence', 'demonstration', 'end', 'definition', 'application', 'smoothed', 'weight', 'evidence', 'format', 'proc', 'format', 'cntlinf', 'run']"
1240,The data set containing the stratum counts is specified with the N= option. The STRATA statement specifies the name of the stratification variable. Implementing Stratified Separate Sampling,DM,189,"['data_set', 'containing', 'stratum', 'count', 'specified', 'n', 'option', 'stratum', 'statement', 'specifies', 'name', 'stratification', 'variable', 'implementing', 'stratified', 'separate', 'sampling']"
1241,"There are many challenges to be faced in the data preparation process. Six of the most important are listed above, in informal terms. Clarification follows on the next slide.",DM,174,"['many', 'challenge', 'faced', 'data', 'preparation', 'process', 'six', 'important', 'listed', 'informal', 'term', 'clarification', 'follows', 'next', 'slide']"
1242,"Open the file Managing Data Pathologies 1.sas in the program editor. This general-purpose program creates a convenient statistical report on any SAS data set and places the report in a PDF file for review and printing. The report includes a CONTENTS procedure summary of the data set columns, statistical summaries and a distribution plot for every numeric variable, a cardinality report for every character variable, and a frequency table for every character variable with cardinality below a specified threshold. The program begins by loading a utility macro file specialized to the needs of this chapter. *** Include pathology macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""pathology_macros.source""); A discussion of the macros used in the report follows in an optional section. Next, the name of the data set to analyze and the location of the analysis report are specified. *** Define data set of interest and report destination; %let data=dmdp.ins_modeling_sample; %let report_name='C:\temp\output.pdf'; The data set DMDP.INS_MODELING_SAMPLE is a merging of all analysis variables created to this point. It also contains input from other data sources related to the INS prediction problem, but not specifically analyzed in the previous chapters. In particular, limited transaction-based inputs from accounts other than checking are attached. In all, the data set contains 89 columns and 2,328 rows. Also, note that none of the census demographic fields from the end of chapter 4 have been appended.",DM,1530,"['open', 'file', 'managing', 'data', 'pathology', '1sas', 'program', 'editor', 'generalpurpose', 'program', 'creates', 'convenient', 'statistical', 'report', 'sa', 'data_set', 'place', 'report', 'pdf', 'file', 'review', 'printing', 'report', 'includes', 'content', 'procedure', 'summary', 'data_set', 'column', 'statistical', 'summary', 'distribution', 'plot', 'every', 'numeric', 'variable', 'cardinality', 'report', 'every', 'character', 'variable', 'frequency', 'table', 'every', 'character', 'variable', 'cardinality', 'specified', 'threshold', 'program', 'begin', 'loading', 'utility', 'macro', 'file', 'specialized', 'need', 'chapter', '', 'include', 'pathology', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacspathologymacrossource', 'discussion', 'macro', 'used', 'report', 'follows', 'optional', 'section', 'next', 'name', 'data_set', 'analyze', 'location', 'analysis', 'report', 'specified', '', 'define', 'data_set', 'interest', 'report', 'destination', 'let', 'datadmdpinsmodelingsample', 'let', 'reportnamectempoutputpdf', 'data_set', 'dmdpinsmodelingsample', 'merging', 'analysis', 'variable', 'created', 'point', 'also', 'contains', 'input', 'data', 'source', 'related', 'prediction', 'problem', 'specifically', 'analyzed', 'previous', 'chapter', 'particular', 'limited', 'transactionbased', 'input', 'account', 'checking', 'attached', 'data_set', 'contains', '89', 'column', '2328', 'row', 'also', 'note', 'none', 'census', 'demographic', 'field', 'end', 'chapter', '4', 'appended']"
1243,"%generate_grouping(from=work.profile_codes,value=PROFILE,group=CODE); There are seven distinct grouping codes of interest generated from ten profile combinations. All other profile combinations are accommodated by the OTHER profile, which maps to the EXD grouping code. The next block of code includes the declaration of the transaction code index and code arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,459,"['generategroupingfromworkprofilecodesvalueprofilegroupcode', 'seven', 'distinct', 'grouping', 'code', 'interest', 'generated', 'ten', 'profile', 'combination', 'profile', 'combination', 'accommodated', 'profile', 'map', 'exd', 'grouping', 'code', 'next', 'block', 'code', 'includes', 'declaration', 'transaction', 'code', 'index', 'code', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1244,"The first column gives the name, the second column the percentage of males in the US population with the name, the third column the cumulative frequency, and the fourth column, the rank. The demonstration begins by translating the names are frequencies to formats. Start with the male names. data f; set dmdp.census_names_male end=LAST;",DM,336,"['first', 'column', 'give', 'name', 'second', 'column', 'percentage', 'male', 'u', 'population', 'name', 'third', 'column', 'cumulative', 'frequency', 'fourth', 'column', 'rank', 'demonstration', 'begin', 'translating', 'name', 'frequency', 'format', 'start', 'male', 'name', 'data', 'f', 'set', 'dmdpcensusnamesmale', 'endlast']"
1245,"Target sample creation for a model with a binary target involves four distinct tasks: *	accessing available data from the operational data repository *	selecting qualified responders, usually the minority target class *	selecting qualified nonresponders, usually the majority target class *	joining the responders and nonresponders to create a model sample, possibly stratified. The first three tasks can involve tens of millions of records from the operational repository and run most efficiently on the relational data base management system (RDBMS) server. The last task involves fewer records and will primarily occur within the SAS environment. 2.2	Simple Random Target Samples",DM,682,"['target', 'sample', 'creation', 'model', 'binary', 'target', 'involves', 'four', 'distinct', 'task', '\taccessing', 'available', 'data', 'operational', 'data', 'repository', '\tselecting', 'qualified', 'responder', 'usually', 'minority', 'target', 'class', '\tselecting', 'qualified', 'nonresponders', 'usually', 'majority', 'target', 'class', '\tjoining', 'responder', 'nonresponders', 'create', 'model', 'sample', 'possibly', 'stratified', 'first', 'three', 'task', 'involve', 'ten', 'million', 'record', 'operational', 'repository', 'run', 'efficiently', 'relational', 'data', 'base', 'management', 'system', 'rdbms', 'server', 'last', 'task', 'involves', 'fewer', 'record', 'primarily', 'occur', 'within', 'sa', 'environment', '22\tsimple', 'random', 'target', 'sample']"
1246,"After a case?s period of interest is defined, there are a multitude of input possibilities. Perhaps the simplest are tabulations such as counts and sums derived from period of interest events.",DM,192,"['case', 'period', 'interest', 'defined', 'multitude', 'input', 'possibility', 'perhaps', 'simplest', 'tabulation', 'count', 'sum', 'derived', 'period', 'interest', 'event']"
1247,"The whimsical portrayals translate to issues well known to data miners. As data collection and storage costs decrease, analytic data sets grow larger and larger. When processing the data, it is easy to introduce artificial input/target associations by ignoring the temporal aspects of data. The most useful data describes the actions individuals take, which are recorded as transactions and events. To use this transaction data in a model, it must be transformed and summarized into a single record per case. Nonnumeric data requires specially treatment for inclusion in a model. However, the traditional approach of creating dummy variables for such data, often severely degrades model performance. Inputs with exceptional, extreme, or missing values pose many challenges to model performance. Finally, stationarity, the assumption that the world in which the model will be deployed resembles the world from which the model was built, must constantly guide the data preparation process.",DM,987,"['whimsical', 'portrayal', 'translate', 'issue', 'well', 'known', 'data', 'miner', 'data', 'collection', 'storage', 'cost', 'decrease', 'analytic', 'data_set', 'grow', 'larger', 'larger', 'processing', 'data', 'easy', 'introduce', 'artificial', 'inputtarget', 'association', 'ignoring', 'temporal', 'aspect', 'data', 'useful', 'data', 'describes', 'action', 'individual', 'take', 'recorded', 'transaction', 'event', 'use', 'transaction', 'data', 'model', 'must', 'transformed', 'summarized', 'single', 'record', 'per', 'case', 'nonnumeric', 'data', 'requires', 'specially', 'treatment', 'inclusion', 'model', 'however', 'traditional', 'approach', 'creating', 'dummy', 'variable', 'data', 'often', 'severely', 'degrades', 'model', 'performance', 'input', 'exceptional', 'extreme', 'missing', 'value', 'pose', 'many', 'challenge', 'model', 'performance', 'finally', 'stationarity', 'assumption', 'world', 'model', 'deployed', 'resembles', 'world', 'model', 'wa', 'built', 'must', 'constantly', 'guide', 'data', 'preparation', 'process']"
1248,*	transposing the transaction case input data just created *	reconciling transaction overflows *	appending client IDs to the transaction based input sample *	merging the transaction input sample to the target sample.,DM,216,"['\ttransposing', 'transaction', 'case', 'input', 'data', 'created', '\treconciling', 'transaction', 'overflow', '\tappending', 'client', 'id', 'transaction', 'based', 'input', 'sample', '\tmerging', 'transaction', 'input', 'sample', 'target', 'sample']"
1249,"The GENERATE_GROUPING macro is used to create a set of grouping formats. These formats are applied in the process step to facilitate stratified analyses. Three keyword parameters must be specified: FROM=, which indicates the class/group correspondence data set; VALUE=, which indicates the source profile; and GROUP=, which indicates the group code.",DM,349,"['generategrouping', 'macro', 'used', 'create', 'set', 'grouping', 'format', 'format', 'applied', 'process', 'step', 'facilitate', 'stratified', 'analysis', 'three', 'keyword', 'parameter', 'must', 'specified', 'indicates', 'classgroup', 'correspondence', 'data_set', 'value', 'indicates', 'source', 'profile', 'group', 'indicates', 'group', 'code']"
1250,Open the file Transaction Input Creation 2.sas in the SAS program editor. The code focuses on the process by ID step in the transaction input creation exercise. The only change in the program occurs in the execute step.,DM,219,"['open', 'file', 'transaction', 'input', 'creation', '2sas', 'sa', 'program', 'editor', 'code', 'focus', 'process', 'id', 'step', 'transaction', 'input', 'creation', 'exercise', 'change', 'program', 'occurs', 'execute', 'step']"
1251,The MEANS procedure is used to find the minimum and mean of each variable and rank group combination. This table will be used to form the rank formats. proc means data=rtranspose noprint; by VARNAME R_VALUE; output out=mrtranspose min=min mean=mean; run;,DM,254,"['mean', 'procedure', 'used', 'find', 'minimum', 'mean', 'variable', 'rank', 'group', 'combination', 'table', 'used', 'form', 'rank', 'format', 'proc', 'mean', 'datartranspose', 'noprint', 'varname', 'rvalue', 'output', 'outmrtranspose', 'minmin', 'meanmean', 'run']"
1252,"?	The macro functions depend on the zip code formats. As defined, these formats are only available in your current SAS session. To make these formats available later, you must store their definitions in a permanent SAS library. This is done using the LIBRARY= option of the FORMAT procedure. Select the online help or ask your instructor for details.",DM,350,"['\tthe', 'macro', 'function', 'depend', 'zip', 'code', 'format', 'defined', 'format', 'available', 'current', 'sa', 'session', 'make', 'format', 'available', 'later', 'must', 'store', 'definition', 'permanent', 'sa', 'library', 'done', 'using', 'library', 'option', 'format', 'procedure', 'select', 'online', 'help', 'ask', 'instructor', 'detail']"
1253,"Knowing what an input should look like helps to detect data errors. Typically, the opportunistic data sets used in predictive models are electronically generated, so ?key-punch? errors are much less common than programming errors. Of course, the number of ways that a program can go wrong is incalculable; however, problems can often be detected by scrutinizing the results and asking if the results make sense. An exhaustive list of what can go wrong is impossible to write, but there are some common signs of coding errors. *	The input range should be checked against expectations. Unexpected negative (or positive) numbers are a sign of trouble. *	A large number of missing values can indicate problems with input transformations. *	Examining the smallest and largest observations can help detect coding errors. *	The overall distribution shape should make sense. *	The cardinality of non-numeric inputs should be verified. *	Frequency counts within categorical levels should be reviewed.",DM,991,"['knowing', 'input', 'look', 'like', 'help', 'detect', 'data', 'error', 'typically', 'opportunistic', 'data_set', 'used', 'predictive', 'model', 'electronically', 'generated', 'keypunch', 'error', 'much', 'le', 'common', 'programming', 'error', 'course', 'number', 'way', 'program', 'go', 'wrong', 'incalculable', 'however', 'problem', 'often', 'detected', 'scrutinizing', 'result', 'asking', 'result', 'make', 'sense', 'exhaustive', 'list', 'go', 'wrong', 'impossible', 'write', 'common', 'sign', 'coding', 'error', '\tthe', 'input', 'range', 'checked', 'expectation', 'unexpected', 'negative', 'positive', 'number', 'sign', 'trouble', '\ta', 'large', 'number', 'missing', 'value', 'indicate', 'problem', 'input', 'transformation', '\texamining', 'smallest', 'largest', 'observation', 'help', 'detect', 'coding', 'error', '\tthe', 'overall', 'distribution', 'shape', 'make', 'sense', '\tthe', 'cardinality', 'nonnumeric', 'input', 'verified', '\tfrequency', 'count', 'within', 'categorical', 'level', 'reviewed']"
1254,Open the file Extract Relevant Data 1.sas in the SAS program editor. This creates a simple random target sample from the raw operational data stored in the DMDP library. Browse the DMDP.INS_ACCOUNT data set.,DM,207,"['open', 'file', 'extract', 'relevant', 'data', '1sas', 'sa', 'program', 'editor', 'creates', 'simple', 'random', 'target', 'sample', 'raw', 'operational', 'data', 'stored', 'dmdp', 'library', 'browse', 'dmdpinsaccount', 'data_set']"
1255,"The actual %N macro appears relatively straightforward. Some complexity is hidden in the %TN_MACRO_SETUP code, used to initialize this and other transaction macro functions. Introduction to Transaction Macros",DM,208,"['actual', 'n', 'macro', 'appears', 'relatively', 'straightforward', 'complexity', 'hidden', 'tnmacrosetup', 'code', 'used', 'initialize', 'transaction', 'macro', 'function', 'introduction', 'transaction', 'macro']"
1256,"The join can be accomplished by bringing the data to the SAS analysis server and using the APPEND procedure, or by using the outer union capabilities of SQL. The CORRESPONDING option in the outer union combines corresponding columns in the selected tables.",DM,256,"['join', 'accomplished', 'bringing', 'data', 'sa', 'analysis', 'server', 'using', 'append', 'procedure', 'using', 'outer', 'union', 'capability', 'sql', 'corresponding', 'option', 'outer', 'union', 'combine', 'corresponding', 'column', 'selected', 'table']"
1257,Processing by transaction groups requires some minor additions to the Declare and Vector tasks and more substantial additions to the Export task. The most important innovation is the transaction macros use of grouping indicators.,DM,229,"['processing', 'transaction', 'group', 'requires', 'minor', 'addition', 'declare', 'vector', 'task', 'substantial', 'addition', 'export', 'task', 'important', 'innovation', 'transaction', 'macro', 'use', 'grouping', 'indicator']"
1258,"The additional transaction arrays combined with the transaction macros allow the creation of stratified inputs. For example, CR_SUM measures the total deposits per month.",DM,170,"['additional', 'transaction', 'array', 'combined', 'transaction', 'macro', 'allow', 'creation', 'stratified', 'input', 'example', 'crsum', 'measure', 'total', 'deposit', 'per', 'month']"
1259,The optional demonstration later in this section details the creation of the report. ?	The %DISTRIBUTION macro can be used on its own to look at the distributions of any variable or set of variables in any SAS data set. The %DISTRIBUTION Macro,DM,243,"['optional', 'demonstration', 'later', 'section', 'detail', 'creation', 'report', '\tthe', 'distribution', 'macro', 'used', 'look', 'distribution', 'variable', 'set', 'variable', 'sa', 'data_set', 'distribution', 'macro']"
1260,"While data used for predictive model development assumes a single row per case ID, data used to record the activities of individuals contains many rows per case ID. This data must be transformed for inclusion in predictive models. An individual transaction record typically contains one or more identification fields, a timestamp field, one or more classification fields, and possibly one or more amount fields.",DM,411,"['data', 'used', 'predictive', 'model', 'development', 'assumes', 'single', 'row', 'per', 'case', 'id', 'data', 'used', 'record', 'activity', 'individual', 'contains', 'many', 'row', 'per', 'case', 'id', 'data', 'must', 'transformed', 'inclusion', 'predictive', 'model', 'individual', 'transaction', 'record', 'typically', 'contains', 'one', 'identification', 'field', 'timestamp', 'field', 'one', 'classification', 'field', 'possibly', 'one', 'amount', 'field']"
1261,"Stratifications can also be used with table statistics, such as counts and sums, to yield profiles. Profiles are extremely useful for identifying patterns of activity in data.",DM,175,"['stratification', 'also', 'used', 'table', 'statistic', 'count', 'sum', 'yield', 'profile', 'profile', 'extremely', 'useful', 'identifying', 'pattern', 'activity', 'data']"
1262,"Ideally, you will have access to a private database closely tied to the RDBMS server that contains the operational data. This database will contain views to the operational data as well as large intermediate tables generated by the SAS/ACCESS Pass-Through facility. Subsets of these intermediate tables will be transferred to the SAS analysis server for processing by SAS. In this way, transfer of data through the network is limited to small amounts of data and occurs only when necessary.",DM,490,"['ideally', 'access', 'private', 'database', 'closely', 'tied', 'rdbms', 'server', 'contains', 'operational', 'data', 'database', 'contain', 'view', 'operational', 'data', 'well', 'large', 'intermediate', 'table', 'generated', 'sasaccess', 'passthrough', 'facility', 'subset', 'intermediate', 'table', 'transferred', 'sa', 'analysis', 'server', 'processing', 'sa', 'way', 'transfer', 'data', 'network', 'limited', 'small', 'amount', 'data', 'occurs', 'necessary']"
1263,"In practice, analysts typically use a slight variation of this recoding method. Instead of representing the levels with integers, they employ the actual target average (or a model-appropriate transformation) to represent the level. Because their encoding is nearly identical, levels with identical expected response are effectively merged. A common name for this approach is the weight of evidence recoding. Weight of evidence recoding works reasonably well when the number of cases in a level is large enough to get stable target average estimates. However, like dummy coding, when the number of levels is large (so that the number of cases in a level is small), weight of evidence recoding results in models with poor generalization.",DM,735,"['practice', 'analyst', 'typically', 'use', 'slight', 'variation', 'recoding', 'method', 'instead', 'representing', 'level', 'integer', 'employ', 'actual', 'target', 'average', 'modelappropriate', 'transformation', 'represent', 'level', 'encoding', 'nearly', 'identical', 'level', 'identical', 'expected', 'response', 'effectively', 'merged', 'common', 'name', 'approach', 'weight', 'evidence', 'recoding', 'weight', 'evidence', 'recoding', 'work', 'reasonably', 'well', 'number', 'case', 'level', 'large', 'enough', 'get', 'stable', 'target', 'average', 'estimate', 'however', 'like', 'dummy', 'coding', 'number', 'level', 'large', 'number', 'case', 'level', 'small', 'weight', 'evidence', 'recoding', 'result', 'model', 'poor', 'generalization']"
1264,Transactions data also promotes modeling challenges. The data is often sequestered on inaccessible servers with little opportunity for mass data transfer. The blessing of high detail is also a curse: the sheer volume of data makes it extremely time consuming to obtain and difficult to process.,DM,294,"['transaction', 'data', 'also', 'promotes', 'modeling', 'challenge', 'data', 'often', 'sequestered', 'inaccessible', 'server', 'little', 'opportunity', 'mass', 'data', 'transfer', 'blessing', 'high', 'detail', 'also', 'curse', 'sheer', 'volume', 'data', 'make', 'extremely', 'time', 'consuming', 'obtain', 'difficult', 'process']"
1265,"In this iteration of the process step, only three inputs are generated per case. The first indicates the presence of a checking account. The second indicates a transaction overflow, in which the observed transaction count exceeds the maximum allowed per case. The third gives the observed transaction count. The transaction case input data must now be transposed to a single row per case and merged with the client ID data set.",DM,427,"['iteration', 'process', 'step', 'three', 'input', 'generated', 'per', 'case', 'first', 'indicates', 'presence', 'checking', 'account', 'second', 'indicates', 'transaction', 'overflow', 'observed', 'transaction', 'count', 'exceeds', 'maximum', 'allowed', 'per', 'case', 'third', 'give', 'observed', 'transaction', 'count', 'transaction', 'case', 'input', 'data', 'must', 'transposed', 'single', 'row', 'per', 'case', 'merged', 'client', 'id', 'data_set']"
1266,"Three types of expertise are required to achieve this (or any) analytic objective. The domain expert thoroughly understands the business aspects of the problem and is usually the ?owner? of the objective. He or she knows the approaches that have been attempted in the past to achieve the objective and their level of success. The data expert specializes in the raw materials of any predictive modeling endeavor. He or she knows where and how historical information is kept and can provide insight into the definitions of the data elements. The analytical methods expert knows the tools of predictive modeling. Ideally, the analytical methods expert prepares the analysis data or, at a minimum, closely supervises the data expert in the task. Each expert checks and influences the others. The analytic and data experts guide the domain expert as to the feasibility of analysis goals. The domain and analytic experts provide meaning and structural requirements to the data expert during data extraction. The domain and data experts offer reality checks on the analytic expert?s results and model implementation plans.",DM,1115,"['three', 'type', 'expertise', 'required', 'achieve', 'analytic', 'objective', 'domain', 'expert', 'thoroughly', 'understands', 'business', 'aspect', 'problem', 'usually', 'owner', 'objective', 'know', 'approach', 'attempted', 'past', 'achieve', 'objective', 'level', 'success', 'data', 'expert', 'specializes', 'raw', 'material', 'predictive', 'modeling', 'endeavor', 'know', 'historical', 'information', 'kept', 'provide', 'insight', 'definition', 'data', 'element', 'analytical', 'method', 'expert', 'know', 'tool', 'predictive', 'modeling', 'ideally', 'analytical', 'method', 'expert', 'prepares', 'analysis', 'data', 'minimum', 'closely', 'supervises', 'data', 'expert', 'task', 'expert', 'check', 'influence', 'others', 'analytic', 'data', 'expert', 'guide', 'domain', 'expert', 'feasibility', 'analysis', 'goal', 'domain', 'analytic', 'expert', 'provide', 'meaning', 'structural', 'requirement', 'data', 'expert', 'data', 'extraction', 'domain', 'data', 'expert', 'offer', 'reality', 'check', 'analytic', 'expert', 'result', 'model', 'implementation', 'plan']"
1267,Much of the course discussion centers on the analytic objective stated above. Financial institutions usually possess highly detailed data that is challenging to transform into a structure suitable for predictive modeling. The approaches used to overcome the challenges are applicable to many domains.,DM,300,"['much', 'course', 'discussion', 'center', 'analytic', 'objective', 'stated', 'financial', 'institution', 'usually', 'posse', 'highly', 'detailed', 'data', 'challenging', 'transform', 'structure', 'suitable', 'predictive', 'modeling', 'approach', 'used', 'overcome', 'challenge', 'applicable', 'many', 'domain']"
1268,Another skewness reduction transformation involves using the RANK procedure to substitute percentiles or other rank-based values for the original input. proc rank data=transformed out=transformed groups=100; var CC_BAL_AVG; ranks R_CC_BAL_AVG; run;,DM,248,"['another', 'skewness', 'reduction', 'transformation', 'involves', 'using', 'rank', 'procedure', 'substitute', 'percentile', 'rankbased', 'value', 'original', 'input', 'proc', 'rank', 'datatransformed', 'outtransformed', 'groups100', 'var', 'ccbalavg', 'rank', 'rccbalavg', 'run']"
1269,Summing the value of events in each group code is the second stratified analysis application. The syntax is virtually identical to the stratified counting example above.,DM,169,"['summing', 'value', 'event', 'group', 'code', 'second', 'stratified', 'analysis', 'application', 'syntax', 'virtually', 'identical', 'stratified', 'counting', 'example']"
1270,A stratified sample is drawn from the non-INS clients. PROC SURVEYSELECT procedure requires the raw data to be sorted by stratification variable. proc sort data=non_ins_clients_qualified; by STRATUM CLIENT_ID; run;,DM,214,"['stratified', 'sample', 'drawn', 'nonins', 'client', 'proc', 'surveyselect', 'procedure', 'requires', 'raw', 'data', 'sorted', 'stratification', 'variable', 'proc', 'sort', 'datanoninsclientsqualified', 'stratum', 'clientid', 'run']"
1271,The DESCRIPTIVE data set is in a most inconvenient form: one row and many columns. The TRANSPOSE procedure reverses this arrangement. *** make descriptive statistics inset data; proc transpose data=descriptive out=descriptive; run;,DM,231,"['descriptive', 'data_set', 'inconvenient', 'form', 'one', 'row', 'many', 'column', 'transpose', 'procedure', 'revers', 'arrangement', '', 'make', 'descriptive', 'statistic', 'inset', 'data', 'proc', 'transpose', 'datadescriptive', 'outdescriptive', 'run']"
1272,"The resulting distributions were obtained from over 100 simulations per strategy. Threshold dummy coding and the smoothed weight of evidence strategies performed comparably on the presented configuration. In further simulations, it was found that higher cardinality inputs favored the smoothed weight of evidence slightly. A more complete discussion of the results is found in a forthcoming paper by the author.",DM,411,"['resulting', 'distribution', 'obtained', '100', 'simulation', 'per', 'strategy', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'strategy', 'performed', 'comparably', 'presented', 'configuration', 'simulation', 'wa', 'found', 'higher', 'cardinality', 'input', 'favored', 'smoothed', 'weight', 'evidence', 'slightly', 'complete', 'discussion', 'result', 'found', 'forthcoming', 'paper', 'author']"
1273,"A small addition to the execute task of the process by ID step generates an input that counts the number of events occurring between day zero and day 30 in relative time. A new variable, TN_LIMIT, is calculated to prevent reading past the limits of the transaction array.",DM,271,"['small', 'addition', 'execute', 'task', 'process', 'id', 'step', 'generates', 'input', 'count', 'number', 'event', 'occurring', 'day', 'zero', 'day', '30', 'relative', 'time', 'new', 'variable', 'tnlimit', 'calculated', 'prevent', 'reading', 'past', 'limit', 'transaction', 'array']"
1274,"Now the punch line: for large Ni (relative to a and b), the expected value of pi is about what you would obtain using traditional weight of evidence methods. For small values of Ni, the expected value of pi is about equal to the overall target average. Thus, the average target estimates based on sparse level counts are smoothed out and the corresponding bias problems are virtually eliminated.",DM,395,"['punch', 'line', 'large', 'ni', 'relative', 'b', 'expected', 'value', 'pi', 'would', 'obtain', 'using', 'traditional', 'weight', 'evidence', 'method', 'small', 'value', 'ni', 'expected', 'value', 'pi', 'equal', 'overall', 'target', 'average', 'thus', 'average', 'target', 'estimate', 'based', 'sparse', 'level', 'count', 'smoothed', 'corresponding', 'bias', 'problem', 'virtually', 'eliminated']"
1275,"The first column gives the name, the second column the percentage of males in the US population with the name, the third column the cumulative frequency, and the fourth column, the rank. The demonstration begins by translating the names are frequencies to formats. Start with the male names. data f; set dmdp.census_names_male end=LAST;",DM,336,"['first', 'column', 'give', 'name', 'second', 'column', 'percentage', 'male', 'u', 'population', 'name', 'third', 'column', 'cumulative', 'frequency', 'fourth', 'column', 'rank', 'demonstration', 'begin', 'translating', 'name', 'frequency', 'format', 'start', 'male', 'name', 'data', 'f', 'set', 'dmdpcensusnamesmale', 'endlast']"
1276,Unknown male names are assigned small (but non-zero) probabilities of being male. Similar processing occurs for the female names. data f; set dmdp.census_names_female end=LAST;,DM,176,"['unknown', 'male', 'name', 'assigned', 'small', 'nonzero', 'probability', 'male', 'similar', 'processing', 'occurs', 'female', 'name', 'data', 'f', 'set', 'dmdpcensusnamesfemale', 'endlast']"
1277,"The GENERATE_GROUPING macro is used to create a set of grouping formats. These formats are applied in the process step to facilitate stratified analyses. Three keyword parameters must be specified: FROM=, which indicates the class/group correspondence data set; VALUE=, which indicates the source profile; and GROUP=, which indicates the group code.",DM,349,"['generategrouping', 'macro', 'used', 'create', 'set', 'grouping', 'format', 'format', 'applied', 'process', 'step', 'facilitate', 'stratified', 'analysis', 'three', 'keyword', 'parameter', 'must', 'specified', 'indicates', 'classgroup', 'correspondence', 'data_set', 'value', 'indicates', 'source', 'profile', 'group', 'indicates', 'group', 'code']"
1278,"Open the file Managing Data Pathologies 2.sas in the program editor. This program demonstrates the three techniques for regularizing extreme distributions. As seen in a distribution plot, the variable CC_BAL_AVG is moderately skewed. There are several ways to compensate for this skewness. %distribution(vars=CC_BAL_AVG,data=dmdp.ins_modeling_sample );",DM,352,"['open', 'file', 'managing', 'data', 'pathology', '2sas', 'program', 'editor', 'program', 'demonstrates', 'three', 'technique', 'regularizing', 'extreme', 'distribution', 'seen', 'distribution', 'plot', 'variable', 'ccbalavg', 'moderately', 'skewed', 'several', 'way', 'compensate', 'skewness', 'distributionvarsccbalavgdatadmdpinsmodelingsample', '']"
1279,"With the BALANCE array containing the actual daily balance of the account, it is easy to generate statistic describing the balance distribution. For example, the %MEAN macro function yields the average daily balance.",DM,216,"['balance', 'array', 'containing', 'actual', 'daily', 'balance', 'account', 'easy', 'generate', 'statistic', 'describing', 'balance', 'distribution', 'example', 'mean', 'macro', 'function', 'yield', 'average', 'daily', 'balance']"
1280,"Second, if the relative time is less than zero (before the target date), the ending balance is changed: incremented for debits and decremented for credits. While this seems backwards, there is a simple explanation for this action.",DM,230,"['second', 'relative', 'time', 'le', 'zero', 'target', 'date', 'ending', 'balance', 'changed', 'incremented', 'debit', 'decremented', 'credit', 'seems', 'backwards', 'simple', 'explanation', 'action']"
1281,"The checking account IDs of clients in the target sample are placed in a data set named SAMPLE_CHECKING_ACCOUNTS. As mentioned above, in practice, several checking account qualifications might be invoked at this point. *** Access Transaction Data from Warehouse; proc sql; create table sample_checking_accounts as select CLIENT_ID, CHECKING_ID from dmdp.client_checking_account where CLIENT_ID in (select CLIENT_ID from dmdp.target_sample);",DM,440,"['checking', 'account', 'id', 'client', 'target', 'sample', 'placed', 'data_set', 'named', 'samplecheckingaccounts', 'mentioned', 'practice', 'several', 'checking', 'account', 'qualification', 'might', 'invoked', 'point', '', 'access', 'transaction', 'data', 'warehouse', 'proc', 'sql', 'create', 'table', 'samplecheckingaccounts', 'select', 'clientid', 'checkingid', 'dmdpclientcheckingaccount', 'clientid', 'select', 'clientid', 'dmdptargetsample']"
1282,"The qualification query joins the intermediate INS_CLIENT table to the CLIENT and CREDIT_BUREAU tables. The CLIENT table contains facts about individual clients including birth date and bank origination date. The CREDIT_BUREAU table contains quarterly snapshots of financial data, including FICO scores, for most clients in the marketing data warehouse. A second intermediate table named INS_CLIENTS_QUALIFIED is created. Again, the client ID and INS account open date are selected from the intermediate INS_CLIENTS table. To satisfy all the qualifications, the INS_CLIENT table is joined with the CLIENT and CREDIT_BUREAU tables. The tables are matched on CLIENT_ID. Clients are filtered by their origination and birth dates (from the CLIENT table) and their first trade line year, trade line count, and FICO score (from the CREDIT_BUREAU table).",DM,847,"['qualification', 'query', 'join', 'intermediate', 'insclient', 'table', 'client', 'creditbureau', 'table', 'client', 'table', 'contains', 'fact', 'individual', 'client', 'including', 'birth', 'date', 'bank', 'origination', 'date', 'creditbureau', 'table', 'contains', 'quarterly', 'snapshot', 'financial', 'data', 'including', 'fico', 'score', 'client', 'marketing', 'data', 'warehouse', 'second', 'intermediate', 'table', 'named', 'insclientsqualified', 'created', 'client', 'id', 'account', 'open', 'date', 'selected', 'intermediate', 'insclients', 'table', 'satisfy', 'qualification', 'insclient', 'table', 'joined', 'client', 'creditbureau', 'table', 'table', 'matched', 'clientid', 'client', 'filtered', 'origination', 'birth', 'date', 'client', 'table', 'first', 'trade', 'line', 'year', 'trade', 'line', 'count', 'fico', 'score', 'creditbureau', 'table']"
1283,"To implement stratified separate sampling, you must add stratification variables to the INS and non-INS client data sets. This involves rerunning the initial queries into the operational data warehouse. Continuous stratification variables must be binned to an appropriate degree (analysis dependent). The desired sample size within each bin must be calculated.",DM,360,"['implement', 'stratified', 'separate', 'sampling', 'must', 'add', 'stratification', 'variable', 'nonins', 'client', 'data_set', 'involves', 'rerunning', 'initial', 'query', 'operational', 'data', 'warehouse', 'continuous', 'stratification', 'variable', 'must', 'binned', 'appropriate', 'degree', 'analysis', 'dependent', 'desired', 'sample_size', 'within', 'bin', 'must', 'calculated']"
1284,"Open the file Using Non-Numeric Data 1.sas in the SAS program editor. This program demonstrates one way to implement threshold-based recoding. The financial institution groups its client by branch region based on the client?s home postal code. The data set DMDP.INPUT_SAMPLE_BRANCH describes each client?s branch region affiliation, five-digit postal code, and target value. ?	To avoid contamination, these values should correspond to measurements taken before the target date.",DM,477,"['open', 'file', 'using', 'nonnumeric', 'data', '1sas', 'sa', 'program', 'editor', 'program', 'demonstrates', 'one', 'way', 'implement', 'thresholdbased', 'recoding', 'financial', 'institution', 'group', 'client', 'branch', 'region', 'based', 'client', 'home', 'postal', 'code', 'data_set', 'dmdpinputsamplebranch', 'describes', 'client', 'branch', 'region', 'affiliation', 'fivedigit', 'postal', 'code', 'target', 'value', '\tto', 'avoid', 'contamination', 'value', 'correspond', 'measurement', 'taken', 'target', 'date']"
1285,"All activities in this course center on transforming operational data into a model development data set. A model development data set consists of independent rows of data called modeling cases and four types of columns: IDs, targets, target dates, and inputs. Each modeling case can correspond to hundreds of records in the operational data.",DM,341,"['activity', 'course', 'center', 'transforming', 'operational', 'data', 'model', 'development', 'data_set', 'model', 'development', 'data_set', 'consists', 'independent', 'row', 'data', 'called', 'modeling', 'case', 'four', 'type', 'column', 'id', 'target', 'target', 'date', 'input', 'modeling', 'case', 'correspond', 'hundred', 'record', 'operational', 'data']"
1286,Many of the records have missing values corresponding to unknown zip codes. Remedying these missing values requires taking advantage of another property of zip codes: hierarchy. Imputing Missing Geocode Values,DM,209,"['many', 'record', 'missing', 'value', 'corresponding', 'unknown', 'zip', 'code', 'remedying', 'missing', 'value', 'requires', 'taking', 'advantage', 'another', 'property', 'zip', 'code', 'hierarchy', 'imputing', 'missing', 'geocode', 'value']"
1287,"In practice, analysts typically use a slight variation of this recoding method. Instead of representing the levels with integers, they employ the actual target average (or a model-appropriate transformation) to represent the level. Because their encoding is nearly identical, levels with identical expected response are effectively merged. A common name for this approach is the weight of evidence recoding. Weight of evidence recoding works reasonably well when the number of cases in a level is large enough to get stable target average estimates. However, like dummy coding, when the number of levels is large (so that the number of cases in a level is small), weight of evidence recoding results in models with poor generalization.",DM,735,"['practice', 'analyst', 'typically', 'use', 'slight', 'variation', 'recoding', 'method', 'instead', 'representing', 'level', 'integer', 'employ', 'actual', 'target', 'average', 'modelappropriate', 'transformation', 'represent', 'level', 'encoding', 'nearly', 'identical', 'level', 'identical', 'expected', 'response', 'effectively', 'merged', 'common', 'name', 'approach', 'weight', 'evidence', 'recoding', 'weight', 'evidence', 'recoding', 'work', 'reasonably', 'well', 'number', 'case', 'level', 'large', 'enough', 'get', 'stable', 'target', 'average', 'estimate', 'however', 'like', 'dummy', 'coding', 'number', 'level', 'large', 'number', 'case', 'level', 'small', 'weight', 'evidence', 'recoding', 'result', 'model', 'poor', 'generalization']"
1288,"The resulting distributions were obtained from over 100 simulations per strategy. Threshold dummy coding and the smoothed weight of evidence strategies performed comparably on the presented configuration. In further simulations, it was found that higher cardinality inputs favored the smoothed weight of evidence slightly. A more complete discussion of the results is found in a forthcoming paper by the author.",DM,411,"['resulting', 'distribution', 'obtained', '100', 'simulation', 'per', 'strategy', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'strategy', 'performed', 'comparably', 'presented', 'configuration', 'simulation', 'wa', 'found', 'higher', 'cardinality', 'input', 'favored', 'smoothed', 'weight', 'evidence', 'slightly', 'complete', 'discussion', 'result', 'found', 'forthcoming', 'paper', 'author']"
1289,"The first column gives the name, the second column the percentage of males in the US population with the name, the third column the cumulative frequency, and the fourth column, the rank. The demonstration begins by translating the names are frequencies to formats. Start with the male names. data f; set dmdp.census_names_male end=LAST;",DM,336,"['first', 'column', 'give', 'name', 'second', 'column', 'percentage', 'male', 'u', 'population', 'name', 'third', 'column', 'cumulative', 'frequency', 'fourth', 'column', 'rank', 'demonstration', 'begin', 'translating', 'name', 'frequency', 'format', 'start', 'male', 'name', 'data', 'f', 'set', 'dmdpcensusnamesmale', 'endlast']"
1290,"Simple measures can be taken to avoid contamination. *	Every predictive modeling data set should include, in addition to a target variable, a target date variable that indicates the date of target measurement. All measurements used to create modeling inputs must be made prior to the target date, less a reasonable latency period. *	A well-designed data warehouse should include documentation on the origin and meaning of table contents. Close and early collaboration with domain experts familiar with past efforts to achieve the analytic objective can identify and help avoid problems in sample creation. *	Explicitly accounting for time in sample and input creation can control for non-stationarities in the data. *	Finally, a healthy dose of skepticism is necessary to detect sampling and programming errors. An analyst must continuously ask, Does this result make sense in light of domain knowledge? In predictive modeling, if it is too good to be true, it almost certainly is an error.",DM,990,"['simple', 'measure', 'taken', 'avoid', 'contamination', '\tevery', 'predictive', 'modeling', 'data_set', 'include', 'addition', 'target', 'variable', 'target', 'date', 'variable', 'indicates', 'date', 'target', 'measurement', 'measurement', 'used', 'create', 'modeling', 'input', 'must', 'made', 'prior', 'target', 'date', 'le', 'reasonable', 'latency', 'period', '\ta', 'welldesigned', 'data', 'warehouse', 'include', 'documentation', 'origin', 'meaning', 'table', 'content', 'close', 'early', 'collaboration', 'domain', 'expert', 'familiar', 'past', 'effort', 'achieve', 'analytic', 'objective', 'identify', 'help', 'avoid', 'problem', 'sample', 'creation', '\texplicitly', 'accounting', 'time', 'sample', 'input', 'creation', 'control', 'nonstationarities', 'data', '\tfinally', 'healthy', 'dose', 'skepticism', 'necessary', 'detect', 'sampling', 'programming', 'error', 'analyst', 'must', 'continuously', 'ask', 'doe', 'result', 'make', 'sense', 'light', 'domain', 'knowledge', 'predictive', 'modeling', 'good', 'true', 'almost', 'certainly', 'error']"
1291,"In a simple random target sample, the non-INS clients outnumber the INS clients by approximately 46 to 1. By using separate sampling techniques, it is possible to substantially reduce the number of clients selected for modeling, without significantly reducing predictive modeling performance. In fact, by using the stratification techniques discussed in Section 2.4, it is possible to obtain a modeling sample that controls for potential non-stationarities in the data and thereby improves predictive model performance.",DM,519,"['simple', 'random', 'target', 'sample', 'nonins', 'client', 'outnumber', 'client', 'approximately', '46', '1', 'using', 'separate', 'sampling', 'technique', 'possible', 'substantially', 'reduce', 'number', 'client', 'selected', 'modeling', 'without', 'significantly', 'reducing', 'predictive', 'modeling', 'performance', 'fact', 'using', 'stratification', 'technique', 'discussed', 'section', '24', 'possible', 'obtain', 'modeling', 'sample', 'control', 'potential', 'nonstationarities', 'data', 'thereby', 'improves', 'predictive', 'model', 'performance']"
1292,"The macro code for the %MAX function is similar to that for the count and sum functions. The function scans the transaction array. For each iteration of the DO loop, the output variable is taken to be the maximum of the previously observed maximum value and the current array value.",DM,282,"['macro', 'code', 'max', 'function', 'similar', 'count', 'sum', 'function', 'function', 'scan', 'transaction', 'array', 'iteration', 'loop', 'output', 'variable', 'taken', 'maximum', 'previously', 'observed', 'maximum', 'value', 'current', 'array', 'value']"
1293,"With the account balance known at the end date, it is possible to use the values of the transaction events to determine the account balance at any point in time.",DM,161,"['account', 'balance', 'known', 'end', 'date', 'possible', 'use', 'value', 'transaction', 'event', 'determine', 'account', 'balance', 'point', 'time']"
1294,"Lastly, the non-numeric frequency distributions show the levels and case counts for all non-numeric variables with the number of levels less than the specified maximum. By default, the levels of the non-numeric variables are ordered by frequency, from highest to lowest frequency count. ?	The order of the levels can be changed to alphabetical by specifying the keyword option FREQ_LEVELS=N in the %DISTRIBUTION macro invocation.",DM,429,"['lastly', 'nonnumeric', 'frequency', 'distribution', 'show', 'level', 'case', 'count', 'nonnumeric', 'variable', 'number', 'level', 'le', 'specified', 'maximum', 'default', 'level', 'nonnumeric', 'variable', 'ordered', 'frequency', 'highest', 'lowest', 'frequency', 'count', '\tthe', 'order', 'level', 'changed', 'alphabetical', 'specifying', 'keyword', 'option', 'freqlevelsn', 'distribution', 'macro', 'invocation']"
1295,Reconciliation of transaction overflows begins with detection. The SQL code lists cases with transaction count in excess of the specified maximum and list observed number of rows. A large number of overflows can be corrected by increasing the max_records_per_case macro variable at the start of the transaction processing code.,DM,327,"['reconciliation', 'transaction', 'overflow', 'begin', 'detection', 'sql', 'code', 'list', 'case', 'transaction', 'count', 'excess', 'specified', 'maximum', 'list', 'observed', 'number', 'row', 'large', 'number', 'overflow', 'corrected', 'increasing', 'maxrecordspercase', 'macro', 'variable', 'start', 'transaction', 'processing', 'code']"
1296,"For predictive models, an analysis data set must contain a collection of independent cases with fields corresponding to the inputs, the target, and, usually, a cases identifier. These fields are usually created from data collected in the operations of an organization. In an ideal situation, the operations data is well organized in a data warehouse that is easy to access. While establishing such a warehouse can be an expensive undertaking, doing so avoids a lengthy data acquisition process, ultimately saving time and money for the organization.",DM,549,"['predictive', 'model', 'analysis', 'data_set', 'must', 'contain', 'collection', 'independent', 'case', 'field', 'corresponding', 'input', 'target', 'usually', 'case', 'identifier', 'field', 'usually', 'created', 'data', 'collected', 'operation', 'organization', 'ideal', 'situation', 'operation', 'data', 'well', 'organized', 'data', 'warehouse', 'easy', 'access', 'establishing', 'warehouse', 'expensive', 'undertaking', 'avoids', 'lengthy', 'data', 'acquisition', 'process', 'ultimately', 'saving', 'time', 'money', 'organization']"
1297,"Transaction events often serve as increments to a fixed value such as an account balance. Properties of account balances over time are often of great interest to the modeler. The existing framework can be modified to analyze account balance as a time series. In this way, properties such as average account balance, account volatility, and, later, balance trends can be used as inputs for predictive models.",DM,407,"['transaction', 'event', 'often', 'serve', 'increment', 'fixed', 'value', 'account', 'balance', 'property', 'account', 'balance', 'time', 'often', 'great', 'interest', 'modeler', 'existing', 'framework', 'modified', 'analyze', 'account', 'balance', 'time', 'series', 'way', 'property', 'average', 'account', 'balance', 'account', 'volatility', 'later', 'balance', 'trend', 'used', 'input', 'predictive', 'model']"
1298,"Without a suitable operational data warehouse, predictive model becomes at best inefficient and at worst impossible. Necessary data might be relegated to paper records in isolated legacy systems. Even in organizations with good data infrastructures, politics can turn data warehouses into data fortresses or data crypts, inaccessible to all but the select and privileged. Before you can even hope to start building predictive models, such impediments must be removed. As such, this course assumes the raw data to be reasonably well organized in a data warehouse.",DM,562,"['without', 'suitable', 'operational', 'data', 'warehouse', 'predictive', 'model', 'becomes', 'best', 'inefficient', 'worst', 'impossible', 'necessary', 'data', 'might', 'relegated', 'paper', 'record', 'isolated', 'legacy', 'system', 'even', 'organization', 'good', 'data', 'infrastructure', 'politics', 'turn', 'data', 'warehouse', 'data', 'fortress', 'data', 'crypt', 'inaccessible', 'select', 'privileged', 'even', 'hope', 'start', 'building', 'predictive', 'model', 'impediment', 'must', 'removed', 'course', 'assumes', 'raw', 'data', 'reasonably', 'well', 'organized', 'data', 'warehouse']"
1299,"The Export task commences upon reading the last transaction record for a given case. The first input created an account ownership indicator. Only accounts with transactions will have a checking account indicator variable (set equal to 1, that is). This fact will be useful during the finalize step.",DM,298,"['export', 'task', 'commences', 'upon', 'reading', 'last', 'transaction', 'record', 'given', 'case', 'first', 'input', 'created', 'account', 'ownership', 'indicator', 'account', 'transaction', 'checking', 'account', 'indicator', 'variable', 'set', 'equal', '1', 'fact', 'useful', 'finalize', 'step']"
1300,"Three types of expertise are required to achieve this (or any) analytic objective. The domain expert thoroughly understands the business aspects of the problem and is usually the ?owner? of the objective. He or she knows the approaches that have been attempted in the past to achieve the objective and their level of success. The data expert specializes in the raw materials of any predictive modeling endeavor. He or she knows where and how historical information is kept and can provide insight into the definitions of the data elements. The analytical methods expert knows the tools of predictive modeling. Ideally, the analytical methods expert prepares the analysis data or, at a minimum, closely supervises the data expert in the task. Each expert checks and influences the others. The analytic and data experts guide the domain expert as to the feasibility of analysis goals. The domain and analytic experts provide meaning and structural requirements to the data expert during data extraction. The domain and data experts offer reality checks on the analytic expert?s results and model implementation plans.",DM,1115,"['three', 'type', 'expertise', 'required', 'achieve', 'analytic', 'objective', 'domain', 'expert', 'thoroughly', 'understands', 'business', 'aspect', 'problem', 'usually', 'owner', 'objective', 'know', 'approach', 'attempted', 'past', 'achieve', 'objective', 'level', 'success', 'data', 'expert', 'specializes', 'raw', 'material', 'predictive', 'modeling', 'endeavor', 'know', 'historical', 'information', 'kept', 'provide', 'insight', 'definition', 'data', 'element', 'analytical', 'method', 'expert', 'know', 'tool', 'predictive', 'modeling', 'ideally', 'analytical', 'method', 'expert', 'prepares', 'analysis', 'data', 'minimum', 'closely', 'supervises', 'data', 'expert', 'task', 'expert', 'check', 'influence', 'others', 'analytic', 'data', 'expert', 'guide', 'domain', 'expert', 'feasibility', 'analysis', 'goal', 'domain', 'analytic', 'expert', 'provide', 'meaning', 'structural', 'requirement', 'data', 'expert', 'data', 'extraction', 'domain', 'data', 'expert', 'offer', 'reality', 'check', 'analytic', 'expert', 'result', 'model', 'implementation', 'plan']"
1301,"The join can be accomplished by bringing the data to the SAS analysis server and using the APPEND procedure, or by using the outer union capabilities of SQL. The CORRESPONDING option in the outer union combines corresponding columns in the selected tables.",DM,256,"['join', 'accomplished', 'bringing', 'data', 'sa', 'analysis', 'server', 'using', 'append', 'procedure', 'using', 'outer', 'union', 'capability', 'sql', 'corresponding', 'option', 'outer', 'union', 'combine', 'corresponding', 'column', 'selected', 'table']"
1302,"With the events extracted and sorted, the transaction transformation moves on to actual processing of individual events by case ID. For clarity, the augmentation of data is deferred until later. The processing step creates a data set, TN_CASE_INPUT, with one row per input per case. As such, the data set must be transposed for use as an input sample. The transposition occurs in the finalize step. The case input structure allows for the addition of an arbitrarily large number of inputs, without the added step of including each input in a keep list. It also facilitates the creation of stratified input variables because stratification levels are easily incorporated into input names.",DM,687,"['event', 'extracted', 'sorted', 'transaction', 'transformation', 'move', 'actual', 'processing', 'individual', 'event', 'case', 'id', 'clarity', 'augmentation', 'data', 'deferred', 'later', 'processing', 'step', 'creates', 'data_set', 'tncaseinput', 'one', 'row', 'per', 'input', 'per', 'case', 'data_set', 'must', 'transposed', 'use', 'input', 'sample', 'transposition', 'occurs', 'finalize', 'step', 'case', 'input', 'structure', 'allows', 'addition', 'arbitrarily', 'large', 'number', 'input', 'without', 'added', 'step', 'including', 'input', 'keep', 'list', 'also', 'facilitates', 'creation', 'stratified', 'input', 'variable', 'stratification', 'level', 'easily', 'incorporated', 'input', 'name']"
1303,"The next task after settling upon a data access method is selecting qualified responders. In the example, the responders are individuals who have already acquired the insurance product and are henceforth called INS clients. The INS clients are subject to a variety of qualification constraints involving recency of account acquisition, bank tenure, client age, and financial maturity. As the constraints are spread across multiple tables in the marketing warehouse, selecting the INS clients will require creating intermediate tables, preferably close to the RDBMS server.",DM,572,"['next', 'task', 'settling', 'upon', 'data', 'access', 'method', 'selecting', 'qualified', 'responder', 'example', 'responder', 'individual', 'already', 'acquired', 'insurance', 'product', 'henceforth', 'called', 'client', 'client', 'subject', 'variety', 'qualification', 'constraint', 'involving', 'recency', 'account', 'acquisition', 'bank', 'tenure', 'client', 'age', 'financial', 'maturity', 'constraint', 'spread', 'across', 'multiple', 'table', 'marketing', 'warehouse', 'selecting', 'client', 'require', 'creating', 'intermediate', 'table', 'preferably', 'close', 'rdbms', 'server']"
1304,"The read task is modified to include reading of the target date data set, which contains the target date and checking account open date. These dates will be incorporated into the transaction processing to establish case-specific relative time scales.",DM,250,"['read', 'task', 'modified', 'include', 'reading', 'target', 'date', 'data_set', 'contains', 'target', 'date', 'checking', 'account', 'open', 'date', 'date', 'incorporated', 'transaction', 'processing', 'establish', 'casespecific', 'relative', 'time', 'scale']"
1305,"The task of predictive modeling does not stand by itself. To build a successful predictive model you must first?unambiguously?define an analytic objective. The predictive model serves as a means of fulfilling the analytic objective. The predictive modeling effort is surrounded by two other tasks. Before modeling begins, data must be assembled, often from a variety of sources, and arranged in a format suitable for model building. After the modeling is complete, the resulting model (and the modeling results) must be integrated into the business environment that originally motivated the modeling. These tasks often require more effort than the modeling itself. This course focuses on the first of the three tasks: data preparation. Note that while the data preparation task comes before model building, this data preparation course is designed to be taken after a suitable predictive modeling course. With the background gained in a predictive modeling course, students gain insight into the reasons behind the data preparation activities.",DM,1043,"['task', 'predictive', 'modeling', 'doe', 'stand', 'build', 'successful', 'predictive', 'model', 'must', 'firstunambiguouslydefine', 'analytic', 'objective', 'predictive', 'model', 'serf', 'mean', 'fulfilling', 'analytic', 'objective', 'predictive', 'modeling', 'effort', 'surrounded', 'two', 'task', 'modeling', 'begin', 'data', 'must', 'assembled', 'often', 'variety', 'source', 'arranged', 'format', 'suitable', 'model', 'building', 'modeling', 'complete', 'resulting', 'model', 'modeling', 'result', 'must', 'integrated', 'business', 'environment', 'originally', 'motivated', 'modeling', 'task', 'often', 'require', 'effort', 'modeling', 'course', 'focus', 'first', 'three', 'task', 'data', 'preparation', 'note', 'data', 'preparation', 'task', 'come', 'model', 'building', 'data', 'preparation', 'course', 'designed', 'taken', 'suitable', 'predictive', 'modeling', 'course', 'background', 'gained', 'predictive', 'modeling', 'course', 'student', 'gain', 'insight', 'reason', 'behind', 'data', 'preparation', 'activity']"
1306,"In this analysis, stratification will occur on the tenure of a client with the financial institution. Tenure is defined as the number of months elapsed since the customer origination date. Because tenure is a continuous quantity, it will be binned using a so-called dilated time format. Using tenure addresses concerns about the exogenous correlation of time factors (such as the economy) with account acquisition. The strategy matches clients that arrive at the financial institution at about the same time. Some acquire the INS account, and some do not. Any observed differences will not result from factors related when the client originates. The bin sizes in the dilated time format increase with increasing number of months since event. Events within the last year are binned by month. Events between one and two years ago are grouped by quarter. Events 2-3 years ago are grouped by half-year. Events 3-8 years ago are grouped by year. Events more than 8 years ago are consolidated into a single bin representing ?the distant past.?",DM,1037,"['analysis', 'stratification', 'occur', 'tenure', 'client', 'financial', 'institution', 'tenure', 'defined', 'number', 'month', 'elapsed', 'since', 'customer', 'origination', 'date', 'tenure', 'continuous', 'quantity', 'binned', 'using', 'socalled', 'dilated', 'time', 'format', 'using', 'tenure', 'address', 'concern', 'exogenous', 'correlation', 'time', 'factor', 'economy', 'account', 'acquisition', 'strategy', 'match', 'client', 'arrive', 'financial', 'institution', 'time', 'acquire', 'account', 'observed', 'difference', 'result', 'factor', 'related', 'client', 'originates', 'bin', 'size', 'dilated', 'time', 'format', 'increase', 'increasing', 'number', 'month', 'since', 'event', 'event', 'within', 'last', 'year', 'binned', 'month', 'event', 'one', 'two', 'year', 'ago', 'grouped', 'quarter', 'event', '23', 'year', 'ago', 'grouped', 'halfyear', 'event', '38', 'year', 'ago', 'grouped', 'year', 'event', '8', 'year', 'ago', 'consolidated', 'single', 'bin', 'representing', 'distant', 'past']"
1307,"The join can be accomplished by bringing the data to the SAS analysis server and using the APPEND procedure, or by using the outer union capabilities of SQL. The CORRESPONDING option in the outer union combines corresponding columns in the selected tables.",DM,256,"['join', 'accomplished', 'bringing', 'data', 'sa', 'analysis', 'server', 'using', 'append', 'procedure', 'using', 'outer', 'union', 'capability', 'sql', 'corresponding', 'option', 'outer', 'union', 'combine', 'corresponding', 'column', 'selected', 'table']"
1308,"Simply knowing latitude and longitude of a case will probably not yield more predictive models. But when position is known, other quantities can also be calculated. One extremely useful quantity is proximity. The next two demonstrations show an effective technique for converting latitude and longitude measures to distance. The distance is calculated using the haversine function, an obscure but highly accurate throwback to the times of trigonometric tables. Combined with the zip code conversion macros, you will have a DATA step function that determines the approximate distance of any two locations (to five- digit zip code resolution). Calculating Distances",DM,663,"['simply', 'knowing', 'latitude', 'longitude', 'case', 'probably', 'yield', 'predictive', 'model', 'position', 'known', 'quantity', 'also', 'calculated', 'one', 'extremely', 'useful', 'quantity', 'proximity', 'next', 'two', 'demonstration', 'show', 'effective', 'technique', 'converting', 'latitude', 'longitude', 'measure', 'distance', 'distance', 'calculated', 'using', 'haversine', 'function', 'obscure', 'highly', 'accurate', 'throwback', 'time', 'trigonometric', 'table', 'combined', 'zip', 'code', 'conversion', 'macro', 'data', 'step', 'function', 'determines', 'approximate', 'distance', 'two', 'location', 'five', 'digit', 'zip', 'code', 'resolution', 'calculating', 'distance']"
1309,"A second input created is a transaction account overflow flag. This flag is zero unless the observed number of events for a case exceeds the assumed maximum. In this case, it is equal to the observed number of events.",DM,217,"['second', 'input', 'created', 'transaction', 'account', 'overflow', 'flag', 'flag', 'zero', 'unless', 'observed', 'number', 'event', 'case', 'exceeds', 'assumed', 'maximum', 'case', 'equal', 'observed', 'number', 'event']"
1310,"Examples of non-numeric data abound in predictive modeling applications. The focus is capturing the qualities of an entity rather than quantities. Ironically, from a modeling perspective the most important quality of non-numeric data is, in fact, a quantity: cardinality. Here, cardinality refers to the number of distinct levels of a non-numeric variable. Using non-numeric data in predictive models increases in difficulty with the cardinality. This chapter introduces strategies for overcoming some of these difficulties.",DM,524,"['example', 'nonnumeric', 'data', 'abound', 'predictive', 'modeling', 'application', 'focus', 'capturing', 'quality', 'entity', 'rather', 'quantity', 'ironically', 'modeling', 'perspective', 'important', 'quality', 'nonnumeric', 'data', 'fact', 'quantity', 'cardinality', 'cardinality', 'refers', 'number', 'distinct', 'level', 'nonnumeric', 'variable', 'using', 'nonnumeric', 'data', 'predictive', 'model', 'increase', 'difficulty', 'cardinality', 'chapter', 'introduces', 'strategy', 'overcoming', 'difficulty']"
1311,"While data used for predictive model development assumes a single row per case ID, data used to record the activities of individuals contains many rows per case ID. This data must be transformed for inclusion in predictive models. An individual transaction record typically contains one or more identification fields, a timestamp field, one or more classification fields, and possibly one or more amount fields.",DM,411,"['data', 'used', 'predictive', 'model', 'development', 'assumes', 'single', 'row', 'per', 'case', 'id', 'data', 'used', 'record', 'activity', 'individual', 'contains', 'many', 'row', 'per', 'case', 'id', 'data', 'must', 'transformed', 'inclusion', 'predictive', 'model', 'individual', 'transaction', 'record', 'typically', 'contains', 'one', 'identification', 'field', 'timestamp', 'field', 'one', 'classification', 'field', 'possibly', 'one', 'amount', 'field']"
1312,The program Extracting Relevant Data 3.sas demonstrates stratified separate sampling using the INS example data. The qualified INS and non-INS client data sets must be regenerated to include stratification source variable origination date. proc sql;,DM,249,"['program', 'extracting', 'relevant', 'data', '3sas', 'demonstrates', 'stratified', 'separate', 'sampling', 'using', 'example', 'data', 'qualified', 'nonins', 'client', 'data_set', 'must', 'regenerated', 'include', 'stratification', 'source', 'variable', 'origination', 'date', 'proc', 'sql']"
1313,"The simulation study shows that, in general, simple dummy coding and simple weight of evidence strategies should be avoided. Better results can be obtained by threshold dummy coding or smoothed weight of evidence approaches.",DM,224,"['simulation', 'study', 'show', 'general', 'simple', 'dummy', 'coding', 'simple', 'weight', 'evidence', 'strategy', 'avoided', 'better', 'result', 'obtained', 'threshold', 'dummy', 'coding', 'smoothed', 'weight', 'evidence', 'approach']"
1314,"The technique employed for reducing the size of the target sample is called separate sampling, although it is known by various other names including case- control sampling, choice-based sampling, biased sampling, y-conditional sampling, outcome-dependent sampling, and oversampling. When the number of nonresponders to responders, the N0:N1 ratio, is large, the usual practice is to take every responder available and an integer multiple of nonresponders for each responder. In the example above, for every INS client, two non-INS clients are selected. This creates a separately sampled target sample with a N0:N1 ratio of 2:1.",DM,627,"['technique', 'employed', 'reducing', 'size', 'target', 'sample', 'called', 'separate', 'sampling', 'although', 'known', 'various', 'name', 'including', 'case', 'control', 'sampling', 'choicebased', 'sampling', 'biased', 'sampling', 'yconditional', 'sampling', 'outcomedependent', 'sampling', 'oversampling', 'number', 'nonresponders', 'responder', 'n0n1', 'ratio', 'large', 'usual', 'practice', 'take', 'every', 'responder', 'available', 'integer', 'multiple', 'nonresponders', 'responder', 'example', 'every', 'client', 'two', 'nonins', 'client', 'selected', 'creates', 'separately', 'sampled', 'target', 'sample', 'n0n1', 'ratio', '21']"
1315,The TRANSPOSE procedure completes the first finalization task by rearranging the transaction case input data set. The output data set has a single row per case with the transaction inputs defining the columns.,DM,209,"['transpose', 'procedure', 'completes', 'first', 'finalization', 'task', 'rearranging', 'transaction', 'case', 'input', 'data_set', 'output', 'data_set', 'ha', 'single', 'row', 'per', 'case', 'transaction', 'input', 'defining', 'column']"
1316,"Subsequent chapters detail creation of the input sample, which consists of inputs derived from measurements in the operational data. The inputs provide facts and particulars about the selected cases. Inputs can be numeric, ordinal, nominal, geographic, or textual information.",DM,276,"['subsequent', 'chapter', 'detail', 'creation', 'input', 'sample', 'consists', 'input', 'derived', 'measurement', 'operational', 'data', 'input', 'provide', 'fact', 'particular', 'selected', 'case', 'input', 'numeric', 'ordinal', 'nominal', 'geographic', 'textual', 'information']"
1317,"The most important difference between access methods is the time required for their completion. Writing DATA step code to translate raw data into SAS data sets is time consuming. If the raw data is in a specific file format (such as a delimited file with column header information), the IMPORT procedure automates some of the DATA step code generation, although some code editing could be required to obtain the desired results. Using SAS/ACCESS products, the raw data appears to SAS as a SAS data set. This trims hours from the time required to read the raw data. Unfortunately, the raw data may need to be pulled across a network for SAS to operate on the data. Performance is then limited by network speed. The most efficient approach utilizes the SAS/ACCESS Pass-Through facility. Queries are then sent and executed directly to the RDBMS server. By limiting the transfer of data across the network, data access time is reduced to seconds even for large queries.",DM,965,"['important', 'difference', 'access', 'method', 'time', 'required', 'completion', 'writing', 'data', 'step', 'code', 'translate', 'raw', 'data', 'sa', 'data_set', 'time', 'consuming', 'raw', 'data', 'specific', 'file', 'format', 'delimited', 'file', 'column', 'header', 'information', 'import', 'procedure', 'automates', 'data', 'step', 'code', 'generation', 'although', 'code', 'editing', 'could', 'required', 'obtain', 'desired', 'result', 'using', 'sasaccess', 'product', 'raw', 'data', 'appears', 'sa', 'sa', 'data_set', 'trim', 'hour', 'time', 'required', 'read', 'raw', 'data', 'unfortunately', 'raw', 'data', 'may', 'need', 'pulled', 'across', 'network', 'sa', 'operate', 'data', 'performance', 'limited', 'network', 'speed', 'efficient', 'approach', 'utilizes', 'sasaccess', 'passthrough', 'facility', 'query', 'sent', 'executed', 'directly', 'rdbms', 'server', 'limiting', 'transfer', 'data', 'across', 'network', 'data', 'access', 'time', 'reduced', 'second', 'even', 'large', 'query']"
1318,Counting the number of transactions in a time period is handled by the macro function %N. This function counts the number of nonmissing values in the vector following the word of. The INTO= keyword parameter specifies the name of the variable for the result. The WHERE= keyword parameter can be used to condition the scope of the macro function.,DM,345,"['counting', 'number', 'transaction', 'time', 'period', 'handled', 'macro', 'function', 'n', 'function', 'count', 'number', 'nonmissing', 'value', 'vector', 'following', 'word', 'keyword', 'parameter', 'specifies', 'name', 'variable', 'result', 'keyword', 'parameter', 'used', 'condition', 'scope', 'macro', 'function']"
1319,"Thus far, the target date has been ignored in the input preparation process. Doing so contaminates any created inputs. In this iteration of the analysis, the target dates are read from the data warehouse. Only events that fall in the relevancy period are allowed in the transaction arrays.",DM,289,"['thus', 'far', 'target', 'date', 'ha', 'ignored', 'input', 'preparation', 'process', 'contaminates', 'created', 'input', 'iteration', 'analysis', 'target', 'date', 'read', 'data', 'warehouse', 'event', 'fall', 'relevancy', 'period', 'allowed', 'transaction', 'array']"
1320,"To avoid input sample contamination, a target date should be included in the target sample. This ensures that all input measurements are made before the target event, avoiding temporal infidelity. For INS clients the target date is obviously the account open date. For non-INS clients this date is undefined. This section demonstrates a method by which a meaningful target date can be established for non-INS clients.",DM,417,"['avoid', 'input', 'sample', 'contamination', 'target', 'date', 'included', 'target', 'sample', 'ensures', 'input', 'measurement', 'made', 'target', 'event', 'avoiding', 'temporal', 'infidelity', 'client', 'target', 'date', 'obviously', 'account', 'open', 'date', 'nonins', 'client', 'date', 'undefined', 'section', 'demonstrates', 'method', 'meaningful', 'target', 'date', 'established', 'nonins', 'client']"
1321,"The DATA step underlying the event processing can be conceptually divided into five tasks labeled Declare, Read, Initialize, Vector, and Export (mnemonic: DRIVE).",DM,162,"['data', 'step', 'underlying', 'event', 'processing', 'conceptually', 'divided', 'five', 'task', 'labeled', 'declare', 'read', 'initialize', 'vector', 'export', 'mnemonic', 'drive']"
1322,"Target sample creation for a model with a binary target involves four distinct tasks: *	accessing available data from the operational data repository *	selecting qualified responders, usually the minority target class *	selecting qualified nonresponders, usually the majority target class *	joining the responders and nonresponders to create a model sample, possibly stratified. The first three tasks can involve tens of millions of records from the operational repository and run most efficiently on the relational data base management system (RDBMS) server. The last task involves fewer records and will primarily occur within the SAS environment. 2.2	Simple Random Target Samples",DM,682,"['target', 'sample', 'creation', 'model', 'binary', 'target', 'involves', 'four', 'distinct', 'task', '\taccessing', 'available', 'data', 'operational', 'data', 'repository', '\tselecting', 'qualified', 'responder', 'usually', 'minority', 'target', 'class', '\tselecting', 'qualified', 'nonresponders', 'usually', 'majority', 'target', 'class', '\tjoining', 'responder', 'nonresponders', 'create', 'model', 'sample', 'possibly', 'stratified', 'first', 'three', 'task', 'involve', 'ten', 'million', 'record', 'operational', 'repository', 'run', 'efficiently', 'relational', 'data', 'base', 'management', 'system', 'rdbms', 'server', 'last', 'task', 'involves', 'fewer', 'record', 'primarily', 'occur', 'within', 'sa', 'environment', '22\tsimple', 'random', 'target', 'sample']"
1323,"Generating a synthetic distribution with mean replacement is an extremely easy to implement task. Open the file Managing Data Pathologies 3.sas in the program editor. Here, missing values will be replaced for three inputs. %let inputs=HMVAL LORES INCOME;",DM,254,"['generating', 'synthetic', 'distribution', 'mean', 'replacement', 'extremely', 'easy', 'implement', 'task', 'open', 'file', 'managing', 'data', 'pathology', '3sas', 'program', 'editor', 'missing', 'value', 'replaced', 'three', 'input', 'let', 'inputshmval', 'lore', 'income']"
1324,Open the file Extract Relevant Data 1.sas in the SAS program editor. This creates a simple random target sample from the raw operational data stored in the DMDP library. Browse the DMDP.INS_ACCOUNT data set.,DM,207,"['open', 'file', 'extract', 'relevant', 'data', '1sas', 'sa', 'program', 'editor', 'creates', 'simple', 'random', 'target', 'sample', 'raw', 'operational', 'data', 'stored', 'dmdp', 'library', 'browse', 'dmdpinsaccount', 'data_set']"
1325,"It is extremely easy to underestimate the scope of the data preparation task. When starting a project, many analysts anticipate ample time to explore a variety of predictive modeling techniques. They are often dismayed to discover that the data preparation activities require a majority of the time allotted. In the worst cases, much of the time is spent acquiring the analysis data from disparate and disorganized sources. Natural projects must be organized to allow ample time for both data preparation and data analysis.",DM,523,"['extremely', 'easy', 'underestimate', 'scope', 'data', 'preparation', 'task', 'starting', 'project', 'many', 'analyst', 'anticipate', 'ample', 'time', 'explore', 'variety', 'predictive', 'modeling', 'technique', 'often', 'dismayed', 'discover', 'data', 'preparation', 'activity', 'require', 'majority', 'time', 'allotted', 'worst', 'case', 'much', 'time', 'spent', 'acquiring', 'analysis', 'data', 'disparate', 'disorganized', 'source', 'natural', 'project', 'must', 'organized', 'allow', 'ample', 'time', 'data', 'preparation', 'data', 'analysis']"
1326,"The whimsical portrayals translate to issues well known to data miners. As data collection and storage costs decrease, analytic data sets grow larger and larger. When processing the data, it is easy to introduce artificial input/target associations by ignoring the temporal aspects of data. The most useful data describes the actions individuals take, which are recorded as transactions and events. To use this transaction data in a model, it must be transformed and summarized into a single record per case. Nonnumeric data requires specially treatment for inclusion in a model. However, the traditional approach of creating dummy variables for such data, often severely degrades model performance. Inputs with exceptional, extreme, or missing values pose many challenges to model performance. Finally, stationarity, the assumption that the world in which the model will be deployed resembles the world from which the model was built, must constantly guide the data preparation process.",DM,987,"['whimsical', 'portrayal', 'translate', 'issue', 'well', 'known', 'data', 'miner', 'data', 'collection', 'storage', 'cost', 'decrease', 'analytic', 'data_set', 'grow', 'larger', 'larger', 'processing', 'data', 'easy', 'introduce', 'artificial', 'inputtarget', 'association', 'ignoring', 'temporal', 'aspect', 'data', 'useful', 'data', 'describes', 'action', 'individual', 'take', 'recorded', 'transaction', 'event', 'use', 'transaction', 'data', 'model', 'must', 'transformed', 'summarized', 'single', 'record', 'per', 'case', 'nonnumeric', 'data', 'requires', 'specially', 'treatment', 'inclusion', 'model', 'however', 'traditional', 'approach', 'creating', 'dummy', 'variable', 'data', 'often', 'severely', 'degrades', 'model', 'performance', 'input', 'exceptional', 'extreme', 'missing', 'value', 'pose', 'many', 'challenge', 'model', 'performance', 'finally', 'stationarity', 'assumption', 'world', 'model', 'deployed', 'resembles', 'world', 'model', 'wa', 'built', 'must', 'constantly', 'guide', 'data', 'preparation', 'process']"
1327,Unknown male names are assigned small (but non-zero) probabilities of being male. Similar processing occurs for the female names. data f; set dmdp.census_names_female end=LAST;,DM,176,"['unknown', 'male', 'name', 'assigned', 'small', 'nonzero', 'probability', 'male', 'similar', 'processing', 'occurs', 'female', 'name', 'data', 'f', 'set', 'dmdpcensusnamesfemale', 'endlast']"
1328,The scratch array is a two-dimensional array used by the transaction macro functions to store intermediate results. Any DATA step that uses the transaction processing macros must include a scratch array definition. The temporary array?s dimensions are 0 to the maximum number records per case in one dimension and 0 to 5 in the other dimension.,DM,344,"['scratch', 'array', 'twodimensional', 'array', 'used', 'transaction', 'macro', 'function', 'store', 'intermediate', 'result', 'data', 'step', 'us', 'transaction', 'processing', 'macro', 'must', 'include', 'scratch', 'array', 'definition', 'temporary', 'array', 'dimension', '0', 'maximum', 'number', 'record', 'per', 'case', 'one', 'dimension', '0', '5', 'dimension']"
1329,"If the relative event date is less than 365 days from the origin, the event is added to the transaction array. The code is similar to previous versions. However, the transaction date is now recorded in relative time. Processing Time-Dependent Data",DM,247,"['relative', 'event', 'date', 'le', '365', 'day', 'origin', 'event', 'added', 'transaction', 'array', 'code', 'similar', 'previous', 'version', 'however', 'transaction', 'date', 'recorded', 'relative', 'time', 'processing', 'timedependent', 'data']"
1330,Unknown male names are assigned small (but non-zero) probabilities of being male. Similar processing occurs for the female names. data f; set dmdp.census_names_female end=LAST;,DM,176,"['unknown', 'male', 'name', 'assigned', 'small', 'nonzero', 'probability', 'male', 'similar', 'processing', 'occurs', 'female', 'name', 'data', 'f', 'set', 'dmdpcensusnamesfemale', 'endlast']"
1331,"Of course, the events occur across time, which immediately suggests time series analysis. Time averages and trends are excellent summaries of case behavior, as are measures of time series variability. The demonstrations in the chapter illustrate creation of each of these types of inputs. Macro functions are provided to allow for straightforward (if not easy) implementation of these techniques on your own data.",DM,413,"['course', 'event', 'occur', 'across', 'time', 'immediately', 'suggests', 'time', 'series', 'analysis', 'time', 'average', 'trend', 'excellent', 'summary', 'case', 'behavior', 'measure', 'time', 'series', 'variability', 'demonstration', 'chapter', 'illustrate', 'creation', 'type', 'input', 'macro', 'function', 'provided', 'allow', 'straightforward', 'easy', 'implementation', 'technique', 'data']"
1332,"The location of the point mass in synthetic distribution methods is not arbitrary. Ideally, to allow variable selection processes to operate correctly, the synthesized value should be chosen to have minimal impact on the magnitude of an input?s association with the target. For many modeling methods, this can be achieved by locating the point mass at the input?s mean value. Cases with input values equal to the mean value have no influence on the estimation of that input?s model parameters. Because predicted response can be different for cases with a missing input value, a binary imputation indicator variable should also be added to the input sample to allow the model to adjust its predictions.",DM,701,"['location', 'point', 'mass', 'synthetic', 'distribution', 'method', 'arbitrary', 'ideally', 'allow', 'variable', 'selection', 'process', 'operate', 'correctly', 'synthesized', 'value', 'chosen', 'minimal', 'impact', 'magnitude', 'input', 'association', 'target', 'many', 'modeling', 'method', 'achieved', 'locating', 'point', 'mass', 'input', 'mean', 'value', 'case', 'input', 'value', 'equal', 'mean', 'value', 'influence', 'estimation', 'input', 'model', 'parameter', 'predicted', 'response', 'different', 'case', 'missing', 'input', 'value', 'binary', 'imputation', 'indicator', 'variable', 'also', 'added', 'input', 'sample', 'allow', 'model', 'adjust', 'prediction']"
1333,"Type, channel, and method codes can be used to group transactions for stratified analyses. Additions to the augmentation and process steps allow the creation of stratified input variables. These inputs can be used to create an account interaction profile for each client.",DM,271,"['type', 'channel', 'method', 'code', 'used', 'group', 'transaction', 'stratified', 'analysis', 'addition', 'augmentation', 'process', 'step', 'allow', 'creation', 'stratified', 'input', 'variable', 'input', 'used', 'create', 'account', 'interaction', 'profile', 'client']"
1334,The events in the period of interest can be stratified by time or transaction class variables. The events within each stratum can be thought of as measurements of a random variable. Descriptive statistics of these random variable distributions generate additional model inputs.,DM,277,"['event', 'period', 'interest', 'stratified', 'time', 'transaction', 'class', 'variable', 'event', 'within', 'stratum', 'thought', 'measurement', 'random', 'variable', 'descriptive', 'statistic', 'random', 'variable', 'distribution', 'generate', 'additional', 'model', 'input']"
1335,"The typical approach (from a statistician?s perspective) is dummy coding the levels of the non-numeric input. In this way, a predictive model sees each level equidistant and can adjust predicted response to accurately reflect the response difference between levels. However, the problem with dummy coding is precisely one of accuracy. A variable with a multitude of levels can generate as many dummy coding inputs as there are cases in the training data set. The model is able to predict response exactly, at least for the training data. This problem is called overgeneralization, in that predicted responses do not generalize to a new, identically distributed set of data.",DM,673,"['typical', 'approach', 'statistician', 'perspective', 'dummy', 'coding', 'level', 'nonnumeric', 'input', 'way', 'predictive', 'model', 'see', 'level', 'equidistant', 'adjust', 'predicted', 'response', 'accurately', 'reflect', 'response', 'difference', 'level', 'however', 'problem', 'dummy', 'coding', 'precisely', 'one', 'accuracy', 'variable', 'multitude', 'level', 'generate', 'many', 'dummy', 'coding', 'input', 'case', 'training', 'data_set', 'model', 'able', 'predict', 'response', 'exactly', 'least', 'training', 'data', 'problem', 'called', 'overgeneralization', 'predicted', 'response', 'generalize', 'new', 'identically', 'distributed', 'set', 'data']"
1336,Time trends in transactions are useful for predicting future events. This final modification to the event processing code demonstrates one way in which balance trends can be identified.,DM,185,"['time', 'trend', 'transaction', 'useful', 'predicting', 'future', 'event', 'final', 'modification', 'event', 'processing', 'code', 'demonstrates', 'one', 'way', 'balance', 'trend', 'identified']"
1337,"A simple but effective remedy for overgeneralization is thresholding?that is, requiring a minimum number of cases in a level before creating a dummy code input. Any level failing to meet this minimum threshold is relegated to a new level called OTHER. By reducing the number of inputs available to a model, thresholding limits the model?s ability to ?discover? spurious input-target associations.",DM,396,"['simple', 'effective', 'remedy', 'overgeneralization', 'thresholdingthat', 'requiring', 'minimum', 'number', 'case', 'level', 'creating', 'dummy', 'code', 'input', 'level', 'failing', 'meet', 'minimum', 'threshold', 'relegated', 'new', 'level', 'called', 'reducing', 'number', 'input', 'available', 'model', 'thresholding', 'limit', 'model', 'ability', 'discover', 'spurious', 'inputtarget', 'association']"
1338,"The data set contains facts describing the insurance account. To minimize disk space, the facts are limited to account ID and account open date. In practice, the data set would contain other fields, such as rates, maturity dates, and initial deposit amount. Browse the DMDP.CLIENT_INS_ACCOUNT data set.",DM,302,"['data_set', 'contains', 'fact', 'describing', 'insurance', 'account', 'minimize', 'disk', 'space', 'fact', 'limited', 'account', 'id', 'account', 'open', 'date', 'practice', 'data_set', 'would', 'contain', 'field', 'rate', 'maturity', 'date', 'initial', 'deposit', 'amount', 'browse', 'dmdpclientinsaccount', 'data_set']"
1339,"With the BALANCE array containing the actual daily balance of the account, it is easy to generate statistic describing the balance distribution. For example, the %MEAN macro function yields the average daily balance.",DM,216,"['balance', 'array', 'containing', 'actual', 'daily', 'balance', 'account', 'easy', 'generate', 'statistic', 'describing', 'balance', 'distribution', 'example', 'mean', 'macro', 'function', 'yield', 'average', 'daily', 'balance']"
1340,The TN_CODE_IDX array is used to capture the grouping code indices of each transaction event. The transaction code indices are generated by translating the raw profile to a grouping code and the grouping code to an index.,DM,221,"['tncodeidx', 'array', 'used', 'capture', 'grouping', 'code', 'index', 'transaction', 'event', 'transaction', 'code', 'index', 'generated', 'translating', 'raw', 'profile', 'grouping', 'code', 'grouping', 'code', 'index']"
1341,"A new process variable, R_OPEN_DT, is declared and retained. R_OPEN_DT will give the checking account open date in relative time. A negative value indicates a checking account open date after the target date minus latency.",DM,222,"['new', 'process', 'variable', 'ropendt', 'declared', 'retained', 'ropendt', 'give', 'checking', 'account', 'open', 'date', 'relative', 'time', 'negative', 'value', 'indicates', 'checking', 'account', 'open', 'date', 'target', 'date', 'minus', 'latency']"
1342,Reconciliation of transaction overflows begins with detection. The SQL code lists cases with transaction count in excess of the specified maximum and list observed number of rows. A large number of overflows can be corrected by increasing the max_records_per_case macro variable at the start of the transaction processing code.,DM,327,"['reconciliation', 'transaction', 'overflow', 'begin', 'detection', 'sql', 'code', 'list', 'case', 'transaction', 'count', 'excess', 'specified', 'maximum', 'list', 'observed', 'number', 'row', 'large', 'number', 'overflow', 'corrected', 'increasing', 'maxrecordspercase', 'macro', 'variable', 'start', 'transaction', 'processing', 'code']"
1343,The program Extracting Relevant Data 3.sas demonstrates stratified separate sampling using the INS example data. The qualified INS and non-INS client data sets must be regenerated to include stratification source variable origination date. proc sql;,DM,249,"['program', 'extracting', 'relevant', 'data', '3sas', 'demonstrates', 'stratified', 'separate', 'sampling', 'using', 'example', 'data', 'qualified', 'nonins', 'client', 'data_set', 'must', 'regenerated', 'include', 'stratification', 'source', 'variable', 'origination', 'date', 'proc', 'sql']"
1344,Many of the records have missing values corresponding to unknown zip codes. Remedying these missing values requires taking advantage of another property of zip codes: hierarchy. Imputing Missing Geocode Values,DM,209,"['many', 'record', 'missing', 'value', 'corresponding', 'unknown', 'zip', 'code', 'remedying', 'missing', 'value', 'requires', 'taking', 'advantage', 'another', 'property', 'zip', 'code', 'hierarchy', 'imputing', 'missing', 'geocode', 'value']"
1345,"A simulation study helps to illustrate the consequences of separate sampling. The details of the simulation are presented above. The results presented are standard logistic regression models with two inputs. The models were correctly specified, so it was possible to achieve an MSB extremely close to zero. The simulation was also run for other input counts and for improperly specified models with similar results.",DM,415,"['simulation', 'study', 'help', 'illustrate', 'consequence', 'separate', 'sampling', 'detail', 'simulation', 'presented', 'result', 'presented', 'standard', 'logistic_regression_model', 'two', 'input', 'model', 'correctly', 'specified', 'wa', 'possible', 'achieve', 'msb', 'extremely', 'close', 'zero', 'simulation', 'wa', 'also', 'run', 'input', 'count', 'improperly', 'specified', 'model', 'similar', 'result']"
1346,"Generating a synthetic distribution with mean replacement is an extremely easy to implement task. Open the file Managing Data Pathologies 3.sas in the program editor. Here, missing values will be replaced for three inputs. %let inputs=HMVAL LORES INCOME;",DM,254,"['generating', 'synthetic', 'distribution', 'mean', 'replacement', 'extremely', 'easy', 'implement', 'task', 'open', 'file', 'managing', 'data', 'pathology', '3sas', 'program', 'editor', 'missing', 'value', 'replaced', 'three', 'input', 'let', 'inputshmval', 'lore', 'income']"
1347,"The checking account IDs of clients in the target sample are placed in a data set named SAMPLE_CHECKING_ACCOUNTS. As mentioned above, in practice, several checking account qualifications might be invoked at this point. *** Access Transaction Data from Warehouse; proc sql; create table sample_checking_accounts as select CLIENT_ID, CHECKING_ID from dmdp.client_checking_account where CLIENT_ID in (select CLIENT_ID from dmdp.target_sample);",DM,440,"['checking', 'account', 'id', 'client', 'target', 'sample', 'placed', 'data_set', 'named', 'samplecheckingaccounts', 'mentioned', 'practice', 'several', 'checking', 'account', 'qualification', 'might', 'invoked', 'point', '', 'access', 'transaction', 'data', 'warehouse', 'proc', 'sql', 'create', 'table', 'samplecheckingaccounts', 'select', 'clientid', 'checkingid', 'dmdpclientcheckingaccount', 'clientid', 'select', 'clientid', 'dmdptargetsample']"
1348,"A small addition to the execute task of the process by ID step generates an input that counts the number of events occurring between day zero and day 30 in relative time. A new variable, TN_LIMIT, is calculated to prevent reading past the limits of the transaction array.",DM,271,"['small', 'addition', 'execute', 'task', 'process', 'id', 'step', 'generates', 'input', 'count', 'number', 'event', 'occurring', 'day', 'zero', 'day', '30', 'relative', 'time', 'new', 'variable', 'tnlimit', 'calculated', 'prevent', 'reading', 'past', 'limit', 'transaction', 'array']"
1349,"This chapter focuses on creation of the target sample, which consists of the ID, target, and target date for cases satisfying the population qualifications of the analytic objective.",DM,182,"['chapter', 'focus', 'creation', 'target', 'sample', 'consists', 'id', 'target', 'target', 'date', 'case', 'satisfying', 'population', 'qualification', 'analytic', 'objective']"
1350,"The most straightforward implementation of separate sampling involves transferring the INS and non-INS qualified client data sets from the warehouse server to the SAS analysis server. Transfer can be accomplished by defining a SAS/ACCESS library reference to the server and copying the data with a DATA step. ?	While most major RDBMS engines (Oracle, DB2, and SQLServer) have functions for implementing separate sampling, the functions are specific to the RDBMS engine and beyond the scope of this course.",DM,505,"['straightforward', 'implementation', 'separate', 'sampling', 'involves', 'transferring', 'nonins', 'qualified', 'client', 'data_set', 'warehouse', 'server', 'sa', 'analysis', 'server', 'transfer', 'accomplished', 'defining', 'sasaccess', 'library', 'reference', 'server', 'copying', 'data', 'data', 'step', '\twhile', 'major', 'rdbms', 'engine', 'oracle', 'db2', 'sqlserver', 'function', 'implementing', 'separate', 'sampling', 'function', 'specific', 'rdbms', 'engine', 'beyond', 'scope', 'course']"
1351,The events in the period of interest can be thought of as measurements of a random variable. All manner of statistics to describe the distribution of this random variable can be used as model inputs.,DM,199,"['event', 'period', 'interest', 'thought', 'measurement', 'random', 'variable', 'manner', 'statistic', 'describe', 'distribution', 'random', 'variable', 'used', 'model', 'input']"
1352,"Potential predictive pitfalls can lurk in data sets with many cleverly crafted inputs. Data pathologies?input miscodings, extreme or outlying cases, highly skewed distributions, and missing values?can all seriously diminish model performance. This chapter offers a three-step regimen for countering these pathologies. Section 5.2 presents methods for finding potential problems in an input sample. Section 5.3 suggests transformations to avoid the debilitating effects of highly skewed inputs. Section 5.4 compares strategies for missing value imputation.",DM,555,"['potential', 'predictive', 'pitfall', 'lurk', 'data_set', 'many', 'cleverly', 'crafted', 'input', 'data', 'pathologiesinput', 'miscodings', 'extreme', 'outlying', 'case', 'highly', 'skewed', 'distribution', 'missing', 'valuescan', 'seriously', 'diminish', 'model', 'performance', 'chapter', 'offer', 'threestep', 'regimen', 'countering', 'pathology', 'section', '52', 'present', 'method', 'finding', 'potential', 'problem', 'input', 'sample', 'section', '53', 'suggests', 'transformation', 'avoid', 'debilitating', 'effect', 'highly', 'skewed', 'input', 'section', '54', 'compare', 'strategy', 'missing', 'value', 'imputation']"
1353,"Examples of non-numeric data abound in predictive modeling applications. The focus is capturing the qualities of an entity rather than quantities. Ironically, from a modeling perspective the most important quality of non-numeric data is, in fact, a quantity: cardinality. Here, cardinality refers to the number of distinct levels of a non-numeric variable. Using non-numeric data in predictive models increases in difficulty with the cardinality. This chapter introduces strategies for overcoming some of these difficulties.",DM,524,"['example', 'nonnumeric', 'data', 'abound', 'predictive', 'modeling', 'application', 'focus', 'capturing', 'quality', 'entity', 'rather', 'quantity', 'ironically', 'modeling', 'perspective', 'important', 'quality', 'nonnumeric', 'data', 'fact', 'quantity', 'cardinality', 'cardinality', 'refers', 'number', 'distinct', 'level', 'nonnumeric', 'variable', 'using', 'nonnumeric', 'data', 'predictive', 'model', 'increase', 'difficulty', 'cardinality', 'chapter', 'introduces', 'strategy', 'overcoming', 'difficulty']"
1354,The MEANS procedure is used to find the minimum and mean of each variable and rank group combination. This table will be used to form the rank formats. proc means data=rtranspose noprint; by VARNAME R_VALUE; output out=mrtranspose min=min mean=mean; run;,DM,254,"['mean', 'procedure', 'used', 'find', 'minimum', 'mean', 'variable', 'rank', 'group', 'combination', 'table', 'used', 'form', 'rank', 'format', 'proc', 'mean', 'datartranspose', 'noprint', 'varname', 'rvalue', 'output', 'outmrtranspose', 'minmin', 'meanmean', 'run']"
1355,"Stratified separate sampling offers an improvement over the simple random approach shown in the previous section. In stratified separate sampling, a specified number of cases are drawn from levels of designated stratification variables. If the stratification variables are carefully chosen, the sample can control for exogenous factors in the data such as time and macroscopic economic conditions. This allows the sample to better represent the target population and thereby improves model accuracy.",DM,499,"['stratified', 'separate', 'sampling', 'offer', 'improvement', 'simple', 'random', 'approach', 'shown', 'previous', 'section', 'stratified', 'separate', 'sampling', 'specified', 'number', 'case', 'drawn', 'level', 'designated', 'stratification', 'variable', 'stratification', 'variable', 'carefully', 'chosen', 'sample', 'control', 'exogenous', 'factor', 'data', 'time', 'macroscopic', 'economic', 'condition', 'allows', 'sample', 'better', 'represent', 'target', 'population', 'thereby', 'improves', 'model', 'accuracy']"
1356,"A different modification to the basic weight of evidence approach (inspired by Bayesian statistical methods) assumes a priori distributions for the target average within level. These so-called prior distributions reflect the analyst?s state of knowledge about the expect value of the target within level. Observations from the training data are then combined with the prior data to form updated estimates of the target average distribution. The expected value of this a posteriori distribution serves as the estimated target value within level. These so-called posterior estimates show substantial reduction prediction bias compared to the basic weight of evidence approach, especially in non-numeric inputs with tens to hundreds of levels.",DM,740,"['different', 'modification', 'basic', 'weight', 'evidence', 'approach', 'inspired', 'bayesian', 'statistical', 'method', 'assumes', 'priori', 'distribution', 'target', 'average', 'within', 'level', 'socalled', 'prior', 'distribution', 'reflect', 'analyst', 'state', 'knowledge', 'expect', 'value', 'target', 'within', 'level', 'observation', 'training', 'data', 'combined', 'prior', 'data', 'form', 'updated', 'estimate', 'target', 'average', 'distribution', 'expected', 'value', 'posteriori', 'distribution', 'serf', 'estimated', 'target', 'value', 'within', 'level', 'socalled', 'posterior', 'estimate', 'show', 'substantial', 'reduction', 'prediction', 'bias', 'compared', 'basic', 'weight', 'evidence', 'approach', 'especially', 'nonnumeric', 'input', 'ten', 'hundred', 'level']"
1357,Time trends in transactions are useful for predicting future events. This final modification to the event processing code demonstrates one way in which balance trends can be identified.,DM,185,"['time', 'trend', 'transaction', 'useful', 'predicting', 'future', 'event', 'final', 'modification', 'event', 'processing', 'code', 'demonstrates', 'one', 'way', 'balance', 'trend', 'identified']"
1358,"In this analysis, stratification will occur on the tenure of a client with the financial institution. Tenure is defined as the number of months elapsed since the customer origination date. Because tenure is a continuous quantity, it will be binned using a so-called dilated time format. Using tenure addresses concerns about the exogenous correlation of time factors (such as the economy) with account acquisition. The strategy matches clients that arrive at the financial institution at about the same time. Some acquire the INS account, and some do not. Any observed differences will not result from factors related when the client originates. The bin sizes in the dilated time format increase with increasing number of months since event. Events within the last year are binned by month. Events between one and two years ago are grouped by quarter. Events 2-3 years ago are grouped by half-year. Events 3-8 years ago are grouped by year. Events more than 8 years ago are consolidated into a single bin representing ?the distant past.?",DM,1037,"['analysis', 'stratification', 'occur', 'tenure', 'client', 'financial', 'institution', 'tenure', 'defined', 'number', 'month', 'elapsed', 'since', 'customer', 'origination', 'date', 'tenure', 'continuous', 'quantity', 'binned', 'using', 'socalled', 'dilated', 'time', 'format', 'using', 'tenure', 'address', 'concern', 'exogenous', 'correlation', 'time', 'factor', 'economy', 'account', 'acquisition', 'strategy', 'match', 'client', 'arrive', 'financial', 'institution', 'time', 'acquire', 'account', 'observed', 'difference', 'result', 'factor', 'related', 'client', 'originates', 'bin', 'size', 'dilated', 'time', 'format', 'increase', 'increasing', 'number', 'month', 'since', 'event', 'event', 'within', 'last', 'year', 'binned', 'month', 'event', 'one', 'two', 'year', 'ago', 'grouped', 'quarter', 'event', '23', 'year', 'ago', 'grouped', 'halfyear', 'event', '38', 'year', 'ago', 'grouped', 'year', 'event', '8', 'year', 'ago', 'consolidated', 'single', 'bin', 'representing', 'distant', 'past']"
1359,"Transaction data is probably the richest source of information for predictive models. It can capture complex individual behavior in a highly detailed fashion. Because the patterns captured in transaction data often mirror the target event, the data yields inputs with strong target correlation potential.",DM,304,"['transaction', 'data', 'probably', 'richest', 'source', 'information', 'predictive', 'model', 'capture', 'complex', 'individual', 'behavior', 'highly', 'detailed', 'fashion', 'pattern', 'captured', 'transaction', 'data', 'often', 'mirror', 'target', 'event', 'data', 'yield', 'input', 'strong', 'target', 'correlation', 'potential']"
1360,"?	The macro functions depend on the zip code formats. As defined, these formats are only available in your current SAS session. To make these formats available later, you must store their definitions in a permanent SAS library. This is done using the LIBRARY= option of the FORMAT procedure. Select the online help or ask your instructor for details.",DM,350,"['\tthe', 'macro', 'function', 'depend', 'zip', 'code', 'format', 'defined', 'format', 'available', 'current', 'sa', 'session', 'make', 'format', 'available', 'later', 'must', 'store', 'definition', 'permanent', 'sa', 'library', 'done', 'using', 'library', 'option', 'format', 'procedure', 'select', 'online', 'help', 'ask', 'instructor', 'detail']"
1361,"Type, channel, and method codes can be used to group transactions for stratified analyses. Additions to the augmentation and process steps allow the creation of stratified input variables. These inputs can be used to create an account interaction profile for each client.",DM,271,"['type', 'channel', 'method', 'code', 'used', 'group', 'transaction', 'stratified', 'analysis', 'addition', 'augmentation', 'process', 'step', 'allow', 'creation', 'stratified', 'input', 'variable', 'input', 'used', 'create', 'account', 'interaction', 'profile', 'client']"
1362,"*	Temporal infidelity occurs when model inputs contain information that will be unavailable at the time the prediction model is deployed. Including an individual?s current credit score in a model to predict a past event like bankruptcy is a case of temporal infidelity. Individual specific data before the event of interest is needed for accurate prediction. *	Hidden or deterministic rules sometimes plague predictive models. For example, a model used to identify customers interested in a credit card protection product could be built from customers with and without the product. However, unbeknownst to the analyst, all credit card customers automatically received the product as part of a special promotion. These customers should be excluded from the analysis, but identifying them can be problematic. *	Temporal factors affect the distribution of modeling data in unaccountable ways. A fundamental assumption of predictive modeling is stationarity?that is, the data from which the models are built looks more or less like the data to which the models will be applied. Macroeconomic factors often cast doubt on such assumptions. For example, a loan prepayment model built from data when interest rates are falling may be of little use when interest rates stabilize or begin to climb. *	Sampling errors, the most insidious problem, can contaminate model data. Creation of modeling data involves the manipulation and transformation of possibly hundreds of data sets. Mistakes at any stage can introduce noise or correlations that corrupt model predictions.",DM,1559,"['\ttemporal', 'infidelity', 'occurs', 'model', 'input', 'contain', 'information', 'unavailable', 'time', 'prediction', 'model', 'deployed', 'including', 'individual', 'current', 'credit', 'score', 'model', 'predict', 'past', 'event', 'like', 'bankruptcy', 'case', 'temporal', 'infidelity', 'individual', 'specific', 'data', 'event', 'interest', 'needed', 'accurate', 'prediction', '\thidden', 'deterministic', 'rule', 'sometimes', 'plague', 'predictive', 'model', 'example', 'model', 'used', 'identify', 'customer', 'interested', 'credit', 'card', 'protection', 'product', 'could', 'built', 'customer', 'without', 'product', 'however', 'unbeknownst', 'analyst', 'credit', 'card', 'customer', 'automatically', 'received', 'product', 'part', 'special', 'promotion', 'customer', 'excluded', 'analysis', 'identifying', 'problematic', '\ttemporal', 'factor', 'affect', 'distribution', 'modeling', 'data', 'unaccountable', 'way', 'fundamental', 'assumption', 'predictive', 'modeling', 'stationaritythat', 'data', 'model', 'built', 'look', 'le', 'like', 'data', 'model', 'applied', 'macroeconomic', 'factor', 'often', 'cast', 'doubt', 'assumption', 'example', 'loan', 'prepayment', 'model', 'built', 'data', 'interest', 'rate', 'falling', 'may', 'little', 'use', 'interest', 'rate', 'stabilize', 'begin', 'climb', '\tsampling', 'error', 'insidious', 'problem', 'contaminate', 'model', 'data', 'creation', 'modeling', 'data', 'involves', 'manipulation', 'transformation', 'possibly', 'hundred', 'data_set', 'mistake', 'stage', 'introduce', 'noise', 'correlation', 'corrupt', 'model', 'prediction']"
1363,"A simulation study helps to illustrate the consequences of separate sampling. The details of the simulation are presented above. The results presented are standard logistic regression models with two inputs. The models were correctly specified, so it was possible to achieve an MSB extremely close to zero. The simulation was also run for other input counts and for improperly specified models with similar results.",DM,415,"['simulation', 'study', 'help', 'illustrate', 'consequence', 'separate', 'sampling', 'detail', 'simulation', 'presented', 'result', 'presented', 'standard', 'logistic_regression_model', 'two', 'input', 'model', 'correctly', 'specified', 'wa', 'possible', 'achieve', 'msb', 'extremely', 'close', 'zero', 'simulation', 'wa', 'also', 'run', 'input', 'count', 'improperly', 'specified', 'model', 'similar', 'result']"
1364,"Any analytic objective involving predictive modeling starts with extraction and transformation of data from remote sources. The level of effort required for this first step is easy to underestimate and is often fraught with difficulties. First, useful data might not exist. For example, a business that wants to predict product failure might collect a large amount of data describing the particulars of defective products, but not record similar information for nondefective products. Even when data exists, it can be impossible to utilize it without violating privacy rules. For example, the Health Insurance Portability and Accountability Act of 1996 prohibits insurance companies from using data used for processing medical claims to underwrite other products, such as life insurance. Assuming that data is available and allowed, useful information is often spread across many disparate sources. Even when data is well organized, the normalized database design disperses information across many tables. For example, a typical marketing data warehouse contains dozens of tables with direct links to dozens more. Because detail tables provide the most insight into customer behavior, they are most valuable for predictive modeling. Yet a single customer can generate thousands of records over the course of a year. Moving these large volumes of data across networks can dramatically slow the data preparation process. Predictive models are often built from a target variable corresponding to a (binary) classification. This classification, in turn, relates to characteristics stored in a database. Success in achieving an analytic objective hinges on a relevant and unambiguous statement of the characteristics corresponding to each class. Without such a statement, it is difficult to extract meaningful modeling data. For example, banks construct risk scores based on the classification of known customers into ?good? and ?bad? credit risks. The precise definition of good and bad risk, however, is somewhat ambiguous and must be agreed upon in advanced. Even when data is available, useable, tractable, and explicable, the largest data extraction challenge remains: drawing an uncontaminated modeling sample. Avoiding the unintentional leakage of target information into the modeling inputs is a recurring theme in this course and the bane of all data mining efforts.",DM,2370,"['analytic', 'objective', 'involving', 'predictive', 'modeling', 'start', 'extraction', 'transformation', 'data', 'remote', 'source', 'level', 'effort', 'required', 'first', 'step', 'easy', 'underestimate', 'often', 'fraught', 'difficulty', 'first', 'useful', 'data', 'might', 'exist', 'example', 'business', 'want', 'predict', 'product', 'failure', 'might', 'collect', 'large', 'amount', 'data', 'describing', 'particular', 'defective', 'product', 'record', 'similar', 'information', 'nondefective', 'product', 'even', 'data', 'exists', 'impossible', 'utilize', 'without', 'violating', 'privacy', 'rule', 'example', 'health', 'insurance', 'portability', 'accountability', 'act', '1996', 'prohibits', 'insurance', 'company', 'using', 'data', 'used', 'processing', 'medical', 'claim', 'underwrite', 'product', 'life', 'insurance', 'assuming', 'data', 'available', 'allowed', 'useful', 'information', 'often', 'spread', 'across', 'many', 'disparate', 'source', 'even', 'data', 'well', 'organized', 'normalized', 'database', 'design', 'disperses', 'information', 'across', 'many', 'table', 'example', 'typical', 'marketing', 'data', 'warehouse', 'contains', 'dozen', 'table', 'direct', 'link', 'dozen', 'detail', 'table', 'provide', 'insight', 'customer', 'behavior', 'valuable', 'predictive', 'modeling', 'yet', 'single', 'customer', 'generate', 'thousand', 'record', 'course', 'year', 'moving', 'large', 'volume', 'data', 'across', 'network', 'dramatically', 'slow', 'data', 'preparation', 'process', 'predictive', 'model', 'often', 'built', 'target', 'variable', 'corresponding', 'binary', 'classification', 'classification', 'turn', 'relates', 'characteristic', 'stored', 'database', 'success', 'achieving', 'analytic', 'objective', 'hinge', 'relevant', 'unambiguous', 'statement', 'characteristic', 'corresponding', 'class', 'without', 'statement', 'difficult', 'extract', 'meaningful', 'modeling', 'data', 'example', 'bank', 'construct', 'risk', 'score', 'based', 'classification', 'known', 'customer', 'good', 'bad', 'credit', 'risk', 'precise', 'definition', 'good', 'bad', 'risk', 'however', 'somewhat', 'ambiguous', 'must', 'agreed', 'upon', 'advanced', 'even', 'data', 'available', 'useable', 'tractable', 'explicable', 'largest', 'data', 'extraction', 'challenge', 'remains', 'drawing', 'uncontaminated', 'modeling', 'sample', 'avoiding', 'unintentional', 'leakage', 'target', 'information', 'modeling', 'input', 'recurring', 'theme', 'course', 'bane', 'data', 'mining', 'effort']"
1365,"Missing values arise for a variety of reasons. In Chapter 3, missing values in the transactions inputs were generated for inputs not applicable to a given case. For example, the total number of checking account transactions is meaningless for cases without checking accounts. In Chapter 4, missing values in the transformed non-numeric inputs occurred when no match was found in the transformation source data. For example, certain zip codes did not appear in the zip code centroid data. In Chapter 5, self-reported fields in the INS_MODELING_SAMPLE data set contained missing values because of non- disclosure by the client. For example 20% clients failed to reveal their income to the financial institution.",DM,709,"['missing', 'value', 'arise', 'variety', 'reason', 'chapter', '3', 'missing', 'value', 'transaction', 'input', 'generated', 'input', 'applicable', 'given', 'case', 'example', 'total', 'number', 'checking', 'account', 'transaction', 'meaningless', 'case', 'without', 'checking', 'account', 'chapter', '4', 'missing', 'value', 'transformed', 'nonnumeric', 'input', 'occurred', 'match', 'wa', 'found', 'transformation', 'source', 'data', 'example', 'certain', 'zip', 'code', 'appear', 'zip', 'code', 'centroid', 'data', 'chapter', '5', 'selfreported', 'field', 'insmodelingsample', 'data_set', 'contained', 'missing', 'value', 'non', 'disclosure', 'client', 'example', '20', 'client', 'failed', 'reveal', 'income', 'financial', 'institution']"
1366,"A simpler, and arguably more effective, approach is to transform offending inputs to less extreme forms and build models on these transformed inputs. This not only reduces the influence of extreme cases, but it also creates an asymptotic association between input and target on the original input scale.",DM,303,"['simpler', 'arguably', 'effective', 'approach', 'transform', 'offending', 'input', 'le', 'extreme', 'form', 'build', 'model', 'transformed', 'input', 'reduces', 'influence', 'extreme', 'case', 'also', 'creates', 'asymptotic', 'association', 'input', 'target', 'original', 'input', 'scale']"
1367,"%distribution(data=&data,out=&report_name,contents=Y,max_levels=120); The %DISTRIBUTION macro is called with the DATA= parameter pointing to the aforementioned data set. The OUT= parameter specifies the location of the PDF report to be generated by the macro. ?	Omission of a report name?or, more specifically, a quoted path pointing to a *.pdf file?results in the macro sending all output to the Graph and Listing windows. The CONTENTS= parameter requests the macro to produce a CONTENTS procedure summary of the specified data set. The MAX_LEVELS= parameter limits the display of non-numeric distributions to those variables with cardinality less than the specified number. The generated report is partitioned into five sections: 1.	data set attributes. 2.	variable listing. 3.	numeric distributions. 4.	cardinality report. 5.	non-numeric frequency distributions. The data set attributes section is generated by the CONTENTS procedure and gives general facts about the selected data set.",DM,989,"['distributiondatadataoutreportnamecontentsymaxlevels120', 'distribution', 'macro', 'called', 'data', 'parameter', 'pointing', 'aforementioned', 'data_set', 'parameter', 'specifies', 'location', 'pdf', 'report', 'generated', 'macro', '\tomission', 'report', 'nameor', 'specifically', 'quoted', 'path', 'pointing', 'pdf', 'fileresults', 'macro', 'sending', 'output', 'graph', 'listing', 'window', 'content', 'parameter', 'request', 'macro', 'produce', 'content', 'procedure', 'summary', 'specified', 'data_set', 'maxlevels', 'parameter', 'limit', 'display', 'nonnumeric', 'distribution', 'variable', 'cardinality', 'le', 'specified', 'number', 'generated', 'report', 'partitioned', 'five', 'section', '1\tdata', 'set', 'attribute', '2\tvariable', 'listing', '3\tnumeric', 'distribution', '4\tcardinality', 'report', '5\tnonnumeric', 'frequency', 'distribution', 'data_set', 'attribute', 'section', 'generated', 'content', 'procedure', 'give', 'general', 'fact', 'selected', 'data_set']"
1368,"Generating a synthetic distribution with mean replacement is an extremely easy to implement task. Open the file Managing Data Pathologies 3.sas in the program editor. Here, missing values will be replaced for three inputs. %let inputs=HMVAL LORES INCOME;",DM,254,"['generating', 'synthetic', 'distribution', 'mean', 'replacement', 'extremely', 'easy', 'implement', 'task', 'open', 'file', 'managing', 'data', 'pathology', '3sas', 'program', 'editor', 'missing', 'value', 'replaced', 'three', 'input', 'let', 'inputshmval', 'lore', 'income']"
1369,"Pathology detection is a combination of knowing what an input should look like and knowing what can harm a predictive model. Because predictive modeling data sets are quite large, analyzing every record is out of the question. However, well- considered descriptive statistics, distributions plots, and frequency tables should provide enough detail for you to know when intervention is needed.",DM,392,"['pathology', 'detection', 'combination', 'knowing', 'input', 'look', 'like', 'knowing', 'harm', 'predictive', 'model', 'predictive', 'modeling', 'data_set', 'quite', 'large', 'analyzing', 'every', 'record', 'question', 'however', 'well', 'considered', 'descriptive', 'statistic', 'distribution', 'plot', 'frequency', 'table', 'provide', 'enough', 'detail', 'know', 'intervention', 'needed']"
1370,"*	Temporal infidelity occurs when model inputs contain information that will be unavailable at the time the prediction model is deployed. Including an individual?s current credit score in a model to predict a past event like bankruptcy is a case of temporal infidelity. Individual specific data before the event of interest is needed for accurate prediction. *	Hidden or deterministic rules sometimes plague predictive models. For example, a model used to identify customers interested in a credit card protection product could be built from customers with and without the product. However, unbeknownst to the analyst, all credit card customers automatically received the product as part of a special promotion. These customers should be excluded from the analysis, but identifying them can be problematic. *	Temporal factors affect the distribution of modeling data in unaccountable ways. A fundamental assumption of predictive modeling is stationarity?that is, the data from which the models are built looks more or less like the data to which the models will be applied. Macroeconomic factors often cast doubt on such assumptions. For example, a loan prepayment model built from data when interest rates are falling may be of little use when interest rates stabilize or begin to climb. *	Sampling errors, the most insidious problem, can contaminate model data. Creation of modeling data involves the manipulation and transformation of possibly hundreds of data sets. Mistakes at any stage can introduce noise or correlations that corrupt model predictions.",DM,1559,"['\ttemporal', 'infidelity', 'occurs', 'model', 'input', 'contain', 'information', 'unavailable', 'time', 'prediction', 'model', 'deployed', 'including', 'individual', 'current', 'credit', 'score', 'model', 'predict', 'past', 'event', 'like', 'bankruptcy', 'case', 'temporal', 'infidelity', 'individual', 'specific', 'data', 'event', 'interest', 'needed', 'accurate', 'prediction', '\thidden', 'deterministic', 'rule', 'sometimes', 'plague', 'predictive', 'model', 'example', 'model', 'used', 'identify', 'customer', 'interested', 'credit', 'card', 'protection', 'product', 'could', 'built', 'customer', 'without', 'product', 'however', 'unbeknownst', 'analyst', 'credit', 'card', 'customer', 'automatically', 'received', 'product', 'part', 'special', 'promotion', 'customer', 'excluded', 'analysis', 'identifying', 'problematic', '\ttemporal', 'factor', 'affect', 'distribution', 'modeling', 'data', 'unaccountable', 'way', 'fundamental', 'assumption', 'predictive', 'modeling', 'stationaritythat', 'data', 'model', 'built', 'look', 'le', 'like', 'data', 'model', 'applied', 'macroeconomic', 'factor', 'often', 'cast', 'doubt', 'assumption', 'example', 'loan', 'prepayment', 'model', 'built', 'data', 'interest', 'rate', 'falling', 'may', 'little', 'use', 'interest', 'rate', 'stabilize', 'begin', 'climb', '\tsampling', 'error', 'insidious', 'problem', 'contaminate', 'model', 'data', 'creation', 'modeling', 'data', 'involves', 'manipulation', 'transformation', 'possibly', 'hundred', 'data_set', 'mistake', 'stage', 'introduce', 'noise', 'correlation', 'corrupt', 'model', 'prediction']"
1371,"The DATA step underlying the event processing can be conceptually divided into five tasks labeled Declare, Read, Initialize, Vector, and Export (mnemonic: DRIVE).",DM,162,"['data', 'step', 'underlying', 'event', 'processing', 'conceptually', 'divided', 'five', 'task', 'labeled', 'declare', 'read', 'initialize', 'vector', 'export', 'mnemonic', 'drive']"
1372,"Pathology detection is a combination of knowing what an input should look like and knowing what can harm a predictive model. Because predictive modeling data sets are quite large, analyzing every record is out of the question. However, well- considered descriptive statistics, distributions plots, and frequency tables should provide enough detail for you to know when intervention is needed.",DM,392,"['pathology', 'detection', 'combination', 'knowing', 'input', 'look', 'like', 'knowing', 'harm', 'predictive', 'model', 'predictive', 'modeling', 'data_set', 'quite', 'large', 'analyzing', 'every', 'record', 'question', 'however', 'well', 'considered', 'descriptive', 'statistic', 'distribution', 'plot', 'frequency', 'table', 'provide', 'enough', 'detail', 'know', 'intervention', 'needed']"
1373,The names of all selected non-numeric variables with a cardinality less than MAX_LEVELS are placed in macro variable CHARVARS. proc sql noprint; select var into :charvars separated by ' ' from counts where levels<&max_levels; quit;,DM,231,"['name', 'selected', 'nonnumeric', 'variable', 'cardinality', 'le', 'maxlevels', 'placed', 'macro', 'variable', 'charvars', 'proc', 'sql', 'noprint', 'select', 'var', 'charvars', 'separated', '', '', 'count', 'levelsmaxlevels', 'quit']"
1374,"Simple measures can be taken to avoid contamination. *	Every predictive modeling data set should include, in addition to a target variable, a target date variable that indicates the date of target measurement. All measurements used to create modeling inputs must be made prior to the target date, less a reasonable latency period. *	A well-designed data warehouse should include documentation on the origin and meaning of table contents. Close and early collaboration with domain experts familiar with past efforts to achieve the analytic objective can identify and help avoid problems in sample creation. *	Explicitly accounting for time in sample and input creation can control for non-stationarities in the data. *	Finally, a healthy dose of skepticism is necessary to detect sampling and programming errors. An analyst must continuously ask, Does this result make sense in light of domain knowledge? In predictive modeling, if it is too good to be true, it almost certainly is an error.",DM,990,"['simple', 'measure', 'taken', 'avoid', 'contamination', '\tevery', 'predictive', 'modeling', 'data_set', 'include', 'addition', 'target', 'variable', 'target', 'date', 'variable', 'indicates', 'date', 'target', 'measurement', 'measurement', 'used', 'create', 'modeling', 'input', 'must', 'made', 'prior', 'target', 'date', 'le', 'reasonable', 'latency', 'period', '\ta', 'welldesigned', 'data', 'warehouse', 'include', 'documentation', 'origin', 'meaning', 'table', 'content', 'close', 'early', 'collaboration', 'domain', 'expert', 'familiar', 'past', 'effort', 'achieve', 'analytic', 'objective', 'identify', 'help', 'avoid', 'problem', 'sample', 'creation', '\texplicitly', 'accounting', 'time', 'sample', 'input', 'creation', 'control', 'nonstationarities', 'data', '\tfinally', 'healthy', 'dose', 'skepticism', 'necessary', 'detect', 'sampling', 'programming', 'error', 'analyst', 'must', 'continuously', 'ask', 'doe', 'result', 'make', 'sense', 'light', 'domain', 'knowledge', 'predictive', 'modeling', 'good', 'true', 'almost', 'certainly', 'error']"
1375,"The most important difference between access methods is the time required for their completion. Writing DATA step code to translate raw data into SAS data sets is time consuming. If the raw data is in a specific file format (such as a delimited file with column header information), the IMPORT procedure automates some of the DATA step code generation, although some code editing could be required to obtain the desired results. Using SAS/ACCESS products, the raw data appears to SAS as a SAS data set. This trims hours from the time required to read the raw data. Unfortunately, the raw data may need to be pulled across a network for SAS to operate on the data. Performance is then limited by network speed. The most efficient approach utilizes the SAS/ACCESS Pass-Through facility. Queries are then sent and executed directly to the RDBMS server. By limiting the transfer of data across the network, data access time is reduced to seconds even for large queries.",DM,965,"['important', 'difference', 'access', 'method', 'time', 'required', 'completion', 'writing', 'data', 'step', 'code', 'translate', 'raw', 'data', 'sa', 'data_set', 'time', 'consuming', 'raw', 'data', 'specific', 'file', 'format', 'delimited', 'file', 'column', 'header', 'information', 'import', 'procedure', 'automates', 'data', 'step', 'code', 'generation', 'although', 'code', 'editing', 'could', 'required', 'obtain', 'desired', 'result', 'using', 'sasaccess', 'product', 'raw', 'data', 'appears', 'sa', 'sa', 'data_set', 'trim', 'hour', 'time', 'required', 'read', 'raw', 'data', 'unfortunately', 'raw', 'data', 'may', 'need', 'pulled', 'across', 'network', 'sa', 'operate', 'data', 'performance', 'limited', 'network', 'speed', 'efficient', 'approach', 'utilizes', 'sasaccess', 'passthrough', 'facility', 'query', 'sent', 'executed', 'directly', 'rdbms', 'server', 'limiting', 'transfer', 'data', 'across', 'network', 'data', 'access', 'time', 'reduced', 'second', 'even', 'large', 'query']"
1376,Processing by transaction groups requires some minor additions to the Declare and Vector tasks and more substantial additions to the Export task. The most important innovation is the transaction macros use of grouping indicators.,DM,229,"['processing', 'transaction', 'group', 'requires', 'minor', 'addition', 'declare', 'vector', 'task', 'substantial', 'addition', 'export', 'task', 'important', 'innovation', 'transaction', 'macro', 'use', 'grouping', 'indicator']"
1377,"Counter to urban legend, classical regression analysis makes no assumptions about the distribution of inputs. The only assumption is that the expected value of the target (or some function thereof) is a linear combination of input measurements. So why worry about the extreme input distributions? There are at least two compelling reasons. First, in most real-world applications, the relationship between expected target value and input value does not increase without bound. Instead, it typically tapers off to some horizontal asymptote. Standard regression models are unable to accommodate such a relationship. Second, the further a point is from the overall mean of a distribution, the more influence, or leverage, the point has on model fit. Models built on inputs with extreme distributions attempt to optimize fit for the most extreme points at the cost of fit for the bulk of the data, usually near the input mean. The first concern can be addressed by abandoning standard regression models for more flexible modeling methods. This is often done at the cost of model interpretability and, more importantly, failure to address the second concern, leverage.",DM,1162,"['counter', 'urban', 'legend', 'classical', 'regression', 'analysis', 'make', 'assumption', 'distribution', 'input', 'assumption', 'expected', 'value', 'target', 'function', 'thereof', 'linear', 'combination', 'input', 'measurement', 'worry', 'extreme', 'input', 'distribution', 'least', 'two', 'compelling', 'reason', 'first', 'realworld', 'application', 'relationship', 'expected', 'target', 'value', 'input', 'value', 'doe', 'increase', 'without', 'bound', 'instead', 'typically', 'taper', 'horizontal', 'asymptote', 'standard', 'regression_model', 'unable', 'accommodate', 'relationship', 'second', 'point', 'overall', 'mean', 'distribution', 'influence', 'leverage', 'point', 'ha', 'model', 'fit', 'model', 'built', 'input', 'extreme', 'distribution', 'attempt', 'optimize', 'fit', 'extreme', 'point', 'cost', 'fit', 'bulk', 'data', 'usually', 'near', 'input', 'mean', 'first', 'concern', 'addressed', 'abandoning', 'standard', 'regression_model', 'flexible', 'modeling', 'method', 'often', 'done', 'cost', 'model', 'interpretability', 'importantly', 'failure', 'address', 'second', 'concern', 'leverage']"
1378,"The technique employed for reducing the size of the target sample is called separate sampling, although it is known by various other names including case- control sampling, choice-based sampling, biased sampling, y-conditional sampling, outcome-dependent sampling, and oversampling. When the number of nonresponders to responders, the N0:N1 ratio, is large, the usual practice is to take every responder available and an integer multiple of nonresponders for each responder. In the example above, for every INS client, two non-INS clients are selected. This creates a separately sampled target sample with a N0:N1 ratio of 2:1.",DM,627,"['technique', 'employed', 'reducing', 'size', 'target', 'sample', 'called', 'separate', 'sampling', 'although', 'known', 'various', 'name', 'including', 'case', 'control', 'sampling', 'choicebased', 'sampling', 'biased', 'sampling', 'yconditional', 'sampling', 'outcomedependent', 'sampling', 'oversampling', 'number', 'nonresponders', 'responder', 'n0n1', 'ratio', 'large', 'usual', 'practice', 'take', 'every', 'responder', 'available', 'integer', 'multiple', 'nonresponders', 'responder', 'example', 'every', 'client', 'two', 'nonins', 'client', 'selected', 'creates', 'separately', 'sampled', 'target', 'sample', 'n0n1', 'ratio', '21']"
1379,Adding debits and subtracting credits to END_BAL for events in the latency period and beyond is used to undo the checking account activities and establish the ending balance at relative time 0.,DM,193,"['adding', 'debit', 'subtracting', 'credit', 'endbal', 'event', 'latency', 'period', 'beyond', 'used', 'undo', 'checking', 'account', 'activity', 'establish', 'ending', 'balance', 'relative', 'time', '0']"
1380,"Stratified separate sampling offers an improvement over the simple random approach shown in the previous section. In stratified separate sampling, a specified number of cases are drawn from levels of designated stratification variables. If the stratification variables are carefully chosen, the sample can control for exogenous factors in the data such as time and macroscopic economic conditions. This allows the sample to better represent the target population and thereby improves model accuracy.",DM,499,"['stratified', 'separate', 'sampling', 'offer', 'improvement', 'simple', 'random', 'approach', 'shown', 'previous', 'section', 'stratified', 'separate', 'sampling', 'specified', 'number', 'case', 'drawn', 'level', 'designated', 'stratification', 'variable', 'stratification', 'variable', 'carefully', 'chosen', 'sample', 'control', 'exogenous', 'factor', 'data', 'time', 'macroscopic', 'economic', 'condition', 'allows', 'sample', 'better', 'represent', 'target', 'population', 'thereby', 'improves', 'model', 'accuracy']"
1381,"In a simple random target sample, the non-INS clients outnumber the INS clients by approximately 46 to 1. By using separate sampling techniques, it is possible to substantially reduce the number of clients selected for modeling, without significantly reducing predictive modeling performance. In fact, by using the stratification techniques discussed in Section 2.4, it is possible to obtain a modeling sample that controls for potential non-stationarities in the data and thereby improves predictive model performance.",DM,519,"['simple', 'random', 'target', 'sample', 'nonins', 'client', 'outnumber', 'client', 'approximately', '46', '1', 'using', 'separate', 'sampling', 'technique', 'possible', 'substantially', 'reduce', 'number', 'client', 'selected', 'modeling', 'without', 'significantly', 'reducing', 'predictive', 'modeling', 'performance', 'fact', 'using', 'stratification', 'technique', 'discussed', 'section', '24', 'possible', 'obtain', 'modeling', 'sample', 'control', 'potential', 'nonstationarities', 'data', 'thereby', 'improves', 'predictive', 'model', 'performance']"
1382,"?	Because non-INS clients do not have an INS account, there is no account open date column. This lack of target date for nonresponse cases is a common source of data contamination and must be dealt with carefully. A method for establishing a target date for nonresponse cases is discussed in the last section of this chapter. The final task is to join the INS and non-INS qualified client tables. create table joined_sample as 	select *, 1 as INS from ins_clients_qualified 	outer union corresponding select *, 0 as INS from non_ins_clients_qualified; The outer union corresponding function joins the two tables and consolidates identical columns. This can be seen if you browse the JOINED_SAMPLE data set. Note the addition of a column INS to the joined sample. This column will ultimately serve as the predictive modeling target.",DM,831,"['\tbecause', 'nonins', 'client', 'account', 'account', 'open', 'date', 'column', 'lack', 'target', 'date', 'nonresponse', 'case', 'common', 'source', 'data', 'contamination', 'must', 'dealt', 'carefully', 'method', 'establishing', 'target', 'date', 'nonresponse', 'case', 'discussed', 'last', 'section', 'chapter', 'final', 'task', 'join', 'nonins', 'qualified', 'client', 'table', 'create', 'table', 'joinedsample', '\tselect', '', '1', 'insclientsqualified', '\touter', 'union', 'corresponding', 'select', '', '0', 'noninsclientsqualified', 'outer', 'union', 'corresponding', 'function', 'join', 'two', 'table', 'consolidates', 'identical', 'column', 'seen', 'browse', 'joinedsample', 'data_set', 'note', 'addition', 'column', 'joined', 'sample', 'column', 'ultimately', 'serve', 'predictive', 'modeling', 'target']"
1383,"Now the punch line: for large Ni (relative to a and b), the expected value of pi is about what you would obtain using traditional weight of evidence methods. For small values of Ni, the expected value of pi is about equal to the overall target average. Thus, the average target estimates based on sparse level counts are smoothed out and the corresponding bias problems are virtually eliminated.",DM,395,"['punch', 'line', 'large', 'ni', 'relative', 'b', 'expected', 'value', 'pi', 'would', 'obtain', 'using', 'traditional', 'weight', 'evidence', 'method', 'small', 'value', 'ni', 'expected', 'value', 'pi', 'equal', 'overall', 'target', 'average', 'thus', 'average', 'target', 'estimate', 'based', 'sparse', 'level', 'count', 'smoothed', 'corresponding', 'bias', 'problem', 'virtually', 'eliminated']"
1384,"The temporary transaction arrays are containers for the complete event history of a given case. The maximum records per case macro variable, defined at the start of the transaction transformation process, must be larger than the maximum number of events for each case.",DM,268,"['temporary', 'transaction', 'array', 'container', 'complete', 'event', 'history', 'given', 'case', 'maximum', 'record', 'per', 'case', 'macro', 'variable', 'defined', 'start', 'transaction', 'transformation', 'process', 'must', 'larger', 'maximum', 'number', 'event', 'case']"
1385,"Open the file Transaction Input Creation 1.sas in the SAS program editor. This program performs the four steps of transaction transformation. This demonstration focuses on the selecting and sorting step. The program begins by including a set of macros used for input creation throughout the course. The macros are studied in some detail later in the chapter. *** Include transaction macros; filename crsmacs catalog ""dmdp.course_macros""; %include crsmacs(""transaction_macros.source"");",DM,484,"['open', 'file', 'transaction', 'input', 'creation', '1sas', 'sa', 'program', 'editor', 'program', 'performs', 'four', 'step', 'transaction', 'transformation', 'demonstration', 'focus', 'selecting', 'sorting', 'step', 'program', 'begin', 'including', 'set', 'macro', 'used', 'input', 'creation', 'throughout', 'course', 'macro', 'studied', 'detail', 'later', 'chapter', '', 'include', 'transaction', 'macro', 'filename', 'crsmacs', 'catalog', 'dmdpcoursemacros', 'include', 'crsmacstransactionmacrossource']"
1386,"Of course, the events occur across time, which immediately suggests time series analysis. Time averages and trends are excellent summaries of case behavior, as are measures of time series variability. The demonstrations in the chapter illustrate creation of each of these types of inputs. Macro functions are provided to allow for straightforward (if not easy) implementation of these techniques on your own data.",DM,413,"['course', 'event', 'occur', 'across', 'time', 'immediately', 'suggests', 'time', 'series', 'analysis', 'time', 'average', 'trend', 'excellent', 'summary', 'case', 'behavior', 'measure', 'time', 'series', 'variability', 'demonstration', 'chapter', 'illustrate', 'creation', 'type', 'input', 'macro', 'function', 'provided', 'allow', 'straightforward', 'easy', 'implementation', 'technique', 'data']"
1387,"The most straightforward implementation of separate sampling involves transferring the INS and non-INS qualified client data sets from the warehouse server to the SAS analysis server. Transfer can be accomplished by defining a SAS/ACCESS library reference to the server and copying the data with a DATA step. ?	While most major RDBMS engines (Oracle, DB2, and SQLServer) have functions for implementing separate sampling, the functions are specific to the RDBMS engine and beyond the scope of this course.",DM,505,"['straightforward', 'implementation', 'separate', 'sampling', 'involves', 'transferring', 'nonins', 'qualified', 'client', 'data_set', 'warehouse', 'server', 'sa', 'analysis', 'server', 'transfer', 'accomplished', 'defining', 'sasaccess', 'library', 'reference', 'server', 'copying', 'data', 'data', 'step', '\twhile', 'major', 'rdbms', 'engine', 'oracle', 'db2', 'sqlserver', 'function', 'implementing', 'separate', 'sampling', 'function', 'specific', 'rdbms', 'engine', 'beyond', 'scope', 'course']"
1388,"Simple measures can be taken to avoid contamination. *	Every predictive modeling data set should include, in addition to a target variable, a target date variable that indicates the date of target measurement. All measurements used to create modeling inputs must be made prior to the target date, less a reasonable latency period. *	A well-designed data warehouse should include documentation on the origin and meaning of table contents. Close and early collaboration with domain experts familiar with past efforts to achieve the analytic objective can identify and help avoid problems in sample creation. *	Explicitly accounting for time in sample and input creation can control for non-stationarities in the data. *	Finally, a healthy dose of skepticism is necessary to detect sampling and programming errors. An analyst must continuously ask, Does this result make sense in light of domain knowledge? In predictive modeling, if it is too good to be true, it almost certainly is an error.",DM,990,"['simple', 'measure', 'taken', 'avoid', 'contamination', '\tevery', 'predictive', 'modeling', 'data_set', 'include', 'addition', 'target', 'variable', 'target', 'date', 'variable', 'indicates', 'date', 'target', 'measurement', 'measurement', 'used', 'create', 'modeling', 'input', 'must', 'made', 'prior', 'target', 'date', 'le', 'reasonable', 'latency', 'period', '\ta', 'welldesigned', 'data', 'warehouse', 'include', 'documentation', 'origin', 'meaning', 'table', 'content', 'close', 'early', 'collaboration', 'domain', 'expert', 'familiar', 'past', 'effort', 'achieve', 'analytic', 'objective', 'identify', 'help', 'avoid', 'problem', 'sample', 'creation', '\texplicitly', 'accounting', 'time', 'sample', 'input', 'creation', 'control', 'nonstationarities', 'data', '\tfinally', 'healthy', 'dose', 'skepticism', 'necessary', 'detect', 'sampling', 'programming', 'error', 'analyst', 'must', 'continuously', 'ask', 'doe', 'result', 'make', 'sense', 'light', 'domain', 'knowledge', 'predictive', 'modeling', 'good', 'true', 'almost', 'certainly', 'error']"
1389,"Potential predictive pitfalls can lurk in data sets with many cleverly crafted inputs. Data pathologies?input miscodings, extreme or outlying cases, highly skewed distributions, and missing values?can all seriously diminish model performance. This chapter offers a three-step regimen for countering these pathologies. Section 5.2 presents methods for finding potential problems in an input sample. Section 5.3 suggests transformations to avoid the debilitating effects of highly skewed inputs. Section 5.4 compares strategies for missing value imputation.",DM,555,"['potential', 'predictive', 'pitfall', 'lurk', 'data_set', 'many', 'cleverly', 'crafted', 'input', 'data', 'pathologiesinput', 'miscodings', 'extreme', 'outlying', 'case', 'highly', 'skewed', 'distribution', 'missing', 'valuescan', 'seriously', 'diminish', 'model', 'performance', 'chapter', 'offer', 'threestep', 'regimen', 'countering', 'pathology', 'section', '52', 'present', 'method', 'finding', 'potential', 'problem', 'input', 'sample', 'section', '53', 'suggests', 'transformation', 'avoid', 'debilitating', 'effect', 'highly', 'skewed', 'input', 'section', '54', 'compare', 'strategy', 'missing', 'value', 'imputation']"
1390,Adding debits and subtracting credits to END_BAL for events in the latency period and beyond is used to undo the checking account activities and establish the ending balance at relative time 0.,DM,193,"['adding', 'debit', 'subtracting', 'credit', 'endbal', 'event', 'latency', 'period', 'beyond', 'used', 'undo', 'checking', 'account', 'activity', 'establish', 'ending', 'balance', 'relative', 'time', '0']"
1391,"Simply knowing latitude and longitude of a case will probably not yield more predictive models. But when position is known, other quantities can also be calculated. One extremely useful quantity is proximity. The next two demonstrations show an effective technique for converting latitude and longitude measures to distance. The distance is calculated using the haversine function, an obscure but highly accurate throwback to the times of trigonometric tables. Combined with the zip code conversion macros, you will have a DATA step function that determines the approximate distance of any two locations (to five- digit zip code resolution). Calculating Distances",DM,663,"['simply', 'knowing', 'latitude', 'longitude', 'case', 'probably', 'yield', 'predictive', 'model', 'position', 'known', 'quantity', 'also', 'calculated', 'one', 'extremely', 'useful', 'quantity', 'proximity', 'next', 'two', 'demonstration', 'show', 'effective', 'technique', 'converting', 'latitude', 'longitude', 'measure', 'distance', 'distance', 'calculated', 'using', 'haversine', 'function', 'obscure', 'highly', 'accurate', 'throwback', 'time', 'trigonometric', 'table', 'combined', 'zip', 'code', 'conversion', 'macro', 'data', 'step', 'function', 'determines', 'approximate', 'distance', 'two', 'location', 'five', 'digit', 'zip', 'code', 'resolution', 'calculating', 'distance']"
1392,"Missing value replacement strategies fall into one of two categories. Estimation methods attempt to provide a reasonable guess as to what the missing value should have been were it not missing. This approach is compatible with missing values resulting from a lack of knowledge (for example, no match or non-disclosure), and not with missing values resulting from the lack of applicability of the inputs. Estimation methods usually closely connected with model building and are outside the scope of this course. Synthetic distribution methods simply modify the distribution in an input to include a point mass at a specific value for cases whose input value is otherwise not known.",DM,680,"['missing', 'value', 'replacement', 'strategy', 'fall', 'one', 'two', 'category', 'estimation', 'method', 'attempt', 'provide', 'reasonable', 'guess', 'missing', 'value', 'missing', 'approach', 'compatible', 'missing', 'value', 'resulting', 'lack', 'knowledge', 'example', 'match', 'nondisclosure', 'missing', 'value', 'resulting', 'lack', 'applicability', 'input', 'estimation', 'method', 'usually', 'closely', 'connected', 'model', 'building', 'outside', 'scope', 'course', 'synthetic', 'distribution', 'method', 'simply', 'modify', 'distribution', 'input', 'include', 'point', 'mass', 'specific', 'value', 'case', 'whose', 'input', 'value', 'otherwise', 'known']"
1393,"To aid discussion of transaction data, several terms and concepts are now introduced. The analytic objective usually restricts transaction data to a particular time range. Records in this time range are called events.",DM,217,"['aid', 'discussion', 'transaction', 'data', 'several', 'term', 'concept', 'introduced', 'analytic', 'objective', 'usually', 'restricts', 'transaction', 'data', 'particular', 'time', 'range', 'record', 'time', 'range', 'called', 'event']"
1394,"Second, if the relative time is less than zero (before the target date), the ending balance is changed: incremented for debits and decremented for credits. While this seems backwards, there is a simple explanation for this action.",DM,230,"['second', 'relative', 'time', 'le', 'zero', 'target', 'date', 'ending', 'balance', 'changed', 'incremented', 'debit', 'decremented', 'credit', 'seems', 'backwards', 'simple', 'explanation', 'action']"
1395,"With the account balance known at the end date, it is possible to use the values of the transaction events to determine the account balance at any point in time.",DM,161,"['account', 'balance', 'known', 'end', 'date', 'possible', 'use', 'value', 'transaction', 'event', 'determine', 'account', 'balance', 'point', 'time']"
1396,"For predictive models, an analysis data set must contain a collection of independent cases with fields corresponding to the inputs, the target, and, usually, a cases identifier. These fields are usually created from data collected in the operations of an organization. In an ideal situation, the operations data is well organized in a data warehouse that is easy to access. While establishing such a warehouse can be an expensive undertaking, doing so avoids a lengthy data acquisition process, ultimately saving time and money for the organization.",DM,549,"['predictive', 'model', 'analysis', 'data_set', 'must', 'contain', 'collection', 'independent', 'case', 'field', 'corresponding', 'input', 'target', 'usually', 'case', 'identifier', 'field', 'usually', 'created', 'data', 'collected', 'operation', 'organization', 'ideal', 'situation', 'operation', 'data', 'well', 'organized', 'data', 'warehouse', 'easy', 'access', 'establishing', 'warehouse', 'expensive', 'undertaking', 'avoids', 'lengthy', 'data', 'acquisition', 'process', 'ultimately', 'saving', 'time', 'money', 'organization']"
1397,"With the events extracted and sorted, the transaction transformation moves on to actual processing of individual events by case ID. For clarity, the augmentation of data is deferred until later. The processing step creates a data set, TN_CASE_INPUT, with one row per input per case. As such, the data set must be transposed for use as an input sample. The transposition occurs in the finalize step. The case input structure allows for the addition of an arbitrarily large number of inputs, without the added step of including each input in a keep list. It also facilitates the creation of stratified input variables because stratification levels are easily incorporated into input names.",DM,687,"['event', 'extracted', 'sorted', 'transaction', 'transformation', 'move', 'actual', 'processing', 'individual', 'event', 'case', 'id', 'clarity', 'augmentation', 'data', 'deferred', 'later', 'processing', 'step', 'creates', 'data_set', 'tncaseinput', 'one', 'row', 'per', 'input', 'per', 'case', 'data_set', 'must', 'transposed', 'use', 'input', 'sample', 'transposition', 'occurs', 'finalize', 'step', 'case', 'input', 'structure', 'allows', 'addition', 'arbitrarily', 'large', 'number', 'input', 'without', 'added', 'step', 'including', 'input', 'keep', 'list', 'also', 'facilitates', 'creation', 'stratified', 'input', 'variable', 'stratification', 'level', 'easily', 'incorporated', 'input', 'name']"
1398,The scratch array is a two-dimensional array used by the transaction macro functions to store intermediate results. Any DATA step that uses the transaction processing macros must include a scratch array definition. The temporary array?s dimensions are 0 to the maximum number records per case in one dimension and 0 to 5 in the other dimension.,DM,344,"['scratch', 'array', 'twodimensional', 'array', 'used', 'transaction', 'macro', 'function', 'store', 'intermediate', 'result', 'data', 'step', 'us', 'transaction', 'processing', 'macro', 'must', 'include', 'scratch', 'array', 'definition', 'temporary', 'array', 'dimension', '0', 'maximum', 'number', 'record', 'per', 'case', 'one', 'dimension', '0', '5', 'dimension']"
1399,Open the file Transaction Input Creation 2.sas in the SAS program editor. The code focuses on the process by ID step in the transaction input creation exercise. The only change in the program occurs in the execute step.,DM,219,"['open', 'file', 'transaction', 'input', 'creation', '2sas', 'sa', 'program', 'editor', 'code', 'focus', 'process', 'id', 'step', 'transaction', 'input', 'creation', 'exercise', 'change', 'program', 'occurs', 'execute', 'step']"
1400,"It is extremely easy to underestimate the scope of the data preparation task. When starting a project, many analysts anticipate ample time to explore a variety of predictive modeling techniques. They are often dismayed to discover that the data preparation activities require a majority of the time allotted. In the worst cases, much of the time is spent acquiring the analysis data from disparate and disorganized sources. Natural projects must be organized to allow ample time for both data preparation and data analysis.",DM,523,"['extremely', 'easy', 'underestimate', 'scope', 'data', 'preparation', 'task', 'starting', 'project', 'many', 'analyst', 'anticipate', 'ample', 'time', 'explore', 'variety', 'predictive', 'modeling', 'technique', 'often', 'dismayed', 'discover', 'data', 'preparation', 'activity', 'require', 'majority', 'time', 'allotted', 'worst', 'case', 'much', 'time', 'spent', 'acquiring', 'analysis', 'data', 'disparate', 'disorganized', 'source', 'natural', 'project', 'must', 'organized', 'allow', 'ample', 'time', 'data', 'preparation', 'data', 'analysis']"
1401,The DATASETS procedure deletes any previous version of the COUNTS data set. The COUNTS data set will contain the cardinality of each non-numeric variable. proc datasets library=work nodetails nolist; delete counts; run;,DM,219,"['datasets', 'procedure', 'deletes', 'previous', 'version', 'count', 'data_set', 'count', 'data_set', 'contain', 'cardinality', 'nonnumeric', 'variable', 'proc', 'datasets', 'librarywork', 'nodetails', 'nolist', 'delete', 'count', 'run']"
1402,"All activities in this course center on transforming operational data into a model development data set. A model development data set consists of independent rows of data called modeling cases and four types of columns: IDs, targets, target dates, and inputs. Each modeling case can correspond to hundreds of records in the operational data.",DM,341,"['activity', 'course', 'center', 'transforming', 'operational', 'data', 'model', 'development', 'data_set', 'model', 'development', 'data_set', 'consists', 'independent', 'row', 'data', 'called', 'modeling', 'case', 'four', 'type', 'column', 'id', 'target', 'target', 'date', 'input', 'modeling', 'case', 'correspond', 'hundred', 'record', 'operational', 'data']"
1403,The program Extracting Relevant Data 3.sas demonstrates stratified separate sampling using the INS example data. The qualified INS and non-INS client data sets must be regenerated to include stratification source variable origination date. proc sql;,DM,249,"['program', 'extracting', 'relevant', 'data', '3sas', 'demonstrates', 'stratified', 'separate', 'sampling', 'using', 'example', 'data', 'qualified', 'nonins', 'client', 'data_set', 'must', 'regenerated', 'include', 'stratification', 'source', 'variable', 'origination', 'date', 'proc', 'sql']"
1404,"Most strategies for representing non-numeric data in predictive models involve some form of recoding or transformation of the non-numeric data to numeric data into numeric data. The approaches taken depend mostly on the degree of cardinality. Low cardinality inputs (fewer than 10 distinct levels) are acceptable to most modeling techniques and need no additional processing (although several low cardinality inputs actually look like a single high cardinality input to a statistical model). When the input cardinality is in the range of ten to several hundred, the techniques built in to many statistical models are not sufficient to avoid overgeneralization. Some form of external recoding is usually deployed. Recoding strategies are discussed in the next section. When the cardinality exceeds several hundred, approaches other than recoding are needed. Many of the approaches involve a transformation dependent on the intrinsic or extrinsic properties of the non-numeric input. For example the intrinsic meaning of a non-numeric field such as postal code (location) enables transformations to numeric inputs (latitude and longitude). Location can be used to create or access a variety of valuable modeling inputs. Section 4.3 discusses geocoding, the transformation of postal code to latitude and longitude. Non-numeric variables also possess extrinsic properties in that they often serve as links to other data sources. Section 4.4 describes how linking can be used to transform a single non-numeric input into hundreds of new, independent, and informative inputs. At the highest end of the cardinality scale are the variables with unbounded cardinality. Free-form text fields are one example. The emerging field of text mining focuses on these extreme cardinality inputs. The techniques are of sufficient complexity to justify a separate course.",DM,1851,"['strategy', 'representing', 'nonnumeric', 'data', 'predictive', 'model', 'involve', 'form', 'recoding', 'transformation', 'nonnumeric', 'data', 'numeric', 'data', 'numeric', 'data', 'approach', 'taken', 'depend', 'mostly', 'degree', 'cardinality', 'low', 'cardinality', 'input', 'fewer', '10', 'distinct', 'level', 'acceptable', 'modeling', 'technique', 'need', 'additional', 'processing', 'although', 'several', 'low', 'cardinality', 'input', 'actually', 'look', 'like', 'single', 'high', 'cardinality', 'input', 'statistical', 'model', 'input', 'cardinality', 'range', 'ten', 'several', 'hundred', 'technique', 'built', 'many', 'statistical', 'model', 'sufficient', 'avoid', 'overgeneralization', 'form', 'external', 'recoding', 'usually', 'deployed', 'recoding', 'strategy', 'discussed', 'next', 'section', 'cardinality', 'exceeds', 'several', 'hundred', 'approach', 'recoding', 'needed', 'many', 'approach', 'involve', 'transformation', 'dependent', 'intrinsic', 'extrinsic', 'property', 'nonnumeric', 'input', 'example', 'intrinsic', 'meaning', 'nonnumeric', 'field', 'postal', 'code', 'location', 'enables', 'transformation', 'numeric', 'input', 'latitude', 'longitude', 'location', 'used', 'create', 'access', 'variety', 'valuable', 'modeling', 'input', 'section', '43', 'discus', 'geocoding', 'transformation', 'postal', 'code', 'latitude', 'longitude', 'nonnumeric', 'variable', 'also', 'posse', 'extrinsic', 'property', 'often', 'serve', 'link', 'data', 'source', 'section', '44', 'describes', 'linking', 'used', 'transform', 'single', 'nonnumeric', 'input', 'hundred', 'new', 'independent', 'informative', 'input', 'highest', 'end', 'cardinality', 'scale', 'variable', 'unbounded', 'cardinality', 'freeform', 'text', 'field', 'one', 'example', 'emerging', 'field', 'text', 'mining', 'focus', 'extreme', 'cardinality', 'input', 'technique', 'sufficient', 'complexity', 'justify', 'separate', 'course']"
1405,"The task of predictive modeling does not stand by itself. To build a successful predictive model you must first?unambiguously?define an analytic objective. The predictive model serves as a means of fulfilling the analytic objective. The predictive modeling effort is surrounded by two other tasks. Before modeling begins, data must be assembled, often from a variety of sources, and arranged in a format suitable for model building. After the modeling is complete, the resulting model (and the modeling results) must be integrated into the business environment that originally motivated the modeling. These tasks often require more effort than the modeling itself. This course focuses on the first of the three tasks: data preparation. Note that while the data preparation task comes before model building, this data preparation course is designed to be taken after a suitable predictive modeling course. With the background gained in a predictive modeling course, students gain insight into the reasons behind the data preparation activities.",DM,1043,"['task', 'predictive', 'modeling', 'doe', 'stand', 'build', 'successful', 'predictive', 'model', 'must', 'firstunambiguouslydefine', 'analytic', 'objective', 'predictive', 'model', 'serf', 'mean', 'fulfilling', 'analytic', 'objective', 'predictive', 'modeling', 'effort', 'surrounded', 'two', 'task', 'modeling', 'begin', 'data', 'must', 'assembled', 'often', 'variety', 'source', 'arranged', 'format', 'suitable', 'model', 'building', 'modeling', 'complete', 'resulting', 'model', 'modeling', 'result', 'must', 'integrated', 'business', 'environment', 'originally', 'motivated', 'modeling', 'task', 'often', 'require', 'effort', 'modeling', 'course', 'focus', 'first', 'three', 'task', 'data', 'preparation', 'note', 'data', 'preparation', 'task', 'come', 'model', 'building', 'data', 'preparation', 'course', 'designed', 'taken', 'suitable', 'predictive', 'modeling', 'course', 'background', 'gained', 'predictive', 'modeling', 'course', 'student', 'gain', 'insight', 'reason', 'behind', 'data', 'preparation', 'activity']"
1406,The TRANSPOSE procedure completes the first finalization task by rearranging the transaction case input data set. The output data set has a single row per case with the transaction inputs defining the columns.,DM,209,"['transpose', 'procedure', 'completes', 'first', 'finalization', 'task', 'rearranging', 'transaction', 'case', 'input', 'data_set', 'output', 'data_set', 'ha', 'single', 'row', 'per', 'case', 'transaction', 'input', 'defining', 'column']"
1407,The program Extracting Relevant Data 4.sas demonstrates assigning target dates to cases in the INS example. The data is sorted by origination date in descending order. proc sort data=ins_clients_qualified; by descending ORIG_DT; run;,DM,233,"['program', 'extracting', 'relevant', 'data', '4sas', 'demonstrates', 'assigning', 'target', 'date', 'case', 'example', 'data', 'sorted', 'origination', 'date', 'descending', 'order', 'proc', 'sort', 'datainsclientsqualified', 'descending', 'origdt', 'run']"
1408,"While data used for predictive model development assumes a single row per case ID, data used to record the activities of individuals contains many rows per case ID. This data must be transformed for inclusion in predictive models. An individual transaction record typically contains one or more identification fields, a timestamp field, one or more classification fields, and possibly one or more amount fields.",DM,411,"['data', 'used', 'predictive', 'model', 'development', 'assumes', 'single', 'row', 'per', 'case', 'id', 'data', 'used', 'record', 'activity', 'individual', 'contains', 'many', 'row', 'per', 'case', 'id', 'data', 'must', 'transformed', 'inclusion', 'predictive', 'model', 'individual', 'transaction', 'record', 'typically', 'contains', 'one', 'identification', 'field', 'timestamp', 'field', 'one', 'classification', 'field', 'possibly', 'one', 'amount', 'field']"
1409,"Missing values arise for a variety of reasons. In Chapter 3, missing values in the transactions inputs were generated for inputs not applicable to a given case. For example, the total number of checking account transactions is meaningless for cases without checking accounts. In Chapter 4, missing values in the transformed non-numeric inputs occurred when no match was found in the transformation source data. For example, certain zip codes did not appear in the zip code centroid data. In Chapter 5, self-reported fields in the INS_MODELING_SAMPLE data set contained missing values because of non- disclosure by the client. For example 20% clients failed to reveal their income to the financial institution.",DM,709,"['missing', 'value', 'arise', 'variety', 'reason', 'chapter', '3', 'missing', 'value', 'transaction', 'input', 'generated', 'input', 'applicable', 'given', 'case', 'example', 'total', 'number', 'checking', 'account', 'transaction', 'meaningless', 'case', 'without', 'checking', 'account', 'chapter', '4', 'missing', 'value', 'transformed', 'nonnumeric', 'input', 'occurred', 'match', 'wa', 'found', 'transformation', 'source', 'data', 'example', 'certain', 'zip', 'code', 'appear', 'zip', 'code', 'centroid', 'data', 'chapter', '5', 'selfreported', 'field', 'insmodelingsample', 'data_set', 'contained', 'missing', 'value', 'non', 'disclosure', 'client', 'example', '20', 'client', 'failed', 'reveal', 'income', 'financial', 'institution']"
1410,This demonstration continues the use of the Transaction Input Creation 1.sas program. Here the process by ID step is examined. The goal is to transform the raw transactions into a so-called case input data set. Each row of the case input data set is the value of an input for a case. The raw data for this process step is the transaction extract TN_EXTRACT created in the previous demonstration.,DM,395,"['demonstration', 'continues', 'use', 'transaction', 'input', 'creation', '1sas', 'program', 'process', 'id', 'step', 'examined', 'goal', 'transform', 'raw', 'transaction', 'socalled', 'case', 'input', 'data_set', 'row', 'case', 'input', 'data_set', 'value', 'input', 'case', 'raw', 'data', 'process', 'step', 'transaction', 'extract', 'tnextract', 'created', 'previous', 'demonstration']"
1411,"The typical approach (from a statistician?s perspective) is dummy coding the levels of the non-numeric input. In this way, a predictive model sees each level equidistant and can adjust predicted response to accurately reflect the response difference between levels. However, the problem with dummy coding is precisely one of accuracy. A variable with a multitude of levels can generate as many dummy coding inputs as there are cases in the training data set. The model is able to predict response exactly, at least for the training data. This problem is called overgeneralization, in that predicted responses do not generalize to a new, identically distributed set of data.",DM,673,"['typical', 'approach', 'statistician', 'perspective', 'dummy', 'coding', 'level', 'nonnumeric', 'input', 'way', 'predictive', 'model', 'see', 'level', 'equidistant', 'adjust', 'predicted', 'response', 'accurately', 'reflect', 'response', 'difference', 'level', 'however', 'problem', 'dummy', 'coding', 'precisely', 'one', 'accuracy', 'variable', 'multitude', 'level', 'generate', 'many', 'dummy', 'coding', 'input', 'case', 'training', 'data_set', 'model', 'able', 'predict', 'response', 'exactly', 'least', 'training', 'data', 'problem', 'called', 'overgeneralization', 'predicted', 'response', 'generalize', 'new', 'identically', 'distributed', 'set', 'data']"
1412,"Stratified separate sampling offers an improvement over the simple random approach shown in the previous section. In stratified separate sampling, a specified number of cases are drawn from levels of designated stratification variables. If the stratification variables are carefully chosen, the sample can control for exogenous factors in the data such as time and macroscopic economic conditions. This allows the sample to better represent the target population and thereby improves model accuracy.",DM,499,"['stratified', 'separate', 'sampling', 'offer', 'improvement', 'simple', 'random', 'approach', 'shown', 'previous', 'section', 'stratified', 'separate', 'sampling', 'specified', 'number', 'case', 'drawn', 'level', 'designated', 'stratification', 'variable', 'stratification', 'variable', 'carefully', 'chosen', 'sample', 'control', 'exogenous', 'factor', 'data', 'time', 'macroscopic', 'economic', 'condition', 'allows', 'sample', 'better', 'represent', 'target', 'population', 'thereby', 'improves', 'model', 'accuracy']"
1413,Event times in the interest period are recalibrated to a scale measuring time from the start of the latency period. Events with small relative times occur closest to the target date.,DM,182,"['event', 'time', 'interest', 'period', 'recalibrated', 'scale', 'measuring', 'time', 'start', 'latency', 'period', 'event', 'small', 'relative', 'time', 'occur', 'closest', 'target', 'date']"
1414,"%generate_grouping(from=work.profile_codes,value=PROFILE,group=CODE); There are seven distinct grouping codes of interest generated from ten profile combinations. All other profile combinations are accommodated by the OTHER profile, which maps to the EXD grouping code. The next block of code includes the declaration of the transaction code index and code arrays. *** Create Transaction Based Inputs; data work.tn_case_inputs; keep CHECKING_ID VARNAME VALUE;",DM,459,"['generategroupingfromworkprofilecodesvalueprofilegroupcode', 'seven', 'distinct', 'grouping', 'code', 'interest', 'generated', 'ten', 'profile', 'combination', 'profile', 'combination', 'accommodated', 'profile', 'map', 'exd', 'grouping', 'code', 'next', 'block', 'code', 'includes', 'declaration', 'transaction', 'code', 'index', 'code', 'array', '', 'create', 'transaction', 'based', 'input', 'data', 'worktncaseinputs', 'keep', 'checkingid', 'varname', 'value']"
1415,"Transaction events often serve as increments to a fixed value such as an account balance. Properties of account balances over time are often of great interest to the modeler. The existing framework can be modified to analyze account balance as a time series. In this way, properties such as average account balance, account volatility, and, later, balance trends can be used as inputs for predictive models.",DM,407,"['transaction', 'event', 'often', 'serve', 'increment', 'fixed', 'value', 'account', 'balance', 'property', 'account', 'balance', 'time', 'often', 'great', 'interest', 'modeler', 'existing', 'framework', 'modified', 'analyze', 'account', 'balance', 'time', 'series', 'way', 'property', 'average', 'account', 'balance', 'account', 'volatility', 'later', 'balance', 'trend', 'used', 'input', 'predictive', 'model']"
1416,"Ideally, you will have access to a private database closely tied to the RDBMS server that contains the operational data. This database will contain views to the operational data as well as large intermediate tables generated by the SAS/ACCESS Pass-Through facility. Subsets of these intermediate tables will be transferred to the SAS analysis server for processing by SAS. In this way, transfer of data through the network is limited to small amounts of data and occurs only when necessary.",DM,490,"['ideally', 'access', 'private', 'database', 'closely', 'tied', 'rdbms', 'server', 'contains', 'operational', 'data', 'database', 'contain', 'view', 'operational', 'data', 'well', 'large', 'intermediate', 'table', 'generated', 'sasaccess', 'passthrough', 'facility', 'subset', 'intermediate', 'table', 'transferred', 'sa', 'analysis', 'server', 'processing', 'sa', 'way', 'transfer', 'data', 'network', 'limited', 'small', 'amount', 'data', 'occurs', 'necessary']"
1417,The program Extracting Relevant Data 4.sas demonstrates assigning target dates to cases in the INS example. The data is sorted by origination date in descending order. proc sort data=ins_clients_qualified; by descending ORIG_DT; run;,DM,233,"['program', 'extracting', 'relevant', 'data', '4sas', 'demonstrates', 'assigning', 'target', 'date', 'case', 'example', 'data', 'sorted', 'origination', 'date', 'descending', 'order', 'proc', 'sort', 'datainsclientsqualified', 'descending', 'origdt', 'run']"
1418,"In the previous section, the inherent meaning of non-numeric variables allowed transformations to useful numeric inputs. In this section, their relationships to other (extrinsic) data is leveraged. It is often possible to think of high cardinality variables as indices to other data sources. For example, a table summarizing the frequency distribution of names by gender can be linked to the first names in the target sample. Bayes? theorem can be employed to translate these gender-specific frequency distributions into probability statements about a specific individual?s gender. As a second example, many demographic data sets are summarized at the postal code level. Linking these demographic summaries to individuals via postal code makes a tremendous amount of (summarized) information available to predictive models. This summarized data can provide hints about race, wealth, employment, education, and lifestyle. Commercial data provides such as Acxiom, Claritas, Experian, and Equifax use even higher cardinality variables such as name, address, and social security number as links to their vast data stores. By using higher cardinality links, the commercial data can provide more accurate information to the predictive model.",DM,1235,"['previous', 'section', 'inherent', 'meaning', 'nonnumeric', 'variable', 'allowed', 'transformation', 'useful', 'numeric', 'input', 'section', 'relationship', 'extrinsic', 'data', 'leveraged', 'often', 'possible', 'think', 'high', 'cardinality', 'variable', 'index', 'data', 'source', 'example', 'table', 'summarizing', 'frequency', 'distribution', 'name', 'gender', 'linked', 'first', 'name', 'target', 'sample', 'bayes', 'theorem', 'employed', 'translate', 'genderspecific', 'frequency', 'distribution', 'probability', 'statement', 'specific', 'individual', 'gender', 'second', 'example', 'many', 'demographic', 'data_set', 'summarized', 'postal', 'code', 'level', 'linking', 'demographic', 'summary', 'individual', 'via', 'postal', 'code', 'make', 'tremendous', 'amount', 'summarized', 'information', 'available', 'predictive', 'model', 'summarized', 'data', 'provide', 'hint', 'race', 'wealth', 'employment', 'education', 'lifestyle', 'commercial', 'data', 'provides', 'acxiom', 'claritas', 'experian', 'equifax', 'use', 'even', 'higher', 'cardinality', 'variable', 'name', 'address', 'social', 'security', 'number', 'link', 'vast', 'data', 'store', 'using', 'higher', 'cardinality', 'link', 'commercial', 'data', 'provide', 'accurate', 'information', 'predictive', 'model']"
1419,"%distribution(data=&data,out=&report_name,contents=Y,max_levels=120); The %DISTRIBUTION macro is called with the DATA= parameter pointing to the aforementioned data set. The OUT= parameter specifies the location of the PDF report to be generated by the macro. ?	Omission of a report name?or, more specifically, a quoted path pointing to a *.pdf file?results in the macro sending all output to the Graph and Listing windows. The CONTENTS= parameter requests the macro to produce a CONTENTS procedure summary of the specified data set. The MAX_LEVELS= parameter limits the display of non-numeric distributions to those variables with cardinality less than the specified number. The generated report is partitioned into five sections: 1.	data set attributes. 2.	variable listing. 3.	numeric distributions. 4.	cardinality report. 5.	non-numeric frequency distributions. The data set attributes section is generated by the CONTENTS procedure and gives general facts about the selected data set.",DM,989,"['distributiondatadataoutreportnamecontentsymaxlevels120', 'distribution', 'macro', 'called', 'data', 'parameter', 'pointing', 'aforementioned', 'data_set', 'parameter', 'specifies', 'location', 'pdf', 'report', 'generated', 'macro', '\tomission', 'report', 'nameor', 'specifically', 'quoted', 'path', 'pointing', 'pdf', 'fileresults', 'macro', 'sending', 'output', 'graph', 'listing', 'window', 'content', 'parameter', 'request', 'macro', 'produce', 'content', 'procedure', 'summary', 'specified', 'data_set', 'maxlevels', 'parameter', 'limit', 'display', 'nonnumeric', 'distribution', 'variable', 'cardinality', 'le', 'specified', 'number', 'generated', 'report', 'partitioned', 'five', 'section', '1\tdata', 'set', 'attribute', '2\tvariable', 'listing', '3\tnumeric', 'distribution', '4\tcardinality', 'report', '5\tnonnumeric', 'frequency', 'distribution', 'data_set', 'attribute', 'section', 'generated', 'content', 'procedure', 'give', 'general', 'fact', 'selected', 'data_set']"
1420,"In this iteration of the process step, only three inputs are generated per case. The first indicates the presence of a checking account. The second indicates a transaction overflow, in which the observed transaction count exceeds the maximum allowed per case. The third gives the observed transaction count. The transaction case input data must now be transposed to a single row per case and merged with the client ID data set.",DM,427,"['iteration', 'process', 'step', 'three', 'input', 'generated', 'per', 'case', 'first', 'indicates', 'presence', 'checking', 'account', 'second', 'indicates', 'transaction', 'overflow', 'observed', 'transaction', 'count', 'exceeds', 'maximum', 'allowed', 'per', 'case', 'third', 'give', 'observed', 'transaction', 'count', 'transaction', 'case', 'input', 'data', 'must', 'transposed', 'single', 'row', 'per', 'case', 'merged', 'client', 'id', 'data_set']"
1421,"The qualification query joins the intermediate INS_CLIENT table to the CLIENT and CREDIT_BUREAU tables. The CLIENT table contains facts about individual clients including birth date and bank origination date. The CREDIT_BUREAU table contains quarterly snapshots of financial data, including FICO scores, for most clients in the marketing data warehouse. A second intermediate table named INS_CLIENTS_QUALIFIED is created. Again, the client ID and INS account open date are selected from the intermediate INS_CLIENTS table. To satisfy all the qualifications, the INS_CLIENT table is joined with the CLIENT and CREDIT_BUREAU tables. The tables are matched on CLIENT_ID. Clients are filtered by their origination and birth dates (from the CLIENT table) and their first trade line year, trade line count, and FICO score (from the CREDIT_BUREAU table).",DM,847,"['qualification', 'query', 'join', 'intermediate', 'insclient', 'table', 'client', 'creditbureau', 'table', 'client', 'table', 'contains', 'fact', 'individual', 'client', 'including', 'birth', 'date', 'bank', 'origination', 'date', 'creditbureau', 'table', 'contains', 'quarterly', 'snapshot', 'financial', 'data', 'including', 'fico', 'score', 'client', 'marketing', 'data', 'warehouse', 'second', 'intermediate', 'table', 'named', 'insclientsqualified', 'created', 'client', 'id', 'account', 'open', 'date', 'selected', 'intermediate', 'insclients', 'table', 'satisfy', 'qualification', 'insclient', 'table', 'joined', 'client', 'creditbureau', 'table', 'table', 'matched', 'clientid', 'client', 'filtered', 'origination', 'birth', 'date', 'client', 'table', 'first', 'trade', 'line', 'year', 'trade', 'line', 'count', 'fico', 'score', 'creditbureau', 'table']"
1422,The DESCRIPTIVE data set is in a most inconvenient form: one row and many columns. The TRANSPOSE procedure reverses this arrangement. *** make descriptive statistics inset data; proc transpose data=descriptive out=descriptive; run;,DM,231,"['descriptive', 'data_set', 'inconvenient', 'form', 'one', 'row', 'many', 'column', 'transpose', 'procedure', 'revers', 'arrangement', '', 'make', 'descriptive', 'statistic', 'inset', 'data', 'proc', 'transpose', 'datadescriptive', 'outdescriptive', 'run']"
1423,"?	The macro functions depend on the zip code formats. As defined, these formats are only available in your current SAS session. To make these formats available later, you must store their definitions in a permanent SAS library. This is done using the LIBRARY= option of the FORMAT procedure. Select the online help or ask your instructor for details.",DM,350,"['\tthe', 'macro', 'function', 'depend', 'zip', 'code', 'format', 'defined', 'format', 'available', 'current', 'sa', 'session', 'make', 'format', 'available', 'later', 'must', 'store', 'definition', 'permanent', 'sa', 'library', 'done', 'using', 'library', 'option', 'format', 'procedure', 'select', 'online', 'help', 'ask', 'instructor', 'detail']"
1424,"If the relative event date is less than 365 days from the origin, the event is added to the transaction array. The code is similar to previous versions. However, the transaction date is now recorded in relative time. Processing Time-Dependent Data",DM,247,"['relative', 'event', 'date', 'le', '365', 'day', 'origin', 'event', 'added', 'transaction', 'array', 'code', 'similar', 'previous', 'version', 'however', 'transaction', 'date', 'recorded', 'relative', 'time', 'processing', 'timedependent', 'data']"
1425,"Second, if the relative time is less than zero (before the target date), the ending balance is changed: incremented for debits and decremented for credits. While this seems backwards, there is a simple explanation for this action.",DM,230,"['second', 'relative', 'time', 'le', 'zero', 'target', 'date', 'ending', 'balance', 'changed', 'incremented', 'debit', 'decremented', 'credit', 'seems', 'backwards', 'simple', 'explanation', 'action']"
1426,"Introduction of the transaction macros enables the transaction processing to begin in earnest. Additional transaction arrays are declared, corresponding to type, channel, and method fields in the transaction data.",DM,213,"['introduction', 'transaction', 'macro', 'enables', 'transaction', 'processing', 'begin', 'earnest', 'additional', 'transaction', 'array', 'declared', 'corresponding', 'type', 'channel', 'method', 'field', 'transaction', 'data']"
1427,"Missing values arise for a variety of reasons. In Chapter 3, missing values in the transactions inputs were generated for inputs not applicable to a given case. For example, the total number of checking account transactions is meaningless for cases without checking accounts. In Chapter 4, missing values in the transformed non-numeric inputs occurred when no match was found in the transformation source data. For example, certain zip codes did not appear in the zip code centroid data. In Chapter 5, self-reported fields in the INS_MODELING_SAMPLE data set contained missing values because of non- disclosure by the client. For example 20% clients failed to reveal their income to the financial institution.",DM,709,"['missing', 'value', 'arise', 'variety', 'reason', 'chapter', '3', 'missing', 'value', 'transaction', 'input', 'generated', 'input', 'applicable', 'given', 'case', 'example', 'total', 'number', 'checking', 'account', 'transaction', 'meaningless', 'case', 'without', 'checking', 'account', 'chapter', '4', 'missing', 'value', 'transformed', 'nonnumeric', 'input', 'occurred', 'match', 'wa', 'found', 'transformation', 'source', 'data', 'example', 'certain', 'zip', 'code', 'appear', 'zip', 'code', 'centroid', 'data', 'chapter', '5', 'selfreported', 'field', 'insmodelingsample', 'data_set', 'contained', 'missing', 'value', 'non', 'disclosure', 'client', 'example', '20', 'client', 'failed', 'reveal', 'income', 'financial', 'institution']"
1428,"Innovating means introducing something new, or as if it were new. In order to try ?new? offers or products, without staking too much capital or time on unknown results, you test the offer carefully to assess its potential.",DO,222,"['innovating', 'mean', 'introducing', 'something', 'new', 'new', 'order', 'try', 'new', 'offer', 'product', 'without', 'staking', 'much', 'capital', 'time', 'unknown', 'result', 'test', 'offer', 'carefully', 'ass', 'potential']"
1429,"For the most part, the example designs that have been considered consisted of most, if not all, two- level factors. Two-level factors are easy to work with and yield designs that are easy to analyze. Of course, there are several situations where two-level factors are not appropriate, including categorical factors with several levels and continuous factors for which you want to estimate higher-order terms. In either of those situations, you can design experiments with those concerns in mind. Designs to accommodate these requirements exist, and they typically can be created using the same %MktEx macro-based approach as you have already seen. However, sometimes the need to estimate higher-order effects, or a particular interaction, is not recognized until after the initial experiment has been run. In such a situation, it is often feasible to run a second, often smaller, experiment to yield enough information to estimate the quantities newly of interest. Typically, the initial experiment and the follow-up treatments will be analyzed as though they had been in blocks.",DO,1079,"['part', 'example', 'design', 'considered', 'consisted', 'two', 'level', 'factor', 'twolevel', 'factor', 'easy', 'work', 'yield', 'design', 'easy', 'analyze', 'course', 'several', 'situation', 'twolevel', 'factor', 'appropriate', 'including', 'categorical', 'factor', 'several', 'level', 'continuous', 'factor', 'want', 'estimate', 'higherorder', 'term', 'either', 'situation', 'design', 'experiment', 'concern', 'mind', 'design', 'accommodate', 'requirement', 'exist', 'typically', 'created', 'using', 'mktex', 'macrobased', 'approach', 'already', 'seen', 'however', 'sometimes', 'need', 'estimate', 'higherorder', 'effect', 'particular', 'interaction', 'recognized', 'initial', 'experiment', 'ha', 'run', 'situation', 'often', 'feasible', 'run', 'second', 'often', 'smaller', 'experiment', 'yield', 'enough', 'information', 'estimate', 'quantity', 'newly', 'interest', 'typically', 'initial', 'experiment', 'followup', 'treatment', 'analyzed', 'though', 'block']"
1430,"Power is the probability of rejecting the null hypothesis when it is false. That is, given that the alternative hypothesis does a better job of explaining the world, what is the probability that our decision will be to reject the null hypothesis?",DO,246,"['power', 'probability', 'rejecting', 'null', 'hypothesis', 'false', 'given', 'alternative', 'hypothesis', 'doe', 'better', 'job', 'explaining', 'world', 'probability', 'decision', 'reject', 'null', 'hypothesis']"
1431,"To see the final design, use the PRINT procedure. Depending on how you created the key data set, formats may improve the appearance of your results. proc print data=final; format intro goto btchg percent8.2; var Intro Duration Goto Color Creative Postage Rewards Fixed AnnFee BTChg; run;",DO,287,"['see', 'final', 'design', 'use', 'print', 'procedure', 'depending', 'created', 'key', 'data_set', 'format', 'may', 'improve', 'appearance', 'result', 'proc', 'print', 'datafinal', 'format', 'intro', 'goto', 'btchg', 'percent82', 'var', 'intro', 'duration', 'goto', 'color', 'creative', 'postage', 'reward', 'fixed', 'annfee', 'btchg', 'run']"
1432,"Certain higher-order interaction effects cannot be estimated with a fractional factorial design. With orthogonal arrays or optimality-criterion based designs, the confounding cannot be compactly expressed, but it is still there. By customizing and augmenting a design, you may be able to undo some of the aliasing in a small experiment; that is, you can permit the estimation of a term that was not explicitly estimable in your original design. Other purposes of augmenting designs include *	adding points to estimate a response surface *	adding points to break confounding *	adding points to test for trend effects *	adding points to discriminate between candidate models. There are many techniques for augmenting designs. A few traditional techniques are discussed in the following slides, and the practice of adding points is demonstrated later. A typical approach includes using several factors at two levels each and then adding a center point to detect any departure from the assumption of linearity.",DO,1006,"['certain', 'higherorder', 'interaction', 'effect', 'cannot', 'estimated', 'fractional', 'factorial', 'design', 'orthogonal', 'array', 'optimalitycriterion', 'based', 'design', 'confounding', 'cannot', 'compactly', 'expressed', 'still', 'customizing', 'augmenting', 'design', 'may', 'able', 'undo', 'aliasing', 'small', 'experiment', 'permit', 'estimation', 'term', 'wa', 'explicitly', 'estimable', 'original', 'design', 'purpose', 'augmenting', 'design', 'include', '\tadding', 'point', 'estimate', 'response', 'surface', '\tadding', 'point', 'break', 'confounding', '\tadding', 'point', 'test', 'trend', 'effect', '\tadding', 'point', 'discriminate', 'candidate', 'model', 'many', 'technique', 'augmenting', 'design', 'traditional', 'technique', 'discussed', 'following', 'slide', 'practice', 'adding', 'point', 'demonstrated', 'later', 'typical', 'approach', 'includes', 'using', 'several', 'factor', 'two', 'level', 'adding', 'center', 'point', 'detect', 'departure', 'assumption', 'linearity']"
1433,"Innovating means introducing something new, or as if it were new. In order to try ?new? offers or products, without staking too much capital or time on unknown results, you test the offer carefully to assess its potential.",DO,222,"['innovating', 'mean', 'introducing', 'something', 'new', 'new', 'order', 'try', 'new', 'offer', 'product', 'without', 'staking', 'much', 'capital', 'time', 'unknown', 'result', 'test', 'offer', 'carefully', 'ass', 'potential']"
1434,"You can see that the intro effect is drastic, the goto effect (the vertical distance between the lines) is less drastic but statistically significant, and the interaction effect is very small and statistically insignificant. 2.2	Multiple Factor Designs",DO,252,"['see', 'intro', 'effect', 'drastic', 'goto', 'effect', 'vertical', 'distance', 'line', 'le', 'drastic', 'statistically', 'significant', 'interaction', 'effect', 'small', 'statistically', 'insignificant', '22\tmultiple', 'factor', 'design']"
1435,"An experimental design defines the rules and procedures by which data is collected. By employing the correct design for any given situation, you can make the most efficient use of the data from the experiment. This means that you may be able to save time and money in the data collection phase and still answer your question. The practice of ?Design of Experiments? or ?Experimental Design? involves a systematic assessment of different tests.",DO,443,"['experimental', 'design', 'defines', 'rule', 'procedure', 'data', 'collected', 'employing', 'correct', 'design', 'given', 'situation', 'make', 'efficient', 'use', 'data', 'experiment', 'mean', 'may', 'able', 'save', 'time', 'money', 'data', 'collection', 'phase', 'still', 'answer', 'question', 'practice', 'design', 'experiment', 'experimental', 'design', 'involves', 'systematic', 'assessment', 'different', 'test']"
1436,"In screening designs, you set the factors at the highest and lowest levels to get the best possible leverage for the response. However, not all factor-response relationships are best represented by a straight line. With only two design points, curvature in a relationship cannot be estimated. A third point, called a center point, is required to test nonlinearity in the response. Of course, there are more possibilities. You can have very high-order polynomial effects that you are trying to detect, but there is always the reality of diminishing returns?you get the most benefit from the first few effects detected. After you detect the big linear effects, you can investigate the quadratic effects. If those models are still not accurate enough, you can continue testing for more complicated effects. When you know you want to test for departures from nonlinearity, you should specify that the factor of interest has three levels so that you have low, medium, and high settings for that factor. If you do not think to test nonlinear effects until after the test is run, you will need to augment an existing design with some runs that include center points.",DO,1159,"['screening', 'design', 'set', 'factor', 'highest', 'lowest', 'level', 'get', 'best', 'possible', 'leverage', 'response', 'however', 'factorresponse', 'relationship', 'best', 'represented', 'straight', 'line', 'two', 'design', 'point', 'curvature', 'relationship', 'cannot', 'estimated', 'third', 'point', 'called', 'center', 'point', 'required', 'test', 'nonlinearity', 'response', 'course', 'possibility', 'highorder', 'polynomial', 'effect', 'trying', 'detect', 'always', 'reality', 'diminishing', 'returnsyou', 'get', 'benefit', 'first', 'effect', 'detected', 'detect', 'big', 'linear', 'effect', 'investigate', 'quadratic', 'effect', 'model', 'still', 'accurate', 'enough', 'continue', 'testing', 'complicated', 'effect', 'know', 'want', 'test', 'departure', 'nonlinearity', 'specify', 'factor', 'interest', 'ha', 'three', 'level', 'low', 'medium', 'high', 'setting', 'factor', 'think', 'test', 'nonlinear', 'effect', 'test', 'run', 'need', 'augment', 'existing', 'design', 'run', 'include', 'center', 'point']"
1437,How much power does this cutoff (or decision rule) give us in an experiment with five observations? That question can only be answered for a particular alternative hypothesis.,DO,175,"['much', 'power', 'doe', 'cutoff', 'decision', 'rule', 'give', 'u', 'experiment', 'five', 'observation', 'question', 'answered', 'particular', 'alternative', 'hypothesis']"
1438,"In most testing situations, you posit a null hypothesis (usually that the difference of interest does not exist) and then test to find evidence to reject that null hypothesis. Of course, only one of the two hypotheses can be true, but if you knew which one, you would not have to test. Hence, you gather some data, and use that data to make a decision: ?reject the null hypothesis? or ?accept the null hypothesis.? Typically, the hypotheses are constructed such that these decisions are synonymous with ?there is no evidence of a significant difference between groups? or ?there is evidence of a significant difference between groups.?",DO,635,"['testing', 'situation', 'posit', 'null', 'hypothesis', 'usually', 'difference', 'interest', 'doe', 'exist', 'test', 'find', 'evidence', 'reject', 'null', 'hypothesis', 'course', 'one', 'two', 'hypothesis', 'true', 'knew', 'one', 'would', 'test', 'hence', 'gather', 'data', 'use', 'data', 'make', 'decision', 'reject', 'null', 'hypothesis', 'accept', 'null', 'hypothesis', 'typically', 'hypothesis', 'constructed', 'decision', 'synonymous', 'evidence', 'significant', 'difference', 'group', 'evidence', 'significant', 'difference', 'group']"
1439,"The blocks that were considered in the last section were restricted to complete blocks; that is, every block had every treatment represented in it. In these examples, you had one factor at two levels, so you could not have had anything less than complete blocks. However, if the treatments consisted of one factor with many levels, or a factorial design too large to fit every treatment into one block, you may have had to abandon this nice complete block structure. What would that do to the experiment and the analysis? One of the nicest properties afforded by complete block designs, or even factorial arrangements of treatments, is orthogonality. Orthogonality means that your contrasts are statistically independent of one another; or all of your contrasts are at right angles to one another. Practically speaking, orthogonality ensures that the analysis that yields, for example, an estimate of the intro APR effect is not affected by the goto APR effect.",DO,961,"['block', 'considered', 'last', 'section', 'restricted', 'complete', 'block', 'every', 'block', 'every', 'treatment', 'represented', 'example', 'one', 'factor', 'two', 'level', 'could', 'anything', 'le', 'complete', 'block', 'however', 'treatment', 'consisted', 'one', 'factor', 'many', 'level', 'factorial', 'design', 'large', 'fit', 'every', 'treatment', 'one', 'block', 'may', 'abandon', 'nice', 'complete', 'block', 'structure', 'would', 'experiment', 'analysis', 'one', 'nicest', 'property', 'afforded', 'complete', 'block', 'design', 'even', 'factorial', 'arrangement', 'treatment', 'orthogonality', 'orthogonality', 'mean', 'contrast', 'statistically', 'independent', 'one', 'another', 'contrast', 'right', 'angle', 'one', 'another', 'practically', 'speaking', 'orthogonality', 'ensures', 'analysis', 'yield', 'example', 'estimate', 'intro', 'apr', 'effect', 'affected', 'goto', 'apr', 'effect']"
1440,"In the last section, blocks were considered a source of a deterministic shift in the response variable, or a source of random variation. This distinction becomes important in the analysis of the data; the former is a fixed effect, and can be treated as any other factor. The latter is a random effect, and should be handled differently. With a random effect, the analysis typically yields a model to capture the deterministic effects, and variance components due to the random effects and noise.",DO,495,"['last', 'section', 'block', 'considered', 'source', 'deterministic', 'shift', 'response_variable', 'source', 'random', 'variation', 'distinction', 'becomes', 'important', 'analysis', 'data', 'former', 'fixed', 'effect', 'treated', 'factor', 'latter', 'random', 'effect', 'handled', 'differently', 'random', 'effect', 'analysis', 'typically', 'yield', 'model', 'capture', 'deterministic', 'effect', 'variance', 'component', 'due', 'random', 'effect', 'noise']"
1441,"Power does not just depend on the alternative hypothesis. It also depends on the sample size. Adding to your sample will change the decision rule, the distributions under the null and alternative hypotheses, and the power.",DO,222,"['power', 'doe', 'depend', 'alternative', 'hypothesis', 'also', 'depends', 'sample_size', 'adding', 'sample', 'change', 'decision', 'rule', 'distribution', 'null', 'alternative', 'hypothesis', 'power']"
1442,"It seems reasonable to assume that the response rate to an offer would depend on both rates, simultaneously. For example, everyone might sign up for the low introductory rate card, regardless of goto. If you charge the high introductory rate, however, you may need a low goto rate to entice prospects to respond. A model that only had an intro term and a goto term would not capture this behavior. You need an interaction term to capture the added complexity.",DO,459,"['seems', 'reasonable', 'assume', 'response', 'rate', 'offer', 'would', 'depend', 'rate', 'simultaneously', 'example', 'everyone', 'might', 'sign', 'low', 'introductory', 'rate', 'card', 'regardless', 'goto', 'charge', 'high', 'introductory', 'rate', 'however', 'may', 'need', 'low', 'goto', 'rate', 'entice', 'prospect', 'respond', 'model', 'intro', 'term', 'goto', 'term', 'would', 'capture', 'behavior', 'need', 'interaction', 'term', 'capture', 'added', 'complexity']"
1443,"If you are interested in having an effect explicitly in the model, to account for the deterministic effect of each variable?s level, then that variable is a fixed effect.",DO,170,"['interested', 'effect', 'explicitly', 'model', 'account', 'deterministic', 'effect', 'variable', 'level', 'variable', 'fixed', 'effect']"
1444,"The concept of power is central to good experimental design sample size determination. There is a complicated relationship between the power of a test, the significance level of the test, and the particular hypotheses that you are testing.",DO,239,"['concept', 'power', 'central', 'good', 'experimental', 'design', 'sample_size', 'determination', 'complicated', 'relationship', 'power', 'test', 'significance', 'level', 'test', 'particular', 'hypothesis', 'testing']"
1445,"When you contrast one factor at a time (OFAT) tests with factorially arranged tests, there are several benefits to using the factorial structure. If you consider a block as a factor for the time being, it is easy to see that a complete block test is like a factorially arranged test, in that every level of every factor of interest is represented at every level of every other factor.",DO,384,"['contrast', 'one', 'factor', 'time', 'ofat', 'test', 'factorially', 'arranged', 'test', 'several', 'benefit', 'using', 'factorial', 'structure', 'consider', 'block', 'factor', 'time', 'easy', 'see', 'complete', 'block', 'test', 'like', 'factorially', 'arranged', 'test', 'every', 'level', 'every', 'factor', 'interest', 'represented', 'every', 'level', 'every', 'factor']"
1446,"The typical experiment will have at least two factors of interest, but may have many more. In addition, the factors themselves may have more than two levels each. This will typically occur with categorical factors, when there are several categories of interest, or with continuous factors where a linear relationship is suspected to be inadequate. This section deals with each of these extensions in turn.",DO,405,"['typical', 'experiment', 'least', 'two', 'factor', 'interest', 'may', 'many', 'addition', 'factor', 'may', 'two', 'level', 'typically', 'occur', 'categorical', 'factor', 'several', 'category', 'interest', 'continuous', 'factor', 'linear', 'relationship', 'suspected', 'inadequate', 'section', 'deal', 'extension', 'turn']"
1447,"You can see that the intro effect is drastic, the goto effect (the vertical distance between the lines) is less drastic but statistically significant, and the interaction effect is very small and statistically insignificant. 2.2	Multiple Factor Designs",DO,252,"['see', 'intro', 'effect', 'drastic', 'goto', 'effect', 'vertical', 'distance', 'line', 'le', 'drastic', 'statistically', 'significant', 'interaction', 'effect', 'small', 'statistically', 'insignificant', '22\tmultiple', 'factor', 'design']"
1448,The %MktEx macro searches over possible designs for a design that is efficient and that satisfies your practical constraints. These constraints can be specified in a restrictions macro. An example follows in the next demonstration. Generating Optimal Designs,DO,258,"['mktex', 'macro', 'search', 'possible', 'design', 'design', 'efficient', 'satisfies', 'practical', 'constraint', 'constraint', 'specified', 'restriction', 'macro', 'example', 'follows', 'next', 'demonstration', 'generating', 'optimal', 'design']"
1449,"In traditional experimental design, reducing on the number of points in the factor space would mean fewer experimental units and a reduced cost design. In the direct marketing context, fewer points in the factor space means *	fewer unique types of mail pieces, leading to lower printing costs *	fewer scripts for the telemarketers to learn *	fewer e-mail messages to manage without necessarily restricting the amount of information you can glean from a test. With the exception of the confounding and aliasing involved, there are no differences in the inferences between a full factorial and a fractional factorial. This is demonstrated in the analysis portion of the following demonstration. In this context, one needs to give careful consideration to sample size. Fractional factorials were first used in the context of experiments that were so expensive that one could not afford one experimental unit for each treatment. However, in direct marketing, you generally have millions of experimental units (individuals or households, depending on your point of view). Your task is to cleverly assign mail volume (telemarketing volume, and so on) to each treatment (combination of factors) such that you can answer the questions of interest.",DO,1239,"['traditional', 'experimental', 'design', 'reducing', 'number', 'point', 'factor', 'space', 'would', 'mean', 'fewer', 'experimental', 'unit', 'reduced', 'cost', 'design', 'direct', 'marketing', 'context', 'fewer', 'point', 'factor', 'space', 'mean', '\tfewer', 'unique', 'type', 'mail', 'piece', 'leading', 'lower', 'printing', 'cost', '\tfewer', 'script', 'telemarketers', 'learn', '\tfewer', 'email', 'message', 'manage', 'without', 'necessarily', 'restricting', 'amount', 'information', 'glean', 'test', 'exception', 'confounding', 'aliasing', 'involved', 'difference', 'inference', 'full', 'factorial', 'fractional', 'factorial', 'demonstrated', 'analysis', 'portion', 'following', 'demonstration', 'context', 'one', 'need', 'give', 'careful', 'consideration', 'sample_size', 'fractional', 'factorial', 'first', 'used', 'context', 'experiment', 'expensive', 'one', 'could', 'afford', 'one', 'experimental', 'unit', 'treatment', 'however', 'direct', 'marketing', 'generally', 'million', 'experimental', 'unit', 'individual', 'household', 'depending', 'point', 'view', 'task', 'cleverly', 'assign', 'mail', 'volume', 'telemarketing', 'volume', 'treatment', 'combination', 'factor', 'answer', 'question', 'interest']"
1450,"You can consider the eight possible treatments as defining a cube, in comparison to the square that resulted from the credit card solicitation 2x2 experiment in the last section. Again, consider how the comparable OFAT experiment would not test as much of the possible factor space. Three Factors at Two Levels Each",DO,315,"['consider', 'eight', 'possible', 'treatment', 'defining', 'cube', 'comparison', 'square', 'resulted', 'credit', 'card', 'solicitation', '2x2', 'experiment', 'last', 'section', 'consider', 'comparable', 'ofat', 'experiment', 'would', 'test', 'much', 'possible', 'factor', 'space', 'three', 'factor', 'two', 'level']"
1451,"To perform a power analysis in the presence of blocks (or even covariates), you need an estimate of how much variability the additional factors explain. For example, if a block factor explains enough variability that your standard errors are all cut in half, then the necessary sample size should be reduced as well. In the context of direct marketing, sample sizes are large and the degrees of freedom lost to blocking are negligible. ?	Traditional experimental design techniques define blocks in two ways, simultaneously: *	The factors, usually nuisance factors, which affect the response of interest but are not, themselves, of interest. *	The factors used to restrict the randomization of experimental units to treatments, which do not interact with treatments. These conditions do not always apply in this context. For example, a block * treatment interaction is evidence that some factor is more effective in one sub-population than another. To detect factors like these may take a larger sample size than ignoring blocks. This is counter-intuitive to practitioners of classical experimental design methodology, but it may be important in your business. For example, month-to-month differences in campaigns might be assumed independent of other factors; risk score differences between individuals might not be. The idea behind this slightly more complicated power analysis is fairly straightforward. Consider two variances: the variance in the analysis variable (?2large) without blocking and the variance in the analysis variable after accounting for block to block variation (?2small). Consider the following ANOVA table: Source df SS MS Block b-1 SSB MSB Error n-b SSE MSE Total n-1 SST",DO,1695,"['perform', 'power', 'analysis', 'presence', 'block', 'even', 'covariates', 'need', 'estimate', 'much', 'variability', 'additional', 'factor', 'explain', 'example', 'block', 'factor', 'explains', 'enough', 'variability', 'standard_error', 'cut', 'half', 'necessary', 'sample_size', 'reduced', 'well', 'context', 'direct', 'marketing', 'sample_size', 'large', 'degree', 'freedom', 'lost', 'blocking', 'negligible', '\ttraditional', 'experimental', 'design', 'technique', 'define', 'block', 'two', 'way', 'simultaneously', '\tthe', 'factor', 'usually', 'nuisance', 'factor', 'affect', 'response', 'interest', 'interest', '\tthe', 'factor', 'used', 'restrict', 'randomization', 'experimental', 'unit', 'treatment', 'interact', 'treatment', 'condition', 'always', 'apply', 'context', 'example', 'block', '', 'treatment', 'interaction', 'evidence', 'factor', 'effective', 'one', 'subpopulation', 'another', 'detect', 'factor', 'like', 'may', 'take', 'larger', 'sample_size', 'ignoring', 'block', 'counterintuitive', 'practitioner', 'classical', 'experimental', 'design', 'methodology', 'may', 'important', 'business', 'example', 'monthtomonth', 'difference', 'campaign', 'might', 'assumed', 'independent', 'factor', 'risk', 'score', 'difference', 'individual', 'might', 'idea', 'behind', 'slightly', 'complicated', 'power', 'analysis', 'fairly', 'straightforward', 'consider', 'two', 'variance', 'variance', 'analysis', 'variable', '2large', 'without', 'blocking', 'variance', 'analysis', 'variable', 'accounting', 'block', 'block', 'variation', '2small', 'consider', 'following', 'anova', 'table', 'source', 'df', 'block', 'b1', 'ssb', 'msb', 'error', 'nb', 'sse', 'mse', 'total', 'n1', 'sst']"
1452,"It seems like the main effects are significant, but that is no insurance that the model is well specified. It may be that there are higher-order interactions that are going undetected. You could test those higher order interactions with a MODEL statement that uses the btapr, points, btapr*points, btapr*btapr, btapr*btapr*points, and so forth, but because the levels of the factors are evenly spaced, you could use orthogonal polynomials and get independent tests of the higher-order effects. The PARAM=ORTHPOLY option, following a slash on the CLASS statement, instructs the LOGISTIC procedure to use orthogonal polynomial recoding of the inputs named in that CLASS statement. Specifying btapr|points in the MODEL statement tests every possible polynomial term and interaction. proc logistic data=orthpoly; class btapr points / param=orthpoly; model resp/volume=btapr|points; run; Partial Output Class Level Information",DO,921,"['seems', 'like', 'main_effect', 'significant', 'insurance', 'model', 'well', 'specified', 'may', 'higherorder', 'interaction', 'going', 'undetected', 'could', 'test', 'higher', 'order', 'interaction', 'model_statement', 'us', 'btapr', 'point', 'btaprpoints', 'btaprbtapr', 'btaprbtaprpoints', 'forth', 'level', 'factor', 'evenly', 'spaced', 'could', 'use', 'orthogonal', 'polynomial', 'get', 'independent', 'test', 'higherorder', 'effect', 'paramorthpoly', 'option', 'following', 'slash', 'class', 'statement', 'instructs', 'logistic', 'procedure', 'use', 'orthogonal', 'polynomial', 'recoding', 'input', 'named', 'class', 'statement', 'specifying', 'btaprpoints', 'model_statement', 'test', 'every', 'possible', 'polynomial', 'term', 'interaction', 'proc_logistic', 'dataorthpoly', 'class', 'btapr', 'point', '', 'paramorthpoly', 'model', 'respvolumebtaprpoints', 'run', 'partial', 'output', 'class', 'level', 'information']"
1453,"In traditional experimental design, defining a blocking factor as a block instead of a factor could explain much of the variability in the data without using many degrees of freedom. Again, in direct marketing context, the extent to which that statement is true depends on many factors.",DO,286,"['traditional', 'experimental', 'design', 'defining', 'blocking', 'factor', 'block', 'instead', 'factor', 'could', 'explain', 'much', 'variability', 'data', 'without', 'using', 'many', 'degree', 'freedom', 'direct', 'marketing', 'context', 'extent', 'statement', 'true', 'depends', 'many', 'factor']"
1454,"The focus of this course is the technical aspects of improved testing techniques?what makes them better than other techniques, examples of how to use them, and caveats to avoid misusing them. These tests do not take place in a vacuum; while there may only be a few individuals involved in any given test's design and analysis cycle, they are set in the expectations of the entire organization. For example, your business may be broken into three groups: Management The management group controls the general direction of the organization. This direction probably involves increasing this financial figure, or decreasing that one. Those financials relate directly to the kinds of metrics that you can analyze as the response variables in these tests. If (corporate level or marketing group level) management has campaign strategies in mind to achieve those goals, that will suggest factors of interest. Factors, features of offers that you can control, are only part of the story. These strategies may also point you to attributes of individuals that will also affect the responses of interest. These attributes, if known a priori, can be used in the designs as blocks or covariates. These attributes, indicated by the campaign strategy, as well as features indicated by subject-matter expertise (they are, after all, your customers) suggest a population or populations of interest as a focal point for the tests. Management has control over a considerable portion of these decisions, which you can lump into the ""what to do"" category. Operations The operations group is in charge of ""how to do it."" At the end of the day, it is their responsibility to apply the right design, at the right time, to the right population. They may or may not be responsible for deciding which design is the right design; they are responsible for turning the test on paper into results in the database. Analytics The analytics group, then, is responsible for ?what does it mean?? They presumably had a hand in the design of the test, and will be in charge of sorting out the results. Together, these groups can take the results of a test and determine (1) what next steps are merited on the basis of the results and (2) what else they want to test, in the light of the present results. If any of the analytics team is in a modeling group, they have probably started dreaming of the ultimate goal?one to one marketing, where the offer that is sent to an individual is the offer that you have reason to believe is the one to which they are most likely to respond.",DO,2540,"['focus', 'course', 'technical', 'aspect', 'improved', 'testing', 'techniqueswhat', 'make', 'better', 'technique', 'example', 'use', 'caveat', 'avoid', 'misusing', 'test', 'take', 'place', 'vacuum', 'may', 'individual', 'involved', 'given', 'test', 'design', 'analysis', 'cycle', 'set', 'expectation', 'entire', 'organization', 'example', 'business', 'may', 'broken', 'three', 'group', 'management', 'management', 'group', 'control', 'general', 'direction', 'organization', 'direction', 'probably', 'involves', 'increasing', 'financial', 'figure', 'decreasing', 'one', 'financials', 'relate', 'directly', 'kind', 'metric', 'analyze', 'response_variable', 'test', 'corporate', 'level', 'marketing', 'group', 'level', 'management', 'ha', 'campaign', 'strategy', 'mind', 'achieve', 'goal', 'suggest', 'factor', 'interest', 'factor', 'feature', 'offer', 'control', 'part', 'story', 'strategy', 'may', 'also', 'point', 'attribute', 'individual', 'also', 'affect', 'response', 'interest', 'attribute', 'known', 'priori', 'used', 'design', 'block', 'covariates', 'attribute', 'indicated', 'campaign', 'strategy', 'well', 'feature', 'indicated', 'subjectmatter', 'expertise', 'customer', 'suggest', 'population', 'population', 'interest', 'focal', 'point', 'test', 'management', 'ha', 'control', 'considerable', 'portion', 'decision', 'lump', 'category', 'operation', 'operation', 'group', 'charge', 'end', 'day', 'responsibility', 'apply', 'right', 'design', 'right', 'time', 'right', 'population', 'may', 'may', 'responsible', 'deciding', 'design', 'right', 'design', 'responsible', 'turning', 'test', 'paper', 'result', 'database', 'analytics', 'analytics', 'group', 'responsible', 'doe', 'mean', 'presumably', 'hand', 'design', 'test', 'charge', 'sorting', 'result', 'together', 'group', 'take', 'result', 'test', 'determine', '1', 'next', 'step', 'merited', 'basis', 'result', '2', 'else', 'want', 'test', 'light', 'present', 'result', 'analytics', 'team', 'modeling', 'group', 'probably', 'started', 'dreaming', 'ultimate', 'goalone', 'one', 'marketing', 'offer', 'sent', 'individual', 'offer', 'reason', 'believe', 'one', 'likely', 'respond']"
1455,"Canonical correlations greater than 0.316 (which is to say, r2 between variables greater than 0.1) are detailed in this small table. Again, the correlations farthest from zero are among the variables that are impacted by the restrictions. The fact that you cannot offer one level of one factor in combination with one level of another factor means that those factors can never be orthogonal. This table attempts to quantify that departure from orthogonality. Summary of Frequencies There are 2 Canonical Correlations Greater Than 0.316 * - Indicates Unequal Frequencies",DO,569,"['canonical', 'correlation', 'greater', '0316', 'say', 'r2', 'variable', 'greater', '01', 'detailed', 'small', 'table', 'correlation', 'farthest', 'zero', 'among', 'variable', 'impacted', 'restriction', 'fact', 'cannot', 'offer', 'one', 'level', 'one', 'factor', 'combination', 'one', 'level', 'another', 'factor', 'mean', 'factor', 'never', 'orthogonal', 'table', 'attempt', 'quantify', 'departure', 'orthogonality', 'summary', 'frequency', '2', 'canonical', 'correlation', 'greater', '0316', '', '', 'indicates', 'unequal', 'frequency']"
1456,"You can consider the eight possible treatments as defining a cube, in comparison to the square that resulted from the credit card solicitation 2x2 experiment in the last section. Again, consider how the comparable OFAT experiment would not test as much of the possible factor space. Three Factors at Two Levels Each",DO,315,"['consider', 'eight', 'possible', 'treatment', 'defining', 'cube', 'comparison', 'square', 'resulted', 'credit', 'card', 'solicitation', '2x2', 'experiment', 'last', 'section', 'consider', 'comparable', 'ofat', 'experiment', 'would', 'test', 'much', 'possible', 'factor', 'space', 'three', 'factor', 'two', 'level']"
1457,"The log shows that the macro creates two data sets; one called design and one called randomize. The design data set has the most efficient experimental design that the macro finds in its search, and the randomized data set has the same design with the order of the rows randomized. This is a nice feature in a laboratory; in direct marketing you will likely use the design data set. Output Algorithm Search History",DO,414,"['log', 'show', 'macro', 'creates', 'two', 'data_set', 'one', 'called', 'design', 'one', 'called', 'randomize', 'design', 'data_set', 'ha', 'efficient', 'experimental', 'design', 'macro', 'find', 'search', 'randomized', 'data_set', 'ha', 'design', 'order', 'row', 'randomized', 'nice', 'feature', 'laboratory', 'direct', 'marketing', 'likely', 'use', 'design', 'data_set', 'output', 'algorithm', 'search', 'history']"
1458,"Notice that the traditional model with blocks assumes an additive effect due to blocks, but no block by treatment interaction. That is because, in the traditional experimental design framework, the degrees of freedom that measure the block by treatment interactions are the same as the degrees of freedom for error. Including a block by treatment interaction in that context eliminated the ability to test. However, in the direct marketing context, where you have many experimental units and hence many degrees of freedom for error, it is feasible to test for these interaction effects.",DO,586,"['notice', 'traditional', 'model', 'block', 'assumes', 'additive', 'effect', 'due', 'block', 'block', 'treatment', 'interaction', 'traditional', 'experimental', 'design', 'framework', 'degree', 'freedom', 'measure', 'block', 'treatment', 'interaction', 'degree', 'freedom', 'error', 'including', 'block', 'treatment', 'interaction', 'context', 'eliminated', 'ability', 'test', 'however', 'direct', 'marketing', 'context', 'many', 'experimental', 'unit', 'hence', 'many', 'degree', 'freedom', 'error', 'feasible', 'test', 'interaction', 'effect']"
1459,"If you are interested in having an effect explicitly in the model, to account for the deterministic effect of each variable?s level, then that variable is a fixed effect.",DO,170,"['interested', 'effect', 'explicitly', 'model', 'account', 'deterministic', 'effect', 'variable', 'level', 'variable', 'fixed', 'effect']"
1460,The output shows that there is some correlation between the block effect and a few factor effects; this is not unreasonable to expect. The largest correlation is with the factor that only has one level represented in the second phase of the experiment. Canonical Correlations Between the Factors There is 1 Canonical Correlation Greater Than 0.316,DO,347,"['output', 'show', 'correlation', 'block', 'effect', 'factor', 'effect', 'unreasonable', 'expect', 'largest', 'correlation', 'factor', 'ha', 'one', 'level', 'represented', 'second', 'phase', 'experiment', 'canonical', 'correlation', 'factor', '1', 'canonical', 'correlation', 'greater', '0316']"
1461,"The usual approach to experimental design is to use a sparse design, like the main effects only design in the last demonstration, to screen for factors that are active. After the important factors have been identified, you can use a less stringent design to try to identify interactions and nonlinearities. This philosophy is predicated on a notion called effect sparsity, which suggests that: *	only a few factors are likely to be very important. *	pure interactions, that is, interaction terms that are important where neither of their component main effects are important, are unlikely.",DO,589,"['usual', 'approach', 'experimental', 'design', 'use', 'sparse', 'design', 'like', 'main_effect', 'design', 'last', 'demonstration', 'screen', 'factor', 'active', 'important', 'factor', 'identified', 'use', 'le', 'stringent', 'design', 'try', 'identify', 'interaction', 'nonlinearities', 'philosophy', 'predicated', 'notion', 'called', 'effect', 'sparsity', 'suggests', '\tonly', 'factor', 'likely', 'important', '\tpure', 'interaction', 'interaction', 'term', 'important', 'neither', 'component', 'main_effect', 'important', 'unlikely']"
1462,"The blocks that were considered in the last section were restricted to complete blocks; that is, every block had every treatment represented in it. In these examples, you had one factor at two levels, so you could not have had anything less than complete blocks. However, if the treatments consisted of one factor with many levels, or a factorial design too large to fit every treatment into one block, you may have had to abandon this nice complete block structure. What would that do to the experiment and the analysis? One of the nicest properties afforded by complete block designs, or even factorial arrangements of treatments, is orthogonality. Orthogonality means that your contrasts are statistically independent of one another; or all of your contrasts are at right angles to one another. Practically speaking, orthogonality ensures that the analysis that yields, for example, an estimate of the intro APR effect is not affected by the goto APR effect.",DO,961,"['block', 'considered', 'last', 'section', 'restricted', 'complete', 'block', 'every', 'block', 'every', 'treatment', 'represented', 'example', 'one', 'factor', 'two', 'level', 'could', 'anything', 'le', 'complete', 'block', 'however', 'treatment', 'consisted', 'one', 'factor', 'many', 'level', 'factorial', 'design', 'large', 'fit', 'every', 'treatment', 'one', 'block', 'may', 'abandon', 'nice', 'complete', 'block', 'structure', 'would', 'experiment', 'analysis', 'one', 'nicest', 'property', 'afforded', 'complete', 'block', 'design', 'even', 'factorial', 'arrangement', 'treatment', 'orthogonality', 'orthogonality', 'mean', 'contrast', 'statistically', 'independent', 'one', 'another', 'contrast', 'right', 'angle', 'one', 'another', 'practically', 'speaking', 'orthogonality', 'ensures', 'analysis', 'yield', 'example', 'estimate', 'intro', 'apr', 'effect', 'affected', 'goto', 'apr', 'effect']"
1463,"In screening designs, you set the factors at the highest and lowest levels to get the best possible leverage for the response. However, not all factor-response relationships are best represented by a straight line. With only two design points, curvature in a relationship cannot be estimated. A third point, called a center point, is required to test nonlinearity in the response. Of course, there are more possibilities. You can have very high-order polynomial effects that you are trying to detect, but there is always the reality of diminishing returns?you get the most benefit from the first few effects detected. After you detect the big linear effects, you can investigate the quadratic effects. If those models are still not accurate enough, you can continue testing for more complicated effects. When you know you want to test for departures from nonlinearity, you should specify that the factor of interest has three levels so that you have low, medium, and high settings for that factor. If you do not think to test nonlinear effects until after the test is run, you will need to augment an existing design with some runs that include center points.",DO,1159,"['screening', 'design', 'set', 'factor', 'highest', 'lowest', 'level', 'get', 'best', 'possible', 'leverage', 'response', 'however', 'factorresponse', 'relationship', 'best', 'represented', 'straight', 'line', 'two', 'design', 'point', 'curvature', 'relationship', 'cannot', 'estimated', 'third', 'point', 'called', 'center', 'point', 'required', 'test', 'nonlinearity', 'response', 'course', 'possibility', 'highorder', 'polynomial', 'effect', 'trying', 'detect', 'always', 'reality', 'diminishing', 'returnsyou', 'get', 'benefit', 'first', 'effect', 'detected', 'detect', 'big', 'linear', 'effect', 'investigate', 'quadratic', 'effect', 'model', 'still', 'accurate', 'enough', 'continue', 'testing', 'complicated', 'effect', 'know', 'want', 'test', 'departure', 'nonlinearity', 'specify', 'factor', 'interest', 'ha', 'three', 'level', 'low', 'medium', 'high', 'setting', 'factor', 'think', 'test', 'nonlinear', 'effect', 'test', 'run', 'need', 'augment', 'existing', 'design', 'run', 'include', 'center', 'point']"
1464,"In most testing situations, you posit a null hypothesis (usually that the difference of interest does not exist) and then test to find evidence to reject that null hypothesis. Of course, only one of the two hypotheses can be true, but if you knew which one, you would not have to test. Hence, you gather some data, and use that data to make a decision: ?reject the null hypothesis? or ?accept the null hypothesis.? Typically, the hypotheses are constructed such that these decisions are synonymous with ?there is no evidence of a significant difference between groups? or ?there is evidence of a significant difference between groups.?",DO,635,"['testing', 'situation', 'posit', 'null', 'hypothesis', 'usually', 'difference', 'interest', 'doe', 'exist', 'test', 'find', 'evidence', 'reject', 'null', 'hypothesis', 'course', 'one', 'two', 'hypothesis', 'true', 'knew', 'one', 'would', 'test', 'hence', 'gather', 'data', 'use', 'data', 'make', 'decision', 'reject', 'null', 'hypothesis', 'accept', 'null', 'hypothesis', 'typically', 'hypothesis', 'constructed', 'decision', 'synonymous', 'evidence', 'significant', 'difference', 'group', 'evidence', 'significant', 'difference', 'group']"
1465,"To perform a power analysis in the presence of blocks (or even covariates), you need an estimate of how much variability the additional factors explain. For example, if a block factor explains enough variability that your standard errors are all cut in half, then the necessary sample size should be reduced as well. In the context of direct marketing, sample sizes are large and the degrees of freedom lost to blocking are negligible. ?	Traditional experimental design techniques define blocks in two ways, simultaneously: *	The factors, usually nuisance factors, which affect the response of interest but are not, themselves, of interest. *	The factors used to restrict the randomization of experimental units to treatments, which do not interact with treatments. These conditions do not always apply in this context. For example, a block * treatment interaction is evidence that some factor is more effective in one sub-population than another. To detect factors like these may take a larger sample size than ignoring blocks. This is counter-intuitive to practitioners of classical experimental design methodology, but it may be important in your business. For example, month-to-month differences in campaigns might be assumed independent of other factors; risk score differences between individuals might not be. The idea behind this slightly more complicated power analysis is fairly straightforward. Consider two variances: the variance in the analysis variable (?2large) without blocking and the variance in the analysis variable after accounting for block to block variation (?2small). Consider the following ANOVA table: Source df SS MS Block b-1 SSB MSB Error n-b SSE MSE Total n-1 SST",DO,1695,"['perform', 'power', 'analysis', 'presence', 'block', 'even', 'covariates', 'need', 'estimate', 'much', 'variability', 'additional', 'factor', 'explain', 'example', 'block', 'factor', 'explains', 'enough', 'variability', 'standard_error', 'cut', 'half', 'necessary', 'sample_size', 'reduced', 'well', 'context', 'direct', 'marketing', 'sample_size', 'large', 'degree', 'freedom', 'lost', 'blocking', 'negligible', '\ttraditional', 'experimental', 'design', 'technique', 'define', 'block', 'two', 'way', 'simultaneously', '\tthe', 'factor', 'usually', 'nuisance', 'factor', 'affect', 'response', 'interest', 'interest', '\tthe', 'factor', 'used', 'restrict', 'randomization', 'experimental', 'unit', 'treatment', 'interact', 'treatment', 'condition', 'always', 'apply', 'context', 'example', 'block', '', 'treatment', 'interaction', 'evidence', 'factor', 'effective', 'one', 'subpopulation', 'another', 'detect', 'factor', 'like', 'may', 'take', 'larger', 'sample_size', 'ignoring', 'block', 'counterintuitive', 'practitioner', 'classical', 'experimental', 'design', 'methodology', 'may', 'important', 'business', 'example', 'monthtomonth', 'difference', 'campaign', 'might', 'assumed', 'independent', 'factor', 'risk', 'score', 'difference', 'individual', 'might', 'idea', 'behind', 'slightly', 'complicated', 'power', 'analysis', 'fairly', 'straightforward', 'consider', 'two', 'variance', 'variance', 'analysis', 'variable', '2large', 'without', 'blocking', 'variance', 'analysis', 'variable', 'accounting', 'block', 'block', 'variation', '2small', 'consider', 'following', 'anova', 'table', 'source', 'df', 'block', 'b1', 'ssb', 'msb', 'error', 'nb', 'sse', 'mse', 'total', 'n1', 'sst']"
1466,The ONEWAYANOVA statement assumes equal variances between the groups. Notice that a larger standard deviation makes it more difficult to detect the same size difference.,DO,169,"['onewayanova', 'statement', 'assumes', 'equal', 'variance', 'group', 'notice', 'larger', 'standard', 'deviation', 'make', 'difficult', 'detect', 'size', 'difference']"
1467,"In many algorithmic optimality searches, faster is not necessarily better. Choosing a slower search algorithm may result in a more rigorous search of the potential designs, and will usually result in finding a better design. The details of the different search algorithms are in the OPTEX procedure documentation; most practitioners recommend using the slowest algorithm you have time for. Even small desktop computers have enough power to tackle typical design problems with the slower algorithms. As a balance between speed and power, the default setting is the exchange algorithm. Unless the design problem is very large , you should change the search algorithm to modified Federov, by stating METHOD=M_FEDEROV in the GENERATE statement. The modified Federov algorithm is similar to the Federov algorithm but should run much faster. The modified Federov algorithm is one of the candidates that the %MktEx macro considers in its first stage, the algorithm search.",DO,965,"['many', 'algorithmic', 'optimality', 'search', 'faster', 'necessarily', 'better', 'choosing', 'slower', 'search', 'algorithm', 'may', 'result', 'rigorous', 'search', 'potential', 'design', 'usually', 'result', 'finding', 'better', 'design', 'detail', 'different', 'search', 'algorithm', 'optex', 'procedure', 'documentation', 'practitioner', 'recommend', 'using', 'slowest', 'algorithm', 'time', 'even', 'small', 'desktop', 'computer', 'enough', 'power', 'tackle', 'typical', 'design', 'problem', 'slower', 'algorithm', 'balance', 'speed', 'power', 'default', 'setting', 'exchange', 'algorithm', 'unless', 'design', 'problem', 'large', '', 'change', 'search', 'algorithm', 'modified', 'federov', 'stating', 'methodmfederov', 'generate', 'statement', 'modified', 'federov', 'algorithm', 'similar', 'federov', 'algorithm', 'run', 'much', 'faster', 'modified', 'federov', 'algorithm', 'one', 'candidate', 'mktex', 'macro', 'considers', 'first', 'stage', 'algorithm', 'search']"
1468,The %MktEx macro searches over possible designs for a design that is efficient and that satisfies your practical constraints. These constraints can be specified in a restrictions macro. An example follows in the next demonstration. Generating Optimal Designs,DO,258,"['mktex', 'macro', 'search', 'possible', 'design', 'design', 'efficient', 'satisfies', 'practical', 'constraint', 'constraint', 'specified', 'restriction', 'macro', 'example', 'follows', 'next', 'demonstration', 'generating', 'optimal', 'design']"
1469,"It seems reasonable to assume that the response rate to an offer would depend on both rates, simultaneously. For example, everyone might sign up for the low introductory rate card, regardless of goto. If you charge the high introductory rate, however, you may need a low goto rate to entice prospects to respond. A model that only had an intro term and a goto term would not capture this behavior. You need an interaction term to capture the added complexity.",DO,459,"['seems', 'reasonable', 'assume', 'response', 'rate', 'offer', 'would', 'depend', 'rate', 'simultaneously', 'example', 'everyone', 'might', 'sign', 'low', 'introductory', 'rate', 'card', 'regardless', 'goto', 'charge', 'high', 'introductory', 'rate', 'however', 'may', 'need', 'low', 'goto', 'rate', 'entice', 'prospect', 'respond', 'model', 'intro', 'term', 'goto', 'term', 'would', 'capture', 'behavior', 'need', 'interaction', 'term', 'capture', 'added', 'complexity']"
1470,"When you contrast one factor at a time (OFAT) tests with factorially arranged tests, there are several benefits to using the factorial structure. If you consider a block as a factor for the time being, it is easy to see that a complete block test is like a factorially arranged test, in that every level of every factor of interest is represented at every level of every other factor.",DO,384,"['contrast', 'one', 'factor', 'time', 'ofat', 'test', 'factorially', 'arranged', 'test', 'several', 'benefit', 'using', 'factorial', 'structure', 'consider', 'block', 'factor', 'time', 'easy', 'see', 'complete', 'block', 'test', 'like', 'factorially', 'arranged', 'test', 'every', 'level', 'every', 'factor', 'interest', 'represented', 'every', 'level', 'every', 'factor']"
1471,"If you have a favorite optimality criterion, then the assessment of different designs is trivial. Whichever design optimizes your criterion is the design of choice. However, faced with so many options, it may be daunting to choose a favorite criterion. There are tools to help you choose, or at least to help you present the different designs to the members of your organization that will use them. *	Using the GLM procedure, it is possible to get a report that details the aliasing that takes place with different designs. This may only be helpful with experiments that use mostly continuous factors. *	Assigning sample size in this context is non-trivial, and there are several different points to consider. *	There is an example in the following demonstration that shows how to get different optimality measures for different designs.",DO,837,"['favorite', 'optimality', 'criterion', 'assessment', 'different', 'design', 'trivial', 'whichever', 'design', 'optimizes', 'criterion', 'design', 'choice', 'however', 'faced', 'many', 'option', 'may', 'daunting', 'choose', 'favorite', 'criterion', 'tool', 'help', 'choose', 'least', 'help', 'present', 'different', 'design', 'member', 'organization', 'use', '\tusing', 'glm', 'procedure', 'possible', 'get', 'report', 'detail', 'aliasing', 'take', 'place', 'different', 'design', 'may', 'helpful', 'experiment', 'use', 'mostly', 'continuous', 'factor', '\tassigning', 'sample_size', 'context', 'nontrivial', 'several', 'different', 'point', 'consider', '\tthere', 'example', 'following', 'demonstration', 'show', 'get', 'different', 'optimality', 'measure', 'different', 'design']"
1472,"In an experiment, the variable that measures the outcome of interest is called the response variable. It is also known as the dependent variable. A factor is an independent or predictor variable that is a possible source of variation in the response variable. An effect is the relationship between a factor and a response. A factor level is a particular value of a factor. In other words, the specific types or amounts of the factor used in the experiment. A treatment is a combination of factor levels used in the experiment. This is sometimes also referred to as the condition. An experimental unit is the smallest object to which a treatment is applied. It is the smallest part of the experimental material where any two experimental units can receive different treatments. A replication occurs when you assign more than one experimental unit to a treatment. Internal to an organization, you may have your own jargon, but these words are the ones you are likely to see in any articles you might read. In this context, experimental units could be a household or an individual. For example, a credit card offer can be sent to an individual; there may be several individuals per household. A mortgage offer can only be made once per household. Replication is often difficult in manufacturing or agriculture, because the experimental unit may be a batch of TVs, or an acre of corn. But in this context, replication is going to be par for the course.",DO,1448,"['experiment', 'variable', 'measure', 'outcome', 'interest', 'called', 'response_variable', 'also', 'known', 'dependent', 'variable', 'factor', 'independent', 'predictor_variable', 'possible', 'source', 'variation', 'response_variable', 'effect', 'relationship', 'factor', 'response', 'factor', 'level', 'particular', 'value', 'factor', 'word', 'specific', 'type', 'amount', 'factor', 'used', 'experiment', 'treatment', 'combination', 'factor', 'level', 'used', 'experiment', 'sometimes', 'also', 'referred', 'condition', 'experimental', 'unit', 'smallest', 'object', 'treatment', 'applied', 'smallest', 'part', 'experimental', 'material', 'two', 'experimental', 'unit', 'receive', 'different', 'treatment', 'replication', 'occurs', 'assign', 'one', 'experimental', 'unit', 'treatment', 'internal', 'organization', 'may', 'jargon', 'word', 'one', 'likely', 'see', 'article', 'might', 'read', 'context', 'experimental', 'unit', 'could', 'household', 'individual', 'example', 'credit', 'card', 'offer', 'sent', 'individual', 'may', 'several', 'individual', 'per', 'household', 'mortgage', 'offer', 'made', 'per', 'household', 'replication', 'often', 'difficult', 'manufacturing', 'agriculture', 'experimental', 'unit', 'may', 'batch', 'tv', 'acre', 'corn', 'context', 'replication', 'going', 'par', 'course']"
1473,"The variance of a distribution affects the power as well. This does not explicitly show up in the response rate example because responder counts typically follow a binomial distribution, and the variance of a binomial random variable is a function of the success rate.",DO,268,"['variance', 'distribution', 'affect', 'power', 'well', 'doe', 'explicitly', 'show', 'response', 'rate', 'example', 'responder', 'count', 'typically', 'follow', 'binomial', 'distribution', 'variance', 'binomial', 'random', 'variable', 'function', 'success', 'rate']"
1474,"The GLM procedure has a RANDOM statement, but that is not what you would use in the absence of a carefully balanced experiment. It is recommended that you use the MIXED procedure if you have random or random and fixed effects. If you are interested in random effects, there is a three- day course titled Mixed Models Analyses Using the SAS System. The demonstration that follows is meant to show what sort of analyses can be done with the MIXED procedure; it is clearly ambitious to expect that this would cover much of the specifics. Random Blocks",DO,548,"['glm', 'procedure', 'ha', 'random', 'statement', 'would', 'use', 'absence', 'carefully', 'balanced', 'experiment', 'recommended', 'use', 'mixed', 'procedure', 'random', 'random', 'fixed', 'effect', 'interested', 'random', 'effect', 'three', 'day', 'course', 'titled', 'mixed', 'model', 'analysis', 'using', 'sa', 'system', 'demonstration', 'follows', 'meant', 'show', 'sort', 'analysis', 'done', 'mixed', 'procedure', 'clearly', 'ambitious', 'expect', 'would', 'cover', 'much', 'specific', 'random', 'block']"
1475,"Certain higher-order interaction effects cannot be estimated with a fractional factorial design. With orthogonal arrays or optimality-criterion based designs, the confounding cannot be compactly expressed, but it is still there. By customizing and augmenting a design, you may be able to undo some of the aliasing in a small experiment; that is, you can permit the estimation of a term that was not explicitly estimable in your original design. Other purposes of augmenting designs include *	adding points to estimate a response surface *	adding points to break confounding *	adding points to test for trend effects *	adding points to discriminate between candidate models. There are many techniques for augmenting designs. A few traditional techniques are discussed in the following slides, and the practice of adding points is demonstrated later. A typical approach includes using several factors at two levels each and then adding a center point to detect any departure from the assumption of linearity.",DO,1006,"['certain', 'higherorder', 'interaction', 'effect', 'cannot', 'estimated', 'fractional', 'factorial', 'design', 'orthogonal', 'array', 'optimalitycriterion', 'based', 'design', 'confounding', 'cannot', 'compactly', 'expressed', 'still', 'customizing', 'augmenting', 'design', 'may', 'able', 'undo', 'aliasing', 'small', 'experiment', 'permit', 'estimation', 'term', 'wa', 'explicitly', 'estimable', 'original', 'design', 'purpose', 'augmenting', 'design', 'include', '\tadding', 'point', 'estimate', 'response', 'surface', '\tadding', 'point', 'break', 'confounding', '\tadding', 'point', 'test', 'trend', 'effect', '\tadding', 'point', 'discriminate', 'candidate', 'model', 'many', 'technique', 'augmenting', 'design', 'traditional', 'technique', 'discussed', 'following', 'slide', 'practice', 'adding', 'point', 'demonstrated', 'later', 'typical', 'approach', 'includes', 'using', 'several', 'factor', 'two', 'level', 'adding', 'center', 'point', 'detect', 'departure', 'assumption', 'linearity']"
1476,"There are many features in a catalog that could be considered in an experiment. Easy to change factors include inserts slipped in to the catalog, or stickers applied to the outside. Hard to change factors include the overall design of the catalog, or the pictures printed on them. Consider a catalog where there are two possible cover photos, two possible pieces of advertising copy on the catalog, and a sticker that can either be applied or left off. It should be clear that this is a 2x2x2 or 23 factorial experiment, because there are three factors at two levels each.",DO,572,"['many', 'feature', 'catalog', 'could', 'considered', 'experiment', 'easy', 'change', 'factor', 'include', 'insert', 'slipped', 'catalog', 'sticker', 'applied', 'outside', 'hard', 'change', 'factor', 'include', 'overall', 'design', 'catalog', 'picture', 'printed', 'consider', 'catalog', 'two', 'possible', 'cover', 'photo', 'two', 'possible', 'piece', 'advertising', 'copy', 'catalog', 'sticker', 'either', 'applied', 'left', 'clear', '2x2x2', '23', 'factorial', 'experiment', 'three', 'factor', 'two', 'level']"
1477,"In traditional experimental design, defining a blocking factor as a block instead of a factor could explain much of the variability in the data without using many degrees of freedom. Again, in direct marketing context, the extent to which that statement is true depends on many factors.",DO,286,"['traditional', 'experimental', 'design', 'defining', 'blocking', 'factor', 'block', 'instead', 'factor', 'could', 'explain', 'much', 'variability', 'data', 'without', 'using', 'many', 'degree', 'freedom', 'direct', 'marketing', 'context', 'extent', 'statement', 'true', 'depends', 'many', 'factor']"
1478,"Aside from having good statistical properties, a balanced and orthogonal design makes it easy to allocate sample size to the different treatments. With restrictions in place a design might not be balanced or orthogonal, but that does not change your sample size requirements. The results from the %MktEval macro include a table that can help you plan how to allocate mail or phone call volume. By default the macro reports on the number of treatments at each level of each factor, at each combination of levels for each pair of factors, and the N-way classification. The FREQS= option enables you to specify what frequencies are of interest. The following code requests solely main effects frequencies. Recall twenty is the data set with the 20-run design with restrictions. %mkteval(data=twenty, freqs=1); Partial Output Summary of Frequencies There are 2 Canonical Correlations Greater Than 0.316 * - Indicates Unequal Frequencies",DO,932,"['aside', 'good', 'statistical', 'property', 'balanced', 'orthogonal', 'design', 'make', 'easy', 'allocate', 'sample_size', 'different', 'treatment', 'restriction', 'place', 'design', 'might', 'balanced', 'orthogonal', 'doe', 'change', 'sample_size', 'requirement', 'result', 'mkteval', 'macro', 'include', 'table', 'help', 'plan', 'allocate', 'mail', 'phone', 'call', 'volume', 'default', 'macro', 'report', 'number', 'treatment', 'level', 'factor', 'combination', 'level', 'pair', 'factor', 'nway', 'classification', 'freqs', 'option', 'enables', 'specify', 'frequency', 'interest', 'following', 'code', 'request', 'solely', 'main_effect', 'frequency', 'recall', 'twenty', 'data_set', '20run', 'design', 'restriction', 'mktevaldatatwenty', 'freqs1', 'partial', 'output', 'summary', 'frequency', '2', 'canonical', 'correlation', 'greater', '0316', '', '', 'indicates', 'unequal', 'frequency']"
1479,"The response rates and variances seem to be on the order of the assumptions in the last demonstration, so these sample sizes should be sufficient to detect the effects of interest. Unfortunately, the Balance Transfer (BT) rate seems to have been a little lower than anticipated, which may impact your ability to detect small effects in BT amount. The MEANS Procedure",DO,366,"['response', 'rate', 'variance', 'seem', 'order', 'assumption', 'last', 'demonstration', 'sample_size', 'sufficient', 'detect', 'effect', 'interest', 'unfortunately', 'balance', 'transfer', 'bt', 'rate', 'seems', 'little', 'lower', 'anticipated', 'may', 'impact', 'ability', 'detect', 'small', 'effect', 'bt', 'amount', 'mean', 'procedure']"
1480,"If you have a favorite optimality criterion, then the assessment of different designs is trivial. Whichever design optimizes your criterion is the design of choice. However, faced with so many options, it may be daunting to choose a favorite criterion. There are tools to help you choose, or at least to help you present the different designs to the members of your organization that will use them. *	Using the GLM procedure, it is possible to get a report that details the aliasing that takes place with different designs. This may only be helpful with experiments that use mostly continuous factors. *	Assigning sample size in this context is non-trivial, and there are several different points to consider. *	There is an example in the following demonstration that shows how to get different optimality measures for different designs.",DO,837,"['favorite', 'optimality', 'criterion', 'assessment', 'different', 'design', 'trivial', 'whichever', 'design', 'optimizes', 'criterion', 'design', 'choice', 'however', 'faced', 'many', 'option', 'may', 'daunting', 'choose', 'favorite', 'criterion', 'tool', 'help', 'choose', 'least', 'help', 'present', 'different', 'design', 'member', 'organization', 'use', '\tusing', 'glm', 'procedure', 'possible', 'get', 'report', 'detail', 'aliasing', 'take', 'place', 'different', 'design', 'may', 'helpful', 'experiment', 'use', 'mostly', 'continuous', 'factor', '\tassigning', 'sample_size', 'context', 'nontrivial', 'several', 'different', 'point', 'consider', '\tthere', 'example', 'following', 'demonstration', 'show', 'get', 'different', 'optimality', 'measure', 'different', 'design']"
1481,"A completely randomized design would ignore the blocking factor. If you suspect that List is a potential source of variation, you would certainly prefer the blocked design to the non-blocked, completely randomized design. Notice, also, that the blocked design would do a better job of helping you detect any block by treatment interactions. Sample Size Determination in the Presence of Blocks",DO,392,"['completely', 'randomized', 'design', 'would', 'ignore', 'blocking', 'factor', 'suspect', 'list', 'potential', 'source', 'variation', 'would', 'certainly', 'prefer', 'blocked', 'design', 'nonblocked', 'completely', 'randomized', 'design', 'notice', 'also', 'blocked', 'design', 'would', 'better', 'job', 'helping', 'detect', 'block', 'treatment', 'interaction', 'sample_size', 'determination', 'presence', 'block']"
1482,"Factors are typically features that you have control over. Features of the mail piece, or of the telemarketing script are factors. Of course, there are some sources of variability in the response metric that you will not have control over. You have no control over the number of points that an individual has on a reward credit card; you have no control over where someone lives, or how recently they were mailed. In a sense, those features are attributes of the individual, not the offer. Features that you cannot control might be considered a nuisance?there is no (practical) way for you to control them, but they may impact the response or spend behavior of the individuals in your test. In order to account for the variability due to these factors, and perhaps even capitalize on it, you need to account for these factors in your analysis.",DO,843,"['factor', 'typically', 'feature', 'control', 'feature', 'mail', 'piece', 'telemarketing', 'script', 'factor', 'course', 'source', 'variability', 'response', 'metric', 'control', 'control', 'number', 'point', 'individual', 'ha', 'reward', 'credit', 'card', 'control', 'someone', 'life', 'recently', 'mailed', 'sense', 'feature', 'attribute', 'individual', 'offer', 'feature', 'cannot', 'control', 'might', 'considered', 'nuisancethere', 'practical', 'way', 'control', 'may', 'impact', 'response', 'spend', 'behavior', 'individual', 'test', 'order', 'account', 'variability', 'due', 'factor', 'perhaps', 'even', 'capitalize', 'need', 'account', 'factor', 'analysis']"
1483,"In many algorithmic optimality searches, faster is not necessarily better. Choosing a slower search algorithm may result in a more rigorous search of the potential designs, and will usually result in finding a better design. The details of the different search algorithms are in the OPTEX procedure documentation; most practitioners recommend using the slowest algorithm you have time for. Even small desktop computers have enough power to tackle typical design problems with the slower algorithms. As a balance between speed and power, the default setting is the exchange algorithm. Unless the design problem is very large , you should change the search algorithm to modified Federov, by stating METHOD=M_FEDEROV in the GENERATE statement. The modified Federov algorithm is similar to the Federov algorithm but should run much faster. The modified Federov algorithm is one of the candidates that the %MktEx macro considers in its first stage, the algorithm search.",DO,965,"['many', 'algorithmic', 'optimality', 'search', 'faster', 'necessarily', 'better', 'choosing', 'slower', 'search', 'algorithm', 'may', 'result', 'rigorous', 'search', 'potential', 'design', 'usually', 'result', 'finding', 'better', 'design', 'detail', 'different', 'search', 'algorithm', 'optex', 'procedure', 'documentation', 'practitioner', 'recommend', 'using', 'slowest', 'algorithm', 'time', 'even', 'small', 'desktop', 'computer', 'enough', 'power', 'tackle', 'typical', 'design', 'problem', 'slower', 'algorithm', 'balance', 'speed', 'power', 'default', 'setting', 'exchange', 'algorithm', 'unless', 'design', 'problem', 'large', '', 'change', 'search', 'algorithm', 'modified', 'federov', 'stating', 'methodmfederov', 'generate', 'statement', 'modified', 'federov', 'algorithm', 'similar', 'federov', 'algorithm', 'run', 'much', 'faster', 'modified', 'federov', 'algorithm', 'one', 'candidate', 'mktex', 'macro', 'considers', 'first', 'stage', 'algorithm', 'search']"
1484,"Invoke the OPTEX procedure, specifying that the only candidate points for inclusion in the design are those points that are currently in the candidate data set. In addition, you can request that the OPTEX procedure use the modified Fedorov search algorithm, which is one of the slowest but also quite meticulous. You can specify interactions of interest in the MODEL statement; in order to compare this design to the one from %MktEx, you should not specify any interactions right now. proc optex data=candidate; class mailpc--product; model mailpc--product; generate keep=10 method=m_fedorov iter=200; examine design; run; quit; ?	The algorithmic design searches are initialized randomly; this means that you can run the same code two different times and potentially get two different designs. If this is a concern, you can force the searches to start with the same random seed by specifying using the SEED= option on the PROC OPTEX statement. This runs quite quickly, even though you requested 200 iterations of the slowest optimization algorithm. In fact, you might look at the output, which begins with the results of the ten best designs, and want to try a few more iterations. Because the first three designs have the same D- efficiency, it is doubtful that more iterations will help . The OPTEX Procedure",DO,1310,"['invoke', 'optex', 'procedure', 'specifying', 'candidate', 'point', 'inclusion', 'design', 'point', 'currently', 'candidate', 'data_set', 'addition', 'request', 'optex', 'procedure', 'use', 'modified', 'fedorov', 'search', 'algorithm', 'one', 'slowest', 'also', 'quite', 'meticulous', 'specify', 'interaction', 'interest', 'model_statement', 'order', 'compare', 'design', 'one', 'mktex', 'specify', 'interaction', 'right', 'proc', 'optex', 'datacandidate', 'class', 'mailpcproduct', 'model', 'mailpcproduct', 'generate', 'keep10', 'methodmfedorov', 'iter200', 'examine', 'design', 'run', 'quit', '\tthe', 'algorithmic', 'design', 'search', 'initialized', 'randomly', 'mean', 'run', 'code', 'two', 'different', 'time', 'potentially', 'get', 'two', 'different', 'design', 'concern', 'force', 'search', 'start', 'random', 'seed', 'specifying', 'using', 'seed', 'option', 'proc', 'optex', 'statement', 'run', 'quite', 'quickly', 'even', 'though', 'requested', '200', 'iteration', 'slowest', 'optimization', 'algorithm', 'fact', 'might', 'look', 'output', 'begin', 'result', 'ten', 'best', 'design', 'want', 'try', 'iteration', 'first', 'three', 'design', 'efficiency', 'doubtful', 'iteration', 'help', '', 'optex', 'procedure']"
1485,"It is worth noting that the name ?optimal? designs may be misleading. The designs sought in this section are not necessarily guaranteed to be optimal, but they are meant to be efficient in the face of practical constraints on traditional factorial experiments. The author of the %MktEx macro, Warren Kuhfeld, reserves the word ?optimal? for designs that have 100% efficiency or that he can prove are as efficient as possible subject to constraints. The jargon ?optimal designs? or ?optimum designs? is generally understood to mean designs found by some algorithm in an attempt to optimize some criterion. The use of the term ?optimal? should not be construed to mean that these designs have been proven to be the absolute best of all possible designs.",DO,751,"['worth', 'noting', 'name', 'optimal', 'design', 'may', 'misleading', 'design', 'sought', 'section', 'necessarily', 'guaranteed', 'optimal', 'meant', 'efficient', 'face', 'practical', 'constraint', 'traditional', 'factorial', 'experiment', 'author', 'mktex', 'macro', 'warren', 'kuhfeld', 'reserve', 'word', 'optimal', 'design', '100', 'efficiency', 'prove', 'efficient', 'possible', 'subject', 'constraint', 'jargon', 'optimal', 'design', 'optimum', 'design', 'generally', 'understood', 'mean', 'design', 'found', 'algorithm', 'attempt', 'optimize', 'criterion', 'use', 'term', 'optimal', 'construed', 'mean', 'design', 'proven', 'absolute', 'best', 'possible', 'design']"
1486,The output shows that there is some correlation between the block effect and a few factor effects; this is not unreasonable to expect. The largest correlation is with the factor that only has one level represented in the second phase of the experiment. Canonical Correlations Between the Factors There is 1 Canonical Correlation Greater Than 0.316,DO,347,"['output', 'show', 'correlation', 'block', 'effect', 'factor', 'effect', 'unreasonable', 'expect', 'largest', 'correlation', 'factor', 'ha', 'one', 'level', 'represented', 'second', 'phase', 'experiment', 'canonical', 'correlation', 'factor', '1', 'canonical', 'correlation', 'greater', '0316']"
1487,"The concept of power is central to good experimental design sample size determination. There is a complicated relationship between the power of a test, the significance level of the test, and the particular hypotheses that you are testing.",DO,239,"['concept', 'power', 'central', 'good', 'experimental', 'design', 'sample_size', 'determination', 'complicated', 'relationship', 'power', 'test', 'significance', 'level', 'test', 'particular', 'hypothesis', 'testing']"
1488,"The %MktEx macro has an extensive catalog of orthogonal arrays available for searching. This has two practical benefits for experimental design practitioners: *	If a design that satisfies your constraints already exists, you do not spend time trying to generate a design; the %MktEx macro simply reports it. (In the log above, you can see that searches were performed. This is because the orthogonal array catalog does not know about interactions.) *	You do not need to check a catalog of known designs, and then check for suitable fractional factorials, and then move on to more extreme measures. You posit your problem, and the macro simulates the steps that someone with considerable expertise in experimental design would take to find a good design.",DO,753,"['mktex', 'macro', 'ha', 'extensive', 'catalog', 'orthogonal', 'array', 'available', 'searching', 'ha', 'two', 'practical', 'benefit', 'experimental', 'design', 'practitioner', '\tif', 'design', 'satisfies', 'constraint', 'already', 'exists', 'spend', 'time', 'trying', 'generate', 'design', 'mktex', 'macro', 'simply', 'report', 'log', 'see', 'search', 'performed', 'orthogonal', 'array', 'catalog', 'doe', 'know', 'interaction', '\tyou', 'need', 'check', 'catalog', 'known', 'design', 'check', 'suitable', 'fractional', 'factorial', 'move', 'extreme', 'measure', 'posit', 'problem', 'macro', 'simulates', 'step', 'someone', 'considerable', 'expertise', 'experimental', 'design', 'would', 'take', 'find', 'good', 'design']"
1489,"*	the notion of controlling for external conditions. The focus of this course is bridging the world of engineers and psychologists to the world of the banker and the direct marketer. In many spheres of influence, testing is commonplace, for example, manufacturing, the pharmaceutical industry, and agriculture. The ideas that are central to good testing are important regardless of industry. You can take the important ideas and apply them to your own tests.",DO,458,"['\tthe', 'notion', 'controlling', 'external', 'condition', 'focus', 'course', 'bridging', 'world', 'engineer', 'psychologist', 'world', 'banker', 'direct', 'marketer', 'many', 'sphere', 'influence', 'testing', 'commonplace', 'example', 'manufacturing', 'pharmaceutical', 'industry', 'agriculture', 'idea', 'central', 'good', 'testing', 'important', 'regardless', 'industry', 'take', 'important', 'idea', 'apply', 'test']"
1490,"Power does not just depend on the alternative hypothesis. It also depends on the sample size. Adding to your sample will change the decision rule, the distributions under the null and alternative hypotheses, and the power.",DO,222,"['power', 'doe', 'depend', 'alternative', 'hypothesis', 'also', 'depends', 'sample_size', 'adding', 'sample', 'change', 'decision', 'rule', 'distribution', 'null', 'alternative', 'hypothesis', 'power']"
1491,"In the last section, blocks were considered a source of a deterministic shift in the response variable, or a source of random variation. This distinction becomes important in the analysis of the data; the former is a fixed effect, and can be treated as any other factor. The latter is a random effect, and should be handled differently. With a random effect, the analysis typically yields a model to capture the deterministic effects, and variance components due to the random effects and noise.",DO,495,"['last', 'section', 'block', 'considered', 'source', 'deterministic', 'shift', 'response_variable', 'source', 'random', 'variation', 'distinction', 'becomes', 'important', 'analysis', 'data', 'former', 'fixed', 'effect', 'treated', 'factor', 'latter', 'random', 'effect', 'handled', 'differently', 'random', 'effect', 'analysis', 'typically', 'yield', 'model', 'capture', 'deterministic', 'effect', 'variance', 'component', 'due', 'random', 'effect', 'noise']"
1492,"Interpreting this plot, one might state that the introductory rate only has a dramatic effect in the presence of the higher goto offer. Of course, you can create the plot with the goto rate on the x- axis, if that would be easier to explain. In the presence of an interaction, the important point to remember is that there is no sensible way to discuss the effect of any of the main effects involved in that interaction. In this example, there is no quantity that describes the effect of the intro rate on response?you need to know the goto rate before you can discuss the effect of changing the intro rate, because that determines which of the two lines, in the plot above, you would focus on. ?	The plot also indicates an alternative method of parameterizing the model, or even reporting the results. Instead of discussing main effects and interactions, it may be easier to explain results with a different parameterization; for example, nesting the effect of the goto rate change within the intro rate change. Two Factors at Two Levels Each",DO,1043,"['interpreting', 'plot', 'one', 'might', 'state', 'introductory', 'rate', 'ha', 'dramatic', 'effect', 'presence', 'higher', 'goto', 'offer', 'course', 'create', 'plot', 'goto', 'rate', 'x', 'axis', 'would', 'easier', 'explain', 'presence', 'interaction', 'important', 'point', 'remember', 'sensible', 'way', 'discus', 'effect', 'main_effect', 'involved', 'interaction', 'example', 'quantity', 'describes', 'effect', 'intro', 'rate', 'responseyou', 'need', 'know', 'goto', 'rate', 'discus', 'effect', 'changing', 'intro', 'rate', 'determines', 'two', 'line', 'plot', 'would', 'focus', '\tthe', 'plot', 'also', 'indicates', 'alternative', 'method', 'parameterizing', 'model', 'even', 'reporting', 'result', 'instead', 'discussing', 'main_effect', 'interaction', 'may', 'easier', 'explain', 'result', 'different', 'parameterization', 'example', 'nesting', 'effect', 'goto', 'rate', 'change', 'within', 'intro', 'rate', 'change', 'two', 'factor', 'two', 'level']"
1493,"The focus of this course is the technical aspects of improved testing techniques?what makes them better than other techniques, examples of how to use them, and caveats to avoid misusing them. These tests do not take place in a vacuum; while there may only be a few individuals involved in any given test's design and analysis cycle, they are set in the expectations of the entire organization. For example, your business may be broken into three groups: Management The management group controls the general direction of the organization. This direction probably involves increasing this financial figure, or decreasing that one. Those financials relate directly to the kinds of metrics that you can analyze as the response variables in these tests. If (corporate level or marketing group level) management has campaign strategies in mind to achieve those goals, that will suggest factors of interest. Factors, features of offers that you can control, are only part of the story. These strategies may also point you to attributes of individuals that will also affect the responses of interest. These attributes, if known a priori, can be used in the designs as blocks or covariates. These attributes, indicated by the campaign strategy, as well as features indicated by subject-matter expertise (they are, after all, your customers) suggest a population or populations of interest as a focal point for the tests. Management has control over a considerable portion of these decisions, which you can lump into the ""what to do"" category. Operations The operations group is in charge of ""how to do it."" At the end of the day, it is their responsibility to apply the right design, at the right time, to the right population. They may or may not be responsible for deciding which design is the right design; they are responsible for turning the test on paper into results in the database. Analytics The analytics group, then, is responsible for ?what does it mean?? They presumably had a hand in the design of the test, and will be in charge of sorting out the results. Together, these groups can take the results of a test and determine (1) what next steps are merited on the basis of the results and (2) what else they want to test, in the light of the present results. If any of the analytics team is in a modeling group, they have probably started dreaming of the ultimate goal?one to one marketing, where the offer that is sent to an individual is the offer that you have reason to believe is the one to which they are most likely to respond.",DO,2540,"['focus', 'course', 'technical', 'aspect', 'improved', 'testing', 'techniqueswhat', 'make', 'better', 'technique', 'example', 'use', 'caveat', 'avoid', 'misusing', 'test', 'take', 'place', 'vacuum', 'may', 'individual', 'involved', 'given', 'test', 'design', 'analysis', 'cycle', 'set', 'expectation', 'entire', 'organization', 'example', 'business', 'may', 'broken', 'three', 'group', 'management', 'management', 'group', 'control', 'general', 'direction', 'organization', 'direction', 'probably', 'involves', 'increasing', 'financial', 'figure', 'decreasing', 'one', 'financials', 'relate', 'directly', 'kind', 'metric', 'analyze', 'response_variable', 'test', 'corporate', 'level', 'marketing', 'group', 'level', 'management', 'ha', 'campaign', 'strategy', 'mind', 'achieve', 'goal', 'suggest', 'factor', 'interest', 'factor', 'feature', 'offer', 'control', 'part', 'story', 'strategy', 'may', 'also', 'point', 'attribute', 'individual', 'also', 'affect', 'response', 'interest', 'attribute', 'known', 'priori', 'used', 'design', 'block', 'covariates', 'attribute', 'indicated', 'campaign', 'strategy', 'well', 'feature', 'indicated', 'subjectmatter', 'expertise', 'customer', 'suggest', 'population', 'population', 'interest', 'focal', 'point', 'test', 'management', 'ha', 'control', 'considerable', 'portion', 'decision', 'lump', 'category', 'operation', 'operation', 'group', 'charge', 'end', 'day', 'responsibility', 'apply', 'right', 'design', 'right', 'time', 'right', 'population', 'may', 'may', 'responsible', 'deciding', 'design', 'right', 'design', 'responsible', 'turning', 'test', 'paper', 'result', 'database', 'analytics', 'analytics', 'group', 'responsible', 'doe', 'mean', 'presumably', 'hand', 'design', 'test', 'charge', 'sorting', 'result', 'together', 'group', 'take', 'result', 'test', 'determine', '1', 'next', 'step', 'merited', 'basis', 'result', '2', 'else', 'want', 'test', 'light', 'present', 'result', 'analytics', 'team', 'modeling', 'group', 'probably', 'started', 'dreaming', 'ultimate', 'goalone', 'one', 'marketing', 'offer', 'sent', 'individual', 'offer', 'reason', 'believe', 'one', 'likely', 'respond']"
1494,"Among the many complications that arise in real world situations are *	restrictions on number of unique treatments, *	restrictions on combinations of factors, and/or *	different numbers of levels for each factor.",DO,212,"['among', 'many', 'complication', 'arise', 'real', 'world', 'situation', '\trestrictions', 'number', 'unique', 'treatment', '\trestrictions', 'combination', 'factor', 'andor', '\tdifferent', 'number', 'level', 'factor']"
1495,"The technical definitions for D-, A-, and G-efficiency are in the online documentation. Unless you are fairly comfortable with matrix algebra, the technical definitions might not be very enlightening. The general idea is that they compare a function of the optimality criterion in question to the theoretical ideal value, calculated on a (usually non-existent) orthogonal design of the same size. It is safest to compare these efficiencies to one another, rather than getting too concerned with the actual values. The average prediction standard error is the square root of the average variance for prediction over the set of candidate points. That is, for every treatment (record) in the candidate set, you could calculate a standard error of prediction (assuming the error variance was 1). For a treatment x? and a design X, this is technically x?(X?X)-1x, and if you average that over all of the treatments x? in the candidate set, you have the average prediction variance. Taking the square root yields the average prediction standard error. This is the quantity optimized by the I-optimality criterion. Comparing Optimal Designs (Self-Study)",DO,1146,"['technical', 'definition', 'gefficiency', 'online', 'documentation', 'unless', 'fairly', 'comfortable', 'matrix', 'algebra', 'technical', 'definition', 'might', 'enlightening', 'general', 'idea', 'compare', 'function', 'optimality', 'criterion', 'question', 'theoretical', 'ideal', 'value', 'calculated', 'usually', 'nonexistent', 'orthogonal', 'design', 'size', 'safest', 'compare', 'efficiency', 'one', 'another', 'rather', 'getting', 'concerned', 'actual', 'value', 'average', 'prediction', 'standard_error', 'square', 'root', 'average', 'variance', 'prediction', 'set', 'candidate', 'point', 'every', 'treatment', 'record', 'candidate', 'set', 'could', 'calculate', 'standard_error', 'prediction', 'assuming', 'error', 'variance', 'wa', '1', 'treatment', 'x', 'design', 'x', 'technically', 'xxx1x', 'average', 'treatment', 'x', 'candidate', 'set', 'average', 'prediction', 'variance', 'taking', 'square', 'root', 'yield', 'average', 'prediction', 'standard_error', 'quantity', 'optimized', 'ioptimality', 'criterion', 'comparing', 'optimal', 'design', 'selfstudy']"
1496,"Familiarity with the one-way, k-level analysis naturally leads to a temptation to consider every test in those terms. If you need to know about intro rate, design an intro rate test. If you need to know about goto, arrange for a separate goto test. Duration is another test. This kind of testing is known as One Factor at a Time, or OFAT, testing. OFAT testing?s attractiveness hinges on the fact that it is easy to interpret and explain. Their unattractive features can be quite daunting. OFAT results are only valid if you assume *	no interactions between any factors, or *	you will have all of the other factors fixed for the foreseeable future. Neither of these is practically feasible, which means you need a more robust testing methodology.",DO,746,"['familiarity', 'oneway', 'klevel', 'analysis', 'naturally', 'lead', 'temptation', 'consider', 'every', 'test', 'term', 'need', 'know', 'intro', 'rate', 'design', 'intro', 'rate', 'test', 'need', 'know', 'goto', 'arrange', 'separate', 'goto', 'test', 'duration', 'another', 'test', 'kind', 'testing', 'known', 'one', 'factor', 'time', 'ofat', 'testing', 'ofat', 'testing', 'attractiveness', 'hinge', 'fact', 'easy', 'interpret', 'explain', 'unattractive', 'feature', 'quite', 'daunting', 'ofat', 'result', 'valid', 'assume', '\tno', 'interaction', 'factor', '\tyou', 'factor', 'fixed', 'foreseeable', 'future', 'neither', 'practically', 'feasible', 'mean', 'need', 'robust', 'testing', 'methodology']"
1497,"A completely randomized design would ignore the blocking factor. If you suspect that List is a potential source of variation, you would certainly prefer the blocked design to the non-blocked, completely randomized design. Notice, also, that the blocked design would do a better job of helping you detect any block by treatment interactions. Sample Size Determination in the Presence of Blocks",DO,392,"['completely', 'randomized', 'design', 'would', 'ignore', 'blocking', 'factor', 'suspect', 'list', 'potential', 'source', 'variation', 'would', 'certainly', 'prefer', 'blocked', 'design', 'nonblocked', 'completely', 'randomized', 'design', 'notice', 'also', 'blocked', 'design', 'would', 'better', 'job', 'helping', 'detect', 'block', 'treatment', 'interaction', 'sample_size', 'determination', 'presence', 'block']"
1498,"You choose a particular fraction, and by definition this forces certain contrasts to be identical. This phenomenon is referred to as confounding. You might say ABC is confounded with the intercept.",DO,197,"['choose', 'particular', 'fraction', 'definition', 'force', 'certain', 'contrast', 'identical', 'phenomenon', 'referred', 'confounding', 'might', 'say', 'abc', 'confounded', 'intercept']"
1499,"The GLM procedure has a RANDOM statement, but that is not what you would use in the absence of a carefully balanced experiment. It is recommended that you use the MIXED procedure if you have random or random and fixed effects. If you are interested in random effects, there is a three- day course titled Mixed Models Analyses Using the SAS System. The demonstration that follows is meant to show what sort of analyses can be done with the MIXED procedure; it is clearly ambitious to expect that this would cover much of the specifics. Random Blocks",DO,548,"['glm', 'procedure', 'ha', 'random', 'statement', 'would', 'use', 'absence', 'carefully', 'balanced', 'experiment', 'recommended', 'use', 'mixed', 'procedure', 'random', 'random', 'fixed', 'effect', 'interested', 'random', 'effect', 'three', 'day', 'course', 'titled', 'mixed', 'model', 'analysis', 'using', 'sa', 'system', 'demonstration', 'follows', 'meant', 'show', 'sort', 'analysis', 'done', 'mixed', 'procedure', 'clearly', 'ambitious', 'expect', 'would', 'cover', 'much', 'specific', 'random', 'block']"
1500,"There are many features in a catalog that could be considered in an experiment. Easy to change factors include inserts slipped in to the catalog, or stickers applied to the outside. Hard to change factors include the overall design of the catalog, or the pictures printed on them. Consider a catalog where there are two possible cover photos, two possible pieces of advertising copy on the catalog, and a sticker that can either be applied or left off. It should be clear that this is a 2x2x2 or 23 factorial experiment, because there are three factors at two levels each.",DO,572,"['many', 'feature', 'catalog', 'could', 'considered', 'experiment', 'easy', 'change', 'factor', 'include', 'insert', 'slipped', 'catalog', 'sticker', 'applied', 'outside', 'hard', 'change', 'factor', 'include', 'overall', 'design', 'catalog', 'picture', 'printed', 'consider', 'catalog', 'two', 'possible', 'cover', 'photo', 'two', 'possible', 'piece', 'advertising', 'copy', 'catalog', 'sticker', 'either', 'applied', 'left', 'clear', '2x2x2', '23', 'factorial', 'experiment', 'three', 'factor', 'two', 'level']"
1501,"The above slide indicates four possible ways to arrange the same OFAT tests, and none of the potential arrangements offers an ability to capture the interaction term described earlier. ?	The discipline of experimental design affords a systematic way of thinking about what data you will want when the time for analysis comes, and ensuring that you will have that data. The above slide indicates four designs that fail to offer the necessary data for testing the presence of an interaction.",DO,489,"['slide', 'indicates', 'four', 'possible', 'way', 'arrange', 'ofat', 'test', 'none', 'potential', 'arrangement', 'offer', 'ability', 'capture', 'interaction', 'term', 'described', 'earlier', '\tthe', 'discipline', 'experimental', 'design', 'affords', 'systematic', 'way', 'thinking', 'data', 'want', 'time', 'analysis', 'come', 'ensuring', 'data', 'slide', 'indicates', 'four', 'design', 'fail', 'offer', 'necessary', 'data', 'testing', 'presence', 'interaction']"
1502,"It seems like the main effects are significant, but that is no insurance that the model is well specified. It may be that there are higher-order interactions that are going undetected. You could test those higher order interactions with a MODEL statement that uses the btapr, points, btapr*points, btapr*btapr, btapr*btapr*points, and so forth, but because the levels of the factors are evenly spaced, you could use orthogonal polynomials and get independent tests of the higher-order effects. The PARAM=ORTHPOLY option, following a slash on the CLASS statement, instructs the LOGISTIC procedure to use orthogonal polynomial recoding of the inputs named in that CLASS statement. Specifying btapr|points in the MODEL statement tests every possible polynomial term and interaction. proc logistic data=orthpoly; class btapr points / param=orthpoly; model resp/volume=btapr|points; run; Partial Output Class Level Information",DO,921,"['seems', 'like', 'main_effect', 'significant', 'insurance', 'model', 'well', 'specified', 'may', 'higherorder', 'interaction', 'going', 'undetected', 'could', 'test', 'higher', 'order', 'interaction', 'model_statement', 'us', 'btapr', 'point', 'btaprpoints', 'btaprbtapr', 'btaprbtaprpoints', 'forth', 'level', 'factor', 'evenly', 'spaced', 'could', 'use', 'orthogonal', 'polynomial', 'get', 'independent', 'test', 'higherorder', 'effect', 'paramorthpoly', 'option', 'following', 'slash', 'class', 'statement', 'instructs', 'logistic', 'procedure', 'use', 'orthogonal', 'polynomial', 'recoding', 'input', 'named', 'class', 'statement', 'specifying', 'btaprpoints', 'model_statement', 'test', 'every', 'possible', 'polynomial', 'term', 'interaction', 'proc_logistic', 'dataorthpoly', 'class', 'btapr', 'point', '', 'paramorthpoly', 'model', 'respvolumebtaprpoints', 'run', 'partial', 'output', 'class', 'level', 'information']"
1503,"In agriculture, you would block on location in a field or mower-driver. In credit cards, you could block on previous mails, point status, risk groups, or other internal groupings. In a retail setting, you could block on months since last purchase, or frequency of purchase. In the case of designs rolled out over time, the phase of the design should be considered a block. Traditionally, you are interested in a block?s effect to account for another source of variation in the data, not to include block-to-block variation as part of the model. In agriculture, health sciences, and so on, this is almost always the case. For the direct marketing context, there is no good general rule. Mail List might be a random source of noise, and risk group may have a fixed, deterministic effect, or vice versa. These considerations will affect your analysis. Finally, there are two sides to the idea of blocking. The first is the one already described?blocks are a restriction on randomization meant to eliminate a potentially large source of error. The second is an implicit assumption made by traditional practitioners?that of no block by treatment interaction. Much of the power of blocking, traditionally, comes from this latter assumption, which is probably not a good one in the direct marketing context. However, the large sample sizes should help you use blocks both to eliminate large sources of variation and recognize?and capitalize on? those block by treatment interactions.",DO,1476,"['agriculture', 'would', 'block', 'location', 'field', 'mowerdriver', 'credit', 'card', 'could', 'block', 'previous', 'mail', 'point', 'status', 'risk', 'group', 'internal', 'grouping', 'retail', 'setting', 'could', 'block', 'month', 'since', 'last', 'purchase', 'frequency', 'purchase', 'case', 'design', 'rolled', 'time', 'phase', 'design', 'considered', 'block', 'traditionally', 'interested', 'block', 'effect', 'account', 'another', 'source', 'variation', 'data', 'include', 'blocktoblock', 'variation', 'part', 'model', 'agriculture', 'health', 'science', 'almost', 'always', 'case', 'direct', 'marketing', 'context', 'good', 'general', 'rule', 'mail', 'list', 'might', 'random', 'source', 'noise', 'risk', 'group', 'may', 'fixed', 'deterministic', 'effect', 'vice', 'versa', 'consideration', 'affect', 'analysis', 'finally', 'two', 'side', 'idea', 'blocking', 'first', 'one', 'already', 'describedblocks', 'restriction', 'randomization', 'meant', 'eliminate', 'potentially', 'large', 'source', 'error', 'second', 'implicit', 'assumption', 'made', 'traditional', 'practitionersthat', 'block', 'treatment', 'interaction', 'much', 'power', 'blocking', 'traditionally', 'come', 'latter', 'assumption', 'probably', 'good', 'one', 'direct', 'marketing', 'context', 'however', 'large', 'sample_size', 'help', 'use', 'block', 'eliminate', 'large', 'source', 'variation', 'recognizeand', 'capitalize', 'block', 'treatment', 'interaction']"
1504,"There is no restriction in an experiment forcing you to choose factors that each have 2 levels, or even the same number of levels. The analysis of an experiment that has factors with more than 2 levels may be complicated by concerns of multiple comparisons, but from a design standpoint, a factorial arrangement of treatments simply means that every possible combination is considered a treatment, regardless of the number of levels or their associated number of factors. You can create a full factorial with one factor at two levels, one factor at three levels, and one factor at four levels with a DATA step. You can also use the PLAN or the FACTEX procedures. Consider a credit card direct mail solicitation. The three factors of interest in this example are Factor Level 1 Level 2 Level 3 Level 4 Envelope White Blue",DO,820,"['restriction', 'experiment', 'forcing', 'choose', 'factor', '2', 'level', 'even', 'number', 'level', 'analysis', 'experiment', 'ha', 'factor', '2', 'level', 'may', 'complicated', 'concern', 'multiple', 'comparison', 'design', 'standpoint', 'factorial', 'arrangement', 'treatment', 'simply', 'mean', 'every', 'possible', 'combination', 'considered', 'treatment', 'regardless', 'number', 'level', 'associated', 'number', 'factor', 'create', 'full', 'factorial', 'one', 'factor', 'two', 'level', 'one', 'factor', 'three', 'level', 'one', 'factor', 'four', 'level', 'data', 'step', 'also', 'use', 'plan', 'factex', 'procedure', 'consider', 'credit', 'card', 'direct', 'mail', 'solicitation', 'three', 'factor', 'interest', 'example', 'factor', 'level', '1', 'level', '2', 'level', '3', 'level', '4', 'envelope', 'white', 'blue']"
1505,"It is worth noting that the name ?optimal? designs may be misleading. The designs sought in this section are not necessarily guaranteed to be optimal, but they are meant to be efficient in the face of practical constraints on traditional factorial experiments. The author of the %MktEx macro, Warren Kuhfeld, reserves the word ?optimal? for designs that have 100% efficiency or that he can prove are as efficient as possible subject to constraints. The jargon ?optimal designs? or ?optimum designs? is generally understood to mean designs found by some algorithm in an attempt to optimize some criterion. The use of the term ?optimal? should not be construed to mean that these designs have been proven to be the absolute best of all possible designs.",DO,751,"['worth', 'noting', 'name', 'optimal', 'design', 'may', 'misleading', 'design', 'sought', 'section', 'necessarily', 'guaranteed', 'optimal', 'meant', 'efficient', 'face', 'practical', 'constraint', 'traditional', 'factorial', 'experiment', 'author', 'mktex', 'macro', 'warren', 'kuhfeld', 'reserve', 'word', 'optimal', 'design', '100', 'efficiency', 'prove', 'efficient', 'possible', 'subject', 'constraint', 'jargon', 'optimal', 'design', 'optimum', 'design', 'generally', 'understood', 'mean', 'design', 'found', 'algorithm', 'attempt', 'optimize', 'criterion', 'use', 'term', 'optimal', 'construed', 'mean', 'design', 'proven', 'absolute', 'best', 'possible', 'design']"
1506,"The four treatments, of the possible 8, are selected systematically. As was mentioned above, the method of selecting treatments implies that, when some factors are not active, you implicitly get replication in the other factors. For example, if factor C is not significant, then the four points in the experiment represent a complete 22 factorial in A and B. Using a Fractional Factorial",DO,387,"['four', 'treatment', 'possible', '8', 'selected', 'systematically', 'wa', 'mentioned', 'method', 'selecting', 'treatment', 'implies', 'factor', 'active', 'implicitly', 'get', 'replication', 'factor', 'example', 'factor', 'c', 'significant', 'four', 'point', 'experiment', 'represent', 'complete', '22', 'factorial', 'b', 'using', 'fractional', 'factorial']"
1507,"The above slide indicates four possible ways to arrange the same OFAT tests, and none of the potential arrangements offers an ability to capture the interaction term described earlier. ?	The discipline of experimental design affords a systematic way of thinking about what data you will want when the time for analysis comes, and ensuring that you will have that data. The above slide indicates four designs that fail to offer the necessary data for testing the presence of an interaction.",DO,489,"['slide', 'indicates', 'four', 'possible', 'way', 'arrange', 'ofat', 'test', 'none', 'potential', 'arrangement', 'offer', 'ability', 'capture', 'interaction', 'term', 'described', 'earlier', '\tthe', 'discipline', 'experimental', 'design', 'affords', 'systematic', 'way', 'thinking', 'data', 'want', 'time', 'analysis', 'come', 'ensuring', 'data', 'slide', 'indicates', 'four', 'design', 'fail', 'offer', 'necessary', 'data', 'testing', 'presence', 'interaction']"
1508,"Consider a series of credit card offers, where the factors of interest are the introductory (or ?teaser?) interest rate, and the rate that takes effect after the introductory period expires, commonly called a ?goto? rate.",DO,221,"['consider', 'series', 'credit', 'card', 'offer', 'factor', 'interest', 'introductory', 'teaser', 'interest', 'rate', 'rate', 'take', 'effect', 'introductory', 'period', 'expires', 'commonly', 'called', 'goto', 'rate']"
1509,"This is the general flow for generating an optimal design: 1.	Generate a set of candidate treatments, taking care to exclude any infeasible combinations. 2.	Use the OPTEX procedure to generate an optimal design. Of course, you could generate several designs and choose the one most suited to your needs. Generating the design entails making several specifications; for example, the model you would like to fit, how many observations you can afford, the criterion you would like to optimize, and the search algorithm you would like to use. 3.	To choose from several designs, you need to consider the optimality criteria. You may also choose to evaluate the aliasing that takes place with each design. To see the aliasing patterns, you can use the GLM procedure with the ALIASING option in the MODEL statement. An example of this code follows. 4.	When you find a design that meets your needs, then you can roll it out and gather data. The analysis of an optimal design can be treated like the analysis of any of the other designs considered. In the case of the fractional factorials, you know exactly what factors are aliased, and so you can assess how sure you are that the A effect actually measures the effect of the A factor. With an optimal design, you specify the model that you suspect is important. Any departure from that model will lead to a potential bias in your parameter estimates. The OPTEX procedure allows you flexibility in building designs. Here are some important features to note about the OPTEX procedure. The OPTEX procedure has algorithms to search for U- and S-optimal designs. These designs do not maximize or minimize some function of the information or variance, as A- and D- optimal designs do. Instead, these designs seek to optimize the design based on distances in the design space. A U- optimal design seeks to minimize the distance from all of the points in the list of candidate points to the points in the design. S-optimal designs seek to maximize the distance between each point in the design and all of the other points in the design. Both of these distance-based measures try to fill the factor space with observations, rather than maximize some fitness measure of the design. *	You can create the candidate data set however you are comfortable. The DATA step, the PLAN procedure, and the FACTEX procedure are reasonable choices. *	If you have a large number of factors with a large number of levels, the full factorial might be too large for the OPTEX procedure to operate with. If that happens, you can use the FACTEX procedure to generate a fractional factorial for use as a candidate set. Of course, if you can run the %MktEx macro, that is a better choice because you will have access to more potential designs and algorithms. *	As in the FACTEX procedure, you specify the effects of interest in a MODEL statement. You should include the interaction terms and higher-order polynomial terms of interest as well. These designs are custom-made to estimate the parameters specifically named in the MODEL statement, and may assume that every other factor is negligible in order to estimate the named factors. *	By default, the OPTEX procedure seeks to find a design with n runs, where n is the number of parameters you want to estimate plus 10. If you want a design with as few runs as possible, you can specify that you want a saturated design. As with the fractional factorials, the smaller the design gets, the more confounding takes place. In the context of optimal designs, however, it is rare that you will be able to write out a set of simple confounding rules. If you want a specific number of runs, then you can set that number as well. ?	Notice that (number of degrees of freedom in the model + 10) may be a reasonable design size if your only concern is having sufficient degrees of freedom to estimate parameters and an error term. In the direct marketing context (as well as many other contexts) this rule could lead you to design sizes that eliminate the possibility of balance or orthogonality! Even if you do not have SAS/IML (necessary to ru",DO,4096,"['general', 'flow', 'generating', 'optimal', 'design', '1\tgenerate', 'set', 'candidate', 'treatment', 'taking', 'care', 'exclude', 'infeasible', 'combination', '2\tuse', 'optex', 'procedure', 'generate', 'optimal', 'design', 'course', 'could', 'generate', 'several', 'design', 'choose', 'one', 'suited', 'need', 'generating', 'design', 'entail', 'making', 'several', 'specification', 'example', 'model', 'would', 'like', 'fit', 'many', 'observation', 'afford', 'criterion', 'would', 'like', 'optimize', 'search', 'algorithm', 'would', 'like', 'use', '3\tto', 'choose', 'several', 'design', 'need', 'consider', 'optimality', 'criterion', 'may', 'also', 'choose', 'evaluate', 'aliasing', 'take', 'place', 'design', 'see', 'aliasing', 'pattern', 'use', 'glm', 'procedure', 'aliasing', 'option', 'model_statement', 'example', 'code', 'follows', '4\twhen', 'find', 'design', 'meet', 'need', 'roll', 'gather', 'data', 'analysis', 'optimal', 'design', 'treated', 'like', 'analysis', 'design', 'considered', 'case', 'fractional', 'factorial', 'know', 'exactly', 'factor', 'aliased', 'ass', 'sure', 'effect', 'actually', 'measure', 'effect', 'factor', 'optimal', 'design', 'specify', 'model', 'suspect', 'important', 'departure', 'model', 'lead', 'potential', 'bias', 'parameter_estimate', 'optex', 'procedure', 'allows', 'flexibility', 'building', 'design', 'important', 'feature', 'note', 'optex', 'procedure', 'optex', 'procedure', 'ha', 'algorithm', 'search', 'u', 'soptimal', 'design', 'design', 'maximize', 'minimize', 'function', 'information', 'variance', 'optimal', 'design', 'instead', 'design', 'seek', 'optimize', 'design', 'based', 'distance', 'design', 'space', 'u', 'optimal', 'design', 'seek', 'minimize', 'distance', 'point', 'list', 'candidate', 'point', 'point', 'design', 'soptimal', 'design', 'seek', 'maximize', 'distance', 'point', 'design', 'point', 'design', 'distancebased', 'measure', 'try', 'fill', 'factor', 'space', 'observation', 'rather', 'maximize', 'fitness', 'measure', 'design', '\tyou', 'create', 'candidate', 'data_set', 'however', 'comfortable', 'data', 'step', 'plan', 'procedure', 'factex', 'procedure', 'reasonable', 'choice', '\tif', 'large', 'number', 'factor', 'large', 'number', 'level', 'full', 'factorial', 'might', 'large', 'optex', 'procedure', 'operate', 'happens', 'use', 'factex', 'procedure', 'generate', 'fractional', 'factorial', 'use', 'candidate', 'set', 'course', 'run', 'mktex', 'macro', 'better', 'choice', 'access', 'potential', 'design', 'algorithm', '\tas', 'factex', 'procedure', 'specify', 'effect', 'interest', 'model_statement', 'include', 'interaction', 'term', 'higherorder', 'polynomial', 'term', 'interest', 'well', 'design', 'custommade', 'estimate', 'parameter', 'specifically', 'named', 'model_statement', 'may', 'assume', 'every', 'factor', 'negligible', 'order', 'estimate', 'named', 'factor', '\tby', 'default', 'optex', 'procedure', 'seek', 'find', 'design', 'n', 'run', 'n', 'number', 'parameter', 'want', 'estimate', 'plus', '10', 'want', 'design', 'run', 'possible', 'specify', 'want', 'saturated', 'design', 'fractional', 'factorial', 'smaller', 'design', 'get', 'confounding', 'take', 'place', 'context', 'optimal', 'design', 'however', 'rare', 'able', 'write', 'set', 'simple', 'confounding', 'rule', 'want', 'specific', 'number', 'run', 'set', 'number', 'well', '\tnotice', 'number', 'degree', 'freedom', 'model', '', '10', 'may', 'reasonable', 'design', 'size', 'concern', 'sufficient', 'degree', 'freedom', 'estimate', 'parameter', 'error', 'term', 'direct', 'marketing', 'context', 'well', 'many', 'context', 'rule', 'could', 'lead', 'design', 'size', 'eliminate', 'possibility', 'balance', 'orthogonality', 'even', 'sasiml', 'necessary', 'ru']"
1510,"For maximum power on all three questions under investigation (intro effect, goto effect, and interaction effect) the best solution is equal sample size allocation across all four treatments, as below.",DO,200,"['maximum', 'power', 'three', 'question', 'investigation', 'intro', 'effect', 'goto', 'effect', 'interaction', 'effect', 'best', 'solution', 'equal', 'sample_size', 'allocation', 'across', 'four', 'treatment']"
1511,"The response rates and variances seem to be on the order of the assumptions in the last demonstration, so these sample sizes should be sufficient to detect the effects of interest. Unfortunately, the Balance Transfer (BT) rate seems to have been a little lower than anticipated, which may impact your ability to detect small effects in BT amount. The MEANS Procedure",DO,366,"['response', 'rate', 'variance', 'seem', 'order', 'assumption', 'last', 'demonstration', 'sample_size', 'sufficient', 'detect', 'effect', 'interest', 'unfortunately', 'balance', 'transfer', 'bt', 'rate', 'seems', 'little', 'lower', 'anticipated', 'may', 'impact', 'ability', 'detect', 'small', 'effect', 'bt', 'amount', 'mean', 'procedure']"
1512,"Other jargon that used in this context is similar, but is often used slightly differently. One could say that A is aliased with the BC interaction. That statement means virtually the same thing as the statement that A is confounded with BC, but there is a subtle distinction. People generally reserve the word confounded for interactions that stem from the defining fraction(s), whereas aliasing reflects the fact that the contrasts for two factors could be identical even though that was not part of the defining rules. This subtlety is merely a thought exercise in an example this small; in the demonstration it will be easier to see the distinction.",DO,652,"['jargon', 'used', 'context', 'similar', 'often', 'used', 'slightly', 'differently', 'one', 'could', 'say', 'aliased', 'bc', 'interaction', 'statement', 'mean', 'virtually', 'thing', 'statement', 'confounded', 'bc', 'subtle', 'distinction', 'people', 'generally', 'reserve', 'word', 'confounded', 'interaction', 'stem', 'defining', 'fraction', 'whereas', 'aliasing', 'reflects', 'fact', 'contrast', 'two', 'factor', 'could', 'identical', 'even', 'though', 'wa', 'part', 'defining', 'rule', 'subtlety', 'merely', 'thought', 'exercise', 'example', 'small', 'demonstration', 'easier', 'see', 'distinction']"
1513,"An experimental design defines the rules and procedures by which data is collected. By employing the correct design for any given situation, you can make the most efficient use of the data from the experiment. This means that you may be able to save time and money in the data collection phase and still answer your question. The practice of ?Design of Experiments? or ?Experimental Design? involves a systematic assessment of different tests.",DO,443,"['experimental', 'design', 'defines', 'rule', 'procedure', 'data', 'collected', 'employing', 'correct', 'design', 'given', 'situation', 'make', 'efficient', 'use', 'data', 'experiment', 'mean', 'may', 'able', 'save', 'time', 'money', 'data', 'collection', 'phase', 'still', 'answer', 'question', 'practice', 'design', 'experiment', 'experimental', 'design', 'involves', 'systematic', 'assessment', 'different', 'test']"
1514,"If an experiment is designed correctly, the analysis of the data is simpler. Too often data is collected before the appropriate design is considered. Sometimes this results in collecting a lot of data, but still not answering your questions.",DO,241,"['experiment', 'designed', 'correctly', 'analysis', 'data', 'simpler', 'often', 'data', 'collected', 'appropriate', 'design', 'considered', 'sometimes', 'result', 'collecting', 'lot', 'data', 'still', 'answering', 'question']"
1515,"The %MktEx macro, which systematically searches for efficient designs, is part of a series of macros developed to streamline the process of finding efficient experimental designs. There is a list of all of the macros available on support.sas.com. A few macros that may prove to be of use in the direct marketing context follows: *	%MktDes requires SAS/STAT and SAS/QC. It is essentially an interface to the FACTEX and OPTEX procedures in SAS/QC, and searches for efficient designs by searching through a list of candidate treatments. *	%MktEval requires SAS/STAT and SAS/IML. It evaluates experimental designs by reporting a matrix of canonical correlations and also frequencies of the occurrence of factor levels in a design. This allows you to assess how ?close? a design is to orthogonal and balanced. *	%MktEx requires SAS/STAT, SAS/QC, and SAS/IML. As seen in the previous demonstration, it searches for efficient designs with whatever tools seem effective for that problem?searching a catalog of extant orthogonal arrays, searching a candidate set, and performing coordinate exchange. *	%MktOrth requires SAS/IML and lists entries from the orthogonal array catalog. *	%MktRuns requires only Base SAS, and identifies the number of treatments necessary to allow a particular design to be orthogonal and balanced. It also lists designs sizes that would not be 100% efficient, and the reasons for their departure from that 100% efficiency.",DO,1441,"['mktex', 'macro', 'systematically', 'search', 'efficient', 'design', 'part', 'series', 'macro', 'developed', 'streamline', 'process', 'finding', 'efficient', 'experimental', 'design', 'list', 'macro', 'available', 'supportsascom', 'macro', 'may', 'prove', 'use', 'direct', 'marketing', 'context', 'follows', '\tmktdes', 'requires', 'sasstat', 'sasqc', 'essentially', 'interface', 'factex', 'optex', 'procedure', 'sasqc', 'search', 'efficient', 'design', 'searching', 'list', 'candidate', 'treatment', '\tmkteval', 'requires', 'sasstat', 'sasiml', 'evaluates', 'experimental', 'design', 'reporting', 'matrix', 'canonical', 'correlation', 'also', 'frequency', 'occurrence', 'factor', 'level', 'design', 'allows', 'ass', 'close', 'design', 'orthogonal', 'balanced', '\tmktex', 'requires', 'sasstat', 'sasqc', 'sasiml', 'seen', 'previous', 'demonstration', 'search', 'efficient', 'design', 'whatever', 'tool', 'seem', 'effective', 'problemsearching', 'catalog', 'extant', 'orthogonal', 'array', 'searching', 'candidate', 'set', 'performing', 'coordinate', 'exchange', '\tmktorth', 'requires', 'sasiml', 'list', 'entry', 'orthogonal', 'array', 'catalog', '\tmktruns', 'requires', 'base', 'sa', 'identifies', 'number', 'treatment', 'necessary', 'allow', 'particular', 'design', 'orthogonal', 'balanced', 'also', 'list', 'design', 'size', 'would', '100', 'efficient', 'reason', 'departure', '100', 'efficiency']"
1516,"In an experiment, the variable that measures the outcome of interest is called the response variable. It is also known as the dependent variable. A factor is an independent or predictor variable that is a possible source of variation in the response variable. An effect is the relationship between a factor and a response. A factor level is a particular value of a factor. In other words, the specific types or amounts of the factor used in the experiment. A treatment is a combination of factor levels used in the experiment. This is sometimes also referred to as the condition. An experimental unit is the smallest object to which a treatment is applied. It is the smallest part of the experimental material where any two experimental units can receive different treatments. A replication occurs when you assign more than one experimental unit to a treatment. Internal to an organization, you may have your own jargon, but these words are the ones you are likely to see in any articles you might read. In this context, experimental units could be a household or an individual. For example, a credit card offer can be sent to an individual; there may be several individuals per household. A mortgage offer can only be made once per household. Replication is often difficult in manufacturing or agriculture, because the experimental unit may be a batch of TVs, or an acre of corn. But in this context, replication is going to be par for the course.",DO,1448,"['experiment', 'variable', 'measure', 'outcome', 'interest', 'called', 'response_variable', 'also', 'known', 'dependent', 'variable', 'factor', 'independent', 'predictor_variable', 'possible', 'source', 'variation', 'response_variable', 'effect', 'relationship', 'factor', 'response', 'factor', 'level', 'particular', 'value', 'factor', 'word', 'specific', 'type', 'amount', 'factor', 'used', 'experiment', 'treatment', 'combination', 'factor', 'level', 'used', 'experiment', 'sometimes', 'also', 'referred', 'condition', 'experimental', 'unit', 'smallest', 'object', 'treatment', 'applied', 'smallest', 'part', 'experimental', 'material', 'two', 'experimental', 'unit', 'receive', 'different', 'treatment', 'replication', 'occurs', 'assign', 'one', 'experimental', 'unit', 'treatment', 'internal', 'organization', 'may', 'jargon', 'word', 'one', 'likely', 'see', 'article', 'might', 'read', 'context', 'experimental', 'unit', 'could', 'household', 'individual', 'example', 'credit', 'card', 'offer', 'sent', 'individual', 'may', 'several', 'individual', 'per', 'household', 'mortgage', 'offer', 'made', 'per', 'household', 'replication', 'often', 'difficult', 'manufacturing', 'agriculture', 'experimental', 'unit', 'may', 'batch', 'tv', 'acre', 'corn', 'context', 'replication', 'going', 'par', 'course']"
1517,"Familiarity with the one-way, k-level analysis naturally leads to a temptation to consider every test in those terms. If you need to know about intro rate, design an intro rate test. If you need to know about goto, arrange for a separate goto test. Duration is another test. This kind of testing is known as One Factor at a Time, or OFAT, testing. OFAT testing?s attractiveness hinges on the fact that it is easy to interpret and explain. Their unattractive features can be quite daunting. OFAT results are only valid if you assume *	no interactions between any factors, or *	you will have all of the other factors fixed for the foreseeable future. Neither of these is practically feasible, which means you need a more robust testing methodology.",DO,746,"['familiarity', 'oneway', 'klevel', 'analysis', 'naturally', 'lead', 'temptation', 'consider', 'every', 'test', 'term', 'need', 'know', 'intro', 'rate', 'design', 'intro', 'rate', 'test', 'need', 'know', 'goto', 'arrange', 'separate', 'goto', 'test', 'duration', 'another', 'test', 'kind', 'testing', 'known', 'one', 'factor', 'time', 'ofat', 'testing', 'ofat', 'testing', 'attractiveness', 'hinge', 'fact', 'easy', 'interpret', 'explain', 'unattractive', 'feature', 'quite', 'daunting', 'ofat', 'result', 'valid', 'assume', '\tno', 'interaction', 'factor', '\tyou', 'factor', 'fixed', 'foreseeable', 'future', 'neither', 'practically', 'feasible', 'mean', 'need', 'robust', 'testing', 'methodology']"
1518,"*	the notion of controlling for external conditions. The focus of this course is bridging the world of engineers and psychologists to the world of the banker and the direct marketer. In many spheres of influence, testing is commonplace, for example, manufacturing, the pharmaceutical industry, and agriculture. The ideas that are central to good testing are important regardless of industry. You can take the important ideas and apply them to your own tests.",DO,458,"['\tthe', 'notion', 'controlling', 'external', 'condition', 'focus', 'course', 'bridging', 'world', 'engineer', 'psychologist', 'world', 'banker', 'direct', 'marketer', 'many', 'sphere', 'influence', 'testing', 'commonplace', 'example', 'manufacturing', 'pharmaceutical', 'industry', 'agriculture', 'idea', 'central', 'good', 'testing', 'important', 'regardless', 'industry', 'take', 'important', 'idea', 'apply', 'test']"
1519,"Power is the probability of rejecting the null hypothesis when it is false. That is, given that the alternative hypothesis does a better job of explaining the world, what is the probability that our decision will be to reject the null hypothesis?",DO,246,"['power', 'probability', 'rejecting', 'null', 'hypothesis', 'false', 'given', 'alternative', 'hypothesis', 'doe', 'better', 'job', 'explaining', 'world', 'probability', 'decision', 'reject', 'null', 'hypothesis']"
1520,"There are six different optimality criteria available in the OPTEX procedure. The technical notation which follows assumes a design matrix, where each row represents an experimental unit in the test and their associated treatment, called X, and a set of candidate points, where each row is a potential treatment, called C. Sometimes people refer to the list of treatments that comprise X as the set of design points D. So you get a design (X) by choosing some n points (D) from a list of candidates (C). Which n points you choose depends on your criterion, but you are typically trying to ensure that your design is ?close? to being orthogonal and balanced. D-optimality Technically, a D-optimal design maximizes |X?X|, or minimizes |(X?X)-1|. Practically, D-optimal designs have the property that they minimize the size of the confidence region around all of the parameter estimates. They are popular with practitioners in many different disciplines. This is the default criterion in the OPTEX procedure, and is the most computationally efficient criterion to search for. D-optimal designs are invariant to nonsingular re-coding of the variables, so it does not matter whether you choose to re-code numeric inputs or use the original values. The values of the determinants might change, but the same design will have the optimal value regardless of the coding method. A-optimality An A-optimal design minimizes the sum of the diagonal elements of (X?X)-1, also known as the trace or tr((X?X)-1). This sum is tied to the total variance of the parameter estimates in your model. An A-optimal design, in practice, minimizes the average variance of the parameter estimates in your model. The OPTEX procedure can be used to find the best design according to the A-optimality criterion, rather than the default D-optimality criterion. This is done with the CRITERION=A option in the GENERATE statement. Other Information Based Criteria There are other well known optimality criteria that try to optimize some function of X?X, using that function to stand in for a feature of the analysis that is important. G-optimal designs seek to minimize the largest variance of any predicted value in the candidate set C. This ?minimizing the maximum variance? is an attractive criterion, but has two faults in practice. First, it is very hard to optimize this criterion?there is no efficient algorithm for this search. Second, it may be too strict. There may be good designs that are not G-optimal, or the average prediction may suffer across the board to reduce the variance in a small region of the sample space. In practice, one way to skirt the first problem is to search for a D-optimal design, retain every design evaluated during that search, and use the design that looks best according to the G-optimality criterion. I-optimal designs seek to minimize the average variance of the predictions across the points in C. Under certain conditions, this criterion yields the same design as A-optimality. Using the CODING=ORTH option on the PROC OPTEX statement and the CRITERION=A option in the GENERATE statement will yield an I-optimal design. Both G- and I-optimality are invariant to re-coding of the factors, because they both deal with variance of the predictions at each point in C, which is static, rather than (solely) a function of the matrix X?X, which can change. Distance Based Criteria The information based criteria seek to find a design with good prediction properties. The differences between them are basically a function of the way you think about good prediction. There is another way to consider selecting treatments D from a candidate set C. You could think about the space spanned by all of the candidate points, and try to select points for the design matrix that best spans that space in some sense. U- and S-optimality try to optimize the design points by uniformly placing points in the space, or by spreading points widely in the space. These criteria offer a different point of view, but may not be too useful in the direct marketing context. Because these criteria are concerned",DO,4094,"['six', 'different', 'optimality', 'criterion', 'available', 'optex', 'procedure', 'technical', 'notation', 'follows', 'assumes', 'design', 'matrix', 'row', 'represents', 'experimental', 'unit', 'test', 'associated', 'treatment', 'called', 'x', 'set', 'candidate', 'point', 'row', 'potential', 'treatment', 'called', 'c', 'sometimes', 'people', 'refer', 'list', 'treatment', 'comprise', 'x', 'set', 'design', 'point', 'get', 'design', 'x', 'choosing', 'n', 'point', 'list', 'candidate', 'c', 'n', 'point', 'choose', 'depends', 'criterion', 'typically', 'trying', 'ensure', 'design', 'close', 'orthogonal', 'balanced', 'doptimality', 'technically', 'doptimal', 'design', 'maximizes', 'xx', 'minimizes', 'xx1', 'practically', 'doptimal', 'design', 'property', 'minimize', 'size', 'confidence', 'region', 'around', 'parameter_estimate', 'popular', 'practitioner', 'many', 'different', 'discipline', 'default', 'criterion', 'optex', 'procedure', 'computationally', 'efficient', 'criterion', 'search', 'doptimal', 'design', 'invariant', 'nonsingular', 'recoding', 'variable', 'doe', 'matter', 'whether', 'choose', 'recode', 'numeric', 'input', 'use', 'original', 'value', 'value', 'determinant', 'might', 'change', 'design', 'optimal', 'value', 'regardless', 'coding', 'method', 'aoptimality', 'aoptimal', 'design', 'minimizes', 'sum', 'diagonal', 'element', 'xx1', 'also', 'known', 'trace', 'trxx1', 'sum', 'tied', 'total', 'variance', 'parameter_estimate', 'model', 'aoptimal', 'design', 'practice', 'minimizes', 'average', 'variance', 'parameter_estimate', 'model', 'optex', 'procedure', 'used', 'find', 'best', 'design', 'according', 'aoptimality', 'criterion', 'rather', 'default', 'doptimality', 'criterion', 'done', 'criteriona', 'option', 'generate', 'statement', 'information', 'based', 'criterion', 'well', 'known', 'optimality', 'criterion', 'try', 'optimize', 'function', 'xx', 'using', 'function', 'stand', 'feature', 'analysis', 'important', 'goptimal', 'design', 'seek', 'minimize', 'largest', 'variance', 'predicted', 'value', 'candidate', 'set', 'c', 'minimizing', 'maximum', 'variance', 'attractive', 'criterion', 'ha', 'two', 'fault', 'practice', 'first', 'hard', 'optimize', 'criterionthere', 'efficient', 'algorithm', 'search', 'second', 'may', 'strict', 'may', 'good', 'design', 'goptimal', 'average', 'prediction', 'may', 'suffer', 'across', 'board', 'reduce', 'variance', 'small', 'region', 'sample', 'space', 'practice', 'one', 'way', 'skirt', 'first', 'problem', 'search', 'doptimal', 'design', 'retain', 'every', 'design', 'evaluated', 'search', 'use', 'design', 'look', 'best', 'according', 'goptimality', 'criterion', 'ioptimal', 'design', 'seek', 'minimize', 'average', 'variance', 'prediction', 'across', 'point', 'c', 'certain', 'condition', 'criterion', 'yield', 'design', 'aoptimality', 'using', 'codingorth', 'option', 'proc', 'optex', 'statement', 'criteriona', 'option', 'generate', 'statement', 'yield', 'ioptimal', 'design', 'g', 'ioptimality', 'invariant', 'recoding', 'factor', 'deal', 'variance', 'prediction', 'point', 'c', 'static', 'rather', 'solely', 'function', 'matrix', 'xx', 'change', 'distance', 'based', 'criterion', 'information', 'based', 'criterion', 'seek', 'find', 'design', 'good', 'prediction', 'property', 'difference', 'basically', 'function', 'way', 'think', 'good', 'prediction', 'another', 'way', 'consider', 'selecting', 'treatment', 'candidate', 'set', 'c', 'could', 'think', 'space', 'spanned', 'candidate', 'point', 'try', 'select', 'point', 'design', 'matrix', 'best', 'span', 'space', 'sense', 'u', 'soptimality', 'try', 'optimize', 'design', 'point', 'uniformly', 'placing', 'point', 'space', 'spreading', 'point', 'widely', 'space', 'criterion', 'offer', 'different', 'point', 'view', 'may', 'useful', 'direct', 'marketing', 'context', 'criterion', 'concerned']"
1521,"The log shows that the macro creates two data sets; one called design and one called randomize. The design data set has the most efficient experimental design that the macro finds in its search, and the randomized data set has the same design with the order of the rows randomized. This is a nice feature in a laboratory; in direct marketing you will likely use the design data set. Output Algorithm Search History",DO,414,"['log', 'show', 'macro', 'creates', 'two', 'data_set', 'one', 'called', 'design', 'one', 'called', 'randomize', 'design', 'data_set', 'ha', 'efficient', 'experimental', 'design', 'macro', 'find', 'search', 'randomized', 'data_set', 'ha', 'design', 'order', 'row', 'randomized', 'nice', 'feature', 'laboratory', 'direct', 'marketing', 'likely', 'use', 'design', 'data_set', 'output', 'algorithm', 'search', 'history']"
1522,"Aside from having good statistical properties, a balanced and orthogonal design makes it easy to allocate sample size to the different treatments. With restrictions in place a design might not be balanced or orthogonal, but that does not change your sample size requirements. The results from the %MktEval macro include a table that can help you plan how to allocate mail or phone call volume. By default the macro reports on the number of treatments at each level of each factor, at each combination of levels for each pair of factors, and the N-way classification. The FREQS= option enables you to specify what frequencies are of interest. The following code requests solely main effects frequencies. Recall twenty is the data set with the 20-run design with restrictions. %mkteval(data=twenty, freqs=1); Partial Output Summary of Frequencies There are 2 Canonical Correlations Greater Than 0.316 * - Indicates Unequal Frequencies",DO,932,"['aside', 'good', 'statistical', 'property', 'balanced', 'orthogonal', 'design', 'make', 'easy', 'allocate', 'sample_size', 'different', 'treatment', 'restriction', 'place', 'design', 'might', 'balanced', 'orthogonal', 'doe', 'change', 'sample_size', 'requirement', 'result', 'mkteval', 'macro', 'include', 'table', 'help', 'plan', 'allocate', 'mail', 'phone', 'call', 'volume', 'default', 'macro', 'report', 'number', 'treatment', 'level', 'factor', 'combination', 'level', 'pair', 'factor', 'nway', 'classification', 'freqs', 'option', 'enables', 'specify', 'frequency', 'interest', 'following', 'code', 'request', 'solely', 'main_effect', 'frequency', 'recall', 'twenty', 'data_set', '20run', 'design', 'restriction', 'mktevaldatatwenty', 'freqs1', 'partial', 'output', 'summary', 'frequency', '2', 'canonical', 'correlation', 'greater', '0316', '', '', 'indicates', 'unequal', 'frequency']"
1523,"If an experiment is designed correctly, the analysis of the data is simpler. Too often data is collected before the appropriate design is considered. Sometimes this results in collecting a lot of data, but still not answering your questions.",DO,241,"['experiment', 'designed', 'correctly', 'analysis', 'data', 'simpler', 'often', 'data', 'collected', 'appropriate', 'design', 'considered', 'sometimes', 'result', 'collecting', 'lot', 'data', 'still', 'answering', 'question']"
1524,"The usual approach to experimental design is to use a sparse design, like the main effects only design in the last demonstration, to screen for factors that are active. After the important factors have been identified, you can use a less stringent design to try to identify interactions and nonlinearities. This philosophy is predicated on a notion called effect sparsity, which suggests that: *	only a few factors are likely to be very important. *	pure interactions, that is, interaction terms that are important where neither of their component main effects are important, are unlikely.",DO,589,"['usual', 'approach', 'experimental', 'design', 'use', 'sparse', 'design', 'like', 'main_effect', 'design', 'last', 'demonstration', 'screen', 'factor', 'active', 'important', 'factor', 'identified', 'use', 'le', 'stringent', 'design', 'try', 'identify', 'interaction', 'nonlinearities', 'philosophy', 'predicated', 'notion', 'called', 'effect', 'sparsity', 'suggests', '\tonly', 'factor', 'likely', 'important', '\tpure', 'interaction', 'interaction', 'term', 'important', 'neither', 'component', 'main_effect', 'important', 'unlikely']"
1525,"There is no restriction in an experiment forcing you to choose factors that each have 2 levels, or even the same number of levels. The analysis of an experiment that has factors with more than 2 levels may be complicated by concerns of multiple comparisons, but from a design standpoint, a factorial arrangement of treatments simply means that every possible combination is considered a treatment, regardless of the number of levels or their associated number of factors. You can create a full factorial with one factor at two levels, one factor at three levels, and one factor at four levels with a DATA step. You can also use the PLAN or the FACTEX procedures. Consider a credit card direct mail solicitation. The three factors of interest in this example are Factor Level 1 Level 2 Level 3 Level 4 Envelope White Blue",DO,820,"['restriction', 'experiment', 'forcing', 'choose', 'factor', '2', 'level', 'even', 'number', 'level', 'analysis', 'experiment', 'ha', 'factor', '2', 'level', 'may', 'complicated', 'concern', 'multiple', 'comparison', 'design', 'standpoint', 'factorial', 'arrangement', 'treatment', 'simply', 'mean', 'every', 'possible', 'combination', 'considered', 'treatment', 'regardless', 'number', 'level', 'associated', 'number', 'factor', 'create', 'full', 'factorial', 'one', 'factor', 'two', 'level', 'one', 'factor', 'three', 'level', 'one', 'factor', 'four', 'level', 'data', 'step', 'also', 'use', 'plan', 'factex', 'procedure', 'consider', 'credit', 'card', 'direct', 'mail', 'solicitation', 'three', 'factor', 'interest', 'example', 'factor', 'level', '1', 'level', '2', 'level', '3', 'level', '4', 'envelope', 'white', 'blue']"
1526,"The %MktEx macro, which systematically searches for efficient designs, is part of a series of macros developed to streamline the process of finding efficient experimental designs. There is a list of all of the macros available on support.sas.com. A few macros that may prove to be of use in the direct marketing context follows: *	%MktDes requires SAS/STAT and SAS/QC. It is essentially an interface to the FACTEX and OPTEX procedures in SAS/QC, and searches for efficient designs by searching through a list of candidate treatments. *	%MktEval requires SAS/STAT and SAS/IML. It evaluates experimental designs by reporting a matrix of canonical correlations and also frequencies of the occurrence of factor levels in a design. This allows you to assess how ?close? a design is to orthogonal and balanced. *	%MktEx requires SAS/STAT, SAS/QC, and SAS/IML. As seen in the previous demonstration, it searches for efficient designs with whatever tools seem effective for that problem?searching a catalog of extant orthogonal arrays, searching a candidate set, and performing coordinate exchange. *	%MktOrth requires SAS/IML and lists entries from the orthogonal array catalog. *	%MktRuns requires only Base SAS, and identifies the number of treatments necessary to allow a particular design to be orthogonal and balanced. It also lists designs sizes that would not be 100% efficient, and the reasons for their departure from that 100% efficiency.",DO,1441,"['mktex', 'macro', 'systematically', 'search', 'efficient', 'design', 'part', 'series', 'macro', 'developed', 'streamline', 'process', 'finding', 'efficient', 'experimental', 'design', 'list', 'macro', 'available', 'supportsascom', 'macro', 'may', 'prove', 'use', 'direct', 'marketing', 'context', 'follows', '\tmktdes', 'requires', 'sasstat', 'sasqc', 'essentially', 'interface', 'factex', 'optex', 'procedure', 'sasqc', 'search', 'efficient', 'design', 'searching', 'list', 'candidate', 'treatment', '\tmkteval', 'requires', 'sasstat', 'sasiml', 'evaluates', 'experimental', 'design', 'reporting', 'matrix', 'canonical', 'correlation', 'also', 'frequency', 'occurrence', 'factor', 'level', 'design', 'allows', 'ass', 'close', 'design', 'orthogonal', 'balanced', '\tmktex', 'requires', 'sasstat', 'sasqc', 'sasiml', 'seen', 'previous', 'demonstration', 'search', 'efficient', 'design', 'whatever', 'tool', 'seem', 'effective', 'problemsearching', 'catalog', 'extant', 'orthogonal', 'array', 'searching', 'candidate', 'set', 'performing', 'coordinate', 'exchange', '\tmktorth', 'requires', 'sasiml', 'list', 'entry', 'orthogonal', 'array', 'catalog', '\tmktruns', 'requires', 'base', 'sa', 'identifies', 'number', 'treatment', 'necessary', 'allow', 'particular', 'design', 'orthogonal', 'balanced', 'also', 'list', 'design', 'size', 'would', '100', 'efficient', 'reason', 'departure', '100', 'efficiency']"
1527,"Interpreting this plot, one might state that the introductory rate only has a dramatic effect in the presence of the higher goto offer. Of course, you can create the plot with the goto rate on the x- axis, if that would be easier to explain. In the presence of an interaction, the important point to remember is that there is no sensible way to discuss the effect of any of the main effects involved in that interaction. In this example, there is no quantity that describes the effect of the intro rate on response?you need to know the goto rate before you can discuss the effect of changing the intro rate, because that determines which of the two lines, in the plot above, you would focus on. ?	The plot also indicates an alternative method of parameterizing the model, or even reporting the results. Instead of discussing main effects and interactions, it may be easier to explain results with a different parameterization; for example, nesting the effect of the goto rate change within the intro rate change. Two Factors at Two Levels Each",DO,1043,"['interpreting', 'plot', 'one', 'might', 'state', 'introductory', 'rate', 'ha', 'dramatic', 'effect', 'presence', 'higher', 'goto', 'offer', 'course', 'create', 'plot', 'goto', 'rate', 'x', 'axis', 'would', 'easier', 'explain', 'presence', 'interaction', 'important', 'point', 'remember', 'sensible', 'way', 'discus', 'effect', 'main_effect', 'involved', 'interaction', 'example', 'quantity', 'describes', 'effect', 'intro', 'rate', 'responseyou', 'need', 'know', 'goto', 'rate', 'discus', 'effect', 'changing', 'intro', 'rate', 'determines', 'two', 'line', 'plot', 'would', 'focus', '\tthe', 'plot', 'also', 'indicates', 'alternative', 'method', 'parameterizing', 'model', 'even', 'reporting', 'result', 'instead', 'discussing', 'main_effect', 'interaction', 'may', 'easier', 'explain', 'result', 'different', 'parameterization', 'example', 'nesting', 'effect', 'goto', 'rate', 'change', 'within', 'intro', 'rate', 'change', 'two', 'factor', 'two', 'level']"
1528,"For maximum power on all three questions under investigation (intro effect, goto effect, and interaction effect) the best solution is equal sample size allocation across all four treatments, as below.",DO,200,"['maximum', 'power', 'three', 'question', 'investigation', 'intro', 'effect', 'goto', 'effect', 'interaction', 'effect', 'best', 'solution', 'equal', 'sample_size', 'allocation', 'across', 'four', 'treatment']"
1529,How much power does this cutoff (or decision rule) give us in an experiment with five observations? That question can only be answered for a particular alternative hypothesis.,DO,175,"['much', 'power', 'doe', 'cutoff', 'decision', 'rule', 'give', 'u', 'experiment', 'five', 'observation', 'question', 'answered', 'particular', 'alternative', 'hypothesis']"
1530,"To see the final design, use the PRINT procedure. Depending on how you created the key data set, formats may improve the appearance of your results. proc print data=final; format intro goto btchg percent8.2; var Intro Duration Goto Color Creative Postage Rewards Fixed AnnFee BTChg; run;",DO,287,"['see', 'final', 'design', 'use', 'print', 'procedure', 'depending', 'created', 'key', 'data_set', 'format', 'may', 'improve', 'appearance', 'result', 'proc', 'print', 'datafinal', 'format', 'intro', 'goto', 'btchg', 'percent82', 'var', 'intro', 'duration', 'goto', 'color', 'creative', 'postage', 'reward', 'fixed', 'annfee', 'btchg', 'run']"
1531,The effect of factor B is the difference between the average response in the shaded rows and the average response in the unshaded cells. Notice that every individual is used in the A and B tests.,DO,195,"['effect', 'factor', 'b', 'difference', 'average', 'response', 'shaded', 'row', 'average', 'response', 'unshaded', 'cell', 'notice', 'every', 'individual', 'used', 'b', 'test']"
1532,"The four treatments, of the possible 8, are selected systematically. As was mentioned above, the method of selecting treatments implies that, when some factors are not active, you implicitly get replication in the other factors. For example, if factor C is not significant, then the four points in the experiment represent a complete 22 factorial in A and B. Using a Fractional Factorial",DO,387,"['four', 'treatment', 'possible', '8', 'selected', 'systematically', 'wa', 'mentioned', 'method', 'selecting', 'treatment', 'implies', 'factor', 'active', 'implicitly', 'get', 'replication', 'factor', 'example', 'factor', 'c', 'significant', 'four', 'point', 'experiment', 'represent', 'complete', '22', 'factorial', 'b', 'using', 'fractional', 'factorial']"
1533,"Invoke the OPTEX procedure, specifying that the only candidate points for inclusion in the design are those points that are currently in the candidate data set. In addition, you can request that the OPTEX procedure use the modified Fedorov search algorithm, which is one of the slowest but also quite meticulous. You can specify interactions of interest in the MODEL statement; in order to compare this design to the one from %MktEx, you should not specify any interactions right now. proc optex data=candidate; class mailpc--product; model mailpc--product; generate keep=10 method=m_fedorov iter=200; examine design; run; quit; ?	The algorithmic design searches are initialized randomly; this means that you can run the same code two different times and potentially get two different designs. If this is a concern, you can force the searches to start with the same random seed by specifying using the SEED= option on the PROC OPTEX statement. This runs quite quickly, even though you requested 200 iterations of the slowest optimization algorithm. In fact, you might look at the output, which begins with the results of the ten best designs, and want to try a few more iterations. Because the first three designs have the same D- efficiency, it is doubtful that more iterations will help . The OPTEX Procedure",DO,1310,"['invoke', 'optex', 'procedure', 'specifying', 'candidate', 'point', 'inclusion', 'design', 'point', 'currently', 'candidate', 'data_set', 'addition', 'request', 'optex', 'procedure', 'use', 'modified', 'fedorov', 'search', 'algorithm', 'one', 'slowest', 'also', 'quite', 'meticulous', 'specify', 'interaction', 'interest', 'model_statement', 'order', 'compare', 'design', 'one', 'mktex', 'specify', 'interaction', 'right', 'proc', 'optex', 'datacandidate', 'class', 'mailpcproduct', 'model', 'mailpcproduct', 'generate', 'keep10', 'methodmfedorov', 'iter200', 'examine', 'design', 'run', 'quit', '\tthe', 'algorithmic', 'design', 'search', 'initialized', 'randomly', 'mean', 'run', 'code', 'two', 'different', 'time', 'potentially', 'get', 'two', 'different', 'design', 'concern', 'force', 'search', 'start', 'random', 'seed', 'specifying', 'using', 'seed', 'option', 'proc', 'optex', 'statement', 'run', 'quite', 'quickly', 'even', 'though', 'requested', '200', 'iteration', 'slowest', 'optimization', 'algorithm', 'fact', 'might', 'look', 'output', 'begin', 'result', 'ten', 'best', 'design', 'want', 'try', 'iteration', 'first', 'three', 'design', 'efficiency', 'doubtful', 'iteration', 'help', '', 'optex', 'procedure']"
1534,"A factorial arrangement of treatments permits you to test the terms of interest: the intro effect, the goto effect, and the interaction effect. This structure of treatments not only adds a piece of information, but it uses the marketing volume more efficiently, because it is possible to use every individual in the experiment in each of the three tests. The efficiency comes from planning the volume in such a way as to maximize the volume used in each test. The mixture of factor levels also provides hidden replication. If goto is irrelevant, and has no effect on the response either by itself or in an interaction term, then the volume at each level of intro is effectively doubled! ?	This kind of experiment is usually called a 2 x 2, or a 22, because it has 2 factors (exponent) each at 2 levels (base). In general, this notation is 2(# of factors with 2 levels) x 3(# of factors with 3 levels) x ? x k(# of factors with k levels). The increase in efficiency, or increased precision for the same number of experimental units, comes from the fact that every experimental unit is used in every comparison. This is apparent if you compare the design matrices of a factorial design and an OFAT design. These matrices will be considered later. The increased efficiency also means that you could get the same precision for smaller sample sizes, although in practice these variance-based benefits are often overridden by practical considerations. The goal of a particular campaign may not be solely response information; sometimes, a campaign will have to answer response questions for the marketing department, spending questions for the finance department, and loss questions for the risk department. This will often lead to sample size considerations in addition to the power-based calculations considered in the previous chapter. Another benefit is that the factor space is more completely explored. The OFAT tests all had missing corners.",DO,1942,"['factorial', 'arrangement', 'treatment', 'permit', 'test', 'term', 'interest', 'intro', 'effect', 'goto', 'effect', 'interaction', 'effect', 'structure', 'treatment', 'add', 'piece', 'information', 'us', 'marketing', 'volume', 'efficiently', 'possible', 'use', 'every', 'individual', 'experiment', 'three', 'test', 'efficiency', 'come', 'planning', 'volume', 'way', 'maximize', 'volume', 'used', 'test', 'mixture', 'factor', 'level', 'also', 'provides', 'hidden', 'replication', 'goto', 'irrelevant', 'ha', 'effect', 'response', 'either', 'interaction', 'term', 'volume', 'level', 'intro', 'effectively', 'doubled', '\tthis', 'kind', 'experiment', 'usually', 'called', '2', 'x', '2', '22', 'ha', '2', 'factor', 'exponent', '2', 'level', 'base', 'general', 'notation', '2', 'factor', '2', 'level', 'x', '3', 'factor', '3', 'level', 'x', '', 'x', 'k', 'factor', 'k', 'level', 'increase', 'efficiency', 'increased', 'precision', 'number', 'experimental', 'unit', 'come', 'fact', 'every', 'experimental', 'unit', 'used', 'every', 'comparison', 'apparent', 'compare', 'design', 'matrix', 'factorial', 'design', 'ofat', 'design', 'matrix', 'considered', 'later', 'increased', 'efficiency', 'also', 'mean', 'could', 'get', 'precision', 'smaller', 'sample_size', 'although', 'practice', 'variancebased', 'benefit', 'often', 'overridden', 'practical', 'consideration', 'goal', 'particular', 'campaign', 'may', 'solely', 'response', 'information', 'sometimes', 'campaign', 'answer', 'response', 'question', 'marketing', 'department', 'spending', 'question', 'finance', 'department', 'loss', 'question', 'risk', 'department', 'often', 'lead', 'sample_size', 'consideration', 'addition', 'powerbased', 'calculation', 'considered', 'previous', 'chapter', 'another', 'benefit', 'factor', 'space', 'completely', 'explored', 'ofat', 'test', 'missing', 'corner']"
1535,"Any experiment should begin with a precise definition of the purpose, or objectives, of the experiment. This purpose can then be further refined to include the specific questions that will be answered as a result of the experiment. After the questions have been documented, the population of interest must be defined. The population of interest determines the scope of the conclusions of the experiment. Based upon the population of interest, you must determine whether it is possible to collect the desired information from the entire population of interest. Most of the time, you lack the time or resources to collect population data and must collect information on a sample of the population. Recall that this sample should be a random sample. The final step before actually collecting and analyzing the data is to define the data collection protocol.",DO,854,"['experiment', 'begin', 'precise', 'definition', 'purpose', 'objective', 'experiment', 'purpose', 'refined', 'include', 'specific', 'question', 'answered', 'result', 'experiment', 'question', 'documented', 'population', 'interest', 'must', 'defined', 'population', 'interest', 'determines', 'scope', 'conclusion', 'experiment', 'based', 'upon', 'population', 'interest', 'must', 'determine', 'whether', 'possible', 'collect', 'desired', 'information', 'entire', 'population', 'interest', 'time', 'lack', 'time', 'resource', 'collect', 'population', 'data', 'must', 'collect', 'information', 'sample', 'population', 'recall', 'sample', 'random', 'sample', 'final', 'step', 'actually', 'collecting', 'analyzing', 'data', 'define', 'data', 'collection', 'protocol']"
1536,The effect of factor B is the difference between the average response in the shaded rows and the average response in the unshaded cells. Notice that every individual is used in the A and B tests.,DO,195,"['effect', 'factor', 'b', 'difference', 'average', 'response', 'shaded', 'row', 'average', 'response', 'unshaded', 'cell', 'notice', 'every', 'individual', 'used', 'b', 'test']"
1537,"The %MktEx macro has an extensive catalog of orthogonal arrays available for searching. This has two practical benefits for experimental design practitioners: *	If a design that satisfies your constraints already exists, you do not spend time trying to generate a design; the %MktEx macro simply reports it. (In the log above, you can see that searches were performed. This is because the orthogonal array catalog does not know about interactions.) *	You do not need to check a catalog of known designs, and then check for suitable fractional factorials, and then move on to more extreme measures. You posit your problem, and the macro simulates the steps that someone with considerable expertise in experimental design would take to find a good design.",DO,753,"['mktex', 'macro', 'ha', 'extensive', 'catalog', 'orthogonal', 'array', 'available', 'searching', 'ha', 'two', 'practical', 'benefit', 'experimental', 'design', 'practitioner', '\tif', 'design', 'satisfies', 'constraint', 'already', 'exists', 'spend', 'time', 'trying', 'generate', 'design', 'mktex', 'macro', 'simply', 'report', 'log', 'see', 'search', 'performed', 'orthogonal', 'array', 'catalog', 'doe', 'know', 'interaction', '\tyou', 'need', 'check', 'catalog', 'known', 'design', 'check', 'suitable', 'fractional', 'factorial', 'move', 'extreme', 'measure', 'posit', 'problem', 'macro', 'simulates', 'step', 'someone', 'considerable', 'expertise', 'experimental', 'design', 'would', 'take', 'find', 'good', 'design']"
1538,"Any experiment should begin with a precise definition of the purpose, or objectives, of the experiment. This purpose can then be further refined to include the specific questions that will be answered as a result of the experiment. After the questions have been documented, the population of interest must be defined. The population of interest determines the scope of the conclusions of the experiment. Based upon the population of interest, you must determine whether it is possible to collect the desired information from the entire population of interest. Most of the time, you lack the time or resources to collect population data and must collect information on a sample of the population. Recall that this sample should be a random sample. The final step before actually collecting and analyzing the data is to define the data collection protocol.",DO,854,"['experiment', 'begin', 'precise', 'definition', 'purpose', 'objective', 'experiment', 'purpose', 'refined', 'include', 'specific', 'question', 'answered', 'result', 'experiment', 'question', 'documented', 'population', 'interest', 'must', 'defined', 'population', 'interest', 'determines', 'scope', 'conclusion', 'experiment', 'based', 'upon', 'population', 'interest', 'must', 'determine', 'whether', 'possible', 'collect', 'desired', 'information', 'entire', 'population', 'interest', 'time', 'lack', 'time', 'resource', 'collect', 'population', 'data', 'must', 'collect', 'information', 'sample', 'population', 'recall', 'sample', 'random', 'sample', 'final', 'step', 'actually', 'collecting', 'analyzing', 'data', 'define', 'data', 'collection', 'protocol']"
1539,"In agriculture, you would block on location in a field or mower-driver. In credit cards, you could block on previous mails, point status, risk groups, or other internal groupings. In a retail setting, you could block on months since last purchase, or frequency of purchase. In the case of designs rolled out over time, the phase of the design should be considered a block. Traditionally, you are interested in a block?s effect to account for another source of variation in the data, not to include block-to-block variation as part of the model. In agriculture, health sciences, and so on, this is almost always the case. For the direct marketing context, there is no good general rule. Mail List might be a random source of noise, and risk group may have a fixed, deterministic effect, or vice versa. These considerations will affect your analysis. Finally, there are two sides to the idea of blocking. The first is the one already described?blocks are a restriction on randomization meant to eliminate a potentially large source of error. The second is an implicit assumption made by traditional practitioners?that of no block by treatment interaction. Much of the power of blocking, traditionally, comes from this latter assumption, which is probably not a good one in the direct marketing context. However, the large sample sizes should help you use blocks both to eliminate large sources of variation and recognize?and capitalize on? those block by treatment interactions.",DO,1476,"['agriculture', 'would', 'block', 'location', 'field', 'mowerdriver', 'credit', 'card', 'could', 'block', 'previous', 'mail', 'point', 'status', 'risk', 'group', 'internal', 'grouping', 'retail', 'setting', 'could', 'block', 'month', 'since', 'last', 'purchase', 'frequency', 'purchase', 'case', 'design', 'rolled', 'time', 'phase', 'design', 'considered', 'block', 'traditionally', 'interested', 'block', 'effect', 'account', 'another', 'source', 'variation', 'data', 'include', 'blocktoblock', 'variation', 'part', 'model', 'agriculture', 'health', 'science', 'almost', 'always', 'case', 'direct', 'marketing', 'context', 'good', 'general', 'rule', 'mail', 'list', 'might', 'random', 'source', 'noise', 'risk', 'group', 'may', 'fixed', 'deterministic', 'effect', 'vice', 'versa', 'consideration', 'affect', 'analysis', 'finally', 'two', 'side', 'idea', 'blocking', 'first', 'one', 'already', 'describedblocks', 'restriction', 'randomization', 'meant', 'eliminate', 'potentially', 'large', 'source', 'error', 'second', 'implicit', 'assumption', 'made', 'traditional', 'practitionersthat', 'block', 'treatment', 'interaction', 'much', 'power', 'blocking', 'traditionally', 'come', 'latter', 'assumption', 'probably', 'good', 'one', 'direct', 'marketing', 'context', 'however', 'large', 'sample_size', 'help', 'use', 'block', 'eliminate', 'large', 'source', 'variation', 'recognizeand', 'capitalize', 'block', 'treatment', 'interaction']"
1540,"The typical experiment will have at least two factors of interest, but may have many more. In addition, the factors themselves may have more than two levels each. This will typically occur with categorical factors, when there are several categories of interest, or with continuous factors where a linear relationship is suspected to be inadequate. This section deals with each of these extensions in turn.",DO,405,"['typical', 'experiment', 'least', 'two', 'factor', 'interest', 'may', 'many', 'addition', 'factor', 'may', 'two', 'level', 'typically', 'occur', 'categorical', 'factor', 'several', 'category', 'interest', 'continuous', 'factor', 'linear', 'relationship', 'suspected', 'inadequate', 'section', 'deal', 'extension', 'turn']"
1541,"The variance of a distribution affects the power as well. This does not explicitly show up in the response rate example because responder counts typically follow a binomial distribution, and the variance of a binomial random variable is a function of the success rate.",DO,268,"['variance', 'distribution', 'affect', 'power', 'well', 'doe', 'explicitly', 'show', 'response', 'rate', 'example', 'responder', 'count', 'typically', 'follow', 'binomial', 'distribution', 'variance', 'binomial', 'random', 'variable', 'function', 'success', 'rate']"
1542,"The technical definitions for D-, A-, and G-efficiency are in the online documentation. Unless you are fairly comfortable with matrix algebra, the technical definitions might not be very enlightening. The general idea is that they compare a function of the optimality criterion in question to the theoretical ideal value, calculated on a (usually non-existent) orthogonal design of the same size. It is safest to compare these efficiencies to one another, rather than getting too concerned with the actual values. The average prediction standard error is the square root of the average variance for prediction over the set of candidate points. That is, for every treatment (record) in the candidate set, you could calculate a standard error of prediction (assuming the error variance was 1). For a treatment x? and a design X, this is technically x?(X?X)-1x, and if you average that over all of the treatments x? in the candidate set, you have the average prediction variance. Taking the square root yields the average prediction standard error. This is the quantity optimized by the I-optimality criterion. Comparing Optimal Designs (Self-Study)",DO,1146,"['technical', 'definition', 'gefficiency', 'online', 'documentation', 'unless', 'fairly', 'comfortable', 'matrix', 'algebra', 'technical', 'definition', 'might', 'enlightening', 'general', 'idea', 'compare', 'function', 'optimality', 'criterion', 'question', 'theoretical', 'ideal', 'value', 'calculated', 'usually', 'nonexistent', 'orthogonal', 'design', 'size', 'safest', 'compare', 'efficiency', 'one', 'another', 'rather', 'getting', 'concerned', 'actual', 'value', 'average', 'prediction', 'standard_error', 'square', 'root', 'average', 'variance', 'prediction', 'set', 'candidate', 'point', 'every', 'treatment', 'record', 'candidate', 'set', 'could', 'calculate', 'standard_error', 'prediction', 'assuming', 'error', 'variance', 'wa', '1', 'treatment', 'x', 'design', 'x', 'technically', 'xxx1x', 'average', 'treatment', 'x', 'candidate', 'set', 'average', 'prediction', 'variance', 'taking', 'square', 'root', 'yield', 'average', 'prediction', 'standard_error', 'quantity', 'optimized', 'ioptimality', 'criterion', 'comparing', 'optimal', 'design', 'selfstudy']"
1543,"This is the general flow for generating an optimal design: 1.	Generate a set of candidate treatments, taking care to exclude any infeasible combinations. 2.	Use the OPTEX procedure to generate an optimal design. Of course, you could generate several designs and choose the one most suited to your needs. Generating the design entails making several specifications; for example, the model you would like to fit, how many observations you can afford, the criterion you would like to optimize, and the search algorithm you would like to use. 3.	To choose from several designs, you need to consider the optimality criteria. You may also choose to evaluate the aliasing that takes place with each design. To see the aliasing patterns, you can use the GLM procedure with the ALIASING option in the MODEL statement. An example of this code follows. 4.	When you find a design that meets your needs, then you can roll it out and gather data. The analysis of an optimal design can be treated like the analysis of any of the other designs considered. In the case of the fractional factorials, you know exactly what factors are aliased, and so you can assess how sure you are that the A effect actually measures the effect of the A factor. With an optimal design, you specify the model that you suspect is important. Any departure from that model will lead to a potential bias in your parameter estimates. The OPTEX procedure allows you flexibility in building designs. Here are some important features to note about the OPTEX procedure. The OPTEX procedure has algorithms to search for U- and S-optimal designs. These designs do not maximize or minimize some function of the information or variance, as A- and D- optimal designs do. Instead, these designs seek to optimize the design based on distances in the design space. A U- optimal design seeks to minimize the distance from all of the points in the list of candidate points to the points in the design. S-optimal designs seek to maximize the distance between each point in the design and all of the other points in the design. Both of these distance-based measures try to fill the factor space with observations, rather than maximize some fitness measure of the design. *	You can create the candidate data set however you are comfortable. The DATA step, the PLAN procedure, and the FACTEX procedure are reasonable choices. *	If you have a large number of factors with a large number of levels, the full factorial might be too large for the OPTEX procedure to operate with. If that happens, you can use the FACTEX procedure to generate a fractional factorial for use as a candidate set. Of course, if you can run the %MktEx macro, that is a better choice because you will have access to more potential designs and algorithms. *	As in the FACTEX procedure, you specify the effects of interest in a MODEL statement. You should include the interaction terms and higher-order polynomial terms of interest as well. These designs are custom-made to estimate the parameters specifically named in the MODEL statement, and may assume that every other factor is negligible in order to estimate the named factors. *	By default, the OPTEX procedure seeks to find a design with n runs, where n is the number of parameters you want to estimate plus 10. If you want a design with as few runs as possible, you can specify that you want a saturated design. As with the fractional factorials, the smaller the design gets, the more confounding takes place. In the context of optimal designs, however, it is rare that you will be able to write out a set of simple confounding rules. If you want a specific number of runs, then you can set that number as well. ?	Notice that (number of degrees of freedom in the model + 10) may be a reasonable design size if your only concern is having sufficient degrees of freedom to estimate parameters and an error term. In the direct marketing context (as well as many other contexts) this rule could lead you to design sizes that eliminate the possibility of balance or orthogonality! Even if you do not have SAS/IML (necessary to ru",DO,4096,"['general', 'flow', 'generating', 'optimal', 'design', '1\tgenerate', 'set', 'candidate', 'treatment', 'taking', 'care', 'exclude', 'infeasible', 'combination', '2\tuse', 'optex', 'procedure', 'generate', 'optimal', 'design', 'course', 'could', 'generate', 'several', 'design', 'choose', 'one', 'suited', 'need', 'generating', 'design', 'entail', 'making', 'several', 'specification', 'example', 'model', 'would', 'like', 'fit', 'many', 'observation', 'afford', 'criterion', 'would', 'like', 'optimize', 'search', 'algorithm', 'would', 'like', 'use', '3\tto', 'choose', 'several', 'design', 'need', 'consider', 'optimality', 'criterion', 'may', 'also', 'choose', 'evaluate', 'aliasing', 'take', 'place', 'design', 'see', 'aliasing', 'pattern', 'use', 'glm', 'procedure', 'aliasing', 'option', 'model_statement', 'example', 'code', 'follows', '4\twhen', 'find', 'design', 'meet', 'need', 'roll', 'gather', 'data', 'analysis', 'optimal', 'design', 'treated', 'like', 'analysis', 'design', 'considered', 'case', 'fractional', 'factorial', 'know', 'exactly', 'factor', 'aliased', 'ass', 'sure', 'effect', 'actually', 'measure', 'effect', 'factor', 'optimal', 'design', 'specify', 'model', 'suspect', 'important', 'departure', 'model', 'lead', 'potential', 'bias', 'parameter_estimate', 'optex', 'procedure', 'allows', 'flexibility', 'building', 'design', 'important', 'feature', 'note', 'optex', 'procedure', 'optex', 'procedure', 'ha', 'algorithm', 'search', 'u', 'soptimal', 'design', 'design', 'maximize', 'minimize', 'function', 'information', 'variance', 'optimal', 'design', 'instead', 'design', 'seek', 'optimize', 'design', 'based', 'distance', 'design', 'space', 'u', 'optimal', 'design', 'seek', 'minimize', 'distance', 'point', 'list', 'candidate', 'point', 'point', 'design', 'soptimal', 'design', 'seek', 'maximize', 'distance', 'point', 'design', 'point', 'design', 'distancebased', 'measure', 'try', 'fill', 'factor', 'space', 'observation', 'rather', 'maximize', 'fitness', 'measure', 'design', '\tyou', 'create', 'candidate', 'data_set', 'however', 'comfortable', 'data', 'step', 'plan', 'procedure', 'factex', 'procedure', 'reasonable', 'choice', '\tif', 'large', 'number', 'factor', 'large', 'number', 'level', 'full', 'factorial', 'might', 'large', 'optex', 'procedure', 'operate', 'happens', 'use', 'factex', 'procedure', 'generate', 'fractional', 'factorial', 'use', 'candidate', 'set', 'course', 'run', 'mktex', 'macro', 'better', 'choice', 'access', 'potential', 'design', 'algorithm', '\tas', 'factex', 'procedure', 'specify', 'effect', 'interest', 'model_statement', 'include', 'interaction', 'term', 'higherorder', 'polynomial', 'term', 'interest', 'well', 'design', 'custommade', 'estimate', 'parameter', 'specifically', 'named', 'model_statement', 'may', 'assume', 'every', 'factor', 'negligible', 'order', 'estimate', 'named', 'factor', '\tby', 'default', 'optex', 'procedure', 'seek', 'find', 'design', 'n', 'run', 'n', 'number', 'parameter', 'want', 'estimate', 'plus', '10', 'want', 'design', 'run', 'possible', 'specify', 'want', 'saturated', 'design', 'fractional', 'factorial', 'smaller', 'design', 'get', 'confounding', 'take', 'place', 'context', 'optimal', 'design', 'however', 'rare', 'able', 'write', 'set', 'simple', 'confounding', 'rule', 'want', 'specific', 'number', 'run', 'set', 'number', 'well', '\tnotice', 'number', 'degree', 'freedom', 'model', '', '10', 'may', 'reasonable', 'design', 'size', 'concern', 'sufficient', 'degree', 'freedom', 'estimate', 'parameter', 'error', 'term', 'direct', 'marketing', 'context', 'well', 'many', 'context', 'rule', 'could', 'lead', 'design', 'size', 'eliminate', 'possibility', 'balance', 'orthogonality', 'even', 'sasiml', 'necessary', 'ru']"
1544,"In traditional experimental design, reducing on the number of points in the factor space would mean fewer experimental units and a reduced cost design. In the direct marketing context, fewer points in the factor space means *	fewer unique types of mail pieces, leading to lower printing costs *	fewer scripts for the telemarketers to learn *	fewer e-mail messages to manage without necessarily restricting the amount of information you can glean from a test. With the exception of the confounding and aliasing involved, there are no differences in the inferences between a full factorial and a fractional factorial. This is demonstrated in the analysis portion of the following demonstration. In this context, one needs to give careful consideration to sample size. Fractional factorials were first used in the context of experiments that were so expensive that one could not afford one experimental unit for each treatment. However, in direct marketing, you generally have millions of experimental units (individuals or households, depending on your point of view). Your task is to cleverly assign mail volume (telemarketing volume, and so on) to each treatment (combination of factors) such that you can answer the questions of interest.",DO,1239,"['traditional', 'experimental', 'design', 'reducing', 'number', 'point', 'factor', 'space', 'would', 'mean', 'fewer', 'experimental', 'unit', 'reduced', 'cost', 'design', 'direct', 'marketing', 'context', 'fewer', 'point', 'factor', 'space', 'mean', '\tfewer', 'unique', 'type', 'mail', 'piece', 'leading', 'lower', 'printing', 'cost', '\tfewer', 'script', 'telemarketers', 'learn', '\tfewer', 'email', 'message', 'manage', 'without', 'necessarily', 'restricting', 'amount', 'information', 'glean', 'test', 'exception', 'confounding', 'aliasing', 'involved', 'difference', 'inference', 'full', 'factorial', 'fractional', 'factorial', 'demonstrated', 'analysis', 'portion', 'following', 'demonstration', 'context', 'one', 'need', 'give', 'careful', 'consideration', 'sample_size', 'fractional', 'factorial', 'first', 'used', 'context', 'experiment', 'expensive', 'one', 'could', 'afford', 'one', 'experimental', 'unit', 'treatment', 'however', 'direct', 'marketing', 'generally', 'million', 'experimental', 'unit', 'individual', 'household', 'depending', 'point', 'view', 'task', 'cleverly', 'assign', 'mail', 'volume', 'telemarketing', 'volume', 'treatment', 'combination', 'factor', 'answer', 'question', 'interest']"
1545,"Consider a series of credit card offers, where the factors of interest are the introductory (or ?teaser?) interest rate, and the rate that takes effect after the introductory period expires, commonly called a ?goto? rate.",DO,221,"['consider', 'series', 'credit', 'card', 'offer', 'factor', 'interest', 'introductory', 'teaser', 'interest', 'rate', 'rate', 'take', 'effect', 'introductory', 'period', 'expires', 'commonly', 'called', 'goto', 'rate']"
1546,"Notice that the traditional model with blocks assumes an additive effect due to blocks, but no block by treatment interaction. That is because, in the traditional experimental design framework, the degrees of freedom that measure the block by treatment interactions are the same as the degrees of freedom for error. Including a block by treatment interaction in that context eliminated the ability to test. However, in the direct marketing context, where you have many experimental units and hence many degrees of freedom for error, it is feasible to test for these interaction effects.",DO,586,"['notice', 'traditional', 'model', 'block', 'assumes', 'additive', 'effect', 'due', 'block', 'block', 'treatment', 'interaction', 'traditional', 'experimental', 'design', 'framework', 'degree', 'freedom', 'measure', 'block', 'treatment', 'interaction', 'degree', 'freedom', 'error', 'including', 'block', 'treatment', 'interaction', 'context', 'eliminated', 'ability', 'test', 'however', 'direct', 'marketing', 'context', 'many', 'experimental', 'unit', 'hence', 'many', 'degree', 'freedom', 'error', 'feasible', 'test', 'interaction', 'effect']"
1547,"Factors are typically features that you have control over. Features of the mail piece, or of the telemarketing script are factors. Of course, there are some sources of variability in the response metric that you will not have control over. You have no control over the number of points that an individual has on a reward credit card; you have no control over where someone lives, or how recently they were mailed. In a sense, those features are attributes of the individual, not the offer. Features that you cannot control might be considered a nuisance?there is no (practical) way for you to control them, but they may impact the response or spend behavior of the individuals in your test. In order to account for the variability due to these factors, and perhaps even capitalize on it, you need to account for these factors in your analysis.",DO,843,"['factor', 'typically', 'feature', 'control', 'feature', 'mail', 'piece', 'telemarketing', 'script', 'factor', 'course', 'source', 'variability', 'response', 'metric', 'control', 'control', 'number', 'point', 'individual', 'ha', 'reward', 'credit', 'card', 'control', 'someone', 'life', 'recently', 'mailed', 'sense', 'feature', 'attribute', 'individual', 'offer', 'feature', 'cannot', 'control', 'might', 'considered', 'nuisancethere', 'practical', 'way', 'control', 'may', 'impact', 'response', 'spend', 'behavior', 'individual', 'test', 'order', 'account', 'variability', 'due', 'factor', 'perhaps', 'even', 'capitalize', 'need', 'account', 'factor', 'analysis']"
1548,The ONEWAYANOVA statement assumes equal variances between the groups. Notice that a larger standard deviation makes it more difficult to detect the same size difference.,DO,169,"['onewayanova', 'statement', 'assumes', 'equal', 'variance', 'group', 'notice', 'larger', 'standard', 'deviation', 'make', 'difficult', 'detect', 'size', 'difference']"
1549,"Among the many complications that arise in real world situations are *	restrictions on number of unique treatments, *	restrictions on combinations of factors, and/or *	different numbers of levels for each factor.",DO,212,"['among', 'many', 'complication', 'arise', 'real', 'world', 'situation', '\trestrictions', 'number', 'unique', 'treatment', '\trestrictions', 'combination', 'factor', 'andor', '\tdifferent', 'number', 'level', 'factor']"
1550,"There are six different optimality criteria available in the OPTEX procedure. The technical notation which follows assumes a design matrix, where each row represents an experimental unit in the test and their associated treatment, called X, and a set of candidate points, where each row is a potential treatment, called C. Sometimes people refer to the list of treatments that comprise X as the set of design points D. So you get a design (X) by choosing some n points (D) from a list of candidates (C). Which n points you choose depends on your criterion, but you are typically trying to ensure that your design is ?close? to being orthogonal and balanced. D-optimality Technically, a D-optimal design maximizes |X?X|, or minimizes |(X?X)-1|. Practically, D-optimal designs have the property that they minimize the size of the confidence region around all of the parameter estimates. They are popular with practitioners in many different disciplines. This is the default criterion in the OPTEX procedure, and is the most computationally efficient criterion to search for. D-optimal designs are invariant to nonsingular re-coding of the variables, so it does not matter whether you choose to re-code numeric inputs or use the original values. The values of the determinants might change, but the same design will have the optimal value regardless of the coding method. A-optimality An A-optimal design minimizes the sum of the diagonal elements of (X?X)-1, also known as the trace or tr((X?X)-1). This sum is tied to the total variance of the parameter estimates in your model. An A-optimal design, in practice, minimizes the average variance of the parameter estimates in your model. The OPTEX procedure can be used to find the best design according to the A-optimality criterion, rather than the default D-optimality criterion. This is done with the CRITERION=A option in the GENERATE statement. Other Information Based Criteria There are other well known optimality criteria that try to optimize some function of X?X, using that function to stand in for a feature of the analysis that is important. G-optimal designs seek to minimize the largest variance of any predicted value in the candidate set C. This ?minimizing the maximum variance? is an attractive criterion, but has two faults in practice. First, it is very hard to optimize this criterion?there is no efficient algorithm for this search. Second, it may be too strict. There may be good designs that are not G-optimal, or the average prediction may suffer across the board to reduce the variance in a small region of the sample space. In practice, one way to skirt the first problem is to search for a D-optimal design, retain every design evaluated during that search, and use the design that looks best according to the G-optimality criterion. I-optimal designs seek to minimize the average variance of the predictions across the points in C. Under certain conditions, this criterion yields the same design as A-optimality. Using the CODING=ORTH option on the PROC OPTEX statement and the CRITERION=A option in the GENERATE statement will yield an I-optimal design. Both G- and I-optimality are invariant to re-coding of the factors, because they both deal with variance of the predictions at each point in C, which is static, rather than (solely) a function of the matrix X?X, which can change. Distance Based Criteria The information based criteria seek to find a design with good prediction properties. The differences between them are basically a function of the way you think about good prediction. There is another way to consider selecting treatments D from a candidate set C. You could think about the space spanned by all of the candidate points, and try to select points for the design matrix that best spans that space in some sense. U- and S-optimality try to optimize the design points by uniformly placing points in the space, or by spreading points widely in the space. These criteria offer a different point of view, but may not be too useful in the direct marketing context. Because these criteria are concerned",DO,4094,"['six', 'different', 'optimality', 'criterion', 'available', 'optex', 'procedure', 'technical', 'notation', 'follows', 'assumes', 'design', 'matrix', 'row', 'represents', 'experimental', 'unit', 'test', 'associated', 'treatment', 'called', 'x', 'set', 'candidate', 'point', 'row', 'potential', 'treatment', 'called', 'c', 'sometimes', 'people', 'refer', 'list', 'treatment', 'comprise', 'x', 'set', 'design', 'point', 'get', 'design', 'x', 'choosing', 'n', 'point', 'list', 'candidate', 'c', 'n', 'point', 'choose', 'depends', 'criterion', 'typically', 'trying', 'ensure', 'design', 'close', 'orthogonal', 'balanced', 'doptimality', 'technically', 'doptimal', 'design', 'maximizes', 'xx', 'minimizes', 'xx1', 'practically', 'doptimal', 'design', 'property', 'minimize', 'size', 'confidence', 'region', 'around', 'parameter_estimate', 'popular', 'practitioner', 'many', 'different', 'discipline', 'default', 'criterion', 'optex', 'procedure', 'computationally', 'efficient', 'criterion', 'search', 'doptimal', 'design', 'invariant', 'nonsingular', 'recoding', 'variable', 'doe', 'matter', 'whether', 'choose', 'recode', 'numeric', 'input', 'use', 'original', 'value', 'value', 'determinant', 'might', 'change', 'design', 'optimal', 'value', 'regardless', 'coding', 'method', 'aoptimality', 'aoptimal', 'design', 'minimizes', 'sum', 'diagonal', 'element', 'xx1', 'also', 'known', 'trace', 'trxx1', 'sum', 'tied', 'total', 'variance', 'parameter_estimate', 'model', 'aoptimal', 'design', 'practice', 'minimizes', 'average', 'variance', 'parameter_estimate', 'model', 'optex', 'procedure', 'used', 'find', 'best', 'design', 'according', 'aoptimality', 'criterion', 'rather', 'default', 'doptimality', 'criterion', 'done', 'criteriona', 'option', 'generate', 'statement', 'information', 'based', 'criterion', 'well', 'known', 'optimality', 'criterion', 'try', 'optimize', 'function', 'xx', 'using', 'function', 'stand', 'feature', 'analysis', 'important', 'goptimal', 'design', 'seek', 'minimize', 'largest', 'variance', 'predicted', 'value', 'candidate', 'set', 'c', 'minimizing', 'maximum', 'variance', 'attractive', 'criterion', 'ha', 'two', 'fault', 'practice', 'first', 'hard', 'optimize', 'criterionthere', 'efficient', 'algorithm', 'search', 'second', 'may', 'strict', 'may', 'good', 'design', 'goptimal', 'average', 'prediction', 'may', 'suffer', 'across', 'board', 'reduce', 'variance', 'small', 'region', 'sample', 'space', 'practice', 'one', 'way', 'skirt', 'first', 'problem', 'search', 'doptimal', 'design', 'retain', 'every', 'design', 'evaluated', 'search', 'use', 'design', 'look', 'best', 'according', 'goptimality', 'criterion', 'ioptimal', 'design', 'seek', 'minimize', 'average', 'variance', 'prediction', 'across', 'point', 'c', 'certain', 'condition', 'criterion', 'yield', 'design', 'aoptimality', 'using', 'codingorth', 'option', 'proc', 'optex', 'statement', 'criteriona', 'option', 'generate', 'statement', 'yield', 'ioptimal', 'design', 'g', 'ioptimality', 'invariant', 'recoding', 'factor', 'deal', 'variance', 'prediction', 'point', 'c', 'static', 'rather', 'solely', 'function', 'matrix', 'xx', 'change', 'distance', 'based', 'criterion', 'information', 'based', 'criterion', 'seek', 'find', 'design', 'good', 'prediction', 'property', 'difference', 'basically', 'function', 'way', 'think', 'good', 'prediction', 'another', 'way', 'consider', 'selecting', 'treatment', 'candidate', 'set', 'c', 'could', 'think', 'space', 'spanned', 'candidate', 'point', 'try', 'select', 'point', 'design', 'matrix', 'best', 'span', 'space', 'sense', 'u', 'soptimality', 'try', 'optimize', 'design', 'point', 'uniformly', 'placing', 'point', 'space', 'spreading', 'point', 'widely', 'space', 'criterion', 'offer', 'different', 'point', 'view', 'may', 'useful', 'direct', 'marketing', 'context', 'criterion', 'concerned']"
1551,"Canonical correlations greater than 0.316 (which is to say, r2 between variables greater than 0.1) are detailed in this small table. Again, the correlations farthest from zero are among the variables that are impacted by the restrictions. The fact that you cannot offer one level of one factor in combination with one level of another factor means that those factors can never be orthogonal. This table attempts to quantify that departure from orthogonality. Summary of Frequencies There are 2 Canonical Correlations Greater Than 0.316 * - Indicates Unequal Frequencies",DO,569,"['canonical', 'correlation', 'greater', '0316', 'say', 'r2', 'variable', 'greater', '01', 'detailed', 'small', 'table', 'correlation', 'farthest', 'zero', 'among', 'variable', 'impacted', 'restriction', 'fact', 'cannot', 'offer', 'one', 'level', 'one', 'factor', 'combination', 'one', 'level', 'another', 'factor', 'mean', 'factor', 'never', 'orthogonal', 'table', 'attempt', 'quantify', 'departure', 'orthogonality', 'summary', 'frequency', '2', 'canonical', 'correlation', 'greater', '0316', '', '', 'indicates', 'unequal', 'frequency']"
1552,"Other jargon that used in this context is similar, but is often used slightly differently. One could say that A is aliased with the BC interaction. That statement means virtually the same thing as the statement that A is confounded with BC, but there is a subtle distinction. People generally reserve the word confounded for interactions that stem from the defining fraction(s), whereas aliasing reflects the fact that the contrasts for two factors could be identical even though that was not part of the defining rules. This subtlety is merely a thought exercise in an example this small; in the demonstration it will be easier to see the distinction.",DO,652,"['jargon', 'used', 'context', 'similar', 'often', 'used', 'slightly', 'differently', 'one', 'could', 'say', 'aliased', 'bc', 'interaction', 'statement', 'mean', 'virtually', 'thing', 'statement', 'confounded', 'bc', 'subtle', 'distinction', 'people', 'generally', 'reserve', 'word', 'confounded', 'interaction', 'stem', 'defining', 'fraction', 'whereas', 'aliasing', 'reflects', 'fact', 'contrast', 'two', 'factor', 'could', 'identical', 'even', 'though', 'wa', 'part', 'defining', 'rule', 'subtlety', 'merely', 'thought', 'exercise', 'example', 'small', 'demonstration', 'easier', 'see', 'distinction']"
1553,"For the most part, the example designs that have been considered consisted of most, if not all, two- level factors. Two-level factors are easy to work with and yield designs that are easy to analyze. Of course, there are several situations where two-level factors are not appropriate, including categorical factors with several levels and continuous factors for which you want to estimate higher-order terms. In either of those situations, you can design experiments with those concerns in mind. Designs to accommodate these requirements exist, and they typically can be created using the same %MktEx macro-based approach as you have already seen. However, sometimes the need to estimate higher-order effects, or a particular interaction, is not recognized until after the initial experiment has been run. In such a situation, it is often feasible to run a second, often smaller, experiment to yield enough information to estimate the quantities newly of interest. Typically, the initial experiment and the follow-up treatments will be analyzed as though they had been in blocks.",DO,1079,"['part', 'example', 'design', 'considered', 'consisted', 'two', 'level', 'factor', 'twolevel', 'factor', 'easy', 'work', 'yield', 'design', 'easy', 'analyze', 'course', 'several', 'situation', 'twolevel', 'factor', 'appropriate', 'including', 'categorical', 'factor', 'several', 'level', 'continuous', 'factor', 'want', 'estimate', 'higherorder', 'term', 'either', 'situation', 'design', 'experiment', 'concern', 'mind', 'design', 'accommodate', 'requirement', 'exist', 'typically', 'created', 'using', 'mktex', 'macrobased', 'approach', 'already', 'seen', 'however', 'sometimes', 'need', 'estimate', 'higherorder', 'effect', 'particular', 'interaction', 'recognized', 'initial', 'experiment', 'ha', 'run', 'situation', 'often', 'feasible', 'run', 'second', 'often', 'smaller', 'experiment', 'yield', 'enough', 'information', 'estimate', 'quantity', 'newly', 'interest', 'typically', 'initial', 'experiment', 'followup', 'treatment', 'analyzed', 'though', 'block']"
1554,"Some features of the time series are noteworthy, but discussion will be postponed until after attempting to use ordinary regression analysis to facilitate planning. The following code fits a regression model expressing U.S. oil production as being influenced by the other seven sources of production. ods trace on; proc reg data=work.WorldOil outest=work.EstFullModel; model USA=Canada Iraq Mexico OAPEC OPEC PersianGulf Venezuela / vif corrb influence edf press aic sbc; run; quit; ods trace off; Using the ODS TRACE feature, you can discover ODS tables associated with PROC REG and capture these for your analysis. ODS TRACE reveals that a parameter estimates table is available, along with others. The following code captures all of the available ODS tables. ods output ParameterEstimates=work.ParmEst ANOVA=work.OutAOV CorrB=work.CorrB FitStatistics=work.FitStatistics OutputStatistics=work.OutStat ResidualStatistics=work.ResStat; proc reg data=work.WorldOil outest=work.EstFullModel; model USA=Canada Iraq Mexico OAPEC OPEC PersianGulf Venezuela / vif corrb influence edf press aic sbc; run; quit; The display of the estimates table is customized using PROC PRINT. ods html; proc print data=work.ParmEst noobs; var Variable DF Estimate StdErr Probt VarianceInflation; run; ods html close; The results follow.",FE,1314,"['feature', 'time', 'series', 'noteworthy', 'discussion', 'postponed', 'attempting', 'use', 'ordinary', 'regression', 'analysis', 'facilitate', 'planning', 'following', 'code', 'fit', 'regression_model', 'expressing', 'u', 'oil', 'production', 'influenced', 'seven', 'source', 'production', 'od', 'trace', 'proc', 'reg', 'dataworkworldoil', 'outestworkestfullmodel', 'model', 'usacanada', 'iraq', 'mexico', 'oapec', 'opec', 'persiangulf', 'venezuela', '', 'vif', 'corrb', 'influence', 'edf', 'press', 'aic', 'sbc', 'run', 'quit', 'od', 'trace', 'using', 'od', 'trace', 'feature', 'discover', 'od', 'table', 'associated', 'proc', 'reg', 'capture', 'analysis', 'od', 'trace', 'reveals', 'parameter_estimate', 'table', 'available', 'along', 'others', 'following', 'code', 'capture', 'available', 'od', 'table', 'od', 'output', 'parameterestimatesworkparmest', 'anovaworkoutaov', 'corrbworkcorrb', 'fitstatisticsworkfitstatistics', 'outputstatisticsworkoutstat', 'residualstatisticsworkresstat', 'proc', 'reg', 'dataworkworldoil', 'outestworkestfullmodel', 'model', 'usacanada', 'iraq', 'mexico', 'oapec', 'opec', 'persiangulf', 'venezuela', '', 'vif', 'corrb', 'influence', 'edf', 'press', 'aic', 'sbc', 'run', 'quit', 'display', 'estimate', 'table', 'customized', 'using', 'proc', 'print', 'od', 'html', 'proc', 'print', 'dataworkparmest', 'noobs', 'var', 'variable', 'df', 'estimate', 'stderr', 'probt', 'varianceinflation', 'run', 'od', 'html', 'close', 'result', 'follow']"
1555,"In a production process, examination of the effects of settings that are at least partially under the control of the process manager help the manager to optimize production. The process must be viewed as a time series because temporal effects contribute to the process. For example, reducing a temperature setting will not have an immediate effect on dropping the temperature to the desired point. Visualization contributes to understanding a time series. This work will emphasize the use of SAS ODS Graphics, available in SAS 9.2 and later. (An experimental version is available in SAS 9.1.3.) ODS Graphics requires SAS/GRAPH software. In addition to ODS Graphics, specific SAS/GRAPH procedures will be employed. Examples from SAS Enterprise Guide will also be given. While ODS Graphics generally provide adequate results, you can choose to customize your plots using SAS/GRAPH procedures directly. To illustrate this choice, consider that the first plot of the airline passengers time series suggests that a dramatic rise in passengers occurred between 1990 and 2000. Other features are also suggested. However, the use of default settings for plotting has exaggerated the magnitude of the increase in passenger counts. The following plot utilizes SAS/GRAPH software and user customization to produce a more representative plot.",FE,1330,"['production', 'process', 'examination', 'effect', 'setting', 'least', 'partially', 'control', 'process', 'manager', 'help', 'manager', 'optimize', 'production', 'process', 'must', 'viewed', 'time', 'series', 'temporal', 'effect', 'contribute', 'process', 'example', 'reducing', 'temperature', 'setting', 'immediate', 'effect', 'dropping', 'temperature', 'desired', 'point', 'visualization', 'contributes', 'understanding', 'time', 'series', 'work', 'emphasize', 'use', 'sa', 'od', 'graphic', 'available', 'sa', '92', 'later', 'experimental', 'version', 'available', 'sa', '913', 'od', 'graphic', 'requires', 'sasgraph', 'software', 'addition', 'od', 'graphic', 'specific', 'sasgraph', 'procedure', 'employed', 'example', 'sa', 'enterprise', 'guide', 'also', 'given', 'od', 'graphic', 'generally', 'provide', 'adequate', 'result', 'choose', 'customize', 'plot', 'using', 'sasgraph', 'procedure', 'directly', 'illustrate', 'choice', 'consider', 'first', 'plot', 'airline', 'passenger', 'time', 'series', 'suggests', 'dramatic', 'rise', 'passenger', 'occurred', '1990', '2000', 'feature', 'also', 'suggested', 'however', 'use', 'default', 'setting', 'plotting', 'ha', 'exaggerated', 'magnitude', 'increase', 'passenger', 'count', 'following', 'plot', 'utilizes', 'sasgraph', 'software', 'user', 'customization', 'produce', 'representative', 'plot']"
1556,"This plot provides the most useful diagnostics for identifying the transfer function. Spikes at lags 0 and 1 suggest separate numerator parameters, and the decay pattern thereafter suggests a single denominator parameter at lag 1. The transfer function plots help you to understand the diagnosis. ods html; %CCF_TF(CCFdata=work.CCF,ParmEstData=work.ParmEst, InputVar=X); ods html close; The overlay plot follows.",FE,412,"['plot', 'provides', 'useful', 'diagnostics', 'identifying', 'transfer', 'function', 'spike', 'lag', '0', '1', 'suggest', 'separate', 'numerator', 'parameter', 'decay', 'pattern', 'thereafter', 'suggests', 'single', 'denominator', 'parameter', 'lag', '1', 'transfer', 'function', 'plot', 'help', 'understand', 'diagnosis', 'od', 'html', 'ccftfccfdataworkccfparmestdataworkparmest', 'inputvarx', 'od', 'html', 'close', 'overlay', 'plot', 'follows']"
1557,"While the plots provide compelling evidence for quadratic trend, all of the trend components introduced in this section can be employed using the macro %AutoTrend, which is described later. Surprisingly, there is some evidence that the monthly primary lead production time series is stationary. The macro %DisplayDF provides a terse mechanism for quickly displaying Dickey- Fuller statistics that are most likely to be relevant for typical time series. %DisplayDF(DSName=SAS-Data-Set, TargetVar=variable, DifList=list, Lag=number, SLag=number); The macro %DisplayDFPlot plots the p-values for the Dickey-Fuller tests and has the same arguments as %DisplayDF. The following code is employed. ods html; %DisplayDF(DSName=work.LeadMonth, TargetVar=Primary,Lag=5); title3 font=&COURSEFONT color=blue ""First Differences""; %DisplayDF(DSName=work.LeadMonth, TargetVar=Primary, DifList=1,Lag=5); title3 font=&COURSEFONT color=blue ""Second Differences""; %DisplayDF(DSName=work.LeadMonth, TargetVar=Primary, DifList=1 1,Lag=5); ods html close; The tables follow.",FE,1052,"['plot', 'provide', 'compelling', 'evidence', 'quadratic', 'trend', 'trend', 'component', 'introduced', 'section', 'employed', 'using', 'macro', 'autotrend', 'described', 'later', 'surprisingly', 'evidence', 'monthly', 'primary', 'lead', 'production', 'time', 'series', 'stationary', 'macro', 'displaydf', 'provides', 'terse', 'mechanism', 'quickly', 'displaying', 'dickey', 'fuller', 'statistic', 'likely', 'relevant', 'typical', 'time', 'series', 'displaydfdsnamesasdataset', 'targetvarvariable', 'diflistlist', 'lagnumber', 'slagnumber', 'macro', 'displaydfplot', 'plot', 'pvalues', 'dickeyfuller', 'test', 'ha', 'argument', 'displaydf', 'following', 'code', 'employed', 'od', 'html', 'displaydfdsnameworkleadmonth', 'targetvarprimarylag5', 'title3', 'fontcoursefont', 'colorblue', 'first', 'difference', 'displaydfdsnameworkleadmonth', 'targetvarprimary', 'diflist1lag5', 'title3', 'fontcoursefont', 'colorblue', 'second', 'difference', 'displaydfdsnameworkleadmonth', 'targetvarprimary', 'diflist1', '1lag5', 'od', 'html', 'close', 'table', 'follow']"
1558,The additive Winters model is best by any criteria. ods html; ods graphics on; ods output SmoothedStates=work.SmoothedStates SeasonStatePlot=work.SeasonStatePlot; proc esm data=work.Air1990_2000 out=work.out outfor=work.foreesm outest=work.estimates outstat=work.StatESM outsum=work.summary lead=12 print=(ESTIMATES STATISTICS SUMMARY STATES) plot=(MODELS FORECASTS LEVELS TRENDS SEASONS); id Date interval=month; forecast Passengers / model=addwinters; run; ods output close; ods graphics off; ods html close; The table of estimated weights follows.,FE,550,"['additive', 'winter', 'model', 'best', 'criterion', 'od', 'html', 'od', 'graphic', 'od', 'output', 'smoothedstatesworksmoothedstates', 'seasonstateplotworkseasonstateplot', 'proc', 'esm', 'dataworkair19902000', 'outworkout', 'outforworkforeesm', 'outestworkestimates', 'outstatworkstatesm', 'outsumworksummary', 'lead12', 'printestimates', 'statistic', 'summary', 'state', 'plotmodels', 'forecast', 'level', 'trend', 'season', 'id', 'date', 'intervalmonth', 'forecast', 'passenger', '', 'modeladdwinters', 'run', 'od', 'output', 'close', 'od', 'graphic', 'od', 'html', 'close', 'table', 'estimated', 'weight', 'follows']"
1559,"In the standard statistical notation, a simple linear trend model can be represented as The signal is represented by the INTERCEPT+SLOPE*TIME portion of the model and the Greek epsilon represents the noise component. In statistical linear regression analysis, the noise component is typically called the error component. Standard linear regression theory assumes that the error component has a Gaussian normal distribution. Furthermore, errors at different time points are assumed to be independent of each other. The assumption of independence and normality for the error component has come to be called white noise error. The term ?white noise? derives from acoustic engineering. Model formulation becomes a problem of identifying the mathematical form of the signal.",FE,769,"['standard', 'statistical', 'notation', 'simple', 'linear', 'trend', 'model', 'represented', 'signal', 'represented', 'interceptslopetime', 'portion', 'model', 'greek', 'epsilon', 'represents', 'noise', 'component', 'statistical', 'linear', 'regression', 'analysis', 'noise', 'component', 'typically', 'called', 'error', 'component', 'standard', 'linear', 'regression', 'theory', 'assumes', 'error', 'component', 'ha', 'gaussian', 'normal', 'distribution', 'furthermore', 'error', 'different', 'time', 'point', 'assumed', 'independent', 'assumption', 'independence', 'normality', 'error', 'component', 'ha', 'come', 'called', 'white', 'noise', 'error', 'term', 'white', 'noise', 'derives', 'acoustic', 'engineering', 'model', 'formulation', 'becomes', 'problem', 'identifying', 'mathematical', 'form', 'signal']"
1560,"Smoothed versions of the series are obtained with the following code. ods html; %PlotSmoothSeries(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date); ods html close; The plots follow.",FE,188,"['smoothed', 'version', 'series', 'obtained', 'following', 'code', 'od', 'html', 'plotsmoothseriesdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'od', 'html', 'close', 'plot', 'follow']"
1561,The third plot shown above uses a bar chart to visualize the multiplicative seasonal factors. The sample spectral density will help provide additional information about the nature of the seasonality. proc spectra data=work.Air1990_2000 out=work.Periodogram s; var Passengers; weights Parzen; run;,FE,296,"['third', 'plot', 'shown', 'us', 'bar', 'chart', 'visualize', 'multiplicative', 'seasonal', 'factor', 'sample', 'spectral', 'density', 'help', 'provide', 'additional', 'information', 'nature', 'seasonality', 'proc', 'spectrum', 'dataworkair19902000', 'outworkperiodogram', 'var', 'passenger', 'weight', 'parzen', 'run']"
1562,"The negative correlation of the estimates reflects the delicate balancing act in climbing a ridge to maximize an objective function. The ridge is the numeric result of collinear variables in the model. Movement that causes one estimate to increase necessarily causes the other estimates to decrease. The use of a mountain ridge to visualize the numerics associated with multicollinearity is the source of a solution to the problem called ridge regression. ?	A least squares problem seeks to minimize an objective function, namely the sum of squared errors, and a closed form solution to the minimization problem obviates the need for employing numerical optimization search algorithms that must traverse mountain ridges of objective function surfaces. However, a calculation required in the closed form solution, namely inverting a matrix, suffers from instabilities induced by multicollinearity, so the description of the interpretation of negative correlations is valid. One solution to the multicollinearity problem is to choose a representative variable from the correlated ones. The source code tries three combinations of variables, with a conclusion that OAPEC and PersianGulf should be dropped in favor of OPEC. ods output ParameterEstimates=work.ParmEst5V FitStatistics=work.FitStat5V; proc reg data=work.WorldOil outest=work.Est5VModel; OAPEC: model USA=Canada Iraq Mexico OAPEC Venezuela / aic sbc edf; OPEC: model USA=Canada Iraq Mexico OPEC Venezuela / aic sbc edf; PGulf: model USA=Canada Iraq Mexico PersianGulf Venezuela / aic sbc edf; run; quit;",FE,1562,"['negative', 'correlation', 'estimate', 'reflects', 'delicate', 'balancing', 'act', 'climbing', 'ridge', 'maximize', 'objective', 'function', 'ridge', 'numeric', 'result', 'collinear', 'variable', 'model', 'movement', 'cause', 'one', 'estimate', 'increase', 'necessarily', 'cause', 'estimate', 'decrease', 'use', 'mountain', 'ridge', 'visualize', 'numerics', 'associated', 'multicollinearity', 'source', 'solution', 'problem', 'called', 'ridge', 'regression', '\ta', 'least', 'square', 'problem', 'seek', 'minimize', 'objective', 'function', 'namely', 'sum', 'squared', 'error', 'closed', 'form', 'solution', 'minimization', 'problem', 'obviates', 'need', 'employing', 'numerical', 'optimization', 'search', 'algorithm', 'must', 'traverse', 'mountain', 'ridge', 'objective', 'function', 'surface', 'however', 'calculation', 'required', 'closed', 'form', 'solution', 'namely', 'inverting', 'matrix', 'suffers', 'instability', 'induced', 'multicollinearity', 'description', 'interpretation', 'negative', 'correlation', 'valid', 'one', 'solution', 'multicollinearity', 'problem', 'choose', 'representative', 'variable', 'correlated', 'one', 'source', 'code', 'try', 'three', 'combination', 'variable', 'conclusion', 'oapec', 'persiangulf', 'dropped', 'favor', 'opec', 'od', 'output', 'parameterestimatesworkparmest5v', 'fitstatisticsworkfitstat5v', 'proc', 'reg', 'dataworkworldoil', 'outestworkest5vmodel', 'oapec', 'model', 'usacanada', 'iraq', 'mexico', 'oapec', 'venezuela', '', 'aic', 'sbc', 'edf', 'opec', 'model', 'usacanada', 'iraq', 'mexico', 'opec', 'venezuela', '', 'aic', 'sbc', 'edf', 'pgulf', 'model', 'usacanada', 'iraq', 'mexico', 'persiangulf', 'venezuela', '', 'aic', 'sbc', 'edf', 'run', 'quit']"
1563,"The forecast equations provided above are infinite memory forecast equations. Finite memory forecast equations change as each new data point is added, so displaying the equations is not feasible. Forecasting with ARMA Models",FE,224,"['forecast', 'equation', 'provided', 'infinite', 'memory', 'forecast', 'equation', 'finite', 'memory', 'forecast', 'equation', 'change', 'new', 'data', 'point', 'added', 'displaying', 'equation', 'feasible', 'forecasting', 'arma', 'model']"
1564,"While the contribution of the ARMA error component to the overall forecast might seem small, the improved fit due to correct specification of an approximating ARMA model can significantly increase the accuracy of the forecast.",FE,226,"['contribution', 'arma', 'error', 'component', 'overall', 'forecast', 'might', 'seem', 'small', 'improved', 'fit', 'due', 'correct', 'specification', 'approximating', 'arma', 'model', 'significantly', 'increase', 'accuracy', 'forecast']"
1565,"Subtracting the mean has historical merit. In the early days of computers, subtracting the mean before continuing an analysis was common. By centering the data, some numerical problems could be averted. Furthermore, by removing the mean from the estimation process, estimation could proceed more efficiently. Unfortunately, the sample mean is not always the best estimate of the population mean, although it usually is ?good enough?. The notation has persisted not because practitioners are still calculating and subtracting the sample mean, but because the notation can easily be expanded to include regression models. You need to remember that the deviations from the regression surface are stationary. Too many students of forecasting try to write down the prediction equation with phi estimates associated with the target variable Y rather than the residual series Z when regressors are employed.",FE,900,"['subtracting', 'mean', 'ha', 'historical', 'merit', 'early', 'day', 'computer', 'subtracting', 'mean', 'continuing', 'analysis', 'wa', 'common', 'centering', 'data', 'numerical', 'problem', 'could', 'averted', 'furthermore', 'removing', 'mean', 'estimation', 'process', 'estimation', 'could', 'proceed', 'efficiently', 'unfortunately', 'sample', 'mean', 'always', 'best', 'estimate', 'population', 'mean', 'although', 'usually', 'good', 'enough', 'notation', 'ha', 'persisted', 'practitioner', 'still', 'calculating', 'subtracting', 'sample', 'mean', 'notation', 'easily', 'expanded', 'include', 'regression_model', 'need', 'remember', 'deviation', 'regression', 'surface', 'stationary', 'many', 'student', 'forecasting', 'try', 'write', 'prediction', 'equation', 'phi', 'estimate', 'associated', 'target', 'variable', 'rather', 'residual', 'series', 'z', 'regressors', 'employed']"
1566,"The following code would have produced the same plots. ods html; %PlotSmoothSeries(DSName=work.SGunemployment, TargetVar=PercentUnemployed, DateVar=Date); ods html close; The %PlotSmoothSeries macro conditionally executes code based on the SYSVER system macro variable. The SYSVER macro variable contains the name of the current version of SAS that is running. If the version number is smaller than 9.2, then the INTERPOL=SMnn option is used in a SYMBOL statement for PROC GPLOT. The syntax is straightforward. %PlotSmoothSeries(DSName=SAS-data-set, TargetVar=variable, DateVar=variable); You can examine the macro code to see how smoothed plots are produced in SAS 9.1.3.",FE,672,"['following', 'code', 'would', 'produced', 'plot', 'od', 'html', 'plotsmoothseriesdsnameworksgunemployment', 'targetvarpercentunemployed', 'datevardate', 'od', 'html', 'close', 'plotsmoothseries', 'macro', 'conditionally', 'executes', 'code', 'based', 'sysver', 'system', 'macro', 'variable', 'sysver', 'macro', 'variable', 'contains', 'name', 'current', 'version', 'sa', 'running', 'version', 'number', 'smaller', '92', 'interpolsmnn', 'option', 'used', 'symbol', 'statement', 'proc', 'gplot', 'syntax', 'straightforward', 'plotsmoothseriesdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'examine', 'macro', 'code', 'see', 'smoothed', 'plot', 'produced', 'sa', '913']"
1567,"The United States Department of Transportation through its Bureau of Transportation Statistics publishes airline transportation statistics on the following Web site, http://www.transtats.bts.gov Monthly data for January 1990, through June 2008, have been extracted for analysis. The data set contains monthly passenger totals for scheduled flights of domestic U.S. carriers. The data helps illustrate concepts of statistical time series analysis. A visual examination of time series data helps suggest strategies for forecasting future values of the series. Program Ch01_01.sas provides SAS code for producing most of the plots that are included in this chapter.",FE,662,"['united', 'state', 'department', 'transportation', 'bureau', 'transportation', 'statistic', 'publishes', 'airline', 'transportation', 'statistic', 'following', 'web', 'site', 'httpwwwtranstatsbtsgov', 'monthly', 'data', 'january', '1990', 'june', '2008', 'extracted', 'analysis', 'data_set', 'contains', 'monthly', 'passenger', 'total', 'scheduled', 'flight', 'domestic', 'u', 'carrier', 'data', 'help', 'illustrate', 'concept', 'statistical', 'time', 'series', 'analysis', 'visual', 'examination', 'time', 'series', 'data', 'help', 'suggest', 'strategy', 'forecasting', 'future', 'value', 'series', 'program', 'ch0101sas', 'provides', 'sa', 'code', 'producing', 'plot', 'included', 'chapter']"
1568,SAS/ETS software anticipates the need to visualize time series data. PROC TIMESERIES provides extensive plotting capabilities. The following code produces a plot of the original series. ods html; ods graphics on; proc timeseries data=work.SGunemployment out=work.temp print=(summary) plot=(series); var PercentUnemployed; id Date interval=year; run; ods graphics off; ods html close; The plot that is produced follows.,FE,418,"['sasets', 'software', 'anticipates', 'need', 'visualize', 'time', 'series', 'data', 'proc', 'timeseries', 'provides', 'extensive', 'plotting', 'capability', 'following', 'code', 'produce', 'plot', 'original', 'series', 'od', 'html', 'od', 'graphic', 'proc', 'timeseries', 'dataworksgunemployment', 'outworktemp', 'printsummary', 'plotseries', 'var', 'percentunemployed', 'id', 'date', 'intervalyear', 'run', 'od', 'graphic', 'od', 'html', 'close', 'plot', 'produced', 'follows']"
1569,"The use of the idiom ?everything but the kitchen sink? is exemplified by, ?He always packs everything but the kitchen sink, even for weekend trips.? The idiom has been expanded to statistical modeling so that a kitchen sink model has everything in it except the kitchen sink, meaning it includes every variable in the modeling data set that could possibly serve as an input variable. Kitchen sink models are not recommended. The curse of dimensionality thwarts the use of kitchen sink models. What is not acceptable is taking 3 months using a spreadsheet application to generate forecasts when use of sophisticated forecasting software can produce superior forecasts in only a few days. Also, use of forecasting software often prevents mistakes that occur when manually copying and pasting data into a spreadsheet.",FE,814,"['use', 'idiom', 'everything', 'kitchen', 'sink', 'exemplified', 'always', 'pack', 'everything', 'kitchen', 'sink', 'even', 'weekend', 'trip', 'idiom', 'ha', 'expanded', 'statistical', 'modeling', 'kitchen', 'sink', 'model', 'ha', 'everything', 'except', 'kitchen', 'sink', 'meaning', 'includes', 'every', 'variable', 'modeling', 'data_set', 'could', 'possibly', 'serve', 'input', 'variable', 'kitchen', 'sink', 'model', 'recommended', 'curse', 'dimensionality', 'thwart', 'use', 'kitchen', 'sink', 'model', 'acceptable', 'taking', '3', 'month', 'using', 'spreadsheet', 'application', 'generate', 'forecast', 'use', 'sophisticated', 'forecasting', 'software', 'produce', 'superior', 'forecast', 'day', 'also', 'use', 'forecasting', 'software', 'often', 'prevents', 'mistake', 'occur', 'manually', 'copying', 'pasting', 'data', 'spreadsheet']"
1570,"The following code investigates exponential smoothing models. The additive Winters model produces the smallest MAPE %AutoESM(work.Air1990_2000,work.esm_stats,Passengers,Date);",FE,175,"['following', 'code', 'investigates', 'exponential', 'smoothing', 'model', 'additive', 'winter', 'model', 'produce', 'smallest', 'mape', 'autoesmworkair19902000workesmstatspassengersdate']"
1571,"The AR(1) forecasts revert to the mean of the series. This is a property of stationary models. Neither model seems adequate for forecasting, but you will have to wait until more advanced models are covered before you can continue the analysis. 1.3	Measuring Goodness-of-Fit and Accuracy",FE,286,"['ar1', 'forecast', 'revert', 'mean', 'series', 'property', 'stationary', 'model', 'neither', 'model', 'seems', 'adequate', 'forecasting', 'wait', 'advanced', 'model', 'covered', 'continue', 'analysis', '13\tmeasuring', 'goodnessoffit', 'accuracy']"
1572,"Time Series Regression Analysis of the World Oil Production Data (Self-Study) This demonstration illustrates how to use PROC ARIMA to build dynamic regression models for the world oil production data. The SAS code for this analysis can be found in Demo4_06Energy.sas. Data Preparation In a previous demonstration, the world oil production data were used, stored in LWFETSP.WorldOil. This data set has been combined with pricing and demand data to create a data set LWFETSP.EnergyPS_USA. The new data set contains the following variables.",FE,537,"['time', 'series', 'regression', 'analysis', 'world', 'oil', 'production', 'data', 'selfstudy', 'demonstration', 'illustrates', 'use', 'proc', 'arima', 'build', 'dynamic', 'regression_model', 'world', 'oil', 'production', 'data', 'sa', 'code', 'analysis', 'found', 'demo406energysas', 'data', 'preparation', 'previous', 'demonstration', 'world', 'oil', 'production', 'data', 'used', 'stored', 'lwfetspworldoil', 'data_set', 'ha', 'combined', 'pricing', 'demand', 'data', 'create', 'data_set', 'lwfetspenergypsusa', 'new', 'data_set', 'contains', 'following', 'variable']"
1573,"The seasonal component plot will always seem to reveal seasonality because it is scaled so that the plot fills the display window. You must examine the vertical axis to determine the magnitude of the seasonal differences. Because the range for multiplicative decomposition is from about 97% to about 102%, there is little evidence that real seasonal changes exist.",FE,364,"['seasonal', 'component', 'plot', 'always', 'seem', 'reveal', 'seasonality', 'scaled', 'plot', 'fill', 'display', 'window', 'must', 'examine', 'vertical', 'axis', 'determine', 'magnitude', 'seasonal', 'difference', 'range', 'multiplicative', 'decomposition', '97', '102', 'little', 'evidence', 'real', 'seasonal', 'change', 'exist']"
1574,"While both selection criteria agree on the best model, they disagree on the order of the next two models. The SAS code is very similar for the identification of all three series. All that changes are the names of variables and the orders of the candidate models. Except for calls to the %AutoARMA macro, only the results will be presented. Following is a plot of the Peanut Butter series.",FE,388,"['selection', 'criterion', 'agree', 'best', 'model', 'disagree', 'order', 'next', 'two', 'model', 'sa', 'code', 'similar', 'identification', 'three', 'series', 'change', 'name', 'variable', 'order', 'candidate', 'model', 'except', 'call', 'autoarma', 'macro', 'result', 'presented', 'following', 'plot', 'peanut', 'butter', 'series']"
1575,"The color is not discernable in grayscale, but you will see that a blue line is produced if you run the demo program. ?	Default settings are device dependent. This is because some devices are limited in the type of graphics that can be produced. For example, a device may be associated with a printer that can only produce black and white output. The SAS/GRAPH procedures with names that begin with SG are statistical graphics procedures introduced with SAS 9.2. The SGPLOT procedure replaces GPLOT for many common plotting tasks. SG procedures do not use SYMBOL or PATTERN statements. Instead, custom features are requested within the call to the procedure. The following code produces a time series plot. ods html; proc sgplot data=work.SGunemployment; series X=Date Y=PercentUnemployed; run; ods html close; If you are using a release prior to SAS 9.2, you must use the GPLOT code because SGPLOT will not be available. The plot produced by SGPLOT follows.",FE,958,"['color', 'discernable', 'grayscale', 'see', 'blue', 'line', 'produced', 'run', 'demo', 'program', '\tdefault', 'setting', 'device', 'dependent', 'device', 'limited', 'type', 'graphic', 'produced', 'example', 'device', 'may', 'associated', 'printer', 'produce', 'black', 'white', 'output', 'sasgraph', 'procedure', 'name', 'begin', 'sg', 'statistical', 'graphic', 'procedure', 'introduced', 'sa', '92', 'sgplot', 'procedure', 'replaces', 'gplot', 'many', 'common', 'plotting', 'task', 'sg', 'procedure', 'use', 'symbol', 'pattern', 'statement', 'instead', 'custom', 'feature', 'requested', 'within', 'call', 'procedure', 'following', 'code', 'produce', 'time', 'series', 'plot', 'od', 'html', 'proc', 'sgplot', 'dataworksgunemployment', 'series', 'xdate', 'ypercentunemployed', 'run', 'od', 'html', 'close', 'using', 'release', 'prior', 'sa', '92', 'must', 'use', 'gplot', 'code', 'sgplot', 'available', 'plot', 'produced', 'sgplot', 'follows']"
1576,"You can see that the AIC and SBC values match those that were produced by the %AutoARMA macro. The values should match because %AutoARMA uses PROC ARIMA to calculate the values. A model should be disqualified if the forecast errors (residuals) do not appear to be from a white noise process. To investigate this requirement, examine the autocorrelation plots for the prediction errors.",FE,385,"['see', 'aic', 'sbc', 'value', 'match', 'produced', 'autoarma', 'macro', 'value', 'match', 'autoarma', 'us', 'proc', 'arima', 'calculate', 'value', 'model', 'disqualified', 'forecast', 'error', 'residual', 'appear', 'white', 'noise', 'process', 'investigate', 'requirement', 'examine', 'autocorrelation', 'plot', 'prediction', 'error']"
1577,The forecast horizon can be extended to investigate if the forecasts converge to a trend line or asymptote to a constant. Extending the forecast horizon shows that the forecasts converge to the mean of the series.,FE,213,"['forecast', 'horizon', 'extended', 'investigate', 'forecast', 'converge', 'trend', 'line', 'asymptote', 'constant', 'extending', 'forecast', 'horizon', 'show', 'forecast', 'converge', 'mean', 'series']"
1578,The likelihood form of AIC and SBC require that models be hierarchically consistent before they can be compared. The error-based form of AIC and SBC allow comparison of any two models. There are variations of the classic R-Square measure that are designed to decrease when adding complexity to a model does not produce a commensurate increase in accuracy. Adjusted R-Square is a popular alternative to R-Square.,FE,411,"['likelihood', 'form', 'aic', 'sbc', 'require', 'model', 'hierarchically', 'consistent', 'compared', 'errorbased', 'form', 'aic', 'sbc', 'allow', 'comparison', 'two', 'model', 'variation', 'classic', 'rsquare', 'measure', 'designed', 'decrease', 'adding', 'complexity', 'model', 'doe', 'produce', 'commensurate', 'increase', 'accuracy', 'adjusted', 'rsquare', 'popular', 'alternative', 'rsquare']"
1579,"SBC disagrees with AIC and suggests that AR(3) and ARMA(2,1) models might be competitive. You should not rely on a single measure to select a best model. Competitive models should be investigated to ensure they are acceptable. The forecasts must be examined to determine if they are plausible. Such activities will occur later, but they are not included in the purpose for this demonstration. Identifying Three Grocery Time Series",FE,430,"['sbc', 'disagrees', 'aic', 'suggests', 'ar3', 'arma21', 'model', 'might', 'competitive', 'rely', 'single', 'measure', 'select', 'best', 'model', 'competitive', 'model', 'investigated', 'ensure', 'acceptable', 'forecast', 'must', 'examined', 'determine', 'plausible', 'activity', 'occur', 'later', 'included', 'purpose', 'demonstration', 'identifying', 'three', 'grocery', 'time', 'series']"
1580,"Cross-correlation plots and values can be obtained from PROC TIMESERIES and from PROC ARIMA. Only PROC ARIMA can apply filtering operations, such as differencing and pre- whitening, to the two time series of interest.",FE,217,"['crosscorrelation', 'plot', 'value', 'obtained', 'proc', 'timeseries', 'proc', 'arima', 'proc', 'arima', 'apply', 'filtering', 'operation', 'differencing', 'pre', 'whitening', 'two', 'time', 'series', 'interest']"
1581,"The presence of trend contradicts stationarity, so the above slide corrects the na?ve mistake of trying to fit a stationary model to the series. Clearly the annual lead production time series cannot be from a stationary process. The negative trend implies that the mean of the series is getting smaller over time and therefore cannot be constant. An RWD model is nonstationary, and so it might be appropriate for the lead series.",FE,429,"['presence', 'trend', 'contradicts', 'stationarity', 'slide', 'corrects', 'nave', 'mistake', 'trying', 'fit', 'stationary', 'model', 'series', 'clearly', 'annual', 'lead', 'production', 'time', 'series', 'cannot', 'stationary', 'process', 'negative', 'trend', 'implies', 'mean', 'series', 'getting', 'smaller', 'time', 'therefore', 'cannot', 'constant', 'rwd', 'model', 'nonstationary', 'might', 'appropriate', 'lead', 'series']"
1582,"None of the estimates are significant at the 1% level, although all are significant at the 5% level. Lack of statistical significance almost never causes a model to be disqualified for forecasting purposes.",FE,206,"['none', 'estimate', 'significant', '1', 'level', 'although', 'significant', '5', 'level', 'lack', 'statistical', 'significance', 'almost', 'never', 'cause', 'model', 'disqualified', 'forecasting', 'purpose']"
1583,"PROC ARIMA provides the essential diagnostic plots, so your use of PROC TIMESERIES might be limited. When you investigate nonstationary series, PROC TIMESERIES provides some useful decomposition options that are not available in PROC ARIMA.",FE,240,"['proc', 'arima', 'provides', 'essential', 'diagnostic', 'plot', 'use', 'proc', 'timeseries', 'might', 'limited', 'investigate', 'nonstationary', 'series', 'proc', 'timeseries', 'provides', 'useful', 'decomposition', 'option', 'available', 'proc', 'arima']"
1584,"Because the exponential decay begins at the second spike, two numerator parameters are required. The following demonstration illustrates the process of pre-whitening and shows that PROC ARIMA handles pre-whitening automatically.",FE,228,"['exponential', 'decay', 'begin', 'second', 'spike', 'two', 'numerator', 'parameter', 'required', 'following', 'demonstration', 'illustrates', 'process', 'prewhitening', 'show', 'proc', 'arima', 'handle', 'prewhitening', 'automatically']"
1585,"This course uses a programming approach for forecasting. As such, the course goes well beyond teaching proper syntax for SAS forecasting procedures. SAS software includes a powerful programming language, a versatile macro language, and a sophisticated Output Delivery System (ODS) to support forecasting projects. Of course, SAS/ETS software contains many procedures that implement specific forecasting methodologies. You can combine the SAS programming language with SAS procedures to enhance quality and productivity for a forecasting project. The programs used in this course are designed to run under SAS 9.2, but many programs will also run successfully under SAS 9.1. The SAS macro variable SYSVER provides a mechanism for programmatically checking and conditionally executing code consistent with the release required for the code to function properly.",FE,859,"['course', 'us', 'programming', 'approach', 'forecasting', 'course', 'go', 'well', 'beyond', 'teaching', 'proper', 'syntax', 'sa', 'forecasting', 'procedure', 'sa', 'software', 'includes', 'powerful', 'programming', 'language', 'versatile', 'macro', 'language', 'sophisticated', 'output', 'delivery', 'system', 'od', 'support', 'forecasting', 'project', 'course', 'sasets', 'software', 'contains', 'many', 'procedure', 'implement', 'specific', 'forecasting', 'methodology', 'combine', 'sa', 'programming', 'language', 'sa', 'procedure', 'enhance', 'quality', 'productivity', 'forecasting', 'project', 'program', 'used', 'course', 'designed', 'run', 'sa', '92', 'many', 'program', 'also', 'run', 'successfully', 'sa', '91', 'sa', 'macro', 'variable', 'sysver', 'provides', 'mechanism', 'programmatically', 'checking', 'conditionally', 'executing', 'code', 'consistent', 'release', 'required', 'code', 'function', 'properly']"
1586,Yule (1927) and Walker (1931) derived the famous equations that bear their names long before modern computers were invented. Both authors contributed to the study of autoregressive processes long before the Box-Jenkins methodology became popular.,FE,246,"['yule', '1927', 'walker', '1931', 'derived', 'famous', 'equation', 'bear', 'name', 'long', 'modern', 'computer', 'invented', 'author', 'contributed', 'study', 'autoregressive', 'process', 'long', 'boxjenkins', 'methodology', 'became', 'popular']"
1587,"While positive autocorrelation ties adjacent data points together ensuring that they are close, negative autocorrelation pushes adjacent data points apart so that they are far apart.",FE,182,"['positive', 'autocorrelation', 'tie', 'adjacent', 'data', 'point', 'together', 'ensuring', 'close', 'negative', 'autocorrelation', 'push', 'adjacent', 'data', 'point', 'apart', 'far', 'apart']"
1588,"1. Forecast domestic consumption of barley for the next five years using the USDA Foreign Agricultural Service data stored in LWFETSP.Barley. Data are for global markets, and domestic consumption includes the use of barley in consumable products like bread and beer for the domestic market in the country where the barley is grown. Feed domestic production is for domestic use in feeding livestock. The data are recorded annually for the trade year defined to be October 1 through September 30 of the following year. Values are in millions of metric tons. a. Identify and fit an appropriate ARMA model. b. Fit a stepwise autoregressive model. c. Fit an exponential smoothing model. d. Pick a winning set of forecasts. Solutions to Exercises 1. Solutions for this exercise can be found in Exercises_Ch2.sas. PROC CONTENTS reveals the content of the data. %WorkCopy(LWFETSP.Barley);",FE,880,"['1', 'forecast', 'domestic', 'consumption', 'barley', 'next', 'five', 'year', 'using', 'usda', 'foreign', 'agricultural', 'service', 'data', 'stored', 'lwfetspbarley', 'data', 'global', 'market', 'domestic', 'consumption', 'includes', 'use', 'barley', 'consumable', 'product', 'like', 'bread', 'beer', 'domestic', 'market', 'country', 'barley', 'grown', 'feed', 'domestic', 'production', 'domestic', 'use', 'feeding', 'livestock', 'data', 'recorded', 'annually', 'trade', 'year', 'defined', 'october', '1', 'september', '30', 'following', 'year', 'value', 'million', 'metric', 'ton', 'identify', 'fit', 'appropriate', 'arma', 'model', 'b', 'fit', 'stepwise', 'autoregressive', 'model', 'c', 'fit', 'exponential', 'smoothing', 'model', 'pick', 'winning', 'set', 'forecast', 'solution', 'exercise', '1', 'solution', 'exercise', 'found', 'exercisesch2sas', 'proc', 'content', 'reveals', 'content', 'data', 'workcopylwfetspbarley']"
1589,"Calculating the IACF is a chicken-and-egg problem. The IACF diagnoses candidate models. A candidate model is needed to calculate the IACF. How can you calculate the IACF when you need the IACF to propose a candidate model? The problem is solved by recognizing that autoregressive models are universal approximators. However, the problem is not really solved, because you do not know what AR order to employ. A variety of techniques exist for automatically picking the order of an approximating autoregressive model: Akaike?s AIC, Schwarz?s SBC, Parzen?s CAT, Akaike?s FPE, and so on. The forecasting community could agree to use, for example, Akaike?s AIC, to calculate the IACF, and then the IACF would be uniquely defined. Such agreement is unlikely, and furthermore, software design forces you to place limits on the maximum order, and a given criterion might select an order greater than the maximum order you imposed. 2.3	PACF and IACF Technical Details (Self-Study)",FE,971,"['calculating', 'iacf', 'chickenandegg', 'problem', 'iacf', 'diagnosis', 'candidate', 'model', 'candidate', 'model', 'needed', 'calculate', 'iacf', 'calculate', 'iacf', 'need', 'iacf', 'propose', 'candidate', 'model', 'problem', 'solved', 'recognizing', 'autoregressive', 'model', 'universal', 'approximators', 'however', 'problem', 'really', 'solved', 'know', 'ar', 'order', 'employ', 'variety', 'technique', 'exist', 'automatically', 'picking', 'order', 'approximating', 'autoregressive', 'model', 'akaikes', 'aic', 'schwarzs', 'sbc', 'parzens', 'cat', 'akaikes', 'fpe', 'forecasting', 'community', 'could', 'agree', 'use', 'example', 'akaikes', 'aic', 'calculate', 'iacf', 'iacf', 'would', 'uniquely', 'defined', 'agreement', 'unlikely', 'furthermore', 'software', 'design', 'force', 'place', 'limit', 'maximum', 'order', 'given', 'criterion', 'might', 'select', 'order', 'greater', 'maximum', 'order', 'imposed', '23\tpacf', 'iacf', 'technical', 'detail', 'selfstudy']"
1590,"Hurricane Katrina to date in the United States is the costliest hurricane on record, causing numerous refineries along the Gulf Coast to shut down. However, according to an ordinary regression model, it had no effect on U.S. oil production! This strange finding reveals among other things the limitation of ordinary regression. Dynamic regression is required to reflect the long-term effect of hurricane Katrina on oil production. For educational purposes, PROC ARIMA is employed to duplicate the estimates produced by PROC REG. This will help you to see how the Box-Jenkins modeling framework is related to a traditional regression framework. ods html; ods graphics on; proc arima data=work.WorldOil; identify var=USA cross=(Iraq OPEC Katrina Rita Ike); estimate input=(Iraq OPEC Katrina Rita Ike) method=ml plot; run; quit; ods graphics off; ods html close; The estimates table from PROC ARIMA appears below.",FE,910,"['hurricane', 'katrina', 'date', 'united', 'state', 'costliest', 'hurricane', 'record', 'causing', 'numerous', 'refinery', 'along', 'gulf', 'coast', 'shut', 'however', 'according', 'ordinary', 'regression_model', 'effect', 'u', 'oil', 'production', 'strange', 'finding', 'reveals', 'among', 'thing', 'limitation', 'ordinary', 'regression', 'dynamic', 'regression', 'required', 'reflect', 'longterm', 'effect', 'hurricane', 'katrina', 'oil', 'production', 'educational', 'purpose', 'proc', 'arima', 'employed', 'duplicate', 'estimate', 'produced', 'proc', 'reg', 'help', 'see', 'boxjenkins', 'modeling', 'framework', 'related', 'traditional', 'regression', 'framework', 'od', 'html', 'od', 'graphic', 'proc', 'arima', 'dataworkworldoil', 'identify', 'varusa', 'crossiraq', 'opec', 'katrina', 'rita', 'ike', 'estimate', 'inputiraq', 'opec', 'katrina', 'rita', 'ike', 'methodml', 'plot', 'run', 'quit', 'od', 'graphic', 'od', 'html', 'close', 'estimate', 'table', 'proc', 'arima', 'appears']"
1591,"The autocorrelation functions shown in the slides are population functions. Dropping to zero for population values is related to becoming insignificant for sample values. Calculated values of the ACF, PACF, and IACF will often be near zero for higher lags.",FE,256,"['autocorrelation', 'function', 'shown', 'slide', 'population', 'function', 'dropping', 'zero', 'population', 'value', 'related', 'becoming', 'insignificant', 'sample', 'value', 'calculated', 'value', 'acf', 'pacf', 'iacf', 'often', 'near', 'zero', 'higher', 'lag']"
1592,"The option P requests that the periodogram be output. The option S requests that the smoothed periodogram be output. The option COEF requests the Fourier coefficients that are employed to calculate the amplitudes in the periodogram. The WEIGHTS statement determines how to smooth the periodogram. The named smoothers represent specific methods for smoothing the periodogram to obtain sample spectral density functions. Parzen , Bartlett, and Tukey pioneered much of the research in estimating the spectral density function and have methods named after them.",FE,557,"['option', 'p', 'request', 'periodogram', 'output', 'option', 'request', 'smoothed', 'periodogram', 'output', 'option', 'coef', 'request', 'fourier', 'coefficient', 'employed', 'calculate', 'amplitude', 'periodogram', 'weight', 'statement', 'determines', 'smooth', 'periodogram', 'named', 'smoother', 'represent', 'specific', 'method', 'smoothing', 'periodogram', 'obtain', 'sample', 'spectral', 'density', 'function', 'parzen', '', 'bartlett', 'tukey', 'pioneered', 'much', 'research', 'estimating', 'spectral', 'density', 'function', 'method', 'named']"
1593,"The estimation results imply that TV and Radio advertising might not have a significant impact on sales. You want to keep TVRadio in the model to estimate its effect, even if the effect is not statistically significant. The Ljung-Box test and the residual plots produced by the above code suggest that the residuals are not white noise.",FE,336,"['estimation', 'result', 'imply', 'tv', 'radio', 'advertising', 'might', 'significant', 'impact', 'sale', 'want', 'keep', 'tvradio', 'model', 'estimate', 'effect', 'even', 'effect', 'statistically', 'significant', 'ljungbox', 'test', 'residual', 'plot', 'produced', 'code', 'suggest', 'residual', 'white', 'noise']"
1594,"Combining all of the components produces a mathematical representation of the signal. This mathematical representation is used to extrapolate over future time points to produce forecasts. The noise component is not part of the extrapolated signal (it is assumed to be on average zero), but an estimate of the noise variation is used to derive confidence intervals.",FE,364,"['combining', 'component', 'produce', 'mathematical', 'representation', 'signal', 'mathematical', 'representation', 'used', 'extrapolate', 'future', 'time', 'point', 'produce', 'forecast', 'noise', 'component', 'part', 'extrapolated', 'signal', 'assumed', 'average', 'zero', 'estimate', 'noise', 'variation', 'used', 'derive', 'confidence', 'interval']"
1595,"This demonstration illustrates the forecast modeling process using the monthly lead production data. The monthly lead production data is stored in LWFETSP.LeadMonth. The data covers the period from January 1986 to September 1992. The source code for this demonstration is in Demo03_01LeadMonth.sas. The course notes provide details of data step programming and calls to PROC ARIMA that support the development of forecast models. A major advantage of the programming approach to forecasting with SAS software is the ability to write macros to customize and automate an analysis. Consequently, the development of a macro for fitting trend curves has partially been completed just by re-using the code that was developed for the annual lead production data. The use of several of the macros developed for this course has been delayed to facilitate learning. It is important that you become familiar with PROC ARIMA syntax for obtaining Dickey-Fuller test statistics and p-values, for fitting trend curves with ARMA errors, and for obtaining diagnostics for a residual analysis. Now that you have seen examples of PROC ARIMA code employed directly, you can benefit from that code converted into general purpose macros. You have already seen various plotting macros. A review of the macro syntax is in order. The %PlotTimeSeries macro plots the time series using PROC TIMESERIES. %PlotTimeSeries(DSName=SAS-Data-Set, TargetVar=variable, DateVar=variable, IntervalName=interval); By default, DateVar=Date and IntervalName=NULL. A value of NULL instructs the macro to use the time index as the variable for the x-axis. Following is an example of the macro used in the demonstration code. ods html; %PlotTimeSeries(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date, IntervalName=Month); ods html close; The result of the above code follows.",FE,1838,"['demonstration', 'illustrates', 'forecast', 'modeling', 'process', 'using', 'monthly', 'lead', 'production', 'data', 'monthly', 'lead', 'production', 'data', 'stored', 'lwfetspleadmonth', 'data', 'cover', 'period', 'january', '1986', 'september', '1992', 'source', 'code', 'demonstration', 'demo0301leadmonthsas', 'course', 'note', 'provide', 'detail', 'data', 'step', 'programming', 'call', 'proc', 'arima', 'support', 'development', 'forecast', 'model', 'major', 'advantage', 'programming', 'approach', 'forecasting', 'sa', 'software', 'ability', 'write', 'macro', 'customize', 'automate', 'analysis', 'consequently', 'development', 'macro', 'fitting', 'trend', 'curve', 'ha', 'partially', 'completed', 'reusing', 'code', 'wa', 'developed', 'annual', 'lead', 'production', 'data', 'use', 'several', 'macro', 'developed', 'course', 'ha', 'delayed', 'facilitate', 'learning', 'important', 'become', 'familiar', 'proc', 'arima', 'syntax', 'obtaining', 'dickeyfuller', 'test', 'statistic', 'pvalues', 'fitting', 'trend', 'curve', 'arma', 'error', 'obtaining', 'diagnostics', 'residual', 'analysis', 'seen', 'example', 'proc', 'arima', 'code', 'employed', 'directly', 'benefit', 'code', 'converted', 'general', 'purpose', 'macro', 'already', 'seen', 'various', 'plotting', 'macro', 'review', 'macro', 'syntax', 'order', 'plottimeseries', 'macro', 'plot', 'time', 'series', 'using', 'proc', 'timeseries', 'plottimeseriesdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'intervalnameinterval', 'default', 'datevardate', 'intervalnamenull', 'value', 'null', 'instructs', 'macro', 'use', 'time', 'index', 'variable', 'xaxis', 'following', 'example', 'macro', 'used', 'demonstration', 'code', 'od', 'html', 'plottimeseriesdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'intervalnamemonth', 'od', 'html', 'close', 'result', 'code', 'follows']"
1596,"For the airline passengers data, as you have seen, the signal is a combination of trend and seasonal components as well as regression components for events and economic conditions.",FE,180,"['airline', 'passenger', 'data', 'seen', 'signal', 'combination', 'trend', 'seasonal', 'component', 'well', 'regression', 'component', 'event', 'economic', 'condition']"
1597,"The use of notation ?t for the stationary component and ?t for the white noise component is nonstandard for time series regression models and is only employed in the above slide to show the transition from ordinary regression to time series regression. The stationary error or irregular component will usually be expressed as a time series Zt, and the white noise error will usually be expressed as ?t.",FE,402,"['use', 'notation', 'stationary', 'component', 'white', 'noise', 'component', 'nonstandard', 'time', 'series', 'regression_model', 'employed', 'slide', 'show', 'transition', 'ordinary', 'regression', 'time', 'series', 'regression', 'stationary', 'error', 'irregular', 'component', 'usually', 'expressed', 'time', 'series', 'zt', 'white', 'noise', 'error', 'usually', 'expressed']"
1598,"Output is produced in HTML format, and each task produces its own HTML output. The following demonstration uses SAS/GRAPH to plot time series data. Plotting a Time Series",FE,170,"['output', 'produced', 'html', 'format', 'task', 'produce', 'html', 'output', 'following', 'demonstration', 'us', 'sasgraph', 'plot', 'time', 'series', 'data', 'plotting', 'time', 'series']"
1599,"The data set contains two variables and 36 observations. The SAS variable DATE is a SAS date variable, which means that it contains the date represented as the number of days since January 1, 1960. A year format is used so that only the year part of the date will be displayed. A temporary copy of the data set is made so that any modifications to the data will not overwrite the original data set. data work.SGunemployment; set LWFETSP.SGunemployment; run; The first attempt to plot the data uses default settings related to graphics device ACTIVEX. goptions reset=symbol; ods html; goptions device=activex; proc gplot data=work.SGunemployment; plot PercentUnemployed*Date; run; quit; ods html close; HTML output is required to display ACTIVEX content. The GOPTIONS statement is not required if this is the first program that you execute in your current SAS session. Otherwise, it is required to reset all SYMBOL statements to default settings. The syntax employed for this PROC GPLOT request is simple. PROC GPLOT DATA=SAS-data-set; PLOT y-variable * x-variable; RUN; QUIT; The SAS windowing environment displays the results using an add-in HTML viewer.",FE,1155,"['data_set', 'contains', 'two', 'variable', '36', 'observation', 'sa', 'variable', 'date', 'sa', 'date', 'variable', 'mean', 'contains', 'date', 'represented', 'number', 'day', 'since', 'january', '1', '1960', 'year', 'format', 'used', 'year', 'part', 'date', 'displayed', 'temporary', 'copy', 'data_set', 'made', 'modification', 'data', 'overwrite', 'original', 'data_set', 'data', 'worksgunemployment', 'set', 'lwfetspsgunemployment', 'run', 'first', 'attempt', 'plot', 'data', 'us', 'default', 'setting', 'related', 'graphic', 'device', 'activex', 'goptions', 'resetsymbol', 'od', 'html', 'goptions', 'deviceactivex', 'proc', 'gplot', 'dataworksgunemployment', 'plot', 'percentunemployeddate', 'run', 'quit', 'od', 'html', 'close', 'html', 'output', 'required', 'display', 'activex', 'content', 'goptions', 'statement', 'required', 'first', 'program', 'execute', 'current', 'sa', 'session', 'otherwise', 'required', 'reset', 'symbol', 'statement', 'default', 'setting', 'syntax', 'employed', 'proc', 'gplot', 'request', 'simple', 'proc', 'gplot', 'datasasdataset', 'plot', 'yvariable', '', 'xvariable', 'run', 'quit', 'sa', 'windowing', 'environment', 'display', 'result', 'using', 'addin', 'html', 'viewer']"
1600,"The more complex ARMA model produces forecasts that converge to the mean more slowly. The stability code is similar to the code used before, so it is omitted. The results follow.",FE,178,"['complex', 'arma', 'model', 'produce', 'forecast', 'converge', 'mean', 'slowly', 'stability', 'code', 'similar', 'code', 'used', 'omitted', 'result', 'follow']"
1601,This demonstration illustrates how to use PROC ESM to forecast the three groceries time series. Code for this demonstration can be found in Demo2_09ESM.sas. The following code creates a working copy of the data and generates forecasts using PROC ESM. %WorkCopy(LWFETSP.Groceries);,FE,280,"['demonstration', 'illustrates', 'use', 'proc', 'esm', 'forecast', 'three', 'grocery', 'time', 'series', 'code', 'demonstration', 'found', 'demo209esmsas', 'following', 'code', 'creates', 'working', 'copy', 'data', 'generates', 'forecast', 'using', 'proc', 'esm', 'workcopylwfetspgroceries']"
1602,"The index that orders a time series is usually a time index, but it could also, for example, be measurements at equidistant points on a metal rod. Equal spacing is critical for the methods described herein. Equal spacing need not be mathematically rigid, because, for example, monthly data are considered to be equally spaced even though months have different number of days. To account for unequal numbers of days, practitioners use trading day adjustments, weekend day adjustments, or similar modifications of the original series.",FE,532,"['index', 'order', 'time', 'series', 'usually', 'time', 'index', 'could', 'also', 'example', 'measurement', 'equidistant', 'point', 'metal', 'rod', 'equal', 'spacing', 'critical', 'method', 'described', 'herein', 'equal', 'spacing', 'need', 'mathematically', 'rigid', 'example', 'monthly', 'data', 'considered', 'equally', 'spaced', 'even', 'though', 'month', 'different', 'number', 'day', 'account', 'unequal', 'number', 'day', 'practitioner', 'use', 'trading', 'day', 'adjustment', 'weekend', 'day', 'adjustment', 'similar', 'modification', 'original', 'series']"
1603,"SAS 9.2 introduced ODS Statistical Graphics, including three new procedures for SAS/GRAPH software. The plots that have been produced so far can be obtained from releases prior to SAS 9.2. As the course progresses, emphasis will shift to using SAS 9.2 ODS Statistical Graphics procedures exclusively. Before demonstrating the software, a review of the SAS System is in order.",FE,375,"['sa', '92', 'introduced', 'od', 'statistical', 'graphic', 'including', 'three', 'new', 'procedure', 'sasgraph', 'software', 'plot', 'produced', 'far', 'obtained', 'release', 'prior', 'sa', '92', 'course', 'progress', 'emphasis', 'shift', 'using', 'sa', '92', 'od', 'statistical', 'graphic', 'procedure', 'exclusively', 'demonstrating', 'software', 'review', 'sa', 'system', 'order']"
1604,"The plot suggests that the influence of all input variables is aligned with the target series, except DirectMail, which appears to be a leading indicator of SalesAmount by two weeks. A time series regression model with regressors Internet, PrintMedia, TVRadio, and SalesRatio, and dynamic regressor DirectMail shifted two weeks is fit to the data. ods html; ods graphics on; proc arima data=work.SaleData; identify var=SalesAmount crosscorr=(PrintMedia TVRadio Internet SalesRatio DirectMail) nlag=24; estimate input=(PrintMedia TVRadio Internet SalesRatio 2 $ DirectMail) method=ML outest=work.SDest plot; forecast id=DATE interval=WEEK align=BEGINNING lead=0 out=work.SDfore; run; ods graphics off; ods html close; The table of estimates follows.",FE,748,"['plot', 'suggests', 'influence', 'input', 'variable', 'aligned', 'target', 'series', 'except', 'directmail', 'appears', 'leading', 'indicator', 'salesamount', 'two', 'week', 'time', 'series', 'regression_model', 'regressors', 'internet', 'printmedia', 'tvradio', 'salesratio', 'dynamic', 'regressor', 'directmail', 'shifted', 'two', 'week', 'fit', 'data', 'od', 'html', 'od', 'graphic', 'proc', 'arima', 'dataworksaledata', 'identify', 'varsalesamount', 'crosscorrprintmedia', 'tvradio', 'internet', 'salesratio', 'directmail', 'nlag24', 'estimate', 'inputprintmedia', 'tvradio', 'internet', 'salesratio', '2', '', 'directmail', 'methodml', 'outestworksdest', 'plot', 'forecast', 'iddate', 'intervalweek', 'alignbeginning', 'lead0', 'outworksdfore', 'run', 'od', 'graphic', 'od', 'html', 'close', 'table', 'estimate', 'follows']"
1605,This demonstration illustrates how to plot several time series together in one graph. The program file Demo1_01Plot.sas contains the following additional code. proc contents data=LWFETSP.DEunemployment; run; proc contents data=LWFETSP.UKunemployment; run; proc contents data=LWFETSP.USaunemployment; run;,FE,304,"['demonstration', 'illustrates', 'plot', 'several', 'time', 'series', 'together', 'one', 'graph', 'program', 'file', 'demo101plotsas', 'contains', 'following', 'additional', 'code', 'proc', 'content', 'datalwfetspdeunemployment', 'run', 'proc', 'content', 'datalwfetspukunemployment', 'run', 'proc', 'content', 'datalwfetspusaunemployment', 'run']"
1606,"This demonstration illustrates how to produce a time plot. For this and subsequent demonstrations, the SAS windowing environment will be used. SAS/GRAPH software is easy to use, but default settings produce rather bland results. ODS Graphics have expanded the capabilities of SAS/GRAPH software to produce publication quality plots with minimal effort. The Ministry of Manpower, Singapore Government, publishes employment statistics. Data can be obtained (with English text) from: http://www.mom.gov.sg/publish/momportal/en/home.html Program Demo1_01Plot.sas contains SAS code to plot the Singapore unemployment time series. Use PROC CONTENTS to obtain information about the SAS data set LWFETSP.SGunemployment. title1 ""Unemployment in Singapore""; proc contents data=LWFETSP.SGunemployment; run; ASCII text from the output window follows. Unemployment in Singapore 2",FE,866,"['demonstration', 'illustrates', 'produce', 'time', 'plot', 'subsequent', 'demonstration', 'sa', 'windowing', 'environment', 'used', 'sasgraph', 'software', 'easy', 'use', 'default', 'setting', 'produce', 'rather', 'bland', 'result', 'od', 'graphic', 'expanded', 'capability', 'sasgraph', 'software', 'produce', 'publication', 'quality', 'plot', 'minimal', 'effort', 'ministry', 'manpower', 'singapore', 'government', 'publishes', 'employment', 'statistic', 'data', 'obtained', 'english', 'text', 'httpwwwmomgovsgpublishmomportalenhomehtml', 'program', 'demo101plotsas', 'contains', 'sa', 'code', 'plot', 'singapore', 'unemployment', 'time', 'series', 'use', 'proc', 'content', 'obtain', 'information', 'sa', 'data_set', 'lwfetspsgunemployment', 'title1', 'unemployment', 'singapore', 'proc', 'content', 'datalwfetspsgunemployment', 'run', 'ascii', 'text', 'output', 'window', 'follows', 'unemployment', 'singapore', '2']"
1607,"The plot also shows the richness of SAS/GRAPH output. The prior plot uses a BMP graphics format, while the above plot uses Activex to display plotted results. The labels Max, Mean, and Min were added after the plot was produced, but these could have been added using the SAS/GRAPH annotate capability. While the above plot might be useful, it might also illustrate overkill in that very little new information is provided by the plot that is not also available elsewhere. Discipline is required to prevent chart information from becoming chart clutter, or chart junk. Tufte (1983) provides useful guidelines for visualizing data. SAS provides many ways to plot a time series.",FE,675,"['plot', 'also', 'show', 'richness', 'sasgraph', 'output', 'prior', 'plot', 'us', 'bmp', 'graphic', 'format', 'plot', 'us', 'activex', 'display', 'plotted', 'result', 'label', 'max', 'mean', 'min', 'added', 'plot', 'wa', 'produced', 'could', 'added', 'using', 'sasgraph', 'annotate', 'capability', 'plot', 'might', 'useful', 'might', 'also', 'illustrate', 'overkill', 'little', 'new', 'information', 'provided', 'plot', 'also', 'available', 'elsewhere', 'discipline', 'required', 'prevent', 'chart', 'information', 'becoming', 'chart', 'clutter', 'chart', 'junk', 'tufte', '1983', 'provides', 'useful', 'guideline', 'visualizing', 'data', 'sa', 'provides', 'many', 'way', 'plot', 'time', 'series']"
1608,"The %AllTSPlots macro uses PROC TIMESERIES to produce all of the usual diagnostic plots for a time series. %AllTSPlots(DSName=SAS-Data-Set, TargetVar=variable, DateVar=variable); To produce plots for the monthly primary lead production time series, the following code is employed. ods html; %AllTSPlots(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date); ods html close; Some of the resulting plots follow.",FE,411,"['alltsplots', 'macro', 'us', 'proc', 'timeseries', 'produce', 'usual', 'diagnostic', 'plot', 'time', 'series', 'alltsplotsdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'produce', 'plot', 'monthly', 'primary', 'lead', 'production', 'time', 'series', 'following', 'code', 'employed', 'od', 'html', 'alltsplotsdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'od', 'html', 'close', 'resulting', 'plot', 'follow']"
1609,"While R-Square always increases when inputs are added to a model, the variations of adjusted R- Square may decrease when an input is added. The random walk R-Square simply compares a forecast model to the random walk forecast model.",FE,232,"['rsquare', 'always', 'increase', 'input', 'added', 'model', 'variation', 'adjusted', 'r', 'square', 'may', 'decrease', 'input', 'added', 'random', 'walk', 'rsquare', 'simply', 'compare', 'forecast', 'model', 'random', 'walk', 'forecast', 'model']"
1610,"The series appears to be nonstationary. In addition to the above smoothed plot, use %PlotSmoothSeries to produce a smoothed version using B-splines and a LOESS smother. ods html; %PlotSmoothSeries(DSName=work.EnergyPS_USA, TargetVar=USA, DateVar=Date); ods html close; Only the b-spline result is displayed below.",FE,313,"['series', 'appears', 'nonstationary', 'addition', 'smoothed', 'plot', 'use', 'plotsmoothseries', 'produce', 'smoothed', 'version', 'using', 'bsplines', 'loess', 'smother', 'od', 'html', 'plotsmoothseriesdsnameworkenergypsusa', 'targetvarusa', 'datevardate', 'od', 'html', 'close', 'bspline', 'result', 'displayed']"
1611,"For the random walk with drift, the name of the target variable is followed by (1), which signifies a first difference. Differencing relates to random walk models as described above.",FE,182,"['random', 'walk', 'drift', 'name', 'target', 'variable', 'followed', '1', 'signifies', 'first', 'difference', 'differencing', 'relates', 'random', 'walk', 'model', 'described']"
1612,"Your computer screen will show the color coded lines. For the grayscale of the course notes, the top line corresponds to the MA estimate, and the bottom line corresponds to the first order AR estimate.",FE,201,"['computer', 'screen', 'show', 'color', 'coded', 'line', 'grayscale', 'course', 'note', 'top', 'line', 'corresponds', 'estimate', 'bottom', 'line', 'corresponds', 'first', 'order', 'ar', 'estimate']"
1613,"One purpose of time series analysis is to explain or describe the behavior of a time series. Examining the annual time series of civilian unemployment in the United States helps explain effects of public policy during the Great Depression. For example, in understanding the spike in unemployment in 1938, analysis reveals that efforts to balance the budget had a negative effect on employment.",FE,393,"['one', 'purpose', 'time', 'series', 'analysis', 'explain', 'describe', 'behavior', 'time', 'series', 'examining', 'annual', 'time', 'series', 'civilian', 'unemployment', 'united', 'state', 'help', 'explain', 'effect', 'public', 'policy', 'great', 'depression', 'example', 'understanding', 'spike', 'unemployment', '1938', 'analysis', 'reveals', 'effort', 'balance', 'budget', 'negative', 'effect', 'employment']"
1614,"Annual lead production in the United States falls into two categories, primary and secondary. Primary production includes mining and processing lead ore, whereas secondary lead production includes recycling of lead extracted from discarded manufactured products. Lead is a basic component in lead acetate batteries and electronic components. Although lead use has been discontinued in many building materials, the increased use of lead in electronics has helped offset the loss in demand. The demand for lead is increasingly satisfied through secondary lead production. The largest source of recovered lead is through the recycling of automobile batteries. There are two datasets containing lead production data at two different frequencies, annual and monthly, and at two different time ranges. Following is a plot of annual primary lead production found in LWFETSP.LEADYEAR. The program Ch02_01.sas contains code that produces the results displayed in this section.",FE,967,"['annual', 'lead', 'production', 'united', 'state', 'fall', 'two', 'category', 'primary', 'secondary', 'primary', 'production', 'includes', 'mining', 'processing', 'lead', 'ore', 'whereas', 'secondary', 'lead', 'production', 'includes', 'recycling', 'lead', 'extracted', 'discarded', 'manufactured', 'product', 'lead', 'basic', 'component', 'lead', 'acetate', 'battery', 'electronic', 'component', 'although', 'lead', 'use', 'ha', 'discontinued', 'many', 'building', 'material', 'increased', 'use', 'lead', 'electronics', 'ha', 'helped', 'offset', 'loss', 'demand', 'demand', 'lead', 'increasingly', 'satisfied', 'secondary', 'lead', 'production', 'largest', 'source', 'recovered', 'lead', 'recycling', 'automobile', 'battery', 'two', 'datasets', 'containing', 'lead', 'production', 'data', 'two', 'different', 'frequency', 'annual', 'monthly', 'two', 'different', 'time', 'range', 'following', 'plot', 'annual', 'primary', 'lead', 'production', 'found', 'lwfetspleadyear', 'program', 'ch0201sas', 'contains', 'code', 'produce', 'result', 'displayed', 'section']"
1615,"This demonstration illustrates the modeling of trend and seasonality using the NOAA temperature data for the state of Texas. The code for this demonstration can be found in Dem3_03Temp.sas. The data was obtained from the National Climatic Data Center Web site of the NOAA. http://www.ncdc.noaa.gov/oa/ncdc.html The SAS data set LWFETSP.USA_TX_NOAA contains several climate variables for the state of Texas in the United States. This demonstration focuses on temperature values in Fahrenheit from January 1895, to February 2009. Temperature data sets gathered over long periods can help determine the effects of global warming. The following program creates a working copy of the temperature data set and provides the primary diagnostic plots for model determination. %WorkCopy(LWFETSP.USA_TX_NOAA); ods html; %AllTSPlots(DSName=work.USA_TX_NOAA, TargetVar=Temperature, DateVar=Date); ods html close; The diagnostic plots follow.",FE,928,"['demonstration', 'illustrates', 'modeling', 'trend', 'seasonality', 'using', 'noaa', 'temperature', 'data', 'state', 'texas', 'code', 'demonstration', 'found', 'dem303tempsas', 'data', 'wa', 'obtained', 'national', 'climatic', 'data', 'center', 'web', 'site', 'noaa', 'httpwwwncdcnoaagovoancdchtml', 'sa', 'data_set', 'lwfetspusatxnoaa', 'contains', 'several', 'climate', 'variable', 'state', 'texas', 'united', 'state', 'demonstration', 'focus', 'temperature', 'value', 'fahrenheit', 'january', '1895', 'february', '2009', 'temperature', 'data_set', 'gathered', 'long', 'period', 'help', 'determine', 'effect', 'global', 'warming', 'following', 'program', 'creates', 'working', 'copy', 'temperature', 'data_set', 'provides', 'primary', 'diagnostic', 'plot', 'model', 'determination', 'workcopylwfetspusatxnoaa', 'od', 'html', 'alltsplotsdsnameworkusatxnoaa', 'targetvartemperature', 'datevardate', 'od', 'html', 'close', 'diagnostic', 'plot', 'follow']"
1616,"The proximity effect makes values separated by two time lags appear to be positively correlated, but this is a spurious result caused by the common negative correlation with the value in the middle.",FE,198,"['proximity', 'effect', 'make', 'value', 'separated', 'two', 'time', 'lag', 'appear', 'positively', 'correlated', 'spurious', 'result', 'caused', 'common', 'negative', 'correlation', 'value', 'middle']"
1617,"Data preparation issues are covered in some detail in a later chapter, but the course focuses on the analysis portion of the project. While plotting a time series can reveal data quality issues, the primary purpose of plotting the data is to identify candidate models for forecasting.",FE,284,"['data', 'preparation', 'issue', 'covered', 'detail', 'later', 'chapter', 'course', 'focus', 'analysis', 'portion', 'project', 'plotting', 'time', 'series', 'reveal', 'data', 'quality', 'issue', 'primary', 'purpose', 'plotting', 'data', 'identify', 'candidate', 'model', 'forecasting']"
1618,"Time series analysis can be univariate/univariable, where a time series is modeled simply using functions of time and past values of the series. Time series analysis can also be univariate/multivariable, where explanatory variables are added to help explain the behavior of the series. Time series analysis can also be multivariate, which is always multivariable, where two or more time series are modeled together to produce forecasts for each series. This course addresses univariate time series analysis. A later chapter focuses on multivariable analysis, framing the topic as time series regression analysis, also called dynamic regression analysis. In time series regression analysis, a regression model having one or more explanatory variables is used to forecast the series of interest.",FE,793,"['time', 'series', 'analysis', 'univariateunivariable', 'time', 'series', 'modeled', 'simply', 'using', 'function', 'time', 'past', 'value', 'series', 'time', 'series', 'analysis', 'also', 'univariatemultivariable', 'explanatory', 'variable', 'added', 'help', 'explain', 'behavior', 'series', 'time', 'series', 'analysis', 'also', 'multivariate', 'always', 'multivariable', 'two', 'time', 'series', 'modeled', 'together', 'produce', 'forecast', 'series', 'course', 'address', 'univariate', 'time', 'series', 'analysis', 'later', 'chapter', 'focus', 'multivariable', 'analysis', 'framing', 'topic', 'time', 'series', 'regression', 'analysis', 'also', 'called', 'dynamic', 'regression', 'analysis', 'time', 'series', 'regression', 'analysis', 'regression_model', 'one', 'explanatory', 'variable', 'used', 'forecast', 'series', 'interest']"
1619,"SAS Enterprise Guide has several tasks for forecasting. If SAS Enterprise Guide is used for this course, tasks will primarily be performed within the SAS Code task. If you use SAS Enterprise Guide, you will need to assign the library LWFETSP, and for programs that use course macros, you will need to include the following statement at the beginning of your program. %include ""S:\workshop\sassrc\LWFETSP.sas"";",FE,409,"['sa', 'enterprise', 'guide', 'ha', 'several', 'task', 'forecasting', 'sa', 'enterprise', 'guide', 'used', 'course', 'task', 'primarily', 'performed', 'within', 'sa', 'code', 'task', 'use', 'sa', 'enterprise', 'guide', 'need', 'assign', 'library', 'lwfetsp', 'program', 'use', 'course', 'macro', 'need', 'include', 'following', 'statement', 'beginning', 'program', 'include', 'sworkshopsassrclwfetspsas']"
1620,"The %PlotSmoothSeriesPlot macro uses PROC SGPLOT to produce two smoothed plots, the first using B-splines, and the second using a LOESS smoother. %PlotSmoothSeries(DSName=SAS-Data-Set, TargetVar=variable, DateVar=variable, Smoothness=number); The default value for DateVar is Date. The Smoothness argument is obsolete in SAS 9.2, but is retained to work with earlier versions of the software. Following is an example. ods html; %PlotSmoothSeries(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date); ods html close; The resulting plots follow.",FE,546,"['plotsmoothseriesplot', 'macro', 'us', 'proc', 'sgplot', 'produce', 'two', 'smoothed', 'plot', 'first', 'using', 'bsplines', 'second', 'using', 'loess', 'smoother', 'plotsmoothseriesdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'smoothnessnumber', 'default', 'value', 'datevar', 'date', 'smoothness', 'argument', 'obsolete', 'sa', '92', 'retained', 'work', 'earlier', 'version', 'software', 'following', 'example', 'od', 'html', 'plotsmoothseriesdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'od', 'html', 'close', 'resulting', 'plot', 'follow']"
1621,"The Yule-Walker equations can be solved when the true population autocorrelations are replaced by sample autocorrelations. The method of moments is a general statistical estimation technique that estimates parameters by substituting sample moments for population moments. The sample autocorrelations are sample moments, so Yule-Walker estimators are method of moments estimators.",FE,379,"['yulewalker', 'equation', 'solved', 'true', 'population', 'autocorrelations', 'replaced', 'sample', 'autocorrelations', 'method', 'moment', 'general', 'statistical', 'estimation', 'technique', 'estimate', 'parameter', 'substituting', 'sample', 'moment', 'population', 'moment', 'sample', 'autocorrelations', 'sample', 'moment', 'yulewalker', 'estimator', 'method', 'moment', 'estimator']"
1622,"While the estimates corresponding to the trend component are not statistically significant, lack of statistical significance is not a sufficient reason to disqualify a model.",FE,174,"['estimate', 'corresponding', 'trend', 'component', 'statistically', 'significant', 'lack', 'statistical', 'significance', 'sufficient', 'reason', 'disqualify', 'model']"
1623,"Box-Jenkins time series analysis promotes the use of differencing to model trend and seasonality. The general Box-Jenkins ARIMA(p,d,q)(P,D,Q)s model can be employed to forecast nonstationary time series using stochastic trend and seasonal components. The Box-Jenkins methodology developed in a previous chapter is expanded to include identification of first difference order d and seasonal orders (P,D,Q). The estimation and forecasting steps include a step to convert a series to stationarity, estimate the stationary component, and then integrate back to the original series. Despite the emphasis on differencing, the methodology accommodates deterministic trend and seasonal components as well as stochastic ones. PROC ARIMA provides a full implementation of Box-Jenkins models. In addition, PROC SPECTRA provides diagnostic functions to help diagnose seasonality. PROC ESM provides three models for time series with trend only, one model for time series with seasonal effects only, and two models for time series with trend and seasonal factors.",FE,1049,"['boxjenkins', 'time', 'series', 'analysis', 'promotes', 'use', 'differencing', 'model', 'trend', 'seasonality', 'general', 'boxjenkins', 'arimapdqpdqs', 'model', 'employed', 'forecast', 'nonstationary', 'time', 'series', 'using', 'stochastic', 'trend', 'seasonal', 'component', 'boxjenkins', 'methodology', 'developed', 'previous', 'chapter', 'expanded', 'include', 'identification', 'first', 'difference', 'order', 'seasonal', 'order', 'pdq', 'estimation', 'forecasting', 'step', 'include', 'step', 'convert', 'series', 'stationarity', 'estimate', 'stationary', 'component', 'integrate', 'back', 'original', 'series', 'despite', 'emphasis', 'differencing', 'methodology', 'accommodates', 'deterministic', 'trend', 'seasonal', 'component', 'well', 'stochastic', 'one', 'proc', 'arima', 'provides', 'full', 'implementation', 'boxjenkins', 'model', 'addition', 'proc', 'spectrum', 'provides', 'diagnostic', 'function', 'help', 'diagnose', 'seasonality', 'proc', 'esm', 'provides', 'three', 'model', 'time', 'series', 'trend', 'one', 'model', 'time', 'series', 'seasonal', 'effect', 'two', 'model', 'time', 'series', 'trend', 'seasonal', 'factor']"
1624,"Examination of the plot reveals no obvious choices for model components. Diagnostics will be introduced later that will suggest one of the two simple models displayed above. To fit a random walk with drift to the time series, and to fit a first order autoregressive model to the time series, PROC ARIMA might be used.",FE,317,"['examination', 'plot', 'reveals', 'obvious', 'choice', 'model', 'component', 'diagnostics', 'introduced', 'later', 'suggest', 'one', 'two', 'simple', 'model', 'displayed', 'fit', 'random', 'walk', 'drift', 'time', 'series', 'fit', 'first', 'order', 'autoregressive', 'model', 'time', 'series', 'proc', 'arima', 'might', 'used']"
1625,The bars labeled Estimate represent the first 12 estimated parameters for the 21 parameter transfer function. The bars labeled Transfer Function represent the weights from the expansion of the ratio of polynomials for the last model proposed above. The data provide a good example of how three parameter estimates can approximate the same behavior as 12 parameter estimates. The program produces the usual residual analysis content and plots the forecasts. PROC ARIMA uses the pre-whitening model for the inputs to forecast the inputs into the future. The forecast plot follows.,FE,578,"['bar', 'labeled', 'estimate', 'represent', 'first', '12', 'estimated', 'parameter', '21', 'parameter', 'transfer', 'function', 'bar', 'labeled', 'transfer', 'function', 'represent', 'weight', 'expansion', 'ratio', 'polynomial', 'last', 'model', 'proposed', 'data', 'provide', 'good', 'example', 'three', 'parameter_estimate', 'approximate', 'behavior', '12', 'parameter_estimate', 'program', 'produce', 'usual', 'residual', 'analysis', 'content', 'plot', 'forecast', 'proc', 'arima', 'us', 'prewhitening', 'model', 'input', 'forecast', 'input', 'future', 'forecast', 'plot', 'follows']"
1626,"The second differences produce equally bewildering results. Nonetheless, the Dickey-Fuller tests provide evidence that the monthly primary lead production series is stationary. The continuing analysis entertains the possibility of trend. As indicated before, the %AutoTrend macro automatically fits and evaluates random walk trend and the seven deterministic trend functions: linear, quadratic, cubic, logistic, logarithmic, hyperbolic, and exponential. %AutoTrend(DSName=SAS-Data-Set, OutDS=SAS-Data-Set, TargetVar=variable, DateVar=variable, Lead=number); Application of the macro to the lead production data follows. %AutoTrend(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date,Lead=12); The table of goodness-of-fit statistics sorted by MAPE appears below.",FE,765,"['second', 'difference', 'produce', 'equally', 'bewildering', 'result', 'nonetheless', 'dickeyfuller', 'test', 'provide', 'evidence', 'monthly', 'primary', 'lead', 'production', 'series', 'stationary', 'continuing', 'analysis', 'entertains', 'possibility', 'trend', 'indicated', 'autotrend', 'macro', 'automatically', 'fit', 'evaluates', 'random', 'walk', 'trend', 'seven', 'deterministic', 'trend', 'function', 'linear', 'quadratic', 'cubic', 'logistic', 'logarithmic', 'hyperbolic', 'exponential', 'autotrenddsnamesasdataset', 'outdssasdataset', 'targetvarvariable', 'datevarvariable', 'leadnumber', 'application', 'macro', 'lead', 'production', 'data', 'follows', 'autotrenddsnameworkleadmonth', 'targetvarprimary', 'datevardatelead12', 'table', 'goodnessoffit', 'statistic', 'sorted', 'mape', 'appears']"
1627,The seasonal components plot is difficult to interpret because it spans all years in the series. One strategy for overcoming this high-density plot problem is to restrict the seasonal values to one full year. Code is presented below the trend plot to accomplish this task. The moving average trend plot follows.,FE,311,"['seasonal', 'component', 'plot', 'difficult', 'interpret', 'span', 'year', 'series', 'one', 'strategy', 'overcoming', 'highdensity', 'plot', 'problem', 'restrict', 'seasonal', 'value', 'one', 'full', 'year', 'code', 'presented', 'trend', 'plot', 'accomplish', 'task', 'moving', 'average', 'trend', 'plot', 'follows']"
1628,"Because the plot always expands to fill the window, you must examine the vertical axis. Changes of more than 5% warrant investigation. The above plot suggests that the lead production data might be seasonal. Following is the trend plot.",FE,236,"['plot', 'always', 'expands', 'fill', 'window', 'must', 'examine', 'vertical', 'axis', 'change', '5', 'warrant', 'investigation', 'plot', 'suggests', 'lead', 'production', 'data', 'might', 'seasonal', 'following', 'trend', 'plot']"
1629,"The identification of an AR(1) model is na?ve, revealing an ignorance of the implication of trend being present in a time series. However, continuing down the wrong path will help illustrate the concept of stationarity.",FE,219,"['identification', 'ar1', 'model', 'nave', 'revealing', 'ignorance', 'implication', 'trend', 'present', 'time', 'series', 'however', 'continuing', 'wrong', 'path', 'help', 'illustrate', 'concept', 'stationarity']"
1630,"This demonstration illustrates how to use PROC ARIMA to analyze the lead production data. There are two lead production data sets supplied with the course, LWFETSP.LeadYear and LWFETSP.LeadMonth. This demonstration will use the monthly lead production data. The code can be found in Demo1_02Lead.sas. The variable PRIMARY contains the number of metric tons of lead produced in the United States per month. Primary production refers to mining, and secondary lead production refers to extracting lead from old manufactured items, like automobile batteries. The DATE variable records the monthly dates beginning in January, 1986, and continuing through September, 1992. The following code lists the contents of the data set. title1 ""Primary U.S. Lead Production""; proc contents data=LWFETSP.LeadMonth; run; The output follows. Primary U.S. Lead Production",FE,852,"['demonstration', 'illustrates', 'use', 'proc', 'arima', 'analyze', 'lead', 'production', 'data', 'two', 'lead', 'production', 'data_set', 'supplied', 'course', 'lwfetspleadyear', 'lwfetspleadmonth', 'demonstration', 'use', 'monthly', 'lead', 'production', 'data', 'code', 'found', 'demo102leadsas', 'variable', 'primary', 'contains', 'number', 'metric', 'ton', 'lead', 'produced', 'united', 'state', 'per', 'month', 'primary', 'production', 'refers', 'mining', 'secondary', 'lead', 'production', 'refers', 'extracting', 'lead', 'old', 'manufactured', 'item', 'like', 'automobile', 'battery', 'date', 'variable', 'record', 'monthly', 'date', 'beginning', 'january', '1986', 'continuing', 'september', '1992', 'following', 'code', 'list', 'content', 'data_set', 'title1', 'primary', 'u', 'lead', 'production', 'proc', 'content', 'datalwfetspleadmonth', 'run', 'output', 'follows', 'primary', 'u', 'lead', 'production']"
1631,1. Forecast the next 24 months of electronics sales for the LWFETSP.Electronics data. a. Use an ARIMA model with differencing to model trend and seasonality. b. Use an ARIMA model using some strategy other than differencing to model trend and seasonality. c. Use a Winters multiplicative exponential smoothing model. Solutions to Exercises 1. Solutions for this exercise are coded in Exercises_Ch3.sas. PROC CONTENTS summarizes the contents of the electronics data set. The program also contains code for adding appropriate trend and seasonal variables. %WorkCopy(LWFETSP.Electronics);,FE,585,"['1', 'forecast', 'next', '24', 'month', 'electronics', 'sale', 'lwfetspelectronics', 'data', 'use', 'arima', 'model', 'differencing', 'model', 'trend', 'seasonality', 'b', 'use', 'arima', 'model', 'using', 'strategy', 'differencing', 'model', 'trend', 'seasonality', 'c', 'use', 'winter', 'multiplicative', 'exponential', 'smoothing', 'model', 'solution', 'exercise', '1', 'solution', 'exercise', 'coded', 'exercisesch3sas', 'proc', 'content', 'summarizes', 'content', 'electronics', 'data_set', 'program', 'also', 'contains', 'code', 'adding', 'appropriate', 'trend', 'seasonal', 'variable', 'workcopylwfetspelectronics']"
1632,"For the additive model, the function simply sums the components. An alternative model is the multiplicative decomposition model. which is additive on the log scale:",FE,164,"['additive', 'model', 'function', 'simply', 'sum', 'component', 'alternative', 'model', 'multiplicative', 'decomposition', 'model', 'additive', 'log', 'scale']"
1633,"MAPE and RMSE select the simple ESM, but the two SSE forms of the information criteria select the random walk with drift model. Solutions to Student Activities (Polls/Quizzes)",FE,175,"['mape', 'rmse', 'select', 'simple', 'esm', 'two', 'sse', 'form', 'information', 'criterion', 'select', 'random', 'walk', 'drift', 'model', 'solution', 'student', 'activity', 'pollsquizzes']"
1634,"With 180 data points (15 years of monthly data!), the first order autocorrelation becomes statistically significant. While such a small value might lack practical significance, you can see the difficulty inherent in diagnosing small autocorrelation values.",FE,256,"['180', 'data', 'point', '15', 'year', 'monthly', 'data', 'first', 'order', 'autocorrelation', 'becomes', 'statistically', 'significant', 'small', 'value', 'might', 'lack', 'practical', 'significance', 'see', 'difficulty', 'inherent', 'diagnosing', 'small', 'autocorrelation', 'value']"
1635,"The forecasts generated by an RWD model are substantially different than forecasts generated by an AR1 model. Furthermore, the confidence intervals for an RWD model are wider than the confidence intervals for an AR1 model. Consequently, choice of forecast model is critically important. If you are having trouble picking a winning forecast model, you might want to plot the competing forecasts together with actual values of the series.",FE,436,"['forecast', 'generated', 'rwd', 'model', 'substantially', 'different', 'forecast', 'generated', 'ar1', 'model', 'furthermore', 'confidence', 'interval', 'rwd', 'model', 'wider', 'confidence', 'interval', 'ar1', 'model', 'consequently', 'choice', 'forecast', 'model', 'critically', 'important', 'trouble', 'picking', 'winning', 'forecast', 'model', 'might', 'want', 'plot', 'competing', 'forecast', 'together', 'actual', 'value', 'series']"
1636,"The CCF works best when the two time series have been pre-whitened. Otherwise, trend, seasonality, and cross-correlations with other input variables can contaminate the CCF and make it almost impossible to identify an appropriate transfer function without some trial and error. Pre- whitening will be discussed I a later section.",FE,329,"['ccf', 'work', 'best', 'two', 'time', 'series', 'prewhitened', 'otherwise', 'trend', 'seasonality', 'crosscorrelations', 'input', 'variable', 'contaminate', 'ccf', 'make', 'almost', 'impossible', 'identify', 'appropriate', 'transfer', 'function', 'without', 'trial', 'error', 'pre', 'whitening', 'discussed', 'later', 'section']"
1637,"The theory of ARMA modeling includes the important property that ARMA models are universal approximators. The technical definition of a universal approximator is beyond the scope of this course. A simple intuitive explanation captures the essence of the technical definition. If you are confronted with any arbitrary stationary process, that process has a true (population) autocorrelation function. Given that true autocorrelation function and a ?closeness? metric D, there exists an ARMA process that has the same autocorrelation function to within D units of the true autocorrelation function. A version of the theory proves that any stationary process can be approximated by an ARMA model in the sense that the spectral density function of the ARMA model will be ?close? to the true spectral density function. ?	Universal approximators are pervasive in the mathematical and statistical literature. Neural networks are universal approximators for a large class of functions. Many advanced calculus courses discuss Fourier series and Taylor series as universal approximators of a large class of mathematical functions. Rational polynomials are universal approximators and provide the foundation for numerical algorithms to approximate mathematical functions. For example, there is a rational polynomial approximation for calculating Gaussian probabilities, which otherwise would require tedious numerical integration techniques. Universal approximators are nice, but the theory only guarantees that an approximator exists, NOT that you will actually be able to find one for a given model and data set.",FE,1603,"['theory', 'arma', 'modeling', 'includes', 'important', 'property', 'arma', 'model', 'universal', 'approximators', 'technical', 'definition', 'universal', 'approximator', 'beyond', 'scope', 'course', 'simple', 'intuitive', 'explanation', 'capture', 'essence', 'technical', 'definition', 'confronted', 'arbitrary', 'stationary', 'process', 'process', 'ha', 'true', 'population', 'autocorrelation', 'function', 'given', 'true', 'autocorrelation', 'function', 'closeness', 'metric', 'exists', 'arma', 'process', 'ha', 'autocorrelation', 'function', 'within', 'unit', 'true', 'autocorrelation', 'function', 'version', 'theory', 'prof', 'stationary', 'process', 'approximated', 'arma', 'model', 'sense', 'spectral', 'density', 'function', 'arma', 'model', 'close', 'true', 'spectral', 'density', 'function', '\tuniversal', 'approximators', 'pervasive', 'mathematical', 'statistical', 'literature', 'neural', 'network', 'universal', 'approximators', 'large', 'class', 'function', 'many', 'advanced', 'calculus', 'course', 'discus', 'fourier', 'series', 'taylor', 'series', 'universal', 'approximators', 'large', 'class', 'mathematical', 'function', 'rational', 'polynomial', 'universal', 'approximators', 'provide', 'foundation', 'numerical', 'algorithm', 'approximate', 'mathematical', 'function', 'example', 'rational', 'polynomial', 'approximation', 'calculating', 'gaussian', 'probability', 'otherwise', 'would', 'require', 'tedious', 'numerical', 'integration', 'technique', 'universal', 'approximators', 'nice', 'theory', 'guarantee', 'approximator', 'exists', 'actually', 'able', 'find', 'one', 'given', 'model', 'data_set']"
1638,"The apparent haphazard use of Greek letters can be confusing; however, there is a strategy behind the notation. Usually beta is reserved as the notation for regression coefficients. Phi applies to autoregressive terms, and theta is employed for moving average terms. If you employed beta for regressors and for AR terms, at some point, the proliferation of subscripts would be overwhelming.",FE,390,"['apparent', 'haphazard', 'use', 'greek', 'letter', 'confusing', 'however', 'strategy', 'behind', 'notation', 'usually', 'beta', 'reserved', 'notation', 'regression', 'coefficient', 'phi', 'applies', 'autoregressive', 'term', 'theta', 'employed', 'moving', 'average', 'term', 'employed', 'beta', 'regressors', 'ar', 'term', 'point', 'proliferation', 'subscript', 'would', 'overwhelming']"
1639,"There is some evidence of a quadratic trend and possible seasonal factors. To obtain further diagnostics, use the following code. ods html; %AllTSPlots(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date); ods html close; The %AllTSPlots macro calls PROC TIMESERIES to produce all of the correlation plots along with other diagnostics. The syntax for this macro follows. %AllTSPlots(DSName=SAS-data-set, TargetVar=variable, DateVar=variable); The following plots are produced, along with normalized versions of the correlation plots, which are omitted.",FE,555,"['evidence', 'quadratic', 'trend', 'possible', 'seasonal', 'factor', 'obtain', 'diagnostics', 'use', 'following', 'code', 'od', 'html', 'alltsplotsdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'od', 'html', 'close', 'alltsplots', 'macro', 'call', 'proc', 'timeseries', 'produce', 'correlation', 'plot', 'along', 'diagnostics', 'syntax', 'macro', 'follows', 'alltsplotsdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'following', 'plot', 'produced', 'along', 'normalized', 'version', 'correlation', 'plot', 'omitted']"
1640,"Omitting Canada or Mexico individually does not make the other variable useful, so both are dropped. Mexico and Canada are major suppliers of oil to the U.S., so the weak influence of Canada and Mexico in the model is surprising. ods output ParameterEstimates=work.ParmEst2V FitStatistics=work.FitStat2V; proc reg data=work.WorldOil outest=work.Est2VModel; OPEC: model USA=Iraq OPEC / vif corrb influence edf press aic sbc; run; quit; ods html; proc print data=work.ParmEst2V noobs; var Variable DF Estimate StdErr Probt VarianceInflation; run; ods html close; The table follows.",FE,579,"['omitting', 'canada', 'mexico', 'individually', 'doe', 'make', 'variable', 'useful', 'dropped', 'mexico', 'canada', 'major', 'supplier', 'oil', 'u', 'weak', 'influence', 'canada', 'mexico', 'model', 'surprising', 'od', 'output', 'parameterestimatesworkparmest2v', 'fitstatisticsworkfitstat2v', 'proc', 'reg', 'dataworkworldoil', 'outestworkest2vmodel', 'opec', 'model', 'usairaq', 'opec', '', 'vif', 'corrb', 'influence', 'edf', 'press', 'aic', 'sbc', 'run', 'quit', 'od', 'html', 'proc', 'print', 'dataworkparmest2v', 'noobs', 'var', 'variable', 'df', 'estimate', 'stderr', 'probt', 'varianceinflation', 'run', 'od', 'html', 'close', 'table', 'follows']"
1641,"This demonstration illustrates estimation methods for fitting ARMA models to data. In a prior demonstration you saw how to identify candidate models for the three time series in the LWFETSP.Groceries data set. You are now ready to fit these candidate models to the data. The code employed in this demonstration may be found in the file Demo2_06Groceries.sas. In the interest of brevity, only a subset of the models suggested by order determining diagnostics will be considered. The Toothpaste series was diagnosed as being approximated by an MA(1) model, among others. The following code estimates the parameters of an MA(1) model using four estimation techniques. ods html; ods graphics on; proc arima data=work.Groceries plots=all; identify var=ToothPaste nlags=14 noprint; estimate q=1 method=cls plot maxiter=0 outest=work.TPyw; estimate q=1 method=cls plot outest=work.TPcls; estimate q=1 method=uls plot outest=work.TPuls; estimate q=1 method=ml plot outest=work.TPml; quit; ods graphics off; ods html close; The first set of estimates is produced by what may be called the two-stage Yule-Walker estimation method as described before. Before looking at each model, view how the estimates differ.",FE,1201,"['demonstration', 'illustrates', 'estimation', 'method', 'fitting', 'arma', 'model', 'data', 'prior', 'demonstration', 'saw', 'identify', 'candidate', 'model', 'three', 'time', 'series', 'lwfetspgroceries', 'data_set', 'ready', 'fit', 'candidate', 'model', 'data', 'code', 'employed', 'demonstration', 'may', 'found', 'file', 'demo206groceriessas', 'interest', 'brevity', 'subset', 'model', 'suggested', 'order', 'determining', 'diagnostics', 'considered', 'toothpaste', 'series', 'wa', 'diagnosed', 'approximated', 'ma1', 'model', 'among', 'others', 'following', 'code', 'estimate', 'parameter', 'ma1', 'model', 'using', 'four', 'estimation', 'technique', 'od', 'html', 'od', 'graphic', 'proc', 'arima', 'dataworkgroceries', 'plotsall', 'identify', 'vartoothpaste', 'nlags14', 'noprint', 'estimate', 'q1', 'methodcls', 'plot', 'maxiter0', 'outestworktpyw', 'estimate', 'q1', 'methodcls', 'plot', 'outestworktpcls', 'estimate', 'q1', 'methoduls', 'plot', 'outestworktpuls', 'estimate', 'q1', 'methodml', 'plot', 'outestworktpml', 'quit', 'od', 'graphic', 'od', 'html', 'close', 'first', 'set', 'estimate', 'produced', 'may', 'called', 'twostage', 'yulewalker', 'estimation', 'method', 'described', 'looking', 'model', 'view', 'estimate', 'differ']"
1642,"PROC TIMESERIES decomposes the series into trend, seasonal, and irregular components. The %AllTSPlots macro is designed to produce decomposition plots when the series is positive at all time points, and when the time interval has a natural seasonal period. Annual data does not have a natural seasonal period, so no decomposition is produced for annual data. Following is a plot representing the multiplicative seasonal components.",FE,431,"['proc', 'timeseries', 'decomposes', 'series', 'trend', 'seasonal', 'irregular', 'component', 'alltsplots', 'macro', 'designed', 'produce', 'decomposition', 'plot', 'series', 'positive', 'time', 'point', 'time', 'interval', 'ha', 'natural', 'seasonal', 'period', 'annual', 'data', 'doe', 'natural', 'seasonal', 'period', 'decomposition', 'produced', 'annual', 'data', 'following', 'plot', 'representing', 'multiplicative', 'seasonal', 'component']"
1643,"The RMSE values differ from those that appeared previously because the number of model parameters is not subtracted from the denominator. The larger denominator should produce smaller values, but RMSE for the first model is actually larger than the previous value. The original RMSE value is actually the maximum likelihood estimate of the prediction variance with a square root applied. It should be similar to the square root of SSE/(n-k), but it is not exactly equivalent. Nonetheless, as before, RMSE selects the second model, but like AIC and SBC, MAPE selects the first model. If the goal is to assess the effect of the events of September 11, 2001, on airline passenger counts, then either model is adequate. If the goal is forecasting, the ramp term will tend to cause the second model to produce smaller forecasts.",FE,823,"['rmse', 'value', 'differ', 'appeared', 'previously', 'number', 'model', 'parameter', 'subtracted', 'denominator', 'larger', 'denominator', 'produce', 'smaller', 'value', 'rmse', 'first', 'model', 'actually', 'larger', 'previous', 'value', 'original', 'rmse', 'value', 'actually', 'maximum', 'likelihood', 'estimate', 'prediction', 'variance', 'square', 'root', 'applied', 'similar', 'square', 'root', 'ssenk', 'exactly', 'equivalent', 'nonetheless', 'rmse', 'selects', 'second', 'model', 'like', 'aic', 'sbc', 'mape', 'selects', 'first', 'model', 'goal', 'ass', 'effect', 'event', 'september', '11', '2001', 'airline', 'passenger', 'count', 'either', 'model', 'adequate', 'goal', 'forecasting', 'ramp', 'term', 'tend', 'cause', 'second', 'model', 'produce', 'smaller', 'forecast']"
1644,"Several macros are supplied that use the forecast data set from PROC ARIMA to produce forecast plots. All of the previous Singapore Unemployment plots were generated using course macros. In the Box-Jenkins approach, the IDENTIFY step uses a variety of tools for identifying candidate models. PROC ARIMA and PROC TIMESERIES provide the relevant plots.",FE,350,"['several', 'macro', 'supplied', 'use', 'forecast', 'data_set', 'proc', 'arima', 'produce', 'forecast', 'plot', 'previous', 'singapore', 'unemployment', 'plot', 'generated', 'using', 'course', 'macro', 'boxjenkins', 'approach', 'identify', 'step', 'us', 'variety', 'tool', 'identifying', 'candidate', 'model', 'proc', 'arima', 'proc', 'timeseries', 'provide', 'relevant', 'plot']"
1645,This demonstration illustrates how to identify ARMA models using automatic order determining techniques. Code for this demonstration may be found in Demo2_4ARMAid.sas. The SAS data set LWFETSP.ARMA_Series05 contains observed values from a autoregressive moving average process. The following code uses PROC ARIMA to generate diagnostic plots. %WorkCopy(LWFETSP.ARMA_Series05); ods html; ods graphics on; proc arima data=work.ARMA_Series05 plots=all; identify var=Y nlags=14; quit; ods graphics off; ods html close; The autocorrelation plots follow.,FE,548,"['demonstration', 'illustrates', 'identify', 'arma', 'model', 'using', 'automatic', 'order', 'determining', 'technique', 'code', 'demonstration', 'may', 'found', 'demo24armaidsas', 'sa', 'data_set', 'lwfetsparmaseries05', 'contains', 'observed', 'value', 'autoregressive', 'moving', 'average', 'process', 'following', 'code', 'us', 'proc', 'arima', 'generate', 'diagnostic', 'plot', 'workcopylwfetsparmaseries05', 'od', 'html', 'od', 'graphic', 'proc', 'arima', 'dataworkarmaseries05', 'plotsall', 'identify', 'vary', 'nlags14', 'quit', 'od', 'graphic', 'od', 'html', 'close', 'autocorrelation', 'plot', 'follow']"
1646,MINIC assumes that the time series is stationary. ESACF and SCAN permit the series to be nonstationary and provide diagnostics to indicate the nature of the nonstationarity.,FE,173,"['minic', 'assumes', 'time', 'series', 'stationary', 'esacf', 'scan', 'permit', 'series', 'nonstationary', 'provide', 'diagnostics', 'indicate', 'nature', 'nonstationarity']"
1647,"Except for anomalies at lags 3 and 5, the first differences also appear to be stationary. This is unusual because differencing a stationary series often induces nonstationarity. ?	Unusually large values of the Rho statistic are probably caused by numerical instability. The instability is caused when division is carried out with a divisor that is near zero. Tau is recommended over Rho when evidence of numerical instability is present.",FE,437,"['except', 'anomaly', 'lag', '3', '5', 'first', 'difference', 'also', 'appear', 'stationary', 'unusual', 'differencing', 'stationary', 'series', 'often', 'induces', 'nonstationarity', '\tunusually', 'large', 'value', 'rho', 'statistic', 'probably', 'caused', 'numerical', 'instability', 'instability', 'caused', 'division', 'carried', 'divisor', 'near', 'zero', 'tau', 'recommended', 'rho', 'evidence', 'numerical', 'instability', 'present']"
1648,"A time series can be decomposed into trend, seasonal, cyclical, and irregular components. Discussion of the irregular component must wait for additional background information.",FE,176,"['time', 'series', 'decomposed', 'trend', 'seasonal', 'cyclical', 'irregular', 'component', 'discussion', 'irregular', 'component', 'must', 'wait', 'additional', 'background', 'information']"
1649,This demonstration illustrates how to use the OUTLIER statement in PROC ARIMA to identify unusual observations. The program Demo4_04GulfOil.sas contains code used for this demonstration. The following SAS code creates a working copy of the data and produces a contents listing. %WorkCopy(LWFETSP.GulfOilGas);,FE,308,"['demonstration', 'illustrates', 'use', 'outlier', 'statement', 'proc', 'arima', 'identify', 'unusual', 'observation', 'program', 'demo404gulfoilsas', 'contains', 'code', 'used', 'demonstration', 'following', 'sa', 'code', 'creates', 'working', 'copy', 'data', 'produce', 'content', 'listing', 'workcopylwfetspgulfoilgas']"
1650,"Initial inspection of a plot of a stationary time series often leads the analysts to classify the series as indistinguishable from white noise. However, with experience, you learn to detect patterns that suggest autocorrelated data.",FE,232,"['initial', 'inspection', 'plot', 'stationary', 'time', 'series', 'often', 'lead', 'analyst', 'classify', 'series', 'indistinguishable', 'white', 'noise', 'however', 'experience', 'learn', 'detect', 'pattern', 'suggest', 'autocorrelated', 'data']"
1651,"SBC actually picks a white noise model, but this model has been rejected by the Ljung-Box test. The source file for this demonstration contains extended analyses relevant for the discussion of anthropogenic global warming.",FE,222,"['sbc', 'actually', 'pick', 'white', 'noise', 'model', 'model', 'ha', 'rejected', 'ljungbox', 'test', 'source', 'file', 'demonstration', 'contains', 'extended', 'analysis', 'relevant', 'discussion', 'anthropogenic', 'global', 'warming']"
1652,"By default, ACTIVEX produces a scatter plot with data points represented by blue, unfilled circles. The default setting for PROC GPLOT is to produce a scatter plot. To enhance the plot, use the following code. symbol1 interpol=join; ods html; proc gplot data=work.SGunemployment; plot PercentUnemployed*Date; run; quit; ods html close; The SYMBOL statement provides instructions for plotting data points. The option INTERPOL= (I=) lets you control how data points are interpolated. The option INTERPOL=JOIN simply connects data points with a straight line.",FE,556,"['default', 'activex', 'produce', 'scatter', 'plot', 'data', 'point', 'represented', 'blue', 'unfilled', 'circle', 'default', 'setting', 'proc', 'gplot', 'produce', 'scatter', 'plot', 'enhance', 'plot', 'use', 'following', 'code', 'symbol1', 'interpoljoin', 'od', 'html', 'proc', 'gplot', 'dataworksgunemployment', 'plot', 'percentunemployeddate', 'run', 'quit', 'od', 'html', 'close', 'symbol', 'statement', 'provides', 'instruction', 'plotting', 'data', 'point', 'option', 'interpol', 'let', 'control', 'data', 'point', 'interpolated', 'option', 'interpoljoin', 'simply', 'connects', 'data', 'point', 'straight', 'line']"
1653,"The variance inflation factor indicates that OAPEC, OPEC, and PersianGulf suffer as a consequence of multicollinearity. This has an operational explanation?OPEC, OAPEC, and Persian Gulf producers share member countries, so some of the same production figures are employed by all three. The oil production sources are not mutually exclusive. ?	Care could have been exercised in extracting of the data, but data on certain individual countries is limited. Furthermore, smaller members of OPEC and OAPEC might have had sporadic production, which would create sparsity problems that can impair modeling. The correlations of the estimates support the multicollinearity diagnostics. ods html; proc print data=work.CorrB noobs; var Variable Canada Iraq Mexico OAPEC OPEC PersianGulf Venezuela; format Canada Iraq Mexico OAPEC OPEC PersianGulf Venezuela 6.3; run; ods html close; The correlation table follows.",FE,902,"['variance', 'inflation', 'factor', 'indicates', 'oapec', 'opec', 'persiangulf', 'suffer', 'consequence', 'multicollinearity', 'ha', 'operational', 'explanationopec', 'oapec', 'persian', 'gulf', 'producer', 'share', 'member', 'country', 'production', 'figure', 'employed', 'three', 'oil', 'production', 'source', 'mutually', 'exclusive', '\tcare', 'could', 'exercised', 'extracting', 'data', 'data', 'certain', 'individual', 'country', 'limited', 'furthermore', 'smaller', 'member', 'opec', 'oapec', 'might', 'sporadic', 'production', 'would', 'create', 'sparsity', 'problem', 'impair', 'modeling', 'correlation', 'estimate', 'support', 'multicollinearity', 'diagnostics', 'od', 'html', 'proc', 'print', 'dataworkcorrb', 'noobs', 'var', 'variable', 'canada', 'iraq', 'mexico', 'oapec', 'opec', 'persiangulf', 'venezuela', 'format', 'canada', 'iraq', 'mexico', 'oapec', 'opec', 'persiangulf', 'venezuela', '63', 'run', 'od', 'html', 'close', 'correlation', 'table', 'follows']"
1654,"The design of PROC ARIMA is based on the pioneering work of Box and Jenkins (1976). They proposed a three-step approach to forecasting: Identify-Estimate-Forecast. The Box-Jenkins approach was outlined in a previous section. Box-Jenkins methodology will be formally introduced in a later section. The basic syntax for PROC ARIMA follows. The VAR= option identifies the target variable to be forecast. The CROSS and INPUT options are for dynamic regression models. The keyword CROSS is an accepted shorthand version of CROSSCORR, for CROSS CORRelations. The P= option identifies the order of the autoregression employed for forecasting. METHOD=ML requests maximum likelihood estimation. The LEAD= option indicates how many time units to predict into the future. If ID= and INTERVAL= options are supplied, PROC ARIMA will extend the ID variable into the future as well. The OUT= option identifies the name of the data set that will contain forecasts. The NLAGS= and Q= options will be described later. The following code fits a random walk model to the time series and then fits an autoregressive order 1 model to the series.",FE,1123,"['design', 'proc', 'arima', 'based', 'pioneering', 'work', 'box', 'jenkins', '1976', 'proposed', 'threestep', 'approach', 'forecasting', 'identifyestimateforecast', 'boxjenkins', 'approach', 'wa', 'outlined', 'previous', 'section', 'boxjenkins', 'methodology', 'formally', 'introduced', 'later', 'section', 'basic', 'syntax', 'proc', 'arima', 'follows', 'var', 'option', 'identifies', 'target', 'variable', 'forecast', 'cross', 'input', 'option', 'dynamic', 'regression_model', 'keyword', 'cross', 'accepted', 'shorthand', 'version', 'crosscorr', 'cross', 'correlation', 'p', 'option', 'identifies', 'order', 'autoregression', 'employed', 'forecasting', 'methodml', 'request', 'maximum', 'likelihood', 'estimation', 'lead', 'option', 'indicates', 'many', 'time', 'unit', 'predict', 'future', 'id', 'interval', 'option', 'supplied', 'proc', 'arima', 'extend', 'id', 'variable', 'future', 'well', 'option', 'identifies', 'name', 'data_set', 'contain', 'forecast', 'nlags', 'q', 'option', 'described', 'later', 'following', 'code', 'fit', 'random', 'walk', 'model', 'time', 'series', 'fit', 'autoregressive', 'order', '1', 'model', 'series']"
1655,"The model with OPEC has the largest R-Square and the smallest RMSE, AIC, and SBC. The tentative model is fit using the following SAS code. ods output ParameterEstimates=work.ParmEst5V FitStatistics=work.FitStat5V; proc reg data=work.WorldOil outest=work.Est5VModel; OPEC: model USA=Canada Iraq Mexico OPEC Venezuela / vif corrb influence edf press aic sbc; run; quit; The parameter estimates table follows.",FE,406,"['model', 'opec', 'ha', 'largest', 'rsquare', 'smallest', 'rmse', 'aic', 'sbc', 'tentative', 'model', 'fit', 'using', 'following', 'sa', 'code', 'od', 'output', 'parameterestimatesworkparmest5v', 'fitstatisticsworkfitstat5v', 'proc', 'reg', 'dataworkworldoil', 'outestworkest5vmodel', 'opec', 'model', 'usacanada', 'iraq', 'mexico', 'opec', 'venezuela', '', 'vif', 'corrb', 'influence', 'edf', 'press', 'aic', 'sbc', 'run', 'quit', 'parameter_estimate', 'table', 'follows']"
1656,PROC ARIMA automatically incorporates the uncertainty in forecasting X into the forecast confidence intervals for Y. The residual analysis panel and table of Ljung-Box values follow.,FE,182,"['proc', 'arima', 'automatically', 'incorporates', 'uncertainty', 'forecasting', 'x', 'forecast', 'confidence', 'interval', 'residual', 'analysis', 'panel', 'table', 'ljungbox', 'value', 'follow']"
1657,"Many textbooks characterize a time series as deterministic systematic variation plus a stochastic irregular component. In the Box-Jenkins framework, the irregular component is a stationary time series. Decomposition models break a model into additive components or multiplicative components.",FE,291,"['many', 'textbook', 'characterize', 'time', 'series', 'deterministic', 'systematic', 'variation', 'plus', 'stochastic', 'irregular', 'component', 'boxjenkins', 'framework', 'irregular', 'component', 'stationary', 'time', 'series', 'decomposition', 'model', 'break', 'model', 'additive', 'component', 'multiplicative', 'component']"
1658,"Veteran SAS users may recall the SAS Display Manager (DM). Display manager has evolved into the windowing environment, although display manager commands and statements are still available.",FE,188,"['veteran', 'sa', 'user', 'may', 'recall', 'sa', 'display', 'manager', 'dm', 'display', 'manager', 'ha', 'evolved', 'windowing', 'environment', 'although', 'display', 'manager', 'command', 'statement', 'still', 'available']"
1659,"Residual diagnostics indicate that the model is adequate. There is insufficient post-intervention data for the September, 2005, hurricanes to produce reliable forecasts. However, the following code can be employed if forecasts must be generated. First, a FORECAST statement must be added to the PROC ARIMA code. forecast id=Date interval=month lead=12 out=work.TempOilF; Analysis of the GAS time series is left as an exercise.",FE,426,"['residual', 'diagnostics', 'indicate', 'model', 'adequate', 'insufficient', 'postintervention', 'data', 'september', '2005', 'hurricane', 'produce', 'reliable', 'forecast', 'however', 'following', 'code', 'employed', 'forecast', 'must', 'generated', 'first', 'forecast', 'statement', 'must', 'added', 'proc', 'arima', 'code', 'forecast', 'iddate', 'intervalmonth', 'lead12', 'outworktempoilf', 'analysis', 'gas', 'time', 'series', 'left', 'exercise']"
1660,"?	The cross-correlation function is the primary tool for identifying a transfer function that relates an input variable to the target. The diagnostic ability of the CCF is best when the two time series have been pre-whitened, but this only helps when all inputs that influence the target are uncorrelated with each other. When inputs are correlated, the CCF exhibits the influence of the given input on the target, but the CCF also exhibits the influence of the correlated variables simultaneously on the target. In such circumstances, the CCF at best can identify possible lead-lag relationships but usually provides no help in diagnosing the form of the transfer function. From Ordinary Regression to Dynamic Regression",FE,721,"['\tthe', 'crosscorrelation', 'function', 'primary', 'tool', 'identifying', 'transfer', 'function', 'relates', 'input', 'variable', 'target', 'diagnostic', 'ability', 'ccf', 'best', 'two', 'time', 'series', 'prewhitened', 'help', 'input', 'influence', 'target', 'uncorrelated', 'input', 'correlated', 'ccf', 'exhibit', 'influence', 'given', 'input', 'target', 'ccf', 'also', 'exhibit', 'influence', 'correlated', 'variable', 'simultaneously', 'target', 'circumstance', 'ccf', 'best', 'identify', 'possible', 'leadlag', 'relationship', 'usually', 'provides', 'help', 'diagnosing', 'form', 'transfer', 'function', 'ordinary', 'regression', 'dynamic', 'regression']"
1661,"The null hypothesis of a unit root is rejected in favor of the alternative hypothesis of stationarity for all approximating AR models. The Dickey-Fuller test concludes that the series is stationary. The conclusion is that the Hurricane series is not changing systematically as a function of time, so it cannot be used to support hypotheses concerning anthropogenic global warming, other than to provide evidence against possible effects of global warming on the development of tropical storms. You can fine tune the analysis by fitting proposed models to the data. You will find that SBC favors a stationary AR(1) model, and AIC favors a stationary ARMA(1,1) model. %AutoARMA(work.NorthAtlanticYears,Hurricanes,1,1,OutData=work.temp); ods html; proc print data=work.temp noobs; run; ods html close; The results follow.",FE,818,"['null', 'hypothesis', 'unit', 'root', 'rejected', 'favor', 'alternative', 'hypothesis', 'stationarity', 'approximating', 'ar', 'model', 'dickeyfuller', 'test', 'concludes', 'series', 'stationary', 'conclusion', 'hurricane', 'series', 'changing', 'systematically', 'function', 'time', 'cannot', 'used', 'support', 'hypothesis', 'concerning', 'anthropogenic', 'global', 'warming', 'provide', 'evidence', 'possible', 'effect', 'global', 'warming', 'development', 'tropical', 'storm', 'fine', 'tune', 'analysis', 'fitting', 'proposed', 'model', 'data', 'find', 'sbc', 'favor', 'stationary', 'ar1', 'model', 'aic', 'favor', 'stationary', 'arma11', 'model', 'autoarmaworknorthatlanticyearshurricanes11outdataworktemp', 'od', 'html', 'proc', 'print', 'dataworktemp', 'noobs', 'run', 'od', 'html', 'close', 'result', 'follow']"
1662,"Spikes at lag 12 emphasize the seasonal nature of temperature data. The temperature time series is not white noise, so clearly the white noise probability plot is erroneous. The enlarged plots are available, but only the enlarged IACF need be viewed. Spikes in the other plots are clearly visible in the correlation panel.",FE,322,"['spike', 'lag', '12', 'emphasize', 'seasonal', 'nature', 'temperature', 'data', 'temperature', 'time', 'series', 'white', 'noise', 'clearly', 'white', 'noise', 'probability', 'plot', 'erroneous', 'enlarged', 'plot', 'available', 'enlarged', 'iacf', 'need', 'viewed', 'spike', 'plot', 'clearly', 'visible', 'correlation', 'panel']"
1663,Failure to reject the null hypothesis for all approximating autoregressive models considered suggests that the airline passengers data is seasonal with a seasonal period of 12 (DLAG=12). Two macros have been created for this course to facilitate rapid access to Dickey-Fuller testing from PROC ARIMA. The %DisplayDF macro produces the Tau and Rho test results for single mean and for trend. The %DisplayDFPlot macro plots the p-values associated with the test. These macros are demonstrated later in the course.,FE,511,"['failure', 'reject', 'null', 'hypothesis', 'approximating', 'autoregressive', 'model', 'considered', 'suggests', 'airline', 'passenger', 'data', 'seasonal', 'seasonal', 'period', '12', 'dlag12', 'two', 'macro', 'created', 'course', 'facilitate', 'rapid', 'access', 'dickeyfuller', 'testing', 'proc', 'arima', 'displaydf', 'macro', 'produce', 'tau', 'rho', 'test', 'result', 'single', 'mean', 'trend', 'displaydfplot', 'macro', 'plot', 'pvalues', 'associated', 'test', 'macro', 'demonstrated', 'later', 'course']"
1664,"Scaling the estimates to permit comparison in an overlay plot, a plot is produced that compares the shape of the transfer function with the shape of the cross-correlation function. While there are similarities between the two functions, the cross-correlation function contains numerous spikes at higher lags.",FE,308,"['scaling', 'estimate', 'permit', 'comparison', 'overlay', 'plot', 'plot', 'produced', 'compare', 'shape', 'transfer', 'function', 'shape', 'crosscorrelation', 'function', 'similarity', 'two', 'function', 'crosscorrelation', 'function', 'contains', 'numerous', 'spike', 'higher', 'lag']"
1665,"You learned earlier that Box and Jenkins (1976) published a textbook that provides a comprehensive framework for forecasting. The textbook includes much of the research of the authors, but also accumulates research from a wealth of different sources. Box and Jenkins did not invent nor discover ARMA models, but their textbook is the primary reason that ARMA models and the Box-Jenkins method are so popular.",FE,408,"['learned', 'earlier', 'box', 'jenkins', '1976', 'published', 'textbook', 'provides', 'comprehensive', 'framework', 'forecasting', 'textbook', 'includes', 'much', 'research', 'author', 'also', 'accumulates', 'research', 'wealth', 'different', 'source', 'box', 'jenkins', 'invent', 'discover', 'arma', 'model', 'textbook', 'primary', 'reason', 'arma', 'model', 'boxjenkins', 'method', 'popular']"
1666,"The process of estimating parameters associated with unobserved error components can seem to be an impossible task. However, the next section provides a simple illustration of how this is accomplished.",FE,201,"['process', 'estimating', 'parameter', 'associated', 'unobserved', 'error', 'component', 'seem', 'impossible', 'task', 'however', 'next', 'section', 'provides', 'simple', 'illustration', 'accomplished']"
1667,The forecast data set is separated into three data sets and then converted from interleaved to concatenated. data work.Toothpaste(drop=PeanutButter Biscuits) work.PeanutButter(drop=ToothPaste Biscuits) work.Biscuits(drop=PeanutButter ToothPaste); set work.StepARfor; run;,FE,271,"['forecast', 'data_set', 'separated', 'three', 'data_set', 'converted', 'interleaved', 'concatenated', 'data', 'worktoothpastedroppeanutbutter', 'biscuit', 'workpeanutbutterdroptoothpaste', 'biscuit', 'workbiscuitsdroppeanutbutter', 'toothpaste', 'set', 'worksteparfor', 'run']"
1668,The forecast equation shown above only approximates the actual forecast equation. Some background information is required before the actual forecast equation can be discussed.,FE,175,"['forecast', 'equation', 'shown', 'approximates', 'actual', 'forecast', 'equation', 'background', 'information', 'required', 'actual', 'forecast', 'equation', 'discussed']"
1669,"The combined diagnostics are presented for each of the two models separately. First, consider the abrupt temporary intervention model. The table of estimate follows.",FE,165,"['combined', 'diagnostics', 'presented', 'two', 'model', 'separately', 'first', 'consider', 'abrupt', 'temporary', 'intervention', 'model', 'table', 'estimate', 'follows']"
1670,The pioneering work of Box and Jenkins (1976) introduced sophisticated statistical models for forecasting. A more formal introduction to Box-Jenkins methodology appears later. 1.2	Introduction to SAS Forecasting Software,FE,220,"['pioneering', 'work', 'box', 'jenkins', '1976', 'introduced', 'sophisticated', 'statistical', 'model', 'forecasting', 'formal', 'introduction', 'boxjenkins', 'methodology', 'appears', 'later', '12\tintroduction', 'sa', 'forecasting', 'software']"
1671,"Apparently many of the spikes in the previous CCF were for spurious relationships that were a result of trend or seasonality. The following code calls the macro that was mentioned above. The %CCF_TF macro produces the three transfer function plots that help relate the CCF to the transfer function. ods html; %CCF_TF(CCFdata=work.CCF,ParmEstData=work.ParmEst, InputVar=X); ods html close; The three plots follow.",FE,412,"['apparently', 'many', 'spike', 'previous', 'ccf', 'spurious', 'relationship', 'result', 'trend', 'seasonality', 'following', 'code', 'call', 'macro', 'wa', 'mentioned', 'ccftf', 'macro', 'produce', 'three', 'transfer', 'function', 'plot', 'help', 'relate', 'ccf', 'transfer', 'function', 'od', 'html', 'ccftfccfdataworkccfparmestdataworkparmest', 'inputvarx', 'od', 'html', 'close', 'three', 'plot', 'follow']"
1672,"Infinite memory forecasts require starting values. The starting values are somewhat arbitrary, and are usually obtained by setting unknown past values to the mean of the series, or by backcasting, a process of forecasting the series in reverse order. The infinite memory forecast equation starts as an equation for the model, and replaces unknown values by estimated or predicted values. The one- step-ahead infinite memory forecast for an ARMA model is given by",FE,462,"['infinite', 'memory', 'forecast', 'require', 'starting', 'value', 'starting', 'value', 'somewhat', 'arbitrary', 'usually', 'obtained', 'setting', 'unknown', 'past', 'value', 'mean', 'series', 'backcasting', 'process', 'forecasting', 'series', 'reverse', 'order', 'infinite', 'memory', 'forecast', 'equation', 'start', 'equation', 'model', 'replaces', 'unknown', 'value', 'estimated', 'predicted', 'value', 'one', 'stepahead', 'infinite', 'memory', 'forecast', 'arma', 'model', 'given']"
1673,"Nonlinear estimation cannot produce a closed-form equation for calculating the parameter estimates. Similar to the problems encountered when trying to calculate the IACF, nonlinear estimation ?guesses? a value, and then performs calculations acting as if the guessed value is true. Sophisticated algorithms do much more than what has been illustrated. For example, sophisticated algorithms suggest what the next ?guess? should be. The estimation section will elaborate on numerical techniques that are applied to this problem. The purpose of this illustration is to reveal that a model can be fit to data even when the model contains unobservable components.",FE,658,"['nonlinear', 'estimation', 'cannot', 'produce', 'closedform', 'equation', 'calculating', 'parameter_estimate', 'similar', 'problem', 'encountered', 'trying', 'calculate', 'iacf', 'nonlinear', 'estimation', 'guess', 'value', 'performs', 'calculation', 'acting', 'guessed', 'value', 'true', 'sophisticated', 'algorithm', 'much', 'ha', 'illustrated', 'example', 'sophisticated', 'algorithm', 'suggest', 'next', 'guess', 'estimation', 'section', 'elaborate', 'numerical', 'technique', 'applied', 'problem', 'purpose', 'illustration', 'reveal', 'model', 'fit', 'data', 'even', 'model', 'contains', 'unobservable', 'component']"
1674,"The notation employs Greek letters that are consistent with a more general notation developed in later chapters. Note that if , then the autoregressive model simplifies to the random walk with drift model. If the drift parameter is zero, , and if , then the model is called a random walk. The error component is white noise.",FE,324,"['notation', 'employ', 'greek', 'letter', 'consistent', 'general', 'notation', 'developed', 'later', 'chapter', 'note', '', 'autoregressive', 'model', 'simplifies', 'random', 'walk', 'drift', 'model', 'drift', 'parameter', 'zero', '', '', 'model', 'called', 'random', 'walk', 'error', 'component', 'white', 'noise']"
1675,"This demonstration illustrates how to obtain cross-correlations when pre-whitening is appropriate. The code for this demonstration can be found in Demo4_05PreWhiten.sas. The data set employed is LWFETSP.TFdata, which contains target variable Y, input variable X, and date variable Date. The following code makes a working copy of the data, prints a summary of the contents, and then produces comparison plots of the target and input series using a B-spline smoother. %WorkCopy(LWFETSP.TFdata);",FE,493,"['demonstration', 'illustrates', 'obtain', 'crosscorrelations', 'prewhitening', 'appropriate', 'code', 'demonstration', 'found', 'demo405prewhitensas', 'data_set', 'employed', 'lwfetsptfdata', 'contains', 'target', 'variable', 'input', 'variable', 'x', 'date', 'variable', 'date', 'following', 'code', 'make', 'working', 'copy', 'data', 'print', 'summary', 'content', 'produce', 'comparison', 'plot', 'target', 'input', 'series', 'using', 'bspline', 'smoother', 'workcopylwfetsptfdata']"
1676,"The %PlotSeriesPlus macro adds minimum, maximum, and mean horizontal lines to the plot, which is produced using PROC SGPLOT. %PlotSeriesPlus(DSName=SAS-Data-Set, TargetVar=variable, DateVar=variable); By default, DateVar=Date. Following is an example. ods html; %PlotSeriesPlus(DSName=work.LeadMonth, TargetVar=Primary, DateVar=Date); ods html close; The example code produces the following plot.",FE,396,"['plotseriesplus', 'macro', 'add', 'minimum', 'maximum', 'mean', 'horizontal', 'line', 'plot', 'produced', 'using', 'proc', 'sgplot', 'plotseriesplusdsnamesasdataset', 'targetvarvariable', 'datevarvariable', 'default', 'datevardate', 'following', 'example', 'od', 'html', 'plotseriesplusdsnameworkleadmonth', 'targetvarprimary', 'datevardate', 'od', 'html', 'close', 'example', 'code', 'produce', 'following', 'plot']"
1677,"The negative drift estimate suggests a downward trend, and this downward trend has been extrapolated to the next 12 months. The 95% prediction limits are very wide indicating great uncertainty in the forecasts. The autoregressive order 1 model results follow.",FE,259,"['negative', 'drift', 'estimate', 'suggests', 'downward', 'trend', 'downward', 'trend', 'ha', 'extrapolated', 'next', '12', 'month', '95', 'prediction', 'limit', 'wide', 'indicating', 'great', 'uncertainty', 'forecast', 'autoregressive', 'order', '1', 'model', 'result', 'follow']"
1678,"While results so far do not provide strong evidence for disqualification of an AR(1) model, a visual inspection of the forecasts raises serious doubts about the adequacy of an AR(1) model for approximating the true underlying process that generates the data.",FE,258,"['result', 'far', 'provide', 'strong', 'evidence', 'disqualification', 'ar1', 'model', 'visual', 'inspection', 'forecast', 'raise', 'serious', 'doubt', 'adequacy', 'ar1', 'model', 'approximating', 'true', 'underlying', 'process', 'generates', 'data']"
1679,"Amos Tversky pioneered the study of human judgment and contributed to one of the first comprehensive studies of judgment (Kahneman, Slavic, and Tversky 1982). The follow-up work by Gilovich, Griffin, and Kahneman (2002) provides additional insight into how humans make decisions. The general finding is that human judgment in forecasting tends to be very poor when compared to analytic techniques.",FE,397,"['amos', 'tversky', 'pioneered', 'study', 'human', 'judgment', 'contributed', 'one', 'first', 'comprehensive', 'study', 'judgment', 'kahneman', 'slavic', 'tversky', '1982', 'followup', 'work', 'gilovich', 'griffin', 'kahneman', '2002', 'provides', 'additional', 'insight', 'human', 'make', 'decision', 'general', 'finding', 'human', 'judgment', 'forecasting', 'tends', 'poor', 'compared', 'analytic', 'technique']"
1680,"Events often cause structural change in a time series. Events can be random or unexpected occurrences, or they can be planned. Examples of random or unexpected events are cyclones, earthquakes, terrorist attacks, scandal, and illness. Examples of planned events include promotions, organizational restructuring, acquisitions, and price changes.",FE,344,"['event', 'often', 'cause', 'structural', 'change', 'time', 'series', 'event', 'random', 'unexpected', 'occurrence', 'planned', 'example', 'random', 'unexpected', 'event', 'cyclone', 'earthquake', 'terrorist', 'attack', 'scandal', 'illness', 'example', 'planned', 'event', 'include', 'promotion', 'organizational', 'restructuring', 'acquisition', 'price', 'change']"
1681,"PROC IML takes the calculated phi estimates, swaps them as theta estimates, and then uses the CALL ARMACOV routine to calculate the autocorrelations for the inverse model. The printed autocorrelations reveal that they are identical (subject to rounding) to the values supplied by PROC ARIMA for the IACF.",FE,304,"['proc', 'iml', 'take', 'calculated', 'phi', 'estimate', 'swap', 'theta', 'estimate', 'us', 'call', 'armacov', 'routine', 'calculate', 'autocorrelations', 'inverse', 'model', 'printed', 'autocorrelations', 'reveal', 'identical', 'subject', 'rounding', 'value', 'supplied', 'proc', 'arima', 'iacf']"
1682,AIC will permit more parameters than SBC when 2k is smaller than klog(n). This occurs for all series with more than seven observations. Schwarz showed that AIC is biased toward over- parameterization. This might actually be a property that favors AIC over SBC.,FE,260,"['aic', 'permit', 'parameter', 'sbc', '2k', 'smaller', 'klogn', 'occurs', 'series', 'seven', 'observation', 'schwarz', 'showed', 'aic', 'biased', 'toward', 'parameterization', 'might', 'actually', 'property', 'favor', 'aic', 'sbc']"
1683,"A nonstationary time series is not stationary; the mean and/or variance of the series depend on the time of the observation. The nonstationarity is attributed to systematic variation resulting from some combination of trend, seasonal, and cyclical effects. For a stationary series, you have to diagnose the nature of the autocorrelation and identify an appropriate approximating ARMA model. For a nonstationary series, you first have to identify the trend, seasonal, or cyclical components that reduce the series to stationarity. When you have a residual series that is stationary, you can use the methods of the last chapter to identify an ARMA model to approximate the series.",FE,678,"['nonstationary', 'time', 'series', 'stationary', 'mean', 'andor', 'variance', 'series', 'depend', 'time', 'observation', 'nonstationarity', 'attributed', 'systematic', 'variation', 'resulting', 'combination', 'trend', 'seasonal', 'cyclical', 'effect', 'stationary', 'series', 'diagnose', 'nature', 'autocorrelation', 'identify', 'appropriate', 'approximating', 'arma', 'model', 'nonstationary', 'series', 'first', 'identify', 'trend', 'seasonal', 'cyclical', 'component', 'reduce', 'series', 'stationarity', 'residual', 'series', 'stationary', 'use', 'method', 'last', 'chapter', 'identify', 'arma', 'model', 'approximate', 'series']"
1684,"A Loess smoother reveals possible systematic variation, but the nature of the smooth curve seems insufficient to reject white noise. The Ljung-Box white noise test results are plotted above, but you can also examine a table of chi- square values.",FE,246,"['loess', 'smoother', 'reveals', 'possible', 'systematic', 'variation', 'nature', 'smooth', 'curve', 'seems', 'insufficient', 'reject', 'white', 'noise', 'ljungbox', 'white', 'noise', 'test', 'result', 'plotted', 'also', 'examine', 'table', 'chi', 'square', 'value']"
1685,"R-Square compares the sum of squared errors (SSE) of the forecast model to the SSE for the forecast model that forecasts every future value as the mean of the historic data. Consequently, if a model produces forecasts worse than the mean, then R-Square will be negative. This seems to contradict R-Square being a squared quantity that must be positive. Some practitioners prefer to define R- Square so that it can never be negative.",FE,432,"['rsquare', 'compare', 'sum', 'squared', 'error', 'sse', 'forecast', 'model', 'sse', 'forecast', 'model', 'forecast', 'every', 'future', 'value', 'mean', 'historic', 'data', 'consequently', 'model', 'produce', 'forecast', 'worse', 'mean', 'rsquare', 'negative', 'seems', 'contradict', 'rsquare', 'squared', 'quantity', 'must', 'positive', 'practitioner', 'prefer', 'define', 'r', 'square', 'never', 'negative']"
1686,"The symmetric MAPE (SMAPE) has been recommended for situations where the actual value of the time series can be zero. The MAE/Mean is a special case of the Weighted Mean Absolute percent Error (WMAPE). SMAPE and MAE/Mean have not been popular in the business world, as MAPE seems to dominate business forecasting.",FE,313,"['symmetric', 'mape', 'smape', 'ha', 'recommended', 'situation', 'actual', 'value', 'time', 'series', 'zero', 'maemean', 'special', 'case', 'weighted', 'mean', 'absolute', 'percent', 'error', 'wmape', 'smape', 'maemean', 'popular', 'business', 'world', 'mape', 'seems', 'dominate', 'business', 'forecasting']"
1687,Using PROC FORECAST to Forecast the Groceries Time Series This demonstration illustrates how to use PROC FORECAST to automatically forecast the three groceries time series. Code for this demonstration can be found in Demo2_08StepAR.sas. The following code creates a working copy of the data and generates forecasts using PROC FORECAST. %WorkCopy(LWFETSP.Groceries);,FE,365,"['using', 'proc', 'forecast', 'forecast', 'grocery', 'time', 'series', 'demonstration', 'illustrates', 'use', 'proc', 'forecast', 'automatically', 'forecast', 'three', 'grocery', 'time', 'series', 'code', 'demonstration', 'found', 'demo208steparsas', 'following', 'code', 'creates', 'working', 'copy', 'data', 'generates', 'forecast', 'using', 'proc', 'forecast', 'workcopylwfetspgroceries']"
1688,"A seasonal component exhibits repeat behavior across periods of time. A seasonal monthly time series has a period of 12 and repeats behavior every 12 months. A cyclical component is identical to a seasonal component except that the period of the cycle cannot be determined in advance of looking at the data. Seasonal fluctuations usually have a period that is determined in one of three ways: (1) by cosmological constants such as the solar cycle of 12 months and the lunar cycle of approximately 28 days; (2) by social convention such as observing an arbitrary seven-day week; or (3) by mechanical features or physical constants such as a turbine making a complete revolution every 37 seconds. A classic example of a cyclical component is sunspot activity, with peaks occurring roughly every 11 years. If scientists discover a physical cause of this phenomenon, such as information about solar fusion, solar rotation, or other factor implying an 11-year period, then the sunspot cyclical component will be reclassified as a seasonal component. Some physical constants reflecting periodicity no doubt started as empirical observations.",FE,1135,"['seasonal', 'component', 'exhibit', 'repeat', 'behavior', 'across', 'period', 'time', 'seasonal', 'monthly', 'time', 'series', 'ha', 'period', '12', 'repeat', 'behavior', 'every', '12', 'month', 'cyclical', 'component', 'identical', 'seasonal', 'component', 'except', 'period', 'cycle', 'cannot', 'determined', 'advance', 'looking', 'data', 'seasonal', 'fluctuation', 'usually', 'period', 'determined', 'one', 'three', 'way', '1', 'cosmological', 'constant', 'solar', 'cycle', '12', 'month', 'lunar', 'cycle', 'approximately', '28', 'day', '2', 'social', 'convention', 'observing', 'arbitrary', 'sevenday', 'week', '3', 'mechanical', 'feature', 'physical', 'constant', 'turbine', 'making', 'complete', 'revolution', 'every', '37', 'second', 'classic', 'example', 'cyclical', 'component', 'sunspot', 'activity', 'peak', 'occurring', 'roughly', 'every', '11', 'year', 'scientist', 'discover', 'physical', 'cause', 'phenomenon', 'information', 'solar', 'fusion', 'solar', 'rotation', 'factor', 'implying', '11year', 'period', 'sunspot', 'cyclical', 'component', 'reclassified', 'seasonal', 'component', 'physical', 'constant', 'reflecting', 'periodicity', 'doubt', 'started', 'empirical', 'observation']"
1689,"Mixed ARMA models are not ?mixed models? in the usual sense applied to situations addressed by the SAS/STAT procedure MIXED. However, many forecasting professionals call ARMA models ?mixed models?. ARMA models pose a challenge, but Box and Jenkins support their use because they promote parsimony. For example, and ARMA(2,1) model might perform just as well as an AR(6) model, but the ARMA model only requires estimation of four parameters (including the constant), whereas the AR model requires estimation of seven parameters.",FE,527,"['mixed', 'arma', 'model', 'mixed', 'model', 'usual', 'sense', 'applied', 'situation', 'addressed', 'sasstat', 'procedure', 'mixed', 'however', 'many', 'forecasting', 'professional', 'call', 'arma', 'model', 'mixed', 'model', 'arma', 'model', 'pose', 'challenge', 'box', 'jenkins', 'support', 'use', 'promote', 'parsimony', 'example', 'arma21', 'model', 'might', 'perform', 'well', 'ar6', 'model', 'arma', 'model', 'requires', 'estimation', 'four', 'parameter', 'including', 'constant', 'whereas', 'ar', 'model', 'requires', 'estimation', 'seven', 'parameter']"
1690,Examination of the number of murders in Texas would support use of a single mean test for seasonality. Evidence suggests that the number of murders in Texas is not seasonal.,FE,173,"['examination', 'number', 'murder', 'texas', 'would', 'support', 'use', 'single', 'mean', 'test', 'seasonality', 'evidence', 'suggests', 'number', 'murder', 'texas', 'seasonal']"
1691,"SAS Enterprise Guide is a thin client residing on the desktop. SAS Enterprise Guide can be installed as a standalone application. As a standalone application, SAS Enterprise Guide uses a local server on the desktop to complete the client-server configuration. Otherwise, SAS Enterprise Guide accesses a SAS server through a network.",FE,332,"['sa', 'enterprise', 'guide', 'thin', 'client', 'residing', 'desktop', 'sa', 'enterprise', 'guide', 'installed', 'standalone', 'application', 'standalone', 'application', 'sa', 'enterprise', 'guide', 'us', 'local', 'server', 'desktop', 'complete', 'clientserver', 'configuration', 'otherwise', 'sa', 'enterprise', 'guide', 'access', 'sa', 'server', 'network']"
1692,"Trend represents systematic variation over time, often in the form of deterministic mathematical functions such as polynomials of time, logarithms of time, and exponential functions of time. In the above plot, the time series through the year 2000 seems to follow a linear trend pattern. A linear trend is a first degree polynomial of time.",FE,340,"['trend', 'represents', 'systematic', 'variation', 'time', 'often', 'form', 'deterministic', 'mathematical', 'function', 'polynomial', 'time', 'logarithm', 'time', 'exponential', 'function', 'time', 'plot', 'time', 'series', 'year', '2000', 'seems', 'follow', 'linear', 'trend', 'pattern', 'linear', 'trend', 'first', 'degree', 'polynomial', 'time']"
1693,"This demonstration illustrates how to use PROC ARIMA to evaluate advertising expenditures on sales. The SAS code for this demonstration can be found in Demo4_07Advertising.sas. An Internet start-up company provides financial and brokerage services to customers. A customer sets up an account with an initial deposit of $1,000, and then the company provides services via the Internet or by phone. Services include a variety of banking and investment options such as automatic debits for paying bills, on-demand transaction and tax information, automatic money market investing for positive balances, and online brokerage services for investing in stocks and mutual funds. The full data contains extensive breakdowns of advertising dollars. For example, for print media advertising, dollar amounts are recorded for each individual newspaper or magazine in which ads were placed. This illustrates a common situation where there are almost as many variables as there are observations. Another problem results from some accounts being tabulated monthly, while others are tabulated weekly. Many advertising accounts are dominated by zeroes, meaning that no advertising dollars were spent on the account for several months in a row. The response variable is the total sales amount for all customers. This amount reflects revenue generated by account activity such as deposits, investments, withdrawals, and so on. Finally, data are obtained from a data vendor that tabulates total sales amounts for a subset of the companies engaged in this type of Internet business. Many of the time-consuming and tedious steps of the analysis will be excluded. Some actions include aggregating data to the same time unit and deriving candidate predictor variables. The demonstration commences after the data has been processed into a form suitable for final modeling. The predictor variables are shown here: Predictor Variable Description DirectMail Weekly direct mail advertising (x$1000) Internet Weekly Internet advertising (x$1000) PrintMedia Weekly print media advertising (x$1000) SalesRatio Ratio of competitor sales to total known sales TVRadio Weekly TV/radio advertising (x$1000) The target variable is SalesAmount, which is total sales in thousands of dollars. An additional variable used in deriving SalesRatio is CompeteSales, which is the vendor-supplied value of sales for competing companies in the Internet domain. The data set that contains these variables is LWFETSP.SALEDATA, which has 88 weekly observations from the week of 28 September 1997 to the week of 30 May 1999. The following code produces a plot for the data. ods html; proc sgplot data=work.temp; series x=Date y=SalesAmount / y2axis lineattrs=GraphPrediction(pattern=1 color=red) legendlabel=""Sales Amount"" name=""series0"";; series x=Date y=DirectMail / lineattrs=GraphPrediction(pattern=2 color=blue) legendlabel=""Direct Mail"" name=""series1""; series x=Date y=Internet / lineattrs=GraphPrediction(pattern=3 color=darkblue) legendlabel=""Internet"" name=""series2""; series x=Date y=PrintMedia / lineattrs=GraphPrediction(pattern=4 color=green) legendlabel=""Print Media"" name=""series3""; series x=Date y=TVRadio / lineattrs=GraphPrediction(pattern=5 color=darkgreen) legendlabel=""TV Radio"" name=""series4""; keylegend ""series0"" ""series1"" ""series2"" ""series3"" ""series4""/ location=outside position=bottom; run; ods html close; The plot follows.",FE,3394,"['demonstration', 'illustrates', 'use', 'proc', 'arima', 'evaluate', 'advertising', 'expenditure', 'sale', 'sa', 'code', 'demonstration', 'found', 'demo407advertisingsas', 'internet', 'startup', 'company', 'provides', 'financial', 'brokerage', 'service', 'customer', 'customer', 'set', 'account', 'initial', 'deposit', '1000', 'company', 'provides', 'service', 'via', 'internet', 'phone', 'service', 'include', 'variety', 'banking', 'investment', 'option', 'automatic', 'debit', 'paying', 'bill', 'ondemand', 'transaction', 'tax', 'information', 'automatic', 'money', 'market', 'investing', 'positive', 'balance', 'online', 'brokerage', 'service', 'investing', 'stock', 'mutual', 'fund', 'full', 'data', 'contains', 'extensive', 'breakdown', 'advertising', 'dollar', 'example', 'print', 'medium', 'advertising', 'dollar', 'amount', 'recorded', 'individual', 'newspaper', 'magazine', 'ad', 'placed', 'illustrates', 'common', 'situation', 'almost', 'many', 'variable', 'observation', 'another', 'problem', 'result', 'account', 'tabulated', 'monthly', 'others', 'tabulated', 'weekly', 'many', 'advertising', 'account', 'dominated', 'zero', 'meaning', 'advertising', 'dollar', 'spent', 'account', 'several', 'month', 'row', 'response_variable', 'total', 'sale', 'amount', 'customer', 'amount', 'reflects', 'revenue', 'generated', 'account', 'activity', 'deposit', 'investment', 'withdrawal', 'finally', 'data', 'obtained', 'data', 'vendor', 'tabulates', 'total', 'sale', 'amount', 'subset', 'company', 'engaged', 'type', 'internet', 'business', 'many', 'timeconsuming', 'tedious', 'step', 'analysis', 'excluded', 'action', 'include', 'aggregating', 'data', 'time', 'unit', 'deriving', 'candidate', 'predictor_variable', 'demonstration', 'commences', 'data', 'ha', 'processed', 'form', 'suitable', 'final', 'modeling', 'predictor_variable', 'shown', 'predictor_variable', 'description', 'directmail', 'weekly', 'direct', 'mail', 'advertising', 'x1000', 'internet', 'weekly', 'internet', 'advertising', 'x1000', 'printmedia', 'weekly', 'print', 'medium', 'advertising', 'x1000', 'salesratio', 'ratio', 'competitor', 'sale', 'total', 'known', 'sale', 'tvradio', 'weekly', 'tvradio', 'advertising', 'x1000', 'target', 'variable', 'salesamount', 'total', 'sale', 'thousand', 'dollar', 'additional', 'variable', 'used', 'deriving', 'salesratio', 'competesales', 'vendorsupplied', 'value', 'sale', 'competing', 'company', 'internet', 'domain', 'data_set', 'contains', 'variable', 'lwfetspsaledata', 'ha', '88', 'weekly', 'observation', 'week', '28', 'september', '1997', 'week', '30', 'may', '1999', 'following', 'code', 'produce', 'plot', 'data', 'od', 'html', 'proc', 'sgplot', 'dataworktemp', 'series', 'xdate', 'ysalesamount', '', 'y2axis', 'lineattrsgraphpredictionpattern1', 'colorred', 'legendlabelsales', 'amount', 'nameseries0', 'series', 'xdate', 'ydirectmail', '', 'lineattrsgraphpredictionpattern2', 'colorblue', 'legendlabeldirect', 'mail', 'nameseries1', 'series', 'xdate', 'yinternet', '', 'lineattrsgraphpredictionpattern3', 'colordarkblue', 'legendlabelinternet', 'nameseries2', 'series', 'xdate', 'yprintmedia', '', 'lineattrsgraphpredictionpattern4', 'colorgreen', 'legendlabelprint', 'medium', 'nameseries3', 'series', 'xdate', 'ytvradio', '', 'lineattrsgraphpredictionpattern5', 'colordarkgreen', 'legendlabeltv', 'radio', 'nameseries4', 'keylegend', 'series0', 'series1', 'series2', 'series3', 'series4', 'locationoutside', 'positionbottom', 'run', 'od', 'html', 'close', 'plot', 'follows']"
1694,"224. The people who rise to positions of power in leftist movements tend to be leftists of the most power-hungry type because power-hungry people are those who strive hardest to get into positions of power. Once the power-hungry types have captured control of the movement, there are many leftists of a gentler breed who inwardly disapprove of many of the actions of the leaders, but cannot bring themselves to oppose them. They NEED their faith in the movement, and because they cannot give up this faith they go along with the leaders. True, SOME leftists do have the guts to oppose the totalitarian tendencies that emerge, but they generally lose, because the power-hungry types are better organized, are more ruthless and Machiavellian and have taken care to build themselves a strong power base.",TK,800,"['224', 'people', 'rise', 'position', 'power', 'leftist', 'movement', 'tend', 'leftist', 'powerhungry', 'type', 'powerhungry', 'people', 'strive', 'hardest', 'get', 'position', 'power', 'powerhungry', 'type', 'captured', 'control', 'movement', 'many', 'leftist', 'gentler', 'breed', 'inwardly', 'disapprove', 'many', 'action', 'leader', 'cannot', 'bring', 'oppose', 'need', 'faith', 'movement', 'cannot', 'give', 'faith', 'go', 'along', 'leader', 'true', 'leftist', 'gut', 'oppose', 'totalitarian', 'tendency', 'emerge', 'generally', 'lose', 'powerhungry', 'type', 'better', 'organized', 'ruthless', 'machiavellian', 'taken', 'care', 'build', 'strong', 'power', 'base']"
1695,179. It would be better to dump the whole stinking system and take the consequences.,TK,84,"['179', 'would', 'better', 'dump', 'whole', 'stinking', 'system', 'take', 'consequence']"
1696,"100. FIRST PRINCIPLE. If a SMALL change is made that affects a long-term historical trend, then the effect of that change will almost always be transitory - the trend will soon revert to its original state. (Example: A reform movement designed to clean up political corruption in a society rarely has more than a short-term effect; sooner or later the reformers relax and corruption creeps back in. The level of political corruption in a given society tends to remain constant, or to change only slowly with the evolution of the society. Normally, a political cleanup will be permanent only if accompanied by widespread social changes; a SMALL change in the society won't be enough.) If a small change in a long-term historical trend appears to be permanent, it is only because the change acts in the direction in which the trend is already moving, so that the trend is not altered but only pushed a step ahead.",TK,911,"['100', 'first', 'principle', 'small', 'change', 'made', 'affect', 'longterm', 'historical', 'trend', 'effect', 'change', 'almost', 'always', 'transitory', '', 'trend', 'soon', 'revert', 'original', 'state', 'example', 'reform', 'movement', 'designed', 'clean', 'political', 'corruption', 'society', 'rarely', 'ha', 'shortterm', 'effect', 'sooner', 'later', 'reformer', 'relax', 'corruption', 'creep', 'back', 'level', 'political', 'corruption', 'given', 'society', 'tends', 'remain', 'constant', 'change', 'slowly', 'evolution', 'society', 'normally', 'political', 'cleanup', 'permanent', 'accompanied', 'widespread', 'social', 'change', 'small', 'change', 'society', 'wont', 'enough', 'small', 'change', 'longterm', 'historical', 'trend', 'appears', 'permanent', 'change', 'act', 'direction', 'trend', 'already', 'moving', 'trend', 'altered', 'pushed', 'step', 'ahead']"
1697,"136. If anyone still imagines that it would be possible to reform the system in such a way as to protect freedom from technology, let him consider how clumsily and for the most part unsuccessfully our society has dealt with other social problems that are far more simple and straightforward. Among other things, the system has failed to stop environmental degradation, political corruption, drug trafficking or domestic abuse.",TK,426,"['136', 'anyone', 'still', 'imago', 'would', 'possible', 'reform', 'system', 'way', 'protect', 'freedom', 'technology', 'let', 'consider', 'clumsily', 'part', 'unsuccessfully', 'society', 'ha', 'dealt', 'social', 'problem', 'far', 'simple', 'straightforward', 'among', 'thing', 'system', 'ha', 'failed', 'stop', 'environmental', 'degradation', 'political', 'corruption', 'drug', 'trafficking', 'domestic', 'abuse']"
1698,"25. The moral code of our society is so demanding that no one can think, feel and act in a completely moral way. For example, we are not supposed to hate anyone, yet almost everyone hates somebody at some time or other, whether he admits it to himself or not. Some people are so highly socialized that the attempt to think, feel and act morally imposes a severe burden on them. In order to avoid feelings of guilt, they continually have to deceive themselves about their own motives and find moral explanations for feelings and actions that in reality have a non-moral origin. We use the term ""oversocialized"" to describe such people. [2]",TK,638,"['25', 'moral', 'code', 'society', 'demanding', 'one', 'think', 'feel', 'act', 'completely', 'moral', 'way', 'example', 'supposed', 'hate', 'anyone', 'yet', 'almost', 'everyone', 'hate', 'somebody', 'time', 'whether', 'admits', 'people', 'highly', 'socialized', 'attempt', 'think', 'feel', 'act', 'morally', 'imposes', 'severe', 'burden', 'order', 'avoid', 'feeling', 'guilt', 'continually', 'deceive', 'motif', 'find', 'moral', 'explanation', 'feeling', 'action', 'reality', 'nonmoral', 'origin', 'use', 'term', 'oversocialized', 'describe', 'people', '2']"
1699,"184. Nature makes a perfect counter-ideal to technology for several reasons. Nature (that which is outside the power of the system) is the opposite of technology (which seeks to expand indefinitely the power of the system). Most people will agree that nature is beautiful; certainly it has tremendous popular appeal. The radical environmentalists ALREADY hold an ideology that exalts nature and opposes technology. [30] It is not necessary for the sake of nature to set up some chimerical utopia or any new kind of social order. Nature takes care of itself: It was a spontaneous creation that existed long before any human society, and for countless centuries many different kinds of human societies coexisted with nature without doing it an excessive amount of damage. Only with the Industrial Revolution did the effect of human society on nature become really devastating. To relieve the pressure on nature it is not necessary to create a special kind of social system, it is only necessary to get rid of industrial society. Granted, this will not solve all problems. Industrial society has already done tremendous damage to nature and it will take a very long time for the scars to heal. Besides, even pre-industrial societies can do significant damage to nature. Nevertheless, getting rid of industrial society will accomplish a great deal. It will relieve the worst of the pressure on nature so that the scars can begin to heal. It will remove the capacity of organized society to keep increasing its control over nature (including human nature). Whatever kind of society may exist after the demise of the industrial system, it is certain that most people will live close to nature, because in the absence of advanced technology there is not other way that people CAN live. To feed themselves they must be peasants or herdsmen or fishermen or hunter, etc., And, generally speaking, local autonomy should tend to increase, because lack of advanced technology and rapid communications will limit the capacity of governments or other large organizations to control local communities.",TK,2085,"['184', 'nature', 'make', 'perfect', 'counterideal', 'technology', 'several', 'reason', 'nature', 'outside', 'power', 'system', 'opposite', 'technology', 'seek', 'expand', 'indefinitely', 'power', 'system', 'people', 'agree', 'nature', 'beautiful', 'certainly', 'ha', 'tremendous', 'popular', 'appeal', 'radical', 'environmentalist', 'already', 'hold', 'ideology', 'exalts', 'nature', 'opposes', 'technology', '30', 'necessary', 'sake', 'nature', 'set', 'chimerical', 'utopia', 'new', 'kind', 'social', 'order', 'nature', 'take', 'care', 'wa', 'spontaneous', 'creation', 'existed', 'long', 'human', 'society', 'countless', 'century', 'many', 'different', 'kind', 'human', 'society', 'coexisted', 'nature', 'without', 'excessive', 'amount', 'damage', 'industrial', 'revolution', 'effect', 'human', 'society', 'nature', 'become', 'really', 'devastating', 'relieve', 'pressure', 'nature', 'necessary', 'create', 'special', 'kind', 'social', 'system', 'necessary', 'get', 'rid', 'industrial', 'society', 'granted', 'solve', 'problem', 'industrial', 'society', 'ha', 'already', 'done', 'tremendous', 'damage', 'nature', 'take', 'long', 'time', 'scar', 'heal', 'besides', 'even', 'preindustrial', 'society', 'significant', 'damage', 'nature', 'nevertheless', 'getting', 'rid', 'industrial', 'society', 'accomplish', 'great', 'deal', 'relieve', 'worst', 'pressure', 'nature', 'scar', 'begin', 'heal', 'remove', 'capacity', 'organized', 'society', 'keep', 'increasing', 'control', 'nature', 'including', 'human', 'nature', 'whatever', 'kind', 'society', 'may', 'exist', 'demise', 'industrial', 'system', 'certain', 'people', 'live', 'close', 'nature', 'absence', 'advanced', 'technology', 'way', 'people', 'live', 'feed', 'must', 'peasant', 'herdsman', 'fisherman', 'hunter', 'etc', 'generally', 'speaking', 'local', 'autonomy', 'tend', 'increase', 'lack', 'advanced', 'technology', 'rapid', 'communication', 'limit', 'capacity', 'government', 'large', 'organization', 'control', 'local', 'community']"
1700,"36. Nonattainment of important goals results in death if the goals are physical necessities, and in frustration if nonattainment of the goals is compatible with survival. Consistent failure to attain goals throughout life results in defeatism, low self-esteem or depression.",TK,274,"['36', 'nonattainment', 'important', 'goal', 'result', 'death', 'goal', 'physical', 'necessity', 'frustration', 'nonattainment', 'goal', 'compatible', 'survival', 'consistent', 'failure', 'attain', 'goal', 'throughout', 'life', 'result', 'defeatism', 'low', 'selfesteem', 'depression']"
1701,"12. Those who are most sensitive about ""politically incorrect"" terminology are not the average black ghetto-dweller, Asian immigrant, abused woman or disabled person, but a minority of activists, many of whom do not even belong to any ""oppressed"" group but come from privileged strata of society. Political correctness has its stronghold among university professors, who have secure employment with comfortable salaries, and the majority of whom are heterosexual, white males from middle-class families.",TK,503,"['12', 'sensitive', 'politically', 'incorrect', 'terminology', 'average', 'black', 'ghettodweller', 'asian', 'immigrant', 'abused', 'woman', 'disabled', 'person', 'minority', 'activist', 'many', 'even', 'belong', 'oppressed', 'group', 'come', 'privileged', 'stratum', 'society', 'political', 'correctness', 'ha', 'stronghold', 'among', 'university', 'professor', 'secure', 'employment', 'comfortable', 'salary', 'majority', 'heterosexual', 'white', 'male', 'middleclass', 'family']"
1702,"115. The system HAS TO force people to behave in ways that are increasingly remote from the natural pattern of human behavior. For example, the system needs scientists, mathematicians and engineers. It can't function without them. So heavy pressure is put on children to excel in these fields. It isn't natural for an adolescent human being to spend the bulk of his time sitting at a desk absorbed in study. A normal adolescent wants to spend his time in active contact with the real world. Among primitive peoples the things that children are trained to do are in natural harmony with natural human impulses. Among the American Indians, for example, boys were trained in active outdoor pursuits -- just the sort of things that boys like. But in our society children are pushed into studying technical subjects, which most do grudgingly.",TK,837,"['115', 'system', 'ha', 'force', 'people', 'behave', 'way', 'increasingly', 'remote', 'natural', 'pattern', 'human', 'behavior', 'example', 'system', 'need', 'scientist', 'mathematician', 'engineer', 'cant', 'function', 'without', 'heavy', 'pressure', 'put', 'child', 'excel', 'field', 'isnt', 'natural', 'adolescent', 'human', 'spend', 'bulk', 'time', 'sitting', 'desk', 'absorbed', 'study', 'normal', 'adolescent', 'want', 'spend', 'time', 'active', 'contact', 'real', 'world', 'among', 'primitive', 'people', 'thing', 'child', 'trained', 'natural', 'harmony', 'natural', 'human', 'impulse', 'among', 'american', 'indian', 'example', 'boy', 'trained', 'active', 'outdoor', 'pursuit', '', 'sort', 'thing', 'boy', 'like', 'society', 'child', 'pushed', 'studying', 'technical', 'subject', 'grudgingly']"
1703,"192. But the way to discourage ethnic conflict is NOT through militant advocacy of minority rights (see paragraphs 21, 29). Instead, the revolutionaries should emphasize that although minorities do suffer more or less disadvantage, this disadvantage is of peripheral significance. Our real enemy is the industrial-technological system, and in the struggle against the system, ethnic distinctions are of no importance.",TK,417,"['192', 'way', 'discourage', 'ethnic', 'conflict', 'militant', 'advocacy', 'minority', 'right', 'see', 'paragraph', '21', '29', 'instead', 'revolutionary', 'emphasize', 'although', 'minority', 'suffer', 'le', 'disadvantage', 'disadvantage', 'peripheral', 'significance', 'real', 'enemy', 'industrialtechnological', 'system', 'struggle', 'system', 'ethnic', 'distinction', 'importance']"
1704,"135. In paragraph 125 we used an analogy of a weak neighbor who is left destitute by a strong neighbor who takes all his land by forcing on him a series of compromises. But suppose now that the strong neighbor gets sick, so that he is unable to defend himself. The weak neighbor can force the strong one to give him his land back, or he can kill him. If he lets the strong man survive and only forces him to give his land back, he is a fool, because when the strong man gets well he will again take all the land for himself. The only sensible alternative for the weaker man is to kill the strong one while he has the chance. In the same way, while the industrial system is sick we must destroy it. If we compromise with it and let it recover from its sickness, it will eventually wipe out all of our freedom.",TK,808,"['135', 'paragraph', '125', 'used', 'analogy', 'weak', 'neighbor', 'left', 'destitute', 'strong', 'neighbor', 'take', 'land', 'forcing', 'series', 'compromise', 'suppose', 'strong', 'neighbor', 'get', 'sick', 'unable', 'defend', 'weak', 'neighbor', 'force', 'strong', 'one', 'give', 'land', 'back', 'kill', 'let', 'strong', 'man', 'survive', 'force', 'give', 'land', 'back', 'fool', 'strong', 'man', 'get', 'well', 'take', 'land', 'sensible', 'alternative', 'weaker', 'man', 'kill', 'strong', 'one', 'ha', 'chance', 'way', 'industrial', 'system', 'sick', 'must', 'destroy', 'compromise', 'let', 'recover', 'sickness', 'eventually', 'wipe', 'freedom']"
1705,"65. Moreover, where goals are pursued through earning money, climbing the status ladder or functioning as part of the system in some other way, most people are not in a position to pursue their goals AUTONOMOUSLY. Most workers are someone else's employee as, as we pointed out in paragraph 61, must spend their days doing what they are told to do in the way they are told to do it. Even most people who are in business for themselves have only limited autonomy. It is a chronic complaint of small-business persons and entrepreneurs that their hands are tied by excessive government regulation. Some of these regulations are doubtless unnecessary, but for the most part government regulations are essential and inevitable parts of our extremely complex society. A large portion of small business today operates on the franchise system. It was reported in the Wall Street Journal a few years ago that many of the franchise-granting companies require applicants for franchises to take a personality test that is designed to EXCLUDE those who have creativity and initiative, because such persons are not sufficiently docile to go along obediently with the franchise system. This excludes from small business many of the people who most need autonomy.",TK,1246,"['65', 'moreover', 'goal', 'pursued', 'earning', 'money', 'climbing', 'status', 'ladder', 'functioning', 'part', 'system', 'way', 'people', 'position', 'pursue', 'goal', 'autonomously', 'worker', 'someone', 'el', 'employee', 'pointed', 'paragraph', '61', 'must', 'spend', 'day', 'told', 'way', 'told', 'even', 'people', 'business', 'limited', 'autonomy', 'chronic', 'complaint', 'smallbusiness', 'person', 'entrepreneur', 'hand', 'tied', 'excessive', 'government', 'regulation', 'regulation', 'doubtless', 'unnecessary', 'part', 'government', 'regulation', 'essential', 'inevitable', 'part', 'extremely', 'complex', 'society', 'large', 'portion', 'small', 'business', 'today', 'operates', 'franchise', 'system', 'wa', 'reported', 'wall', 'street', 'journal', 'year', 'ago', 'many', 'franchisegranting', 'company', 'require', 'applicant', 'franchise', 'take', 'personality', 'test', 'designed', 'exclude', 'creativity', 'initiative', 'person', 'sufficiently', 'docile', 'go', 'along', 'obediently', 'franchise', 'system', 'excludes', 'small', 'business', 'many', 'people', 'need', 'autonomy']"
1706,126. Let us explain why technology is a more powerful social force than the aspiration for freedom.,TK,99,"['126', 'let', 'u', 'explain', 'technology', 'powerful', 'social', 'force', 'aspiration', 'freedom']"
1707,"63. So certain artificial needs have been created that fall into group 2, hence serve the need for the power process. Advertising and marketing techniques have been developed that make many people feel they need things that their grandparents never desired or even dreamed of. It requires serious effort to earn enough money to satisfy these artificial needs, hence they fall into group 2. (But see paragraphs 80-82.) Modern man must satisfy his need for the power process largely through pursuit of the artificial needs created by the advertising and marketing industry [11], and through surrogate activities.",TK,610,"['63', 'certain', 'artificial', 'need', 'created', 'fall', 'group', '2', 'hence', 'serve', 'need', 'power', 'process', 'advertising', 'marketing', 'technique', 'developed', 'make', 'many', 'people', 'feel', 'need', 'thing', 'grandparent', 'never', 'desired', 'even', 'dreamed', 'requires', 'serious', 'effort', 'earn', 'enough', 'money', 'satisfy', 'artificial', 'need', 'hence', 'fall', 'group', '2', 'see', 'paragraph', '8082', 'modern', 'man', 'must', 'satisfy', 'need', 'power', 'process', 'largely', 'pursuit', 'artificial', 'need', 'created', 'advertising', 'marketing', 'industry', '11', 'surrogate', 'activity']"
1708,"32. The problems of the leftist are indicative of the problems of our society as a whole. Low self-esteem, depressive tendencies and defeatism are not restricted to the left. Though they are especially noticeable in the left, they are widespread in our society. And today's society tries to socialize us to a greater extent than any previous society. We are even told by experts how to eat, how to exercise, how to make love, how to raise our kids and so forth.",TK,461,"['32', 'problem', 'leftist', 'indicative', 'problem', 'society', 'whole', 'low', 'selfesteem', 'depressive', 'tendency', 'defeatism', 'restricted', 'left', 'though', 'especially', 'noticeable', 'left', 'widespread', 'society', 'today', 'society', 'try', 'socialize', 'u', 'greater', 'extent', 'previous', 'society', 'even', 'told', 'expert', 'eat', 'exercise', 'make', 'love', 'raise', 'kid', 'forth']"
1709,"10. By ""feelings of inferiority"" we mean not only inferiority feelings in the strictest sense but a whole spectrum of related traits: low self-esteem, feelings of powerlessness, depressive tendencies, defeatism, guilt, self-hatred, etc. We argue that modern leftists tend to have such feelings (possibly more or less repressed) and that these feelings are decisive in determining the direction of modern leftism.",TK,412,"['10', 'feeling', 'inferiority', 'mean', 'inferiority', 'feeling', 'strictest', 'sense', 'whole', 'spectrum', 'related', 'trait', 'low', 'selfesteem', 'feeling', 'powerlessness', 'depressive', 'tendency', 'defeatism', 'guilt', 'selfhatred', 'etc', 'argue', 'modern', 'leftist', 'tend', 'feeling', 'possibly', 'le', 'repressed', 'feeling', 'decisive', 'determining', 'direction', 'modern', 'leftism']"
1710,146. Drugs that affect the mind are only one example of the methods of controlling human behavior that modern society is developing. Let us look at some of the other methods.,TK,174,"['146', 'drug', 'affect', 'mind', 'one', 'example', 'method', 'controlling', 'human', 'behavior', 'modern', 'society', 'developing', 'let', 'u', 'look', 'method']"
1711,"199. Instead of arguing for powerlessness and passivity, one should argue that the power of the INDUSTRIAL SYSTEM should be broken, and that this will greatly INCREASE the power and freedom of INDIVIDUALS and SMALL GROUPS.",TK,222,"['199', 'instead', 'arguing', 'powerlessness', 'passivity', 'one', 'argue', 'power', 'industrial', 'system', 'broken', 'greatly', 'increase', 'power', 'freedom', 'individual', 'small', 'group']"
1712,"220. Suppose you asked leftists to make a list of ALL the things that were wrong with society, and then suppose you instituted EVERY social change that they demanded. It is safe to say that within a couple of years the majority of leftists would find something new to complain about, some new social ""evil"" to correct because, once again, the leftist is motivated less by distress at society's ills than by the need to satisfy his drive for power by imposing his solutions on society.",TK,484,"['220', 'suppose', 'asked', 'leftist', 'make', 'list', 'thing', 'wrong', 'society', 'suppose', 'instituted', 'every', 'social', 'change', 'demanded', 'safe', 'say', 'within', 'couple', 'year', 'majority', 'leftist', 'would', 'find', 'something', 'new', 'complain', 'new', 'social', 'evil', 'correct', 'leftist', 'motivated', 'le', 'distress', 'society', 'ill', 'need', 'satisfy', 'drive', 'power', 'imposing', 'solution', 'society']"
1713,"90. Of course, it's not that simple. Other motives do play a role for many scientists. Money and status for example. Some scientists may be persons of the type who have an insatiable drive for status (see paragraph 79) and this may provide much of the motivation for their work. No doubt the majority of scientists, like the majority of the general population, are more or less susceptible to advertising and marketing techniques and need money to satisfy their craving for goods and services. Thus science is not a PURE surrogate activity. But it is in large part a surrogate activity.",TK,586,"['90', 'course', 'simple', 'motif', 'play', 'role', 'many', 'scientist', 'money', 'status', 'example', 'scientist', 'may', 'person', 'type', 'insatiable', 'drive', 'status', 'see', 'paragraph', '79', 'may', 'provide', 'much', 'motivation', 'work', 'doubt', 'majority', 'scientist', 'like', 'majority', 'general', 'population', 'le', 'susceptible', 'advertising', 'marketing', 'technique', 'need', 'money', 'satisfy', 'craving', 'good', 'service', 'thus', 'science', 'pure', 'surrogate', 'activity', 'large', 'part', 'surrogate', 'activity']"
1714,"182. It will be objected that the French and Russian Revolutions were failures. But most revolutions have two goals. One is to destroy an old form of society and the other is to set up the new form of society envisioned by the revolutionaries. The French and Russian revolutionaries failed (fortunately!) to create the new kind of society of which they dreamed, but they were quite successful in destroying the existing form of society.",TK,436,"['182', 'objected', 'french', 'russian', 'revolution', 'failure', 'revolution', 'two', 'goal', 'one', 'destroy', 'old', 'form', 'society', 'set', 'new', 'form', 'society', 'envisioned', 'revolutionary', 'french', 'russian', 'revolutionary', 'failed', 'fortunately', 'create', 'new', 'kind', 'society', 'dreamed', 'quite', 'successful', 'destroying', 'existing', 'form', 'society']"
1715,"29. Here is an illustration of the way in which the oversocialized leftist shows his real attachment to the conventional attitudes of our society while pretending to be in rebellion against it. Many leftists push for affirmative action, for moving black people into high-prestige jobs, for improved education in black schools and more money for such schools; the way of life of the black ""underclass"" they regard as a social disgrace. They want to integrate the black man into the system, make him a business executive, a lawyer, a scientist just like upper-middle-class white people. The leftists will reply that the last thing they want is to make the black man into a copy of the white man; instead, they want to preserve African American culture. But in what does this preservation of African American culture consist? It can hardly consist in anything more than eating black-style food, listening to black-style music, wearing black-style clothing and going to a black-style church or mosque. In other words, it can express itself only in superficial matters. In all ESSENTIAL respects more leftists of the oversocialized type want to make the black man conform to white, middle-class ideals. They want to make him study technical subjects, become an executive or a scientist, spend his life climbing the status ladder to prove that black people are as good as white. They want to make black fathers ""responsible."" they want black gangs to become nonviolent, etc. But these are exactly the values of the industrial-technological system. The system couldn't care less what kind of music a man listens to, what kind of clothes he wears or what religion he believes in as long as he studies in school, holds a respectable job, climbs the status ladder, is a ""responsible"" parent, is nonviolent and so forth. In effect, however much he may deny it, the oversocialized leftist wants to integrate the black man into the system and make him adopt its values.",TK,1956,"['29', 'illustration', 'way', 'oversocialized', 'leftist', 'show', 'real', 'attachment', 'conventional', 'attitude', 'society', 'pretending', 'rebellion', 'many', 'leftist', 'push', 'affirmative', 'action', 'moving', 'black', 'people', 'highprestige', 'job', 'improved', 'education', 'black', 'school', 'money', 'school', 'way', 'life', 'black', 'underclass', 'regard', 'social', 'disgrace', 'want', 'integrate', 'black', 'man', 'system', 'make', 'business', 'executive', 'lawyer', 'scientist', 'like', 'uppermiddleclass', 'white', 'people', 'leftist', 'reply', 'last', 'thing', 'want', 'make', 'black', 'man', 'copy', 'white', 'man', 'instead', 'want', 'preserve', 'african', 'american', 'culture', 'doe', 'preservation', 'african', 'american', 'culture', 'consist', 'hardly', 'consist', 'anything', 'eating', 'blackstyle', 'food', 'listening', 'blackstyle', 'music', 'wearing', 'blackstyle', 'clothing', 'going', 'blackstyle', 'church', 'mosque', 'word', 'express', 'superficial', 'matter', 'essential', 'respect', 'leftist', 'oversocialized', 'type', 'want', 'make', 'black', 'man', 'conform', 'white', 'middleclass', 'ideal', 'want', 'make', 'study', 'technical', 'subject', 'become', 'executive', 'scientist', 'spend', 'life', 'climbing', 'status', 'ladder', 'prove', 'black', 'people', 'good', 'white', 'want', 'make', 'black', 'father', 'responsible', 'want', 'black', 'gang', 'become', 'nonviolent', 'etc', 'exactly', 'value', 'industrialtechnological', 'system', 'system', 'couldnt', 'care', 'le', 'kind', 'music', 'man', 'listens', 'kind', 'clothes', 'wear', 'religion', 'belief', 'long', 'study', 'school', 'hold', 'respectable', 'job', 'climb', 'status', 'ladder', 'responsible', 'parent', 'nonviolent', 'forth', 'effect', 'however', 'much', 'may', 'deny', 'oversocialized', 'leftist', 'want', 'integrate', 'black', 'man', 'system', 'make', 'adopt', 'value']"
1716,"33. Human beings have a need (probably based in biology) for something that we will call the ""power process."" This is closely related to the need for power (which is widely recognized) but is not quite the same thing. The power process has four elements. The three most clear-cut of these we call goal, effort and attainment of goal. (Everyone needs to have goals whose attainment requires effort, and needs to succeed in attaining at least some of his goals.) The fourth element is more difficult to define and may not be necessary for everyone. We call it autonomy and will discuss it later (paragraphs 42-44).",TK,612,"['33', 'human', 'need', 'probably', 'based', 'biology', 'something', 'call', 'power', 'process', 'closely', 'related', 'need', 'power', 'widely', 'recognized', 'quite', 'thing', 'power', 'process', 'ha', 'four', 'element', 'three', 'clearcut', 'call', 'goal', 'effort', 'attainment', 'goal', 'everyone', 'need', 'goal', 'whose', 'attainment', 'requires', 'effort', 'need', 'succeed', 'attaining', 'least', 'goal', 'fourth', 'element', 'difficult', 'define', 'may', 'necessary', 'everyone', 'call', 'autonomy', 'discus', 'later', 'paragraph', '4244']"
1717,"34. Consider the hypothetical case of a man who can have anything he wants just by wishing for it. Such a man has power, but he will develop serious psychological problems. At first he will have a lot of fun, but by and by he will become acutely bored and demoralized. Eventually he may become clinically depressed. History shows that leisured aristocracies tend to become decadent. This is not true of fighting aristocracies that have to struggle to maintain their power. But leisured, secure aristocracies that have no need to exert themselves usually become bored, hedonistic and demoralized, even though they have power. This shows that power is not enough. One must have goals toward which to exercise one's power.",TK,719,"['34', 'consider', 'hypothetical', 'case', 'man', 'anything', 'want', 'wishing', 'man', 'ha', 'power', 'develop', 'serious', 'psychological', 'problem', 'first', 'lot', 'fun', 'become', 'acutely', 'bored', 'demoralized', 'eventually', 'may', 'become', 'clinically', 'depressed', 'history', 'show', 'leisured', 'aristocracy', 'tend', 'become', 'decadent', 'true', 'fighting', 'aristocracy', 'struggle', 'maintain', 'power', 'leisured', 'secure', 'aristocracy', 'need', 'exert', 'usually', 'become', 'bored', 'hedonistic', 'demoralized', 'even', 'though', 'power', 'show', 'power', 'enough', 'one', 'must', 'goal', 'toward', 'exercise', 'one', 'power']"
1718,"197. Some people take the line that modern man has too much power, too much control over nature; they argue for a more passive attitude on the part of the human race. At best these people are expressing themselves unclearly, because they fail to distinguish between power for LARGE ORGANIZATIONS and power for INDIVIDUALS and SMALL GROUPS. It is a mistake to argue for powerlessness and passivity, because people NEED power. Modern man as a collective entity--that is, the industrial system--has immense power over nature, and we (FC) regard this as evil. But modern INDIVIDUALS and SMALL GROUPS OF INDIVIDUALS have far less power than primitive man ever did. Generally speaking, the vast power of ""modern man"" over nature is exercised not by individuals or small groups but by large organizations. To the extent that the average modern INDIVIDUAL can wield the power of technology, he is permitted to do so only within narrow limits and only under the supervision and control of the system. (You need a license for everything and with the license come rules and regulations). The individual has only those technological powers with which the system chooses to provide him. His PERSONAL power over nature is slight.",TK,1215,"['197', 'people', 'take', 'line', 'modern', 'man', 'ha', 'much', 'power', 'much', 'control', 'nature', 'argue', 'passive', 'attitude', 'part', 'human', 'race', 'best', 'people', 'expressing', 'unclearly', 'fail', 'distinguish', 'power', 'large', 'organization', 'power', 'individual', 'small', 'group', 'mistake', 'argue', 'powerlessness', 'passivity', 'people', 'need', 'power', 'modern', 'man', 'collective', 'entitythat', 'industrial', 'systemhas', 'immense', 'power', 'nature', 'fc', 'regard', 'evil', 'modern', 'individual', 'small', 'group', 'individual', 'far', 'le', 'power', 'primitive', 'man', 'ever', 'generally', 'speaking', 'vast', 'power', 'modern', 'man', 'nature', 'exercised', 'individual', 'small', 'group', 'large', 'organization', 'extent', 'average', 'modern', 'individual', 'wield', 'power', 'technology', 'permitted', 'within', 'narrow', 'limit', 'supervision', 'control', 'system', 'need', 'license', 'everything', 'license', 'come', 'rule', 'regulation', 'individual', 'ha', 'technological', 'power', 'system', 'chooses', 'provide', 'personal', 'power', 'nature', 'slight']"
1719,"15. Leftists tend to hate anything that has an image of being strong, good and successful. They hate America, they hate Western civilization, they hate white males, they hate rationality. The reasons that leftists give for hating the West, etc. clearly do not correspond with their real motives. They SAY they hate the West because it is warlike, imperialistic, sexist, ethnocentric and so forth, but where these same faults appear in socialist countries or in primitive cultures, the leftist finds excuses for them, or at best he GRUDGINGLY admits that they exist; whereas he ENTHUSIASTICALLY points out (and often greatly exaggerates) these faults where they appear in Western civilization. Thus it is clear that these faults are not the leftist's real motive for hating America and the West. He hates America and the West because they are strong and successful.",TK,864,"['15', 'leftist', 'tend', 'hate', 'anything', 'ha', 'image', 'strong', 'good', 'successful', 'hate', 'america', 'hate', 'western', 'civilization', 'hate', 'white', 'male', 'hate', 'rationality', 'reason', 'leftist', 'give', 'hating', 'west', 'etc', 'clearly', 'correspond', 'real', 'motif', 'say', 'hate', 'west', 'warlike', 'imperialistic', 'sexist', 'ethnocentric', 'forth', 'fault', 'appear', 'socialist', 'country', 'primitive', 'culture', 'leftist', 'find', 'excuse', 'best', 'grudgingly', 'admits', 'exist', 'whereas', 'enthusiastically', 'point', 'often', 'greatly', 'exaggerates', 'fault', 'appear', 'western', 'civilization', 'thus', 'clear', 'fault', 'leftist', 'real', 'motive', 'hating', 'america', 'west', 'hate', 'america', 'west', 'strong', 'successful']"
1720,"74. We suggest that modern man's obsession with longevity, and with maintaining physical vigor and sexual attractiveness to an advanced age, is a symptom of unfulfillment resulting from deprivation with respect to the power process. The ""mid-life crisis"" also is such a symptom. So is the lack of interest in having children that is fairly common in modern society but almost unheard-of in primitive societies.",TK,410,"['74', 'suggest', 'modern', 'man', 'obsession', 'longevity', 'maintaining', 'physical', 'vigor', 'sexual', 'attractiveness', 'advanced', 'age', 'symptom', 'unfulfillment', 'resulting', 'deprivation', 'respect', 'power', 'process', 'midlife', 'crisis', 'also', 'symptom', 'lack', 'interest', 'child', 'fairly', 'common', 'modern', 'society', 'almost', 'unheardof', 'primitive', 'society']"
1721,"5. In this article we give attention to only some of the negative developments that have grown out of the industrial-technological system. Other such developments we mention only briefly or ignore altogether. This does not mean that we regard these other developments as unimportant. For practical reasons we have to confine our discussion to areas that have received insufficient public attention or in which we have something new to say. For example, since there are well-developed environmental and wilderness movements, we have written very little about environmental degradation or the destruction of wild nature, even though we consider these to be highly important.",TK,672,"['5', 'article', 'give', 'attention', 'negative', 'development', 'grown', 'industrialtechnological', 'system', 'development', 'mention', 'briefly', 'ignore', 'altogether', 'doe', 'mean', 'regard', 'development', 'unimportant', 'practical', 'reason', 'confine', 'discussion', 'area', 'received', 'insufficient', 'public', 'attention', 'something', 'new', 'say', 'example', 'since', 'welldeveloped', 'environmental', 'wilderness', 'movement', 'written', 'little', 'environmental', 'degradation', 'destruction', 'wild', 'nature', 'even', 'though', 'consider', 'highly', 'important']"
1722,"149. Presumably, research will continue to increas the effectiveness of psychological techniques for controlling human behavior. But we think it is unlikely that psychological techniques alone will be sufficient to adjust human beings to the kind of society that technology is creating. Biological methods probably will have to be used. We have already mentiond the use of drugs in this connection. Neurology may provide other avenues of modifying the human mind. Genetic engineering of human beings is already beginning to occur in the form of ""gene therapy,"" and there is no reason to assume the such methods will not eventually be used to modify those aspects of the body that affect mental funtioning.",TK,705,"['149', 'presumably', 'research', 'continue', 'increas', 'effectiveness', 'psychological', 'technique', 'controlling', 'human', 'behavior', 'think', 'unlikely', 'psychological', 'technique', 'alone', 'sufficient', 'adjust', 'human', 'kind', 'society', 'technology', 'creating', 'biological', 'method', 'probably', 'used', 'already', 'mentiond', 'use', 'drug', 'connection', 'neurology', 'may', 'provide', 'avenue', 'modifying', 'human', 'mind', 'genetic', 'engineering', 'human', 'already', 'beginning', 'occur', 'form', 'gene', 'therapy', 'reason', 'assume', 'method', 'eventually', 'used', 'modify', 'aspect', 'body', 'affect', 'mental', 'funtioning']"
1723,46. We attribute the social and psychological problems of modern society to the fact that that society requires people to live under conditions radically different from those under which the human race evolved and to behave in ways that conflict with the patterns of behavior that the human race developed while living under the earlier conditions. It is clear from what we have already written that we consider lack of opportunity to properly experience the power process as the most important of the abnormal conditions to which modern society subjects people. But it is not the only one. Before dealing with disruption of the power process as a source of social problems we will discuss some of the other sources.,TK,716,"['46', 'attribute', 'social', 'psychological', 'problem', 'modern', 'society', 'fact', 'society', 'requires', 'people', 'live', 'condition', 'radically', 'different', 'human', 'race', 'evolved', 'behave', 'way', 'conflict', 'pattern', 'behavior', 'human', 'race', 'developed', 'living', 'earlier', 'condition', 'clear', 'already', 'written', 'consider', 'lack', 'opportunity', 'properly', 'experience', 'power', 'process', 'important', 'abnormal', 'condition', 'modern', 'society', 'subject', 'people', 'one', 'dealing', 'disruption', 'power', 'process', 'source', 'social', 'problem', 'discus', 'source']"
1724,"101. The first principle is almost a tautology. If a trend were not stable with respect to small changes, it would wander at random rather than following a definite direction; in other words it would not be a long-term trend at all.",TK,232,"['101', 'first', 'principle', 'almost', 'tautology', 'trend', 'stable', 'respect', 'small', 'change', 'would', 'wander', 'random', 'rather', 'following', 'definite', 'direction', 'word', 'would', 'longterm', 'trend']"
1725,"139. And note this important difference: It is conceivable that our environmental problems (for example) may some day be settled through a rational, comprehensive plan, but if this happens it will be only because it is in the long-term interest of the system to solve these problems. But it is NOT in the interest of the system to preserve freedom or small-group autonomy. On the contrary, it is in the interest of the system to bring human behavior under control to the greatest possible extent. Thus, while practical considerations may eventually force the system to take a rational, prudent approach to environmental problems, equally practical considerations will force the system to regulate human behavior ever more closely (preferably by indirect means that will disguise the encroachment on freedom.) This isn't just our opinion. Eminent social scientists (e.g. James Q. Wilson) have stressed the importance of ""socializing"" people more effectively.",TK,957,"['139', 'note', 'important', 'difference', 'conceivable', 'environmental', 'problem', 'example', 'may', 'day', 'settled', 'rational', 'comprehensive', 'plan', 'happens', 'longterm', 'interest', 'system', 'solve', 'problem', 'interest', 'system', 'preserve', 'freedom', 'smallgroup', 'autonomy', 'contrary', 'interest', 'system', 'bring', 'human', 'behavior', 'control', 'greatest', 'possible', 'extent', 'thus', 'practical', 'consideration', 'may', 'eventually', 'force', 'system', 'take', 'rational', 'prudent', 'approach', 'environmental', 'problem', 'equally', 'practical', 'consideration', 'force', 'system', 'regulate', 'human', 'behavior', 'ever', 'closely', 'preferably', 'indirect', 'mean', 'disguise', 'encroachment', 'freedom', 'isnt', 'opinion', 'eminent', 'social', 'scientist', 'eg', 'james', 'q', 'wilson', 'stressed', 'importance', 'socializing', 'people', 'effectively']"
1726,"175. But suppose now that the computer scientists do not succeed in developing artificial intelligence, so that human work remains necessary. Even so, machines will take care of more and more of the simpler tasks so that there will be an increasing surplus of human workers at the lower levels of ability. (We see this happening already. There are many people who find it difficult or impossible to get work, because for intellectual or psychological reasons they cannot acquire the level of training necessary to make themselves useful in the present system.) On those who are employed, ever-increasing demands will be placed; They will need more and m ore training, more and more ability, and will have to be ever more reliable, conforming and docile, because they will be more and more like cells of a giant organism. Their tasks will be increasingly specialized so that their work will be, in a sense, out of touch with the real world, being concentrated on one tiny slice of reality. The system will have to use any means that I can, whether psychological or biological, to engineer people to be docile, to have the abilities that the system requires and to ""sublimate"" their drive for power into some specialized task. But the statement that the people of such a society will have to be docile may require qualification. The society may find competitiveness useful, provided that ways are found of directing competitiveness into channels that serve that needs of the system. We can imagine into channels that serve the needs of the system. We can imagine a future society in which there is endless competition for positions of prestige an power. But no more than a very few people will ever reach the top, where the only real power is (see end of paragraph 163). Very repellent is a society in which a person can satisfy his needs for power only by pushing large numbers of other people out of the way and depriving them of THEIR opportunity for power.",TK,1958,"['175', 'suppose', 'computer', 'scientist', 'succeed', 'developing', 'artificial', 'intelligence', 'human', 'work', 'remains', 'necessary', 'even', 'machine', 'take', 'care', 'simpler', 'task', 'increasing', 'surplus', 'human', 'worker', 'lower', 'level', 'ability', 'see', 'happening', 'already', 'many', 'people', 'find', 'difficult', 'impossible', 'get', 'work', 'intellectual', 'psychological', 'reason', 'cannot', 'acquire', 'level', 'training', 'necessary', 'make', 'useful', 'present', 'system', 'employed', 'everincreasing', 'demand', 'placed', 'need', 'ore', 'training', 'ability', 'ever', 'reliable', 'conforming', 'docile', 'like', 'cell', 'giant', 'organism', 'task', 'increasingly', 'specialized', 'work', 'sense', 'touch', 'real', 'world', 'concentrated', 'one', 'tiny', 'slice', 'reality', 'system', 'use', 'mean', 'whether', 'psychological', 'biological', 'engineer', 'people', 'docile', 'ability', 'system', 'requires', 'sublimate', 'drive', 'power', 'specialized', 'task', 'statement', 'people', 'society', 'docile', 'may', 'require', 'qualification', 'society', 'may', 'find', 'competitiveness', 'useful', 'provided', 'way', 'found', 'directing', 'competitiveness', 'channel', 'serve', 'need', 'system', 'imagine', 'channel', 'serve', 'need', 'system', 'imagine', 'future', 'society', 'endless', 'competition', 'position', 'prestige', 'power', 'people', 'ever', 'reach', 'top', 'real', 'power', 'see', 'end', 'paragraph', '163', 'repellent', 'society', 'person', 'satisfy', 'need', 'power', 'pushing', 'large', 'number', 'people', 'way', 'depriving', 'opportunity', 'power']"
1727,"117. In any technologically advanced society the individual's fate MUST depend on decisions that he personally cannot influence to any great extent. A technological society cannot be broken down into small, autonomous communities, because production depends on the cooperation of very large numbers of people and machines. Such a society MUST be highly organized and decisions HAVE TO be made that affect very large numbers of people. When a decision affects, say, a million people, then each of the affected individuals has, on the average, only a one-millionth share in making the decision. What usually happens in practice is that decisions are made by public officials or corporation executives, or by technical specialists, but even when the public votes on a decision the number of voters ordinarily is too large for the vote of any one individual to be significant. [17] Thus most individuals are unable to influence measurably the major decisions that affect their lives. Their is no conceivable way to remedy this in a technologically advanced society. The system tries to ""solve"" this problem by using propaganda to make people WANT the decisions that have been made for them, but even if this ""solution"" were completely successful in making people feel better, it would be demeaning.",TK,1294,"['117', 'technologically', 'advanced', 'society', 'individual', 'fate', 'must', 'depend', 'decision', 'personally', 'cannot', 'influence', 'great', 'extent', 'technological', 'society', 'cannot', 'broken', 'small', 'autonomous', 'community', 'production', 'depends', 'cooperation', 'large', 'number', 'people', 'machine', 'society', 'must', 'highly', 'organized', 'decision', 'made', 'affect', 'large', 'number', 'people', 'decision', 'affect', 'say', 'million', 'people', 'affected', 'individual', 'ha', 'average', 'onemillionth', 'share', 'making', 'decision', 'usually', 'happens', 'practice', 'decision', 'made', 'public', 'official', 'corporation', 'executive', 'technical', 'specialist', 'even', 'public', 'vote', 'decision', 'number', 'voter', 'ordinarily', 'large', 'vote', 'one', 'individual', 'significant', '17', 'thus', 'individual', 'unable', 'influence', 'measurably', 'major', 'decision', 'affect', 'life', 'conceivable', 'way', 'remedy', 'technologically', 'advanced', 'society', 'system', 'try', 'solve', 'problem', 'using', 'propaganda', 'make', 'people', 'want', 'decision', 'made', 'even', 'solution', 'completely', 'successful', 'making', 'people', 'feel', 'better', 'would', 'demeaning']"
1728,"170. ""Oh!"" say the technophiles, ""Science is going to fix all that! We will conquer famine, eliminate psychological suffering, make everybody healthy and happy!"" Yeah, sure. That's what they said 200 years ago. The Industrial Revolution was supposed to eliminate poverty, make everybody happy, etc. The actual result has been quite different. The technophiles are hopelessly naive (or self-deceiving) in their understanding of social problems. They are unaware of (or choose to ignore) the fact that when large changes, even seemingly beneficial ones, are introduced into a society, they lead to a long sequence of other changes, most of which are impossible to predict (paragraph 103). The result is disruption of the society. So it is very probable that in their attempt to end poverty and disease, engineer docile, happy personalities and so forth, the technophiles will create social systems that are terribly troubled, even more so that the present one. For example, the scientists boast that they will end famine by creating new, genetically engineered food plants. But this will allow the human population to keep expanding indefinitely, and it is well known that crowding leads to increased stress and aggression. This is merely one example of the PREDICTABLE problems that will arise. We emphasize that, as past experience has shown, technical progress will lead to other new problems for society far more rapidly that it has been solving old ones. Thus it will take a long difficult period of trial and error for the technophiles to work the bugs out of their Brave New World (if they ever do). In the meantime there will be great suffering. So it is not all clear that the survival of industrial society would involve less suffering than the breakdown of that society would. Technology has gotten the human race into a fix from which there is not likely to be any easy escape.",TK,1887,"['170', 'oh', 'say', 'technophile', 'science', 'going', 'fix', 'conquer', 'famine', 'eliminate', 'psychological', 'suffering', 'make', 'everybody', 'healthy', 'happy', 'yeah', 'sure', 'thats', 'said', '200', 'year', 'ago', 'industrial', 'revolution', 'wa', 'supposed', 'eliminate', 'poverty', 'make', 'everybody', 'happy', 'etc', 'actual', 'result', 'ha', 'quite', 'different', 'technophile', 'hopelessly', 'naive', 'selfdeceiving', 'understanding', 'social', 'problem', 'unaware', 'choose', 'ignore', 'fact', 'large', 'change', 'even', 'seemingly', 'beneficial', 'one', 'introduced', 'society', 'lead', 'long', 'sequence', 'change', 'impossible', 'predict', 'paragraph', '103', 'result', 'disruption', 'society', 'probable', 'attempt', 'end', 'poverty', 'disease', 'engineer', 'docile', 'happy', 'personality', 'forth', 'technophile', 'create', 'social', 'system', 'terribly', 'troubled', 'even', 'present', 'one', 'example', 'scientist', 'boast', 'end', 'famine', 'creating', 'new', 'genetically', 'engineered', 'food', 'plant', 'allow', 'human', 'population', 'keep', 'expanding', 'indefinitely', 'well', 'known', 'crowding', 'lead', 'increased', 'stress', 'aggression', 'merely', 'one', 'example', 'predictable', 'problem', 'arise', 'emphasize', 'past', 'experience', 'ha', 'shown', 'technical', 'progress', 'lead', 'new', 'problem', 'society', 'far', 'rapidly', 'ha', 'solving', 'old', 'one', 'thus', 'take', 'long', 'difficult', 'period', 'trial', 'error', 'technophile', 'work', 'bug', 'brave', 'new', 'world', 'ever', 'meantime', 'great', 'suffering', 'clear', 'survival', 'industrial', 'society', 'would', 'involve', 'le', 'suffering', 'breakdown', 'society', 'would', 'technology', 'ha', 'gotten', 'human', 'race', 'fix', 'likely', 'easy', 'escape']"
1729,"225. These phenomena appeared clearly in Russia and other countries that were taken over by leftists. Similarly, before the breakdown of communism in the USSR, leftish types in the West would seldom criticize that country. If prodded they would admit that the USSR did many wrong things, but then they would try to find excuses for the communists and begin talking about the faults of the West. They always opposed Western military resistance to communist aggression. Leftish types all over the world vigorously protested the U.S. military action in Vietnam, but when the USSR invaded Afghanistan they did nothing. Not that they approved of the Soviet actions; but because of their leftist faith, they just couldn't bear to put themselves in opposition to communism. Today, in those of our universities where ""political correctness"" has become dominant, there are probably many leftish types who privately disapprove of the suppression of academic freedom, but they go along with it anyway.",TK,990,"['225', 'phenomenon', 'appeared', 'clearly', 'russia', 'country', 'taken', 'leftist', 'similarly', 'breakdown', 'communism', 'ussr', 'leftish', 'type', 'west', 'would', 'seldom', 'criticize', 'country', 'prodded', 'would', 'admit', 'ussr', 'many', 'wrong', 'thing', 'would', 'try', 'find', 'excuse', 'communist', 'begin', 'talking', 'fault', 'west', 'always', 'opposed', 'western', 'military', 'resistance', 'communist', 'aggression', 'leftish', 'type', 'world', 'vigorously', 'protested', 'u', 'military', 'action', 'vietnam', 'ussr', 'invaded', 'afghanistan', 'nothing', 'approved', 'soviet', 'action', 'leftist', 'faith', 'couldnt', 'bear', 'put', 'opposition', 'communism', 'today', 'university', 'political', 'correctness', 'ha', 'become', 'dominant', 'probably', 'many', 'leftish', 'type', 'privately', 'disapprove', 'suppression', 'academic', 'freedom', 'go', 'along', 'anyway']"
1730,"35. Everyone has goals; if nothing else, to obtain the physical necessities of life: food, water and whatever clothing and shelter are made necessary by the climate. But the leisured aristocrat obtains these things without effort. Hence his boredom and demoralization.",TK,268,"['35', 'everyone', 'ha', 'goal', 'nothing', 'else', 'obtain', 'physical', 'necessity', 'life', 'food', 'water', 'whatever', 'clothing', 'shelter', 'made', 'necessary', 'climate', 'leisured', 'aristocrat', 'obtains', 'thing', 'without', 'effort', 'hence', 'boredom', 'demoralization']"
1731,"78. First, there doubtless are differences in the strength of the drive for power. Individuals with a weak drive for power may have relatively little need to go through the power process, or at least relatively little need for autonomy in the power process. These are docile types who would have been happy as plantation darkies in the Old South. (We don't mean to sneer at ""plantation darkies"" of the Old South. To their credit, most of the slaves were NOT content with their servitude. We do sneer at people who ARE content with servitude.)",TK,542,"['78', 'first', 'doubtless', 'difference', 'strength', 'drive', 'power', 'individual', 'weak', 'drive', 'power', 'may', 'relatively', 'little', 'need', 'go', 'power', 'process', 'least', 'relatively', 'little', 'need', 'autonomy', 'power', 'process', 'docile', 'type', 'would', 'happy', 'plantation', 'darky', 'old', 'south', 'dont', 'mean', 'sneer', 'plantation', 'darky', 'old', 'south', 'credit', 'slave', 'content', 'servitude', 'sneer', 'people', 'content', 'servitude']"
1732,"190. Any kind of social conflict helps to destabilize the system, but one should be careful about what kind of conflict one encourages. The line of conflict should be drawn between the mass of the people and the power-holding elite of industrial society (politicians, scientists, upper-level business executives, government officials, etc..). It should NOT be drawn between the revolutionaries and the mass of the people. For example, it would be bad strategy for the revolutionaries to condemn Americans for their habits of consumption. Instead, the average American should be portrayed as a victim of the advertising and marketing industry, which has suckered him into buying a lot of junk that he doesn't need and that is very poor compensation for his lost freedom. Either approach is consistent with the facts. It is merely a matter of attitude whether you blame the advertising industry for manipulating the public or blame the public for allowing itself to be manipulated. As a matter of strategy one should generally avoid blaming the public.",TK,1050,"['190', 'kind', 'social', 'conflict', 'help', 'destabilize', 'system', 'one', 'careful', 'kind', 'conflict', 'one', 'encourages', 'line', 'conflict', 'drawn', 'mass', 'people', 'powerholding', 'elite', 'industrial', 'society', 'politician', 'scientist', 'upperlevel', 'business', 'executive', 'government', 'official', 'etc', 'drawn', 'revolutionary', 'mass', 'people', 'example', 'would', 'bad', 'strategy', 'revolutionary', 'condemn', 'american', 'habit', 'consumption', 'instead', 'average', 'american', 'portrayed', 'victim', 'advertising', 'marketing', 'industry', 'ha', 'suckered', 'buying', 'lot', 'junk', 'doesnt', 'need', 'poor', 'compensation', 'lost', 'freedom', 'either', 'approach', 'consistent', 'fact', 'merely', 'matter', 'attitude', 'whether', 'blame', 'advertising', 'industry', 'manipulating', 'public', 'blame', 'public', 'allowing', 'manipulated', 'matter', 'strategy', 'one', 'generally', 'avoid', 'blaming', 'public']"
1733,"221. Because of the restrictions placed on their thoughts and behavior by their high level of socialization, many leftists of the over-socialized type cannot pursue power in the ways that other people do. For them the drive for power has only one morally acceptable outlet, and that is in the struggle to impose their morality on everyone.",TK,339,"['221', 'restriction', 'placed', 'thought', 'behavior', 'high', 'level', 'socialization', 'many', 'leftist', 'oversocialized', 'type', 'cannot', 'pursue', 'power', 'way', 'people', 'drive', 'power', 'ha', 'one', 'morally', 'acceptable', 'outlet', 'struggle', 'impose', 'morality', 'everyone']"
1734,"112. People anxious to rescue freedom without sacrificing the supposed benefits of technology will suggest naive schemes for some new form of society that would reconcile freedom with technology. Apart from the fact that people who make suggestions seldom propose any practical means by which the new form of society could be set up in the first place, it follows from the fourth principle that even if the new form of society could be once established, it either would collapse or would give results very different from those expected.",TK,536,"['112', 'people', 'anxious', 'rescue', 'freedom', 'without', 'sacrificing', 'supposed', 'benefit', 'technology', 'suggest', 'naive', 'scheme', 'new', 'form', 'society', 'would', 'reconcile', 'freedom', 'technology', 'apart', 'fact', 'people', 'make', 'suggestion', 'seldom', 'propose', 'practical', 'mean', 'new', 'form', 'society', 'could', 'set', 'first', 'place', 'follows', 'fourth', 'principle', 'even', 'new', 'form', 'society', 'could', 'established', 'either', 'would', 'collapse', 'would', 'give', 'result', 'different', 'expected']"
1735,"196. Revolutionaries might consider favoring measures that tend to bind the world economy into a unified whole. Free trade agreements like NAFTA and GATT are probably harmful to the environment in the short run, but in the long run they may perhaps be advantageous because they foster economic interdependence between nations. I will be eaier to destroy the industrial system on a worldwide basis if he world economy is so unified that its breakdown in any on major nation will lead to its breakdwon in al industrialized nations.",TK,529,"['196', 'revolutionary', 'might', 'consider', 'favoring', 'measure', 'tend', 'bind', 'world', 'economy', 'unified', 'whole', 'free', 'trade', 'agreement', 'like', 'nafta', 'gatt', 'probably', 'harmful', 'environment', 'short', 'run', 'long', 'run', 'may', 'perhaps', 'advantageous', 'foster', 'economic', 'interdependence', 'nation', 'eaier', 'destroy', 'industrial', 'system', 'worldwide', 'basis', 'world', 'economy', 'unified', 'breakdown', 'major', 'nation', 'lead', 'breakdwon', 'al', 'industrialized', 'nation']"
1736,"134. For all of the foregoing reasons, technology is a more powerful social force than the aspiration for freedom. But this statement requires an important qualification. It appears that during the next several decades the industrial-technological system will be undergoing severe stresses due to economic and environmental problems, and especially due to problems of human behavior (alienation, rebellion, hostility, a variety of social and psychological difficulties). We hope that the stresses through which the system is likely to pass will cause it to break down, or at least weaken it sufficiently so that a revolution occurs and is successful, then at that particular moment the aspiration for freedom will have proved more powerful than technology.",TK,756,"['134', 'foregoing', 'reason', 'technology', 'powerful', 'social', 'force', 'aspiration', 'freedom', 'statement', 'requires', 'important', 'qualification', 'appears', 'next', 'several', 'decade', 'industrialtechnological', 'system', 'undergoing', 'severe', 'stress', 'due', 'economic', 'environmental', 'problem', 'especially', 'due', 'problem', 'human', 'behavior', 'alienation', 'rebellion', 'hostility', 'variety', 'social', 'psychological', 'difficulty', 'hope', 'stress', 'system', 'likely', 'pas', 'cause', 'break', 'least', 'weaken', 'sufficiently', 'revolution', 'occurs', 'successful', 'particular', 'moment', 'aspiration', 'freedom', 'proved', 'powerful', 'technology']"
1737,"19. The leftist is not typically the kind of person whose feelings of inferiority make him a braggart, an egotist, a bully, a self-promoter, a ruthless competitor. This kind of person has not wholly lost faith in himself. He has a deficit in his sense of power and self-worth, but he can still conceive of himself as having the capacity to be strong, and his efforts to make himself strong produce his unpleasant behavior. [1] But the leftist is too far gone for that. His feelings of inferiority are so ingrained that he cannot conceive of himself as individually strong and valuable. Hence the collectivism of the leftist. He can feel strong only as a member of a large organization or a mass movement with which he identifies himself.",TK,737,"['19', 'leftist', 'typically', 'kind', 'person', 'whose', 'feeling', 'inferiority', 'make', 'braggart', 'egotist', 'bully', 'selfpromoter', 'ruthless', 'competitor', 'kind', 'person', 'ha', 'wholly', 'lost', 'faith', 'ha', 'deficit', 'sense', 'power', 'selfworth', 'still', 'conceive', 'capacity', 'strong', 'effort', 'make', 'strong', 'produce', 'unpleasant', 'behavior', '1', 'leftist', 'far', 'gone', 'feeling', 'inferiority', 'ingrained', 'cannot', 'conceive', 'individually', 'strong', 'valuable', 'hence', 'collectivism', 'leftist', 'feel', 'strong', 'member', 'large', 'organization', 'mass', 'movement', 'identifies']"
1738,"111. The foregoing principles help to show how hopelessly difficult it would be to reform the industrial system in such a way as to prevent it from progressively narrowing our sphere of freedom. There has been a consistent tendency, going back at least to the Industrial Revolution for technology to strengthen the system at a high cost in individual freedom and local autonomy. Hence any change designed to protect freedom from technology would be contrary to a fundamental trend in the development of our society.",TK,515,"['111', 'foregoing', 'principle', 'help', 'show', 'hopelessly', 'difficult', 'would', 'reform', 'industrial', 'system', 'way', 'prevent', 'progressively', 'narrowing', 'sphere', 'freedom', 'ha', 'consistent', 'tendency', 'going', 'back', 'least', 'industrial', 'revolution', 'technology', 'strengthen', 'system', 'high', 'cost', 'individual', 'freedom', 'local', 'autonomy', 'hence', 'change', 'designed', 'protect', 'freedom', 'technology', 'would', 'contrary', 'fundamental', 'trend', 'development', 'society']"
1739,"122. Even if medical progress could be maintained without the rest of the technological system, it would by itself bring certain evils. Suppose for example that a cure for diabetes is discovered. People with a genetic tendency to diabetes will then be able to survive and reproduce as well as anyone else. Natural selection against genes for diabetes will cease and such genes will spread throughout the population. (This may be occurring to some extent already, since diabetes, while not curable, can be controlled through the use of insulin.) The same thing will happen with many other diseases susceptibility to which is affected by genetic degradation of the population. The only solution will be some sort of eugenics program or extensive genetic engineering of human beings, so that man in the future will no longer be a creation of nature, or of chance, or of God (depending on your religious or philosophical opinions), but a manufactured product.",TK,955,"['122', 'even', 'medical', 'progress', 'could', 'maintained', 'without', 'rest', 'technological', 'system', 'would', 'bring', 'certain', 'evil', 'suppose', 'example', 'cure', 'diabetes', 'discovered', 'people', 'genetic', 'tendency', 'diabetes', 'able', 'survive', 'reproduce', 'well', 'anyone', 'else', 'natural', 'selection', 'gene', 'diabetes', 'cease', 'gene', 'spread', 'throughout', 'population', 'may', 'occurring', 'extent', 'already', 'since', 'diabetes', 'curable', 'controlled', 'use', 'insulin', 'thing', 'happen', 'many', 'disease', 'susceptibility', 'affected', 'genetic', 'degradation', 'population', 'solution', 'sort', 'eugenics', 'program', 'extensive', 'genetic', 'engineering', 'human', 'man', 'future', 'longer', 'creation', 'nature', 'chance', 'god', 'depending', 'religious', 'philosophical', 'opinion', 'manufactured', 'product']"
1740,"1. The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in ""advanced"" countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in ""advanced"" countries.",TK,785,"['1', 'industrial', 'revolution', 'consequence', 'disaster', 'human', 'race', 'greatly', 'increased', 'lifeexpectancy', 'u', 'live', 'advanced', 'country', 'destabilized', 'society', 'made', 'life', 'unfulfilling', 'subjected', 'human', 'indignity', 'led', 'widespread', 'psychological', 'suffering', 'third', 'world', 'physical', 'suffering', 'well', 'inflicted', 'severe', 'damage', 'natural', 'world', 'continued', 'development', 'technology', 'worsen', 'situation', 'certainly', 'subject', 'human', 'greater', 'indignity', 'inflict', 'greater', 'damage', 'natural', 'world', 'probably', 'lead', 'greater', 'social', 'disruption', 'psychological', 'suffering', 'may', 'lead', 'increased', 'physical', 'suffering', 'even', 'advanced', 'country']"
1741,"227. Our discussion of leftism has a serious weakness. It is still far from clear what we mean by the word ""leftist."" There doesn't seem to be much we can do about this. Today leftism is fragmented into a whole spectrum of activist movements. Yet not all activist movements are leftist, and some activist movements (e.g.., radical environmentalism) seem to include both personalities of the leftist type and personalities of thoroughly un-leftist types who ought to know better than to collaborate with leftists. Varieties of leftists fade out gradually into varieties of non-leftists and we ourselves would often be hard-pressed to decide whether a given individual is or is not a leftist. To the extent that it is defined at all, our conception of leftism is defined by the discussion of it that we have given in this article, and we can only advise the reader to use his own judgment in deciding who is a leftist.",TK,916,"['227', 'discussion', 'leftism', 'ha', 'serious', 'weakness', 'still', 'far', 'clear', 'mean', 'word', 'leftist', 'doesnt', 'seem', 'much', 'today', 'leftism', 'fragmented', 'whole', 'spectrum', 'activist', 'movement', 'yet', 'activist', 'movement', 'leftist', 'activist', 'movement', 'eg', 'radical', 'environmentalism', 'seem', 'include', 'personality', 'leftist', 'type', 'personality', 'thoroughly', 'unleftist', 'type', 'ought', 'know', 'better', 'collaborate', 'leftist', 'variety', 'leftist', 'fade', 'gradually', 'variety', 'nonleftists', 'would', 'often', 'hardpressed', 'decide', 'whether', 'given', 'individual', 'leftist', 'extent', 'defined', 'conception', 'leftism', 'defined', 'discussion', 'given', 'article', 'advise', 'reader', 'use', 'judgment', 'deciding', 'leftist']"
1742,"98. One more point to be made in this section: It should not be assumed that a person has enough freedom just because he SAYS he has enough. Freedom is restricted in part by psychological control of which people are unconscious, and moreover many people's ideas of what constitutes freedom are governed more by social convention than by their real needs. For example, it's likely that many leftists of the oversocialized type would say that most people, including themselves are socialized too little rather than too much, yet the oversocialized leftist pays a heavy psychological price for his high level of socialization.",TK,623,"['98', 'one', 'point', 'made', 'section', 'assumed', 'person', 'ha', 'enough', 'freedom', 'say', 'ha', 'enough', 'freedom', 'restricted', 'part', 'psychological', 'control', 'people', 'unconscious', 'moreover', 'many', 'people', 'idea', 'constitutes', 'freedom', 'governed', 'social', 'convention', 'real', 'need', 'example', 'likely', 'many', 'leftist', 'oversocialized', 'type', 'would', 'say', 'people', 'including', 'socialized', 'little', 'rather', 'much', 'yet', 'oversocialized', 'leftist', 'pay', 'heavy', 'psychological', 'price', 'high', 'level', 'socialization']"
1743,"39. We use the term ""surrogate activity"" to designate an activity that is directed toward an artificial goal that people set up for themselves merely in order to have some goal to work toward, or let us say, merely for the sake of the ""fulfillment"" that they get from pursuing the goal. Here is a rule of thumb for the identification of surrogate activities. Given a person who devotes much time and energy to the pursuit of goal X, ask yourself this: If he had to devote most of his time and energy to satisfying his biological needs, and if that effort required him to use his physical and mental facilities in a varied and interesting way, would he feel seriously deprived because he did not attain goal X? If the answer is no, then the person's pursuit of a goal X is a surrogate activity. Hirohito's studies in marine biology clearly constituted a surrogate activity, since it is pretty certain that if Hirohito had had to spend his time working at interesting non-scientific tasks in order to obtain the necessities of life, he would not have felt deprived because he didn't know all about the anatomy and life-cycles of marine animals. On the other hand the pursuit of sex and love (for example) is not a surrogate activity, because most people, even if their existence were otherwise satisfactory, would feel deprived if they passed their lives without ever having a relationship with a member of the opposite sex. (But pursuit of an excessive amount of sex, more than one really needs, can be a surrogate activity.)",TK,1524,"['39', 'use', 'term', 'surrogate', 'activity', 'designate', 'activity', 'directed', 'toward', 'artificial', 'goal', 'people', 'set', 'merely', 'order', 'goal', 'work', 'toward', 'let', 'u', 'say', 'merely', 'sake', 'fulfillment', 'get', 'pursuing', 'goal', 'rule', 'thumb', 'identification', 'surrogate', 'activity', 'given', 'person', 'devotes', 'much', 'time', 'energy', 'pursuit', 'goal', 'x', 'ask', 'devote', 'time', 'energy', 'satisfying', 'biological', 'need', 'effort', 'required', 'use', 'physical', 'mental', 'facility', 'varied', 'interesting', 'way', 'would', 'feel', 'seriously', 'deprived', 'attain', 'goal', 'x', 'answer', 'person', 'pursuit', 'goal', 'x', 'surrogate', 'activity', 'hirohito', 'study', 'marine', 'biology', 'clearly', 'constituted', 'surrogate', 'activity', 'since', 'pretty', 'certain', 'hirohito', 'spend', 'time', 'working', 'interesting', 'nonscientific', 'task', 'order', 'obtain', 'necessity', 'life', 'would', 'felt', 'deprived', 'didnt', 'know', 'anatomy', 'lifecycles', 'marine', 'animal', 'hand', 'pursuit', 'sex', 'love', 'example', 'surrogate', 'activity', 'people', 'even', 'existence', 'otherwise', 'satisfactory', 'would', 'feel', 'deprived', 'passed', 'life', 'without', 'ever', 'relationship', 'member', 'opposite', 'sex', 'pursuit', 'excessive', 'amount', 'sex', 'one', 'really', 'need', 'surrogate', 'activity']"
1744,"167. The industrial system will not break down purely as a result of revolutionary action. It will not be vulnerable to revolutionary attack unless its own internal problems of development lead it into very serious difficulties. So if the system breaks down it will do so either spontaneously, or through a process that is in part spontaneous but helped along by revolutionaries. If the breakdown is sudden, many people will die, since the world's population has become so overblown that it cannot even feed itself any longer without advanced technology. Even if the breakdown is gradual enough so that reduction of the population can occur more through lowering of the birth rate than through elevation of the death rate, the process of de-industrialization probably will be very chaotic and involve much suffering. It is naive to think it likely that technology can be phased out in a smoothly managed orderly way, especially since the technophiles will fight stubbornly at every step. Is it therefore cruel to work for the breakdown of the system? Maybe, but maybe not. In the first place, revolutionaries will not be able to break the system down unless it is already in deep trouble so that there would be a good chance of its eventually breaking down by itself anyway; and the bigger the system grows, the more disastrous the consequences of its breakdown will be; so it may be that revolutionaries, by hastening the onset of the breakdown will be reducing the extent of the disaster.",TK,1490,"['167', 'industrial', 'system', 'break', 'purely', 'result', 'revolutionary', 'action', 'vulnerable', 'revolutionary', 'attack', 'unless', 'internal', 'problem', 'development', 'lead', 'serious', 'difficulty', 'system', 'break', 'either', 'spontaneously', 'process', 'part', 'spontaneous', 'helped', 'along', 'revolutionary', 'breakdown', 'sudden', 'many', 'people', 'die', 'since', 'world', 'population', 'ha', 'become', 'overblown', 'cannot', 'even', 'feed', 'longer', 'without', 'advanced', 'technology', 'even', 'breakdown', 'gradual', 'enough', 'reduction', 'population', 'occur', 'lowering', 'birth', 'rate', 'elevation', 'death', 'rate', 'process', 'deindustrialization', 'probably', 'chaotic', 'involve', 'much', 'suffering', 'naive', 'think', 'likely', 'technology', 'phased', 'smoothly', 'managed', 'orderly', 'way', 'especially', 'since', 'technophile', 'fight', 'stubbornly', 'every', 'step', 'therefore', 'cruel', 'work', 'breakdown', 'system', 'maybe', 'maybe', 'first', 'place', 'revolutionary', 'able', 'break', 'system', 'unless', 'already', 'deep', 'trouble', 'would', 'good', 'chance', 'eventually', 'breaking', 'anyway', 'bigger', 'system', 'grows', 'disastrous', 'consequence', 'breakdown', 'may', 'revolutionary', 'hastening', 'onset', 'breakdown', 'reducing', 'extent', 'disaster']"
1745,"118. Conservatives and some others advocate more ""local autonomy."" Local communities once did have autonomy, but such autonomy becomes less and less possible as local communities become more enmeshed with and dependent on large-scale systems like public utilities, computer networks, highway systems, the mass communications media, the modern health care system. Also operating against autonomy is the fact that technology applied in one location often affects people at other locations far away. Thus pesticide or chemical use near a creek may contaminate the water supply hundreds of miles downstream, and the greenhouse effect affects the whole world.",TK,654,"['118', 'conservative', 'others', 'advocate', 'local', 'autonomy', 'local', 'community', 'autonomy', 'autonomy', 'becomes', 'le', 'le', 'possible', 'local', 'community', 'become', 'enmeshed', 'dependent', 'largescale', 'system', 'like', 'public', 'utility', 'computer', 'network', 'highway', 'system', 'mass', 'communication', 'medium', 'modern', 'health', 'care', 'system', 'also', 'operating', 'autonomy', 'fact', 'technology', 'applied', 'one', 'location', 'often', 'affect', 'people', 'location', 'far', 'away', 'thus', 'pesticide', 'chemical', 'use', 'near', 'creek', 'may', 'contaminate', 'water', 'supply', 'hundred', 'mile', 'downstream', 'greenhouse', 'effect', 'affect', 'whole', 'world']"
1746,"105. The third and fourth principles result from the complexity of human societies. A change in human behavior will affect the economy of a society and its physical environment; the economy will affect the environment and vice versa, and the changes in the economy and the environment will affect human behavior in complex, unpredictable ways; and so forth. The network of causes and effects is far too complex to be untangled and understood.",TK,442,"['105', 'third', 'fourth', 'principle', 'result', 'complexity', 'human', 'society', 'change', 'human', 'behavior', 'affect', 'economy', 'society', 'physical', 'environment', 'economy', 'affect', 'environment', 'vice', 'versa', 'change', 'economy', 'environment', 'affect', 'human', 'behavior', 'complex', 'unpredictable', 'way', 'forth', 'network', 'cause', 'effect', 'far', 'complex', 'untangled', 'understood']"
1747,"195. The revolution must be international and worldwide. It cannot be carried out on a nation-by-nation basis. Whenever it is suggested that the United States, for example, should cut back on technological progress or economic growth, people get hysterical and start screaming that if we fall behind in technology the Japanese will get ahead of us. Holy robots The world will fly off its orbit if the Japanese ever sell more cars than we do! (Nationalism is a great promoter of technology.) More reasonably, it is argued that if the relatively democratic nations of the world fall behind in technology while nasty, dictatorial nations like China, Vietnam and North Korea continue to progress, eventually the dictators may come to dominate the world. That is why the industrial system should be attacked in all nations simultaneously, to the extent that this may be possible. True, there is no assurance that the industrial system can be destroyed at approximately the same time all over the world, and it is even conceivable that the attempt to overthrow the system could lead instead to the domination of the system by dictators. That is a risk that has to be taken. And it is worth taking, since the difference between a ""democratic"" industrial system and one controlled by dictators is small compared with the difference between an industrial system and a non-industrial one. [33] It might even be argued that an industrial system controlled by dictators would be preferable, because dictator-controlled systems usually have proved inefficient, hence they are presumably more likely to break down. Look at Cuba.",TK,1614,"['195', 'revolution', 'must', 'international', 'worldwide', 'cannot', 'carried', 'nationbynation', 'basis', 'whenever', 'suggested', 'united', 'state', 'example', 'cut', 'back', 'technological', 'progress', 'economic', 'growth', 'people', 'get', 'hysterical', 'start', 'screaming', 'fall', 'behind', 'technology', 'japanese', 'get', 'ahead', 'u', 'holy', 'robot', 'world', 'fly', 'orbit', 'japanese', 'ever', 'sell', 'car', 'nationalism', 'great', 'promoter', 'technology', 'reasonably', 'argued', 'relatively', 'democratic', 'nation', 'world', 'fall', 'behind', 'technology', 'nasty', 'dictatorial', 'nation', 'like', 'china', 'vietnam', 'north', 'korea', 'continue', 'progress', 'eventually', 'dictator', 'may', 'come', 'dominate', 'world', 'industrial', 'system', 'attacked', 'nation', 'simultaneously', 'extent', 'may', 'possible', 'true', 'assurance', 'industrial', 'system', 'destroyed', 'approximately', 'time', 'world', 'even', 'conceivable', 'attempt', 'overthrow', 'system', 'could', 'lead', 'instead', 'domination', 'system', 'dictator', 'risk', 'ha', 'taken', 'worth', 'taking', 'since', 'difference', 'democratic', 'industrial', 'system', 'one', 'controlled', 'dictator', 'small', 'compared', 'difference', 'industrial', 'system', 'nonindustrial', 'one', '33', 'might', 'even', 'argued', 'industrial', 'system', 'controlled', 'dictator', 'would', 'preferable', 'dictatorcontrolled', 'system', 'usually', 'proved', 'inefficient', 'hence', 'presumably', 'likely', 'break', 'look', 'cuba']"
1748,"59. We divide human drives into three groups: (1) those drives that can be satisfied with minimal effort; (2) those that can be satisfied but only at the cost of serious effort; (3) those that cannot be adequately satisfied no matter how much effort one makes. The power process is the process of satisfying the drives of the second group. The more drives there are in the third group, the more there is frustration, anger, eventually defeatism, depression, etc.",TK,462,"['59', 'divide', 'human', 'drive', 'three', 'group', '1', 'drive', 'satisfied', 'minimal', 'effort', '2', 'satisfied', 'cost', 'serious', 'effort', '3', 'cannot', 'adequately', 'satisfied', 'matter', 'much', 'effort', 'one', 'make', 'power', 'process', 'process', 'satisfying', 'drive', 'second', 'group', 'drive', 'third', 'group', 'frustration', 'anger', 'eventually', 'defeatism', 'depression', 'etc']"
1749,"48. It is well known that crowding increases stress and aggression. The degree of crowding that exists today and the isolation of man from nature are consequences of technological progress. All pre-industrial societies were predominantly rural. The industrial Revolution vastly increased the size of cities and the proportion of the population that lives in them, and modern agricultural technology has made it possible for the Earth to support a far denser population than it ever did before. (Also, technology exacerbates the effects of crowding because it puts increased disruptive powers in people's hands. For example, a variety of noise-making devices: power mowers, radios, motorcycles, etc. If the use of these devices is unrestricted, people who want peace and quiet are frustrated by the noise. If their use is restricted, people who use the devices are frustrated by the regulations... But if these machines had never been invented there would have been no conflict and no frustration generated by them.)",TK,1015,"['48', 'well', 'known', 'crowding', 'increase', 'stress', 'aggression', 'degree', 'crowding', 'exists', 'today', 'isolation', 'man', 'nature', 'consequence', 'technological', 'progress', 'preindustrial', 'society', 'predominantly', 'rural', 'industrial', 'revolution', 'vastly', 'increased', 'size', 'city', 'proportion', 'population', 'life', 'modern', 'agricultural', 'technology', 'ha', 'made', 'possible', 'earth', 'support', 'far', 'denser', 'population', 'ever', 'also', 'technology', 'exacerbates', 'effect', 'crowding', 'put', 'increased', 'disruptive', 'power', 'people', 'hand', 'example', 'variety', 'noisemaking', 'device', 'power', 'mower', 'radio', 'motorcycle', 'etc', 'use', 'device', 'unrestricted', 'people', 'want', 'peace', 'quiet', 'frustrated', 'noise', 'use', 'restricted', 'people', 'use', 'device', 'frustrated', 'regulation', 'machine', 'never', 'invented', 'would', 'conflict', 'frustration', 'generated']"
1750,"161. But we have gotten ahead of our story. It is one thing to develop in the laboratory a series of psychological or biological techniques for manipulating human behavior and quite another to integrate these techniques into a functioning social system. The latter problem is the more difficult of the two. For example, while the techniques of educational psychology doubtless work quite well in the ""lab schools"" where they are developed, it is not necessarily easy to apply them effectively throughout our educational system. We all know what many of our schools are like. The teachers are too busy taking knives and guns away from the kids to subject them to the latest techniques for making them into computer nerds. Thus, in spite of all its technical advances relating to human behavior the system to date has not been impressively successful in controlling human beings. The people whose behavior is fairly well under the control of the system are those of the type that might be called ""bourgeois."" But there are growing numbers of people who in one way or another are rebels against the system: welfare leaches, youth gangs cultists, satanists, nazis, radical environmentalists, militiamen, etc..",TK,1205,"['161', 'gotten', 'ahead', 'story', 'one', 'thing', 'develop', 'laboratory', 'series', 'psychological', 'biological', 'technique', 'manipulating', 'human', 'behavior', 'quite', 'another', 'integrate', 'technique', 'functioning', 'social', 'system', 'latter', 'problem', 'difficult', 'two', 'example', 'technique', 'educational', 'psychology', 'doubtless', 'work', 'quite', 'well', 'lab', 'school', 'developed', 'necessarily', 'easy', 'apply', 'effectively', 'throughout', 'educational', 'system', 'know', 'many', 'school', 'like', 'teacher', 'busy', 'taking', 'knife', 'gun', 'away', 'kid', 'subject', 'latest', 'technique', 'making', 'computer', 'nerd', 'thus', 'spite', 'technical', 'advance', 'relating', 'human', 'behavior', 'system', 'date', 'ha', 'impressively', 'successful', 'controlling', 'human', 'people', 'whose', 'behavior', 'fairly', 'well', 'control', 'system', 'type', 'might', 'called', 'bourgeois', 'growing', 'number', 'people', 'one', 'way', 'another', 'rebel', 'system', 'welfare', 'leach', 'youth', 'gang', 'cultist', 'satanist', 'nazi', 'radical', 'environmentalist', 'militiaman', 'etc']"
1751,"148. Other techniques strike deeper that the foregoing. Education is no longer a simple affair of paddling a kid's behind when he doesn't know his lessons and patting him on the head when he does know them. It is becoming a scientific technique for controlling the child's development. Sylvan Learning Centers, for example, have had great success in motivating children to study, and psychological techniques are also used with more or less success in many conventional schools. ""Parenting"" techniques that are taught to parents are designed to make children accept fundamental values of the system and behave in ways that the system finds desirable. ""Mental health"" programs, ""intervention"" techniques, psychotherapy and so forth are ostensibly designed to benefit individuals, but in practice they usually serve as methods for inducing individuals to think and behave as the system requires. (There is no contradiction here; an individual whose attitudes or behavior bring him into conflict with the system is up against a force that is too powerful for him to conquer or escape from, hence he is likely to suffer from stress, frustration, defeat. His path will be much easier if he thinks and behaves as the system requires. In that sense the system is acting for the benefit of the individual when it brainwashes him into conformity.) Child abuse in its gross and obvious forms is disapproved in most if not all cultures. Tormenting a child for a trivial reason or no reason at all is something that appalls almost everyone. But many psychologists interpret the concept of abuse much more broadly. Is spanking, when used as part of a rational and consistent system of discipline, a form of abuse? The question will ultimately be decided by whether or not spanking tends to produce behavior that makes a person fit in well with the existing system of society. In practice, the word ""abuse"" tends to be interpreted to include any method of child-rearing that produces behavior inconvenient for the system. Thus, when they go beyond the prevention of obvious, senseless cruelty, programs for preventing ""child abuse"" are directed toward the control of human behavior of the system.",TK,2182,"['148', 'technique', 'strike', 'deeper', 'foregoing', 'education', 'longer', 'simple', 'affair', 'paddling', 'kid', 'behind', 'doesnt', 'know', 'lesson', 'patting', 'head', 'doe', 'know', 'becoming', 'scientific', 'technique', 'controlling', 'child', 'development', 'sylvan', 'learning', 'center', 'example', 'great', 'success', 'motivating', 'child', 'study', 'psychological', 'technique', 'also', 'used', 'le', 'success', 'many', 'conventional', 'school', 'parenting', 'technique', 'taught', 'parent', 'designed', 'make', 'child', 'accept', 'fundamental', 'value', 'system', 'behave', 'way', 'system', 'find', 'desirable', 'mental', 'health', 'program', 'intervention', 'technique', 'psychotherapy', 'forth', 'ostensibly', 'designed', 'benefit', 'individual', 'practice', 'usually', 'serve', 'method', 'inducing', 'individual', 'think', 'behave', 'system', 'requires', 'contradiction', 'individual', 'whose', 'attitude', 'behavior', 'bring', 'conflict', 'system', 'force', 'powerful', 'conquer', 'escape', 'hence', 'likely', 'suffer', 'stress', 'frustration', 'defeat', 'path', 'much', 'easier', 'think', 'behaves', 'system', 'requires', 'sense', 'system', 'acting', 'benefit', 'individual', 'brainwashes', 'conformity', 'child', 'abuse', 'gross', 'obvious', 'form', 'disapproved', 'culture', 'tormenting', 'child', 'trivial', 'reason', 'reason', 'something', 'appalls', 'almost', 'everyone', 'many', 'psychologist', 'interpret', 'concept', 'abuse', 'much', 'broadly', 'spanking', 'used', 'part', 'rational', 'consistent', 'system', 'discipline', 'form', 'abuse', 'question', 'ultimately', 'decided', 'whether', 'spanking', 'tends', 'produce', 'behavior', 'make', 'person', 'fit', 'well', 'existing', 'system', 'society', 'practice', 'word', 'abuse', 'tends', 'interpreted', 'include', 'method', 'childrearing', 'produce', 'behavior', 'inconvenient', 'system', 'thus', 'go', 'beyond', 'prevention', 'obvious', 'senseless', 'cruelty', 'program', 'preventing', 'child', 'abuse', 'directed', 'toward', 'control', 'human', 'behavior', 'system']"
1752,4. We therefore advocate a revolution against the industrial system. This revolution may or may not make use of violence: it may be sudden or it may be a relatively gradual process spanning a few decades. We can't predict any of that. But we do outline in a very general way the measures that those who hate the industrial system should take in order to prepare the way for a revolution against that form of society. This is not to be a POLITICAL revolution. Its object will be to overthrow not governments but the economic and technological basis of the present society.,TK,571,"['4', 'therefore', 'advocate', 'revolution', 'industrial', 'system', 'revolution', 'may', 'may', 'make', 'use', 'violence', 'may', 'sudden', 'may', 'relatively', 'gradual', 'process', 'spanning', 'decade', 'cant', 'predict', 'outline', 'general', 'way', 'measure', 'hate', 'industrial', 'system', 'take', 'order', 'prepare', 'way', 'revolution', 'form', 'society', 'political', 'revolution', 'object', 'overthrow', 'government', 'economic', 'technological', 'basis', 'present', 'society']"
1753,"83. Some people partly satisfy their need for power by identifying themselves with a powerful organization or mass movement. An individual lacking goals or power joins a movement or an organization, adopts its goals as his own, then works toward these goals. When some of the goals are attained, the individual, even though his personal efforts have played only an insignificant part in the attainment of the goals, feels (through his identification with the movement or organization) as if he had gone through the power process. This phenomenon was exploited by the fascists, nazis and communists. Our society uses it, too, though less crudely. Example: Manuel Noriega was an irritant to the U.S. (goal: punish Noriega). The U.S. invaded Panama (effort) and punished Noriega (attainment of goal). The U.S. went through the power process and many Americans, because of their identification with the U.S., experienced the power process vicariously. Hence the widespread public approval of the Panama invasion; it gave people a sense of power. [15] We see the same phenomenon in armies, corporations, political parties, humanitarian organizations, religious or ideological movements. In particular, leftist movements tend to attract people who are seeking to satisfy their need for power. But for most people identification with a large organization or a mass movement does not fully satisfy the need for power.",TK,1409,"['83', 'people', 'partly', 'satisfy', 'need', 'power', 'identifying', 'powerful', 'organization', 'mass', 'movement', 'individual', 'lacking', 'goal', 'power', 'join', 'movement', 'organization', 'adopts', 'goal', 'work', 'toward', 'goal', 'goal', 'attained', 'individual', 'even', 'though', 'personal', 'effort', 'played', 'insignificant', 'part', 'attainment', 'goal', 'feel', 'identification', 'movement', 'organization', 'gone', 'power', 'process', 'phenomenon', 'wa', 'exploited', 'fascist', 'nazi', 'communist', 'society', 'us', 'though', 'le', 'crudely', 'example', 'manuel', 'noriega', 'wa', 'irritant', 'u', 'goal', 'punish', 'noriega', 'u', 'invaded', 'panama', 'effort', 'punished', 'noriega', 'attainment', 'goal', 'u', 'went', 'power', 'process', 'many', 'american', 'identification', 'u', 'experienced', 'power', 'process', 'vicariously', 'hence', 'widespread', 'public', 'approval', 'panama', 'invasion', 'gave', 'people', 'sense', 'power', '15', 'see', 'phenomenon', 'army', 'corporation', 'political', 'party', 'humanitarian', 'organization', 'religious', 'ideological', 'movement', 'particular', 'leftist', 'movement', 'tend', 'attract', 'people', 'seeking', 'satisfy', 'need', 'power', 'people', 'identification', 'large', 'organization', 'mass', 'movement', 'doe', 'fully', 'satisfy', 'need', 'power']"
1754,"205. The trouble is that many of the people who are inclined to rebel against the industrial system are also concerned about the population problems, hence they are apt to have few or no children. In this way they may be handing the world over to the sort of people who support or at least accept the industrial system. To insure the strength of the next generation of revolutionaries the present generation must reproduce itself abundantly. In doing so they will be worsening the population problem only slightly. And the most important problem is to get rid of the industrial system, because once the industrial system is gone the world's population necessarily will decrease (see paragraph 167); whereas, if the industrial system survives, it will continue developing new techniques of food production that may enable the world's population to keep increasing almost indefinitely.",TK,883,"['205', 'trouble', 'many', 'people', 'inclined', 'rebel', 'industrial', 'system', 'also', 'concerned', 'population', 'problem', 'hence', 'apt', 'child', 'way', 'may', 'handing', 'world', 'sort', 'people', 'support', 'least', 'accept', 'industrial', 'system', 'insure', 'strength', 'next', 'generation', 'revolutionary', 'present', 'generation', 'must', 'reproduce', 'abundantly', 'worsening', 'population', 'problem', 'slightly', 'important', 'problem', 'get', 'rid', 'industrial', 'system', 'industrial', 'system', 'gone', 'world', 'population', 'necessarily', 'decrease', 'see', 'paragraph', '167', 'whereas', 'industrial', 'system', 'survives', 'continue', 'developing', 'new', 'technique', 'food', 'production', 'may', 'enable', 'world', 'population', 'keep', 'increasing', 'almost', 'indefinitely']"
1755,"185. As for the negative consequences of eliminating industrial society -- well, you can't eat your cake and have it too. To gain one thing you have to sacrifice another.",TK,170,"['185', 'negative', 'consequence', 'eliminating', 'industrial', 'society', '', 'well', 'cant', 'eat', 'cake', 'gain', 'one', 'thing', 'sacrifice', 'another']"
1756,"28. The leftist of the oversocialized type tries to get off his psychological leash and assert his autonomy by rebelling. But usually he is not strong enough to rebel against the most basic values of society. Generally speaking, the goals of today's leftists are NOT in conflict with the accepted morality. On the contrary, the left takes an accepted moral principle, adopts it as its own, and then accuses mainstream society of violating that principle. Examples: racial equality, equality of the sexes, helping poor people, peace as opposed to war, nonviolence generally, freedom of expression, kindness to animals. More fundamentally, the duty of the individual to serve society and the duty of society to take care of the individual. All these have been deeply rooted values of our society (or at least of its middle and upper classes (4) for a long time. These values are explicitly or implicitly expressed or presupposed in most of the material presented to us by the mainstream communications media and the educational system. Leftists, especially those of the oversocialized type, usually do not rebel against these principles but justify their hostility to society by claiming (with some degree of truth) that society is not living up to these principles.",TK,1264,"['28', 'leftist', 'oversocialized', 'type', 'try', 'get', 'psychological', 'leash', 'assert', 'autonomy', 'rebelling', 'usually', 'strong', 'enough', 'rebel', 'basic', 'value', 'society', 'generally', 'speaking', 'goal', 'today', 'leftist', 'conflict', 'accepted', 'morality', 'contrary', 'left', 'take', 'accepted', 'moral', 'principle', 'adopts', 'accuses', 'mainstream', 'society', 'violating', 'principle', 'example', 'racial', 'equality', 'equality', 'sex', 'helping', 'poor', 'people', 'peace', 'opposed', 'war', 'nonviolence', 'generally', 'freedom', 'expression', 'kindness', 'animal', 'fundamentally', 'duty', 'individual', 'serve', 'society', 'duty', 'society', 'take', 'care', 'individual', 'deeply', 'rooted', 'value', 'society', 'least', 'middle', 'upper', 'class', '4', 'long', 'time', 'value', 'explicitly', 'implicitly', 'expressed', 'presupposed', 'material', 'presented', 'u', 'mainstream', 'communication', 'medium', 'educational', 'system', 'leftist', 'especially', 'oversocialized', 'type', 'usually', 'rebel', 'principle', 'justify', 'hostility', 'society', 'claiming', 'degree', 'truth', 'society', 'living', 'principle']"
1757,"125. It is not possible to make a LASTING compromise between technology and freedom, because technology is by far the more powerful social force and continually encroaches on freedom through REPEATED compromises. Imagine the case of two neighbors, each of whom at the outset owns the same amount of land, but one of whom is more powerful than the other. The powerful one demands a piece of the other's land. The weak one refuses. The powerful one says, ""OK, let's compromise. Give me half of what I asked."" The weak one has little choice but to give in. Some time later the powerful neighbor demands another piece of land, again there is a compromise, and so forth. By forcing a long series of compromises on the weaker man, the powerful one eventually gets all of his land. So it goes in the conflict between technology and freedom.",TK,833,"['125', 'possible', 'make', 'lasting', 'compromise', 'technology', 'freedom', 'technology', 'far', 'powerful', 'social', 'force', 'continually', 'encroaches', 'freedom', 'repeated', 'compromise', 'imagine', 'case', 'two', 'neighbor', 'outset', 'owns', 'amount', 'land', 'one', 'powerful', 'powerful', 'one', 'demand', 'piece', 'others', 'land', 'weak', 'one', 'refuse', 'powerful', 'one', 'say', 'ok', 'let', 'compromise', 'give', 'half', 'asked', 'weak', 'one', 'ha', 'little', 'choice', 'give', 'time', 'later', 'powerful', 'neighbor', 'demand', 'another', 'piece', 'land', 'compromise', 'forth', 'forcing', 'long', 'series', 'compromise', 'weaker', 'man', 'powerful', 'one', 'eventually', 'get', 'land', 'go', 'conflict', 'technology', 'freedom']"
1758,"20. Notice the masochistic tendency of leftist tactics. Leftists protest by lying down in front of vehicles, they intentionally provoke police or racists to abuse them, etc. These tactics may often be effective, but many leftists use them not as a means to an end but because they PREFER masochistic tactics. Self-hatred is a leftist trait.",TK,340,"['20', 'notice', 'masochistic', 'tendency', 'leftist', 'tactic', 'leftist', 'protest', 'lying', 'front', 'vehicle', 'intentionally', 'provoke', 'police', 'racist', 'abuse', 'etc', 'tactic', 'may', 'often', 'effective', 'many', 'leftist', 'use', 'mean', 'end', 'prefer', 'masochistic', 'tactic', 'selfhatred', 'leftist', 'trait']"
1759,"150. As we mentioned in paragraph 134, industrial society seems likely to be entering a period of severe stress, due in part to problems of human behavior and in part to economic and environmental problems. And a considerable proportion of the system's economic and environmental problems result from the way human beings behave. Alienation, low self-esteem, depression, hostility, rebellion; children who won't study, youth gangs, illegal drug use, rape, child abuse , other crimes, unsafe sex, teen pregnancy, population growth, political corruption, race hatred, ethnic rivalry, bitter ideological conflict (i.e., pro-choice vs. pro-life), political extremism, terrorism, sabotage, anti-government groups, hate groups. All these threaten the very survival of the system. The system will be FORCED to use every practical means of controlling human behavior.",TK,859,"['150', 'mentioned', 'paragraph', '134', 'industrial', 'society', 'seems', 'likely', 'entering', 'period', 'severe', 'stress', 'due', 'part', 'problem', 'human', 'behavior', 'part', 'economic', 'environmental', 'problem', 'considerable', 'proportion', 'system', 'economic', 'environmental', 'problem', 'result', 'way', 'human', 'behave', 'alienation', 'low', 'selfesteem', 'depression', 'hostility', 'rebellion', 'child', 'wont', 'study', 'youth', 'gang', 'illegal', 'drug', 'use', 'rape', 'child', 'abuse', '', 'crime', 'unsafe', 'sex', 'teen', 'pregnancy', 'population', 'growth', 'political', 'corruption', 'race', 'hatred', 'ethnic', 'rivalry', 'bitter', 'ideological', 'conflict', 'ie', 'prochoice', 'v', 'prolife', 'political', 'extremism', 'terrorism', 'sabotage', 'antigovernment', 'group', 'hate', 'group', 'threaten', 'survival', 'system', 'system', 'forced', 'use', 'every', 'practical', 'mean', 'controlling', 'human', 'behavior']"
1760,"160. To those who think that all this sounds like science fiction, we point out that yesterday's science fiction is today's fact. The Industrial Revolution has radically altered man's environment and way of life, and it is only to be expected that as technology is increasingly applied to the human body and mind, man himself will be altered as radically as his environment and way of life have been.",TK,400,"['160', 'think', 'sound', 'like', 'science', 'fiction', 'point', 'yesterday', 'science', 'fiction', 'today', 'fact', 'industrial', 'revolution', 'ha', 'radically', 'altered', 'man', 'environment', 'way', 'life', 'expected', 'technology', 'increasingly', 'applied', 'human', 'body', 'mind', 'man', 'altered', 'radically', 'environment', 'way', 'life']"
1761,"168. In the second place, one has to balance the struggle and death against the loss of freedom and dignity. To many of us, freedom and dignity are more important than a long life or avoidance of physical pain. Besides, we all have to die some time, and it may be better to die fighting for survival, or for a cause, than to live a long but empty and purposeless life.",TK,368,"['168', 'second', 'place', 'one', 'ha', 'balance', 'struggle', 'death', 'loss', 'freedom', 'dignity', 'many', 'u', 'freedom', 'dignity', 'important', 'long', 'life', 'avoidance', 'physical', 'pain', 'besides', 'die', 'time', 'may', 'better', 'die', 'fighting', 'survival', 'cause', 'live', 'long', 'empty', 'purposeless', 'life']"
1762,"159. Will public resistance prevent the introduction of technological control of human behavior? It certainly would if an attempt were made to introduce such control all at once. But since technological control will be introduced through a long sequence of small advances, there will be no rational and effective public resistance. (See paragraphs 127,132, 153.)",TK,362,"['159', 'public', 'resistance', 'prevent', 'introduction', 'technological', 'control', 'human', 'behavior', 'certainly', 'would', 'attempt', 'made', 'introduce', 'control', 'since', 'technological', 'control', 'introduced', 'long', 'sequence', 'small', 'advance', 'rational', 'effective', 'public', 'resistance', 'see', 'paragraph', '127132', '153']"
1763,"73. Behavior is regulated not only through explicit rules and not only by the government. Control is often exercised through indirect coercion or through psychological pressure or manipulation, and by organizations other than the government, or by the system as a whole. Most large organizations use some form of propaganda [14] to manipulate public attitudes or behavior. Propaganda is not limited to ""commercials"" and advertisements, and sometimes it is not even consciously intended as propaganda by the people who make it. For instance, the content of entertainment programming is a powerful form of propaganda. An example of indirect coercion: There is no law that says we have to go to work every day and follow our employer's orders. Legally there is nothing to prevent us from going to live in the wild like primitive people or from going into business for ourselves. But in practice there is very little wild country left, and there is room in the economy for only a limited number of small business owners. Hence most of us can survive only as someone else's employee.",TK,1078,"['73', 'behavior', 'regulated', 'explicit', 'rule', 'government', 'control', 'often', 'exercised', 'indirect', 'coercion', 'psychological', 'pressure', 'manipulation', 'organization', 'government', 'system', 'whole', 'large', 'organization', 'use', 'form', 'propaganda', '14', 'manipulate', 'public', 'attitude', 'behavior', 'propaganda', 'limited', 'commercial', 'advertisement', 'sometimes', 'even', 'consciously', 'intended', 'propaganda', 'people', 'make', 'instance', 'content', 'entertainment', 'programming', 'powerful', 'form', 'propaganda', 'example', 'indirect', 'coercion', 'law', 'say', 'go', 'work', 'every', 'day', 'follow', 'employer', 'order', 'legally', 'nothing', 'prevent', 'u', 'going', 'live', 'wild', 'like', 'primitive', 'people', 'going', 'business', 'practice', 'little', 'wild', 'country', 'left', 'room', 'economy', 'limited', 'number', 'small', 'business', 'owner', 'hence', 'u', 'survive', 'someone', 'el', 'employee']"
1764,202. It would be hopeless for revolutionaries to try to attack the system without using SOME modern technology. If nothing else they must use the communications media to spread their message. But they should use modern technology for only ONE purpose: to attack the technological system.,TK,287,"['202', 'would', 'hopeless', 'revolutionary', 'try', 'attack', 'system', 'without', 'using', 'modern', 'technology', 'nothing', 'else', 'must', 'use', 'communication', 'medium', 'spread', 'message', 'use', 'modern', 'technology', 'one', 'purpose', 'attack', 'technological', 'system']"
1765,"128. While technological progress AS A WHOLE continually narrows our sphere of freedom, each new technical advance CONSIDERED BY ITSELF appears to be desirable. Electricity, indoor plumbing, rapid long-distance communications . . . how could one argue against any of these things, or against any other of the innumerable technical advances that have made modern society? It would have been absurd to resist the introduction of the telephone, for example. It offered many advantages and no disadvantages. Yet as we explained in paragraphs 59-76, all these technical advances taken together have created world in which the average man's fate is no longer in his own hands or in the hands of his neighbors and friends, but in those of politicians, corporation executives and remote, anonymous technicians and bureaucrats whom he as an individual has no power to influence. [21] The same process will continue in the future. Take genetic engineering, for example. Few people will resist the introduction of a genetic technique that eliminates a hereditary disease It does no apparent harm and prevents much suffering. Yet a large number of genetic improvements taken together will make the human being into an engineered product rather than a free creation of chance (or of God, or whatever, depending on your religious beliefs).",TK,1325,"['128', 'technological', 'progress', 'whole', 'continually', 'narrow', 'sphere', 'freedom', 'new', 'technical', 'advance', 'considered', 'appears', 'desirable', 'electricity', 'indoor', 'plumbing', 'rapid', 'longdistance', 'communication', '', '', '', 'could', 'one', 'argue', 'thing', 'innumerable', 'technical', 'advance', 'made', 'modern', 'society', 'would', 'absurd', 'resist', 'introduction', 'telephone', 'example', 'offered', 'many', 'advantage', 'disadvantage', 'yet', 'explained', 'paragraph', '5976', 'technical', 'advance', 'taken', 'together', 'created', 'world', 'average', 'man', 'fate', 'longer', 'hand', 'hand', 'neighbor', 'friend', 'politician', 'corporation', 'executive', 'remote', 'anonymous', 'technician', 'bureaucrat', 'individual', 'ha', 'power', 'influence', '21', 'process', 'continue', 'future', 'take', 'genetic', 'engineering', 'example', 'people', 'resist', 'introduction', 'genetic', 'technique', 'eliminates', 'hereditary', 'disease', 'doe', 'apparent', 'harm', 'prevents', 'much', 'suffering', 'yet', 'large', 'number', 'genetic', 'improvement', 'taken', 'together', 'make', 'human', 'engineered', 'product', 'rather', 'free', 'creation', 'chance', 'god', 'whatever', 'depending', 'religious', 'belief']"
1766,226. Thus the fact that many individual leftists are personally mild and fairly tolerant people by no means prevents leftism as a whole form having a totalitarian tendency.,TK,172,"['226', 'thus', 'fact', 'many', 'individual', 'leftist', 'personally', 'mild', 'fairly', 'tolerant', 'people', 'mean', 'prevents', 'leftism', 'whole', 'form', 'totalitarian', 'tendency']"
1767,27. We argue that a very important and influential segment of the modern left is oversocialized and that their oversocialization is of great importance in determining the direction of modern leftism. Leftists of the oversocialized type tend to be intellectuals or members of the upper-middle class. Notice that university intellectuals (3) constitute the most highly socialized segment of our society and also the most left-wing segment.,TK,437,"['27', 'argue', 'important', 'influential', 'segment', 'modern', 'left', 'oversocialized', 'oversocialization', 'great', 'importance', 'determining', 'direction', 'modern', 'leftism', 'leftist', 'oversocialized', 'type', 'tend', 'intellectual', 'member', 'uppermiddle', 'class', 'notice', 'university', 'intellectual', '3', 'constitute', 'highly', 'socialized', 'segment', 'society', 'also', 'leftwing', 'segment']"
1768,"232. All the same we are reasonably confident that the general outlines of the picture we have painted here are roughly correct. We have portrayed leftism in its modern form as a phenomenon peculiar to our time and as a symptom of the disruption of the power process. But we might possibly be wrong about this. Oversocialized types who try to satisfy their drive for power by imposing their morality on everyone have certainly been around for a long time. But we THINK that the decisive role played by feelings of inferiority, low self-esteem, powerlessness, identification with victims by people who are not themselves victims, is a peculiarity of modern leftism. Identification with victims by people not themselves victims can be seen to some extent in 19th century leftism and early Christianity but as far as we can make out, symptoms of low self-esteem, etc., were not nearly so evident in these movements, or in any other movements, as they are in modern leftism. But we are not in a position to assert confidently that no such movements have existed prior to modern leftism. This is a significant question to which historians ought to give their attention.",TK,1164,"['232', 'reasonably', 'confident', 'general', 'outline', 'picture', 'painted', 'roughly', 'correct', 'portrayed', 'leftism', 'modern', 'form', 'phenomenon', 'peculiar', 'time', 'symptom', 'disruption', 'power', 'process', 'might', 'possibly', 'wrong', 'oversocialized', 'type', 'try', 'satisfy', 'drive', 'power', 'imposing', 'morality', 'everyone', 'certainly', 'around', 'long', 'time', 'think', 'decisive', 'role', 'played', 'feeling', 'inferiority', 'low', 'selfesteem', 'powerlessness', 'identification', 'victim', 'people', 'victim', 'peculiarity', 'modern', 'leftism', 'identification', 'victim', 'people', 'victim', 'seen', 'extent', '19th', 'century', 'leftism', 'early', 'christianity', 'far', 'make', 'symptom', 'low', 'selfesteem', 'etc', 'nearly', 'evident', 'movement', 'movement', 'modern', 'leftism', 'position', 'assert', 'confidently', 'movement', 'existed', 'prior', 'modern', 'leftism', 'significant', 'question', 'historian', 'ought', 'give', 'attention']"
1769,"132. It is well known that people generally work better and more persistently when striving for a reward than when attempting to avoid a punishment or negative outcome. Scientists and other technicians are motivated mainly by the rewards they get through their work. But those who oppose technilogiccal invasions of freedom are working to avoid a negative outcome, consequently there are a few who work persistently and well at this discouraging task. If reformers ever achieved a signal victory that seemed to set up a solid barrier against further erosion of freedom through technological progress, most would tend to relax and turn their attention to more agreeable pursuits. But the scientists would remain busy in their laboratories, and technology as it progresses would find ways, in spite of any barriers, to exert more and more control over individuals and make them always more dependent on the system.",TK,912,"['132', 'well', 'known', 'people', 'generally', 'work', 'better', 'persistently', 'striving', 'reward', 'attempting', 'avoid', 'punishment', 'negative', 'outcome', 'scientist', 'technician', 'motivated', 'mainly', 'reward', 'get', 'work', 'oppose', 'technilogiccal', 'invasion', 'freedom', 'working', 'avoid', 'negative', 'outcome', 'consequently', 'work', 'persistently', 'well', 'discouraging', 'task', 'reformer', 'ever', 'achieved', 'signal', 'victory', 'seemed', 'set', 'solid', 'barrier', 'erosion', 'freedom', 'technological', 'progress', 'would', 'tend', 'relax', 'turn', 'attention', 'agreeable', 'pursuit', 'scientist', 'would', 'remain', 'busy', 'laboratory', 'technology', 'progress', 'would', 'find', 'way', 'spite', 'barrier', 'exert', 'control', 'individual', 'make', 'always', 'dependent', 'system']"
1770,"188. On a second level, the ideology should be propagated in a simplified form that will enable the unthinking majority to see the conflict of technology vs. nature in unambiguous terms. But even on this second level the ideology should not be expressed in language that is so cheap, intemperate or irrational that it alienates people of the thoughtful and rational type. Cheap, intemperate propaganda sometimes achieves impressive short-term gains, but it will be more advantageous in the long run to keep the loyalty of a small number of intelligently committed people than to arouse the passions of an unthinking, fickle mob who will change their attitude as soon as someone comes along with a better propaganda gimmick. However, propaganda of the rabble-rousing type may be necessary when the system is nearing the point of collapse and there is a final struggle between rival ideologies to determine which will become dominant when the old world-view goes under.",TK,967,"['188', 'second', 'level', 'ideology', 'propagated', 'simplified', 'form', 'enable', 'unthinking', 'majority', 'see', 'conflict', 'technology', 'v', 'nature', 'unambiguous', 'term', 'even', 'second', 'level', 'ideology', 'expressed', 'language', 'cheap', 'intemperate', 'irrational', 'alienates', 'people', 'thoughtful', 'rational', 'type', 'cheap', 'intemperate', 'propaganda', 'sometimes', 'achieves', 'impressive', 'shortterm', 'gain', 'advantageous', 'long', 'run', 'keep', 'loyalty', 'small', 'number', 'intelligently', 'committed', 'people', 'arouse', 'passion', 'unthinking', 'fickle', 'mob', 'change', 'attitude', 'soon', 'someone', 'come', 'along', 'better', 'propaganda', 'gimmick', 'however', 'propaganda', 'rabblerousing', 'type', 'may', 'necessary', 'system', 'nearing', 'point', 'collapse', 'final', 'struggle', 'rival', 'ideology', 'determine', 'become', 'dominant', 'old', 'worldview', 'go']"
1771,"116. Because of the constant pressure that the system exerts to modify human behavior, there is a gradual increase in the number of people who cannot or will not adjust to society's requirements: welfare leeches, youth-gang members, cultists, anti-government rebels, radical environmentalist saboteurs, dropouts and resisters of various kinds.",TK,343,"['116', 'constant', 'pressure', 'system', 'exerts', 'modify', 'human', 'behavior', 'gradual', 'increase', 'number', 'people', 'cannot', 'adjust', 'society', 'requirement', 'welfare', 'leech', 'youthgang', 'member', 'cultist', 'antigovernment', 'rebel', 'radical', 'environmentalist', 'saboteur', 'dropout', 'resister', 'various', 'kind']"
1772,"58. It would be possible to give other examples of societies in which there has been rapid change and/or lack of close community ties without he kind of massive behavioral aberration that is seen in today's industrial society. We contend that the most important cause of social and psychological problems in modern society is the fact that people have insufficient opportunity to go through the power process in a normal way. We don't mean to say that modern society is the only one in which the power process has been disrupted. Probably most if not all civilized societies have interfered with the power ' process to a greater or lesser extent. But in modern industrial society the problem has become particularly acute. Leftism, at least in its recent (mid-to-late -20th century) form, is in part a symptom of deprivation with respect to the power process.",TK,859,"['58', 'would', 'possible', 'give', 'example', 'society', 'ha', 'rapid', 'change', 'andor', 'lack', 'close', 'community', 'tie', 'without', 'kind', 'massive', 'behavioral', 'aberration', 'seen', 'today', 'industrial', 'society', 'contend', 'important', 'cause', 'social', 'psychological', 'problem', 'modern', 'society', 'fact', 'people', 'insufficient', 'opportunity', 'go', 'power', 'process', 'normal', 'way', 'dont', 'mean', 'say', 'modern', 'society', 'one', 'power', 'process', 'ha', 'disrupted', 'probably', 'civilized', 'society', 'interfered', 'power', '', 'process', 'greater', 'lesser', 'extent', 'modern', 'industrial', 'society', 'problem', 'ha', 'become', 'particularly', 'acute', 'leftism', 'least', 'recent', 'midtolate', '20th', 'century', 'form', 'part', 'symptom', 'deprivation', 'respect', 'power', 'process']"
1773,"187. On the more sophisticated level the ideology should address itself to people who are intelligent, thoughtful and rational. The object should be to create a core of people who will be opposed to the industrial system on a rational, thought-out basis, with full appreciation of the problems and ambiguities involved, and of the price that has to be paid for getting rid of the system. It is particularly important to attract people of this type, as they are capable people and will be instrumental in influencing others. These people should be addressed on as rational a level as possible. Facts should never intentionally be distorted and intemperate language should be avoided. This does not mean that no appeal can be made to the emotions, but in making such appeal care should be taken to avoid misrepresenting the truth or doing anything else that would destroy the intellectual respectability of the ideology.",TK,918,"['187', 'sophisticated', 'level', 'ideology', 'address', 'people', 'intelligent', 'thoughtful', 'rational', 'object', 'create', 'core', 'people', 'opposed', 'industrial', 'system', 'rational', 'thoughtout', 'basis', 'full', 'appreciation', 'problem', 'ambiguity', 'involved', 'price', 'ha', 'paid', 'getting', 'rid', 'system', 'particularly', 'important', 'attract', 'people', 'type', 'capable', 'people', 'instrumental', 'influencing', 'others', 'people', 'addressed', 'rational', 'level', 'possible', 'fact', 'never', 'intentionally', 'distorted', 'intemperate', 'language', 'avoided', 'doe', 'mean', 'appeal', 'made', 'emotion', 'making', 'appeal', 'care', 'taken', 'avoid', 'misrepresenting', 'truth', 'anything', 'else', 'would', 'destroy', 'intellectual', 'respectability', 'ideology']"
1774,"129 Another reason why technology is such a powerful social force is that, within the context of a given society, technological progress marches in only one direction; it can never be reversed. Once a technical innovation has been introduced, people usually become dependent on it, unless it is replaced by some still more advanced innovation. Not only do people become dependent as individuals on a new item of technology, but, even more, the system as a whole becomes dependent on it. (Imagine what would happen to the system today if computers, for example, were eliminated.) Thus the system can move in only one direction, toward greater technologization. Technology repeatedly forces freedom to take a step back -- short of the overthrow of the whole technological system.",TK,777,"['129', 'another', 'reason', 'technology', 'powerful', 'social', 'force', 'within', 'context', 'given', 'society', 'technological', 'progress', 'march', 'one', 'direction', 'never', 'reversed', 'technical', 'innovation', 'ha', 'introduced', 'people', 'usually', 'become', 'dependent', 'unless', 'replaced', 'still', 'advanced', 'innovation', 'people', 'become', 'dependent', 'individual', 'new', 'item', 'technology', 'even', 'system', 'whole', 'becomes', 'dependent', 'imagine', 'would', 'happen', 'system', 'today', 'computer', 'example', 'eliminated', 'thus', 'system', 'move', 'one', 'direction', 'toward', 'greater', 'technologization', 'technology', 'repeatedly', 'force', 'freedom', 'take', 'step', 'back', '', 'short', 'overthrow', 'whole', 'technological', 'system']"
1775,"164. Don't imagine that the systems will stop developing further techniques for controlling human beings and nature once the crisis of the next few decades is over and increasing control is no longer necessary for the system's survival. On the contrary, once the hard times are over the system will increase its control over people and nature more rapidly, because it will no longer be hampered by difficulties of the kind that it is currently experiencing. Survival is not the principal motive for extending control. As we explained in paragraphs 87-90, technicians and scientists carry on their work largely as a surrogate activity; that is, they satisfy their need for power by solving technical problems. They will continue to do this with unabated enthusiasm, and among the most interesting and challenging problems for them to solve will be those of understanding the human body and mind and intervening in their development. For the ""good of humanity,"" of course.",TK,970,"['164', 'dont', 'imagine', 'system', 'stop', 'developing', 'technique', 'controlling', 'human', 'nature', 'crisis', 'next', 'decade', 'increasing', 'control', 'longer', 'necessary', 'system', 'survival', 'contrary', 'hard', 'time', 'system', 'increase', 'control', 'people', 'nature', 'rapidly', 'longer', 'hampered', 'difficulty', 'kind', 'currently', 'experiencing', 'survival', 'principal', 'motive', 'extending', 'control', 'explained', 'paragraph', '8790', 'technician', 'scientist', 'carry', 'work', 'largely', 'surrogate', 'activity', 'satisfy', 'need', 'power', 'solving', 'technical', 'problem', 'continue', 'unabated', 'enthusiasm', 'among', 'interesting', 'challenging', 'problem', 'solve', 'understanding', 'human', 'body', 'mind', 'intervening', 'development', 'good', 'humanity', 'course']"
1776,"207. An argument likely to be raised against our proposed revolution is that it is bound to fail, because (it is claimed) throughout history technology has always progressed, never regressed, hence technological regression is impossible. But this claim is false.",TK,262,"['207', 'argument', 'likely', 'raised', 'proposed', 'revolution', 'bound', 'fail', 'claimed', 'throughout', 'history', 'technology', 'ha', 'always', 'progressed', 'never', 'regressed', 'hence', 'technological', 'regression', 'impossible', 'claim', 'false']"
1777,"38. But not every leisured aristocrat becomes bored and demoralized. For example, the emperor Hirohito, instead of sinking into decadent hedonism, devoted himself to marine biology, a field in which he became distinguished. When people do not have to exert themselves to satisfy their physical needs they often set up artificial goals for themselves. In many cases they then pursue these goals with the same energy and emotional involvement that they otherwise would have put into the search for physical necessities. Thus the aristocrats of the Roman Empire had their literary pretentions; many European aristocrats a few centuries ago invested tremendous time and energy in hunting, though they certainly didn't need the meat; other aristocracies have competed for status through elaborate displays of wealth; and a few aristocrats, like Hirohito, have turned to science.",TK,873,"['38', 'every', 'leisured', 'aristocrat', 'becomes', 'bored', 'demoralized', 'example', 'emperor', 'hirohito', 'instead', 'sinking', 'decadent', 'hedonism', 'devoted', 'marine', 'biology', 'field', 'became', 'distinguished', 'people', 'exert', 'satisfy', 'physical', 'need', 'often', 'set', 'artificial', 'goal', 'many', 'case', 'pursue', 'goal', 'energy', 'emotional', 'involvement', 'otherwise', 'would', 'put', 'search', 'physical', 'necessity', 'thus', 'aristocrat', 'roman', 'empire', 'literary', 'pretentions', 'many', 'european', 'aristocrat', 'century', 'ago', 'invested', 'tremendous', 'time', 'energy', 'hunting', 'though', 'certainly', 'didnt', 'need', 'meat', 'aristocracy', 'competed', 'status', 'elaborate', 'display', 'wealth', 'aristocrat', 'like', 'hirohito', 'turned', 'science']"
1778,"211. In the late Middle Ages there were four main civilizations that were about equally ""advanced"": Europe, the Islamic world, India, and the Far East (China, Japan, Korea). Three of those civilizations remained more or less stable, and only Europe became dynamic. No one knows why Europe became dynamic at that time; historians have their theories but these are only speculation. At any rate, it is clear that rapid development toward a technological form of society occurs only under special conditions. So there is no reason to assume that long-lasting technological regression cannot be brought about.",TK,605,"['211', 'late', 'middle', 'age', 'four', 'main', 'civilization', 'equally', 'advanced', 'europe', 'islamic', 'world', 'india', 'far', 'east', 'china', 'japan', 'korea', 'three', 'civilization', 'remained', 'le', 'stable', 'europe', 'became', 'dynamic', 'one', 'know', 'europe', 'became', 'dynamic', 'time', 'historian', 'theory', 'speculation', 'rate', 'clear', 'rapid', 'development', 'toward', 'technological', 'form', 'society', 'occurs', 'special', 'condition', 'reason', 'assume', 'longlasting', 'technological', 'regression', 'cannot', 'brought']"
1779,"91. Also, science and technology constitute a mass power movement, and many scientists gratify their need for power through identification with this mass movement (see paragraph 83).",TK,182,"['91', 'also', 'science', 'technology', 'constitute', 'mass', 'power', 'movement', 'many', 'scientist', 'gratify', 'need', 'power', 'identification', 'mass', 'movement', 'see', 'paragraph', '83']"
1780,"121. A further reason why industrial society cannot be reformed in favor of freedom is that modern technology is a unified system in which all parts are dependent on one another. You can't get rid of the ""bad"" parts of technology and retain only the ""good"" parts. Take modern medicine, for example. Progress in medical science depends on progress in chemistry, physics, biology, computer science and other fields. Advanced medical treatments require expensive, high-tech equipment that can be made available only by a technologically progressive, economically rich society. Clearly you can't have much progress in medicine without the whole technological system and everything that goes with it.",TK,695,"['121', 'reason', 'industrial', 'society', 'cannot', 'reformed', 'favor', 'freedom', 'modern', 'technology', 'unified', 'system', 'part', 'dependent', 'one', 'another', 'cant', 'get', 'rid', 'bad', 'part', 'technology', 'retain', 'good', 'part', 'take', 'modern', 'medicine', 'example', 'progress', 'medical', 'science', 'depends', 'progress', 'chemistry', 'physic', 'biology', 'computer', 'science', 'field', 'advanced', 'medical', 'treatment', 'require', 'expensive', 'hightech', 'equipment', 'made', 'available', 'technologically', 'progressive', 'economically', 'rich', 'society', 'clearly', 'cant', 'much', 'progress', 'medicine', 'without', 'whole', 'technological', 'system', 'everything', 'go']"
1781,"158. It presumably would be impractical for all people to have electrodes inserted in their heads so that they could be controlled by the authorities. But the fact that human thoughts and feelings are so open to biological intervention shows that the problem of controlling human behavior is mainly a technical problem; a problem of neurons, hormones and complex molecules; the kind of problem that is accessible to scientific attack. Given the outstanding record of our society in solving technical problems, it is overwhelmingly probable that great advances will be made in the control of human behavior.",TK,606,"['158', 'presumably', 'would', 'impractical', 'people', 'electrode', 'inserted', 'head', 'could', 'controlled', 'authority', 'fact', 'human', 'thought', 'feeling', 'open', 'biological', 'intervention', 'show', 'problem', 'controlling', 'human', 'behavior', 'mainly', 'technical', 'problem', 'problem', 'neuron', 'hormone', 'complex', 'molecule', 'kind', 'problem', 'accessible', 'scientific', 'attack', 'given', 'outstanding', 'record', 'society', 'solving', 'technical', 'problem', 'overwhelmingly', 'probable', 'great', 'advance', 'made', 'control', 'human', 'behavior']"
1782,"82. People who have medium susceptibility to advertising and marketing techniques are able to earn enough money to satisfy their craving for goods and services, but only at the cost of serious effort (putting in overtime, taking a second job, earning promotions, etc.) Thus material acquisition serves their need for the power process. But it does not necessarily follow that their need is fully satisfied. They may have insufficient autonomy in the power process (their work may consist of following orders) and some of their drives may be frustrated (e.g., security, aggression). (We are guilty of oversimplification in paragraphs 80-82 because we have assumed that the desire for material acquisition is entirely a creation of the advertising and marketing industry. Of course it's not that simple.",TK,801,"['82', 'people', 'medium', 'susceptibility', 'advertising', 'marketing', 'technique', 'able', 'earn', 'enough', 'money', 'satisfy', 'craving', 'good', 'service', 'cost', 'serious', 'effort', 'putting', 'overtime', 'taking', 'second', 'job', 'earning', 'promotion', 'etc', 'thus', 'material', 'acquisition', 'serf', 'need', 'power', 'process', 'doe', 'necessarily', 'follow', 'need', 'fully', 'satisfied', 'may', 'insufficient', 'autonomy', 'power', 'process', 'work', 'may', 'consist', 'following', 'order', 'drive', 'may', 'frustrated', 'eg', 'security', 'aggression', 'guilty', 'oversimplification', 'paragraph', '8082', 'assumed', 'desire', 'material', 'acquisition', 'entirely', 'creation', 'advertising', 'marketing', 'industry', 'course', 'simple']"
1783,14. Feminists are desperately anxious to prove that women are as strong as capable as men. Clearly they are nagged by a fear that women may NOT be as strong and as capable as men.,TK,179,"['14', 'feminist', 'desperately', 'anxious', 'prove', 'woman', 'strong', 'capable', 'men', 'clearly', 'nagged', 'fear', 'woman', 'may', 'strong', 'capable', 'men']"
1784,"229. The leftist is oriented toward largescale collectivism. He emphasizes the duty of the individual to serve society and the duty of society to take care of the individual. He has a negative attitude toward individualism. He often takes a moralistic tone. He tends to be for gun control, for sex education and other psychologically ""enlightened"" educational methods, for planning, for affirmative action, for multiculturalism. He tends to identify with victims. He tends to be against competition and against violence, but he often finds excuses for those leftists who do commit violence. He is fond of using the common catch-phrases of the left like ""racism, "" ""sexism, "" ""homophobia, "" ""capitalism,"" ""imperialism,"" ""neocolonialism "" ""genocide,"" ""social change,"" ""social justice,"" ""social responsibility."" Maybe the best diagnostic trait of the leftist is his tendency to sympathize with the following movements: feminism, gay rights, ethnic rights, disability rights, animal rights political correctness. Anyone who strongly sympathizes with ALL of these movements is almost certainly a leftist. [36]",TK,1104,"['229', 'leftist', 'oriented', 'toward', 'largescale', 'collectivism', 'emphasizes', 'duty', 'individual', 'serve', 'society', 'duty', 'society', 'take', 'care', 'individual', 'ha', 'negative', 'attitude', 'toward', 'individualism', 'often', 'take', 'moralistic', 'tone', 'tends', 'gun', 'control', 'sex', 'education', 'psychologically', 'enlightened', 'educational', 'method', 'planning', 'affirmative', 'action', 'multiculturalism', 'tends', 'identify', 'victim', 'tends', 'competition', 'violence', 'often', 'find', 'excuse', 'leftist', 'commit', 'violence', 'fond', 'using', 'common', 'catchphrase', 'left', 'like', 'racism', '', 'sexism', '', 'homophobia', '', 'capitalism', 'imperialism', 'neocolonialism', '', 'genocide', 'social', 'change', 'social', 'justice', 'social', 'responsibility', 'maybe', 'best', 'diagnostic', 'trait', 'leftist', 'tendency', 'sympathize', 'following', 'movement', 'feminism', 'gay', 'right', 'ethnic', 'right', 'disability', 'right', 'animal', 'right', 'political', 'correctness', 'anyone', 'strongly', 'sympathizes', 'movement', 'almost', 'certainly', 'leftist', '36']"
1785,"114. As explained in paragraph 65-67, 70-73, modern man is strapped down by a network of rules and regulations, and his fate depends on the actions of persons remote from him whose decisions he cannot influence. This is not accidental or a result of the arbitrariness of arrogant bureaucrats. It is necessary and inevitable in any technologically advanced society. The system HAS TO regulate human behavior closely in order to function. At work, people have to do what they are told to do, otherwise production would be thrown into chaos. Bureaucracies HAVE TO be run according to rigid rules. To allow any substantial personal discretion to lower-level bureaucrats would disrupt the system and lead to charges of unfairness due to differences in the way individual bureaucrats exercised their discretion. It is true that some restrictions on our freedom could be eliminated, but GENERALLY SPEAKING the regulation of our lives by large organizations is necessary for the functioning of industrial-technological society. The result is a sense of powerlessness on the part of the average person. It may be, however, that formal regulations will tend increasingly to be replaced by psychological tools that make us want to do what the system requires of us. (Propaganda [14], educational techniques, ""mental health"" programs, etc.)",TK,1328,"['114', 'explained', 'paragraph', '6567', '7073', 'modern', 'man', 'strapped', 'network', 'rule', 'regulation', 'fate', 'depends', 'action', 'person', 'remote', 'whose', 'decision', 'cannot', 'influence', 'accidental', 'result', 'arbitrariness', 'arrogant', 'bureaucrat', 'necessary', 'inevitable', 'technologically', 'advanced', 'society', 'system', 'ha', 'regulate', 'human', 'behavior', 'closely', 'order', 'function', 'work', 'people', 'told', 'otherwise', 'production', 'would', 'thrown', 'chaos', 'bureaucracy', 'run', 'according', 'rigid', 'rule', 'allow', 'substantial', 'personal', 'discretion', 'lowerlevel', 'bureaucrat', 'would', 'disrupt', 'system', 'lead', 'charge', 'unfairness', 'due', 'difference', 'way', 'individual', 'bureaucrat', 'exercised', 'discretion', 'true', 'restriction', 'freedom', 'could', 'eliminated', 'generally', 'speaking', 'regulation', 'life', 'large', 'organization', 'necessary', 'functioning', 'industrialtechnological', 'society', 'result', 'sense', 'powerlessness', 'part', 'average', 'person', 'may', 'however', 'formal', 'regulation', 'tend', 'increasingly', 'replaced', 'psychological', 'tool', 'make', 'u', 'want', 'system', 'requires', 'u', 'propaganda', '14', 'educational', 'technique', 'mental', 'health', 'program', 'etc']"
1786,"144. Thus human nature has in the past put certain limits on the development of societies. People coud be pushed only so far and no farther. But today this may be changing, because modern technology is developing way of modifying human beings.",TK,243,"['144', 'thus', 'human', 'nature', 'ha', 'past', 'put', 'certain', 'limit', 'development', 'society', 'people', 'coud', 'pushed', 'far', 'farther', 'today', 'may', 'changing', 'modern', 'technology', 'developing', 'way', 'modifying', 'human']"
1787,"140. We hope we have convinced the reader that the system cannot be reformed in a such a way as to reconcile freedom with technology. The only way out is to dispense with the industrial-technological system altogether. This implies revolution, not necessarily an armed uprising, but certainly a radical and fundamental change in the nature of society.",TK,351,"['140', 'hope', 'convinced', 'reader', 'system', 'cannot', 'reformed', 'way', 'reconcile', 'freedom', 'technology', 'way', 'dispense', 'industrialtechnological', 'system', 'altogether', 'implies', 'revolution', 'necessarily', 'armed', 'uprising', 'certainly', 'radical', 'fundamental', 'change', 'nature', 'society']"
1788,"162. The system is currently engaged in a desperate struggle to overcome certain problems that threaten its survival, among which the problems of human behavior are the most important. If the system succeeds in acquiring sufficient control over human behavior quickly enough, it will probably survive. Otherwise it will break down. We think the issue will most likely be resolved within the next several decades, say 40 to 100 years.",TK,433,"['162', 'system', 'currently', 'engaged', 'desperate', 'struggle', 'overcome', 'certain', 'problem', 'threaten', 'survival', 'among', 'problem', 'human', 'behavior', 'important', 'system', 'succeeds', 'acquiring', 'sufficient', 'control', 'human', 'behavior', 'quickly', 'enough', 'probably', 'survive', 'otherwise', 'break', 'think', 'issue', 'likely', 'resolved', 'within', 'next', 'several', 'decade', 'say', '40', '100', 'year']"
1789,"119. The system does not and cannot exist to satisfy human needs. Instead, it is human behavior that has to be modified to fit the needs of the system. This has nothing to do with the political or social ideology that may pretend to guide the technological system. It is the fault of technology, because the system is guided not by ideology but by technical necessity. [18] Of course the system does satisfy many human needs, but generally speaking it does this only to the extent that it is to the advantage of the system to do it. It is the needs of the system that are paramount, not those of the human being. For example, the system provides people with food because the system couldn't function if everyone starved; it attends to people's psychological needs whenever it can CONVENIENTLY do so, because it couldn't function if too many people became depressed or rebellious. But the system, for good, solid, practical reasons, must exert constant pressure on people to mold their behavior to the needs of the system. Too much waste accumulating? The government, the media, the educational system, environmentalists, everyone inundates us with a mass of propaganda about recycling. Need more technical personnel? A chorus of voices exhorts kids to study science. No one stops to ask whether it is inhumane to force adolescents to spend the bulk of their time studying subjects most of them hate. When skilled workers are put out of a job by technical advances and have to undergo ""retraining,"" no one asks whether it is humiliating for them to be pushed around in this way. It is simply taken for granted that everyone must bow to technical necessity and for good reason: If human needs were put before technical necessity there would be economic problems, unemployment, shortages or worse. The concept of ""mental health"" in our society is defined largely by the extent to which an individual behaves in accord with the needs of the system and does so without showing signs of stress.",TK,1988,"['119', 'system', 'doe', 'cannot', 'exist', 'satisfy', 'human', 'need', 'instead', 'human', 'behavior', 'ha', 'modified', 'fit', 'need', 'system', 'ha', 'nothing', 'political', 'social', 'ideology', 'may', 'pretend', 'guide', 'technological', 'system', 'fault', 'technology', 'system', 'guided', 'ideology', 'technical', 'necessity', '18', 'course', 'system', 'doe', 'satisfy', 'many', 'human', 'need', 'generally', 'speaking', 'doe', 'extent', 'advantage', 'system', 'need', 'system', 'paramount', 'human', 'example', 'system', 'provides', 'people', 'food', 'system', 'couldnt', 'function', 'everyone', 'starved', 'attends', 'people', 'psychological', 'need', 'whenever', 'conveniently', 'couldnt', 'function', 'many', 'people', 'became', 'depressed', 'rebellious', 'system', 'good', 'solid', 'practical', 'reason', 'must', 'exert', 'constant', 'pressure', 'people', 'mold', 'behavior', 'need', 'system', 'much', 'waste', 'accumulating', 'government', 'medium', 'educational', 'system', 'environmentalist', 'everyone', 'inundates', 'u', 'mass', 'propaganda', 'recycling', 'need', 'technical', 'personnel', 'chorus', 'voice', 'exhorts', 'kid', 'study', 'science', 'one', 'stop', 'ask', 'whether', 'inhumane', 'force', 'adolescent', 'spend', 'bulk', 'time', 'studying', 'subject', 'hate', 'skilled', 'worker', 'put', 'job', 'technical', 'advance', 'undergo', 'retraining', 'one', 'asks', 'whether', 'humiliating', 'pushed', 'around', 'way', 'simply', 'taken', 'granted', 'everyone', 'must', 'bow', 'technical', 'necessity', 'good', 'reason', 'human', 'need', 'put', 'technical', 'necessity', 'would', 'economic', 'problem', 'unemployment', 'shortage', 'worse', 'concept', 'mental', 'health', 'society', 'defined', 'largely', 'extent', 'individual', 'behaves', 'accord', 'need', 'system', 'doe', 'without', 'showing', 'sign', 'stress']"
1790,"8. Even so, our conception of leftism will remain a good deal less clear than we would wish, but there doesn't seem to be any remedy for this. All we are trying to do is indicate in a rough and approximate way the two psychological tendencies that we believe are the main driving force of modern leftism. We by no means claim to be telling the WHOLE truth about leftist psychology. Also, our discussion is meant to apply to modern leftism only. We leave open the question of the extent to which our discussion could be applied to the leftists of the 19th and early 20th century.",TK,578,"['8', 'even', 'conception', 'leftism', 'remain', 'good', 'deal', 'le', 'clear', 'would', 'wish', 'doesnt', 'seem', 'remedy', 'trying', 'indicate', 'rough', 'approximate', 'way', 'two', 'psychological', 'tendency', 'believe', 'main', 'driving', 'force', 'modern', 'leftism', 'mean', 'claim', 'telling', 'whole', 'truth', 'leftist', 'psychology', 'also', 'discussion', 'meant', 'apply', 'modern', 'leftism', 'leave', 'open', 'question', 'extent', 'discussion', 'could', 'applied', 'leftist', '19th', 'early', '20th', 'century']"
1791,"204. Revolutionaries should have as many children as they can. There is strong scientific evidence that social attitudes are to a significant extent inherited. No one suggests that a social attitude is a direct outcome of a person's genetic constitution, but it appears that personality traits tend, within the context of our society, to make a person more likely to hold this or that social attitude. Objections to these findings have been raised, but objections are feeble and seem to be ideologically motivated. In any event, no one denies that children tend on the average to hold social attitudes similar to those of their parents. From our point of view it doesn't matter all that much whether the attitudes are passed on genetically or through childhood training. In either case the ARE passed on.",TK,804,"['204', 'revolutionary', 'many', 'child', 'strong', 'scientific', 'evidence', 'social', 'attitude', 'significant', 'extent', 'inherited', 'one', 'suggests', 'social', 'attitude', 'direct', 'outcome', 'person', 'genetic', 'constitution', 'appears', 'personality', 'trait', 'tend', 'within', 'context', 'society', 'make', 'person', 'likely', 'hold', 'social', 'attitude', 'objection', 'finding', 'raised', 'objection', 'feeble', 'seem', 'ideologically', 'motivated', 'event', 'one', 'denies', 'child', 'tend', 'average', 'hold', 'social', 'attitude', 'similar', 'parent', 'point', 'view', 'doesnt', 'matter', 'much', 'whether', 'attitude', 'passed', 'genetically', 'childhood', 'training', 'either', 'case', 'passed']"
1792,"123. If you think that big government interferes in your life too much NOW, just wait till the government starts regulating the genetic constitution of your children. Such regulation will inevitably follow the introduction of genetic engineering of human beings, because the consequences of unregulated genetic engineering would be disastrous. [19]",TK,348,"['123', 'think', 'big', 'government', 'interferes', 'life', 'much', 'wait', 'till', 'government', 'start', 'regulating', 'genetic', 'constitution', 'child', 'regulation', 'inevitably', 'follow', 'introduction', 'genetic', 'engineering', 'human', 'consequence', 'unregulated', 'genetic', 'engineering', 'would', 'disastrous', '19']"
1793,"26. Oversocialization can lead to low self-esteem, a sense of powerlessness, defeatism, guilt, etc. One of the most important means by which our society socializes children is by making them feel ashamed of behavior or speech that is contrary to society's expectations. If this is overdone, or if a particular child is especially susceptible to such feelings, he ends by feeling ashamed of HIMSELF. Moreover the thought and the behavior of the oversocialized person are more restricted by society's expectations than are those of the lightly socialized person. The majority of people engage in a significant amount of naughty behavior. They lie, they commit petty thefts, they break traffic laws, they goof off at work, they hate someone, they say spiteful things or they use some underhanded trick to get ahead of the other guy. The oversocialized person cannot do these things, or if he does do them he generates in himself a sense of shame and self-hatred. The oversocialized person cannot even experience, without guilt, thoughts or feelings that are contrary to the accepted morality; he cannot think ""unclean"" thoughts. And socialization is not just a matter of morality; we are socialized to confirm to many norms of behavior that do not fall under the heading of morality. Thus the oversocialized person is kept on a psychological leash and spends his life running on rails that society has laid down for him. In many oversocialized people this results in a sense of constraint and powerlessness that can be a severe hardship. We suggest that oversocialization is among the more serious cruelties that human beings inflict on one another.",TK,1646,"['26', 'oversocialization', 'lead', 'low', 'selfesteem', 'sense', 'powerlessness', 'defeatism', 'guilt', 'etc', 'one', 'important', 'mean', 'society', 'socializes', 'child', 'making', 'feel', 'ashamed', 'behavior', 'speech', 'contrary', 'society', 'expectation', 'overdone', 'particular', 'child', 'especially', 'susceptible', 'feeling', 'end', 'feeling', 'ashamed', 'moreover', 'thought', 'behavior', 'oversocialized', 'person', 'restricted', 'society', 'expectation', 'lightly', 'socialized', 'person', 'majority', 'people', 'engage', 'significant', 'amount', 'naughty', 'behavior', 'lie', 'commit', 'petty', 'theft', 'break', 'traffic', 'law', 'goof', 'work', 'hate', 'someone', 'say', 'spiteful', 'thing', 'use', 'underhanded', 'trick', 'get', 'ahead', 'guy', 'oversocialized', 'person', 'cannot', 'thing', 'doe', 'generates', 'sense', 'shame', 'selfhatred', 'oversocialized', 'person', 'cannot', 'even', 'experience', 'without', 'guilt', 'thought', 'feeling', 'contrary', 'accepted', 'morality', 'cannot', 'think', 'unclean', 'thought', 'socialization', 'matter', 'morality', 'socialized', 'confirm', 'many', 'norm', 'behavior', 'fall', 'heading', 'morality', 'thus', 'oversocialized', 'person', 'kept', 'psychological', 'leash', 'spends', 'life', 'running', 'rail', 'society', 'ha', 'laid', 'many', 'oversocialized', 'people', 'result', 'sense', 'constraint', 'powerlessness', 'severe', 'hardship', 'suggest', 'oversocialization', 'among', 'serious', 'cruelty', 'human', 'inflict', 'one', 'another']"
1794,"57. The difference, we argue, is that modern man has the sense (largely justified) that change is IMPOSED on him, whereas the 19th century frontiersman had the sense (also largely justified) that he created change himself, by his own choice. Thus a pioneer settled on a piece of land of his own choosing and made it into a farm through his own effort. In those days an entire county might have only a couple of hundred inhabitants and was a far more isolated and autonomous entity than a modern county is. Hence the pioneer farmer participated as a member of a relatively small group in the creation of a new, ordered community. One may well question whether the creation of this community was an improvement, but at any rate it satisfied the pioneer's need for the power process.",TK,780,"['57', 'difference', 'argue', 'modern', 'man', 'ha', 'sense', 'largely', 'justified', 'change', 'imposed', 'whereas', '19th', 'century', 'frontiersman', 'sense', 'also', 'largely', 'justified', 'created', 'change', 'choice', 'thus', 'pioneer', 'settled', 'piece', 'land', 'choosing', 'made', 'farm', 'effort', 'day', 'entire', 'county', 'might', 'couple', 'hundred', 'inhabitant', 'wa', 'far', 'isolated', 'autonomous', 'entity', 'modern', 'county', 'hence', 'pioneer', 'farmer', 'participated', 'member', 'relatively', 'small', 'group', 'creation', 'new', 'ordered', 'community', 'one', 'may', 'well', 'question', 'whether', 'creation', 'community', 'wa', 'improvement', 'rate', 'satisfied', 'pioneer', 'need', 'power', 'process']"
1795,"213. Because of their need for rebellion and for membership in a movement, leftists or persons of similar psychological type are often unattracted to a rebellious or activist movement whose goals and membership are not initially leftist. The resulting influx of leftish types can easily turn a non-leftist movement into a leftist one, so that leftist goals replace or distort the original goals of the movement.",TK,411,"['213', 'need', 'rebellion', 'membership', 'movement', 'leftist', 'person', 'similar', 'psychological', 'type', 'often', 'unattracted', 'rebellious', 'activist', 'movement', 'whose', 'goal', 'membership', 'initially', 'leftist', 'resulting', 'influx', 'leftish', 'type', 'easily', 'turn', 'nonleftist', 'movement', 'leftist', 'one', 'leftist', 'goal', 'replace', 'distort', 'original', 'goal', 'movement']"
1796,"68. It may be objected that primitive man is physically less secure than modern man, as is shown by his shorter life expectancy; hence modern man suffers from less, not more than the amount of insecurity that is normal for human beings. but psychological security does not closely correspond with physical security. What makes us FEEL secure is not so much objective security as a sense of confidence in our ability to take care of ourselves. Primitive man, threatened by a fierce animal or by hunger, can fight in self-defense or travel in search of food. He has no certainty of success in these efforts, but he is by no means helpless against the things that threaten him. The modern individual on the other hand is threatened by many things against which he is helpless; nuclear accidents, carcinogens in food, environmental pollution, war, increasing taxes, invasion of his privacy by large organizations, nation-wide social or economic phenomena that may disrupt his way of life.",TK,984,"['68', 'may', 'objected', 'primitive', 'man', 'physically', 'le', 'secure', 'modern', 'man', 'shown', 'shorter', 'life', 'expectancy', 'hence', 'modern', 'man', 'suffers', 'le', 'amount', 'insecurity', 'normal', 'human', 'psychological', 'security', 'doe', 'closely', 'correspond', 'physical', 'security', 'make', 'u', 'feel', 'secure', 'much', 'objective', 'security', 'sense', 'confidence', 'ability', 'take', 'care', 'primitive', 'man', 'threatened', 'fierce', 'animal', 'hunger', 'fight', 'selfdefense', 'travel', 'search', 'food', 'ha', 'certainty', 'success', 'effort', 'mean', 'helpless', 'thing', 'threaten', 'modern', 'individual', 'hand', 'threatened', 'many', 'thing', 'helpless', 'nuclear', 'accident', 'carcinogen', 'food', 'environmental', 'pollution', 'war', 'increasing', 'tax', 'invasion', 'privacy', 'large', 'organization', 'nationwide', 'social', 'economic', 'phenomenon', 'may', 'disrupt', 'way', 'life']"
1797,"214. To avoid this, a movement that exalts nature and opposes technology must take a resolutely anti-leftist stance and must avoid all collaboration with leftists. Leftism is in the long run inconsistent with wild nature, with human freedom and with the elimination of modern technology. Leftism is collectivist; it seeks to bind together the entire world (both nature and the human race) into a unified whole. But this implies management of nature and of human life by organized society, and it requires advanced technology. You can't have a united world without rapid transportation and communication, you can't make all people love one another without sophisticated psychological techniques, you can't have a ""planned society"" without the necessary technological base. Above all, leftism is driven by the need for power, and the leftist seeks power on a collective basis, through identification with a mass movement or an organization. Leftism is unlikely ever to give up technology, because technology is too valuable a source of collective power.",TK,1051,"['214', 'avoid', 'movement', 'exalts', 'nature', 'opposes', 'technology', 'must', 'take', 'resolutely', 'antileftist', 'stance', 'must', 'avoid', 'collaboration', 'leftist', 'leftism', 'long', 'run', 'inconsistent', 'wild', 'nature', 'human', 'freedom', 'elimination', 'modern', 'technology', 'leftism', 'collectivist', 'seek', 'bind', 'together', 'entire', 'world', 'nature', 'human', 'race', 'unified', 'whole', 'implies', 'management', 'nature', 'human', 'life', 'organized', 'society', 'requires', 'advanced', 'technology', 'cant', 'united', 'world', 'without', 'rapid', 'transportation', 'communication', 'cant', 'make', 'people', 'love', 'one', 'another', 'without', 'sophisticated', 'psychological', 'technique', 'cant', 'planned', 'society', 'without', 'necessary', 'technological', 'base', 'leftism', 'driven', 'need', 'power', 'leftist', 'seek', 'power', 'collective', 'basis', 'identification', 'mass', 'movement', 'organization', 'leftism', 'unlikely', 'ever', 'give', 'technology', 'technology', 'valuable', 'source', 'collective', 'power']"
1798,"30. We certainly do not claim that leftists, even of the oversocialized type, NEVER rebel against the fundamental values of our society. Clearly they sometimes do. Some oversocialized leftists have gone so far as to rebel against one of modern society's most important principles by engaging in physical violence. By their own account, violence is for them a form of ""liberation."" In other words, by committing violence they break through the psychological restraints that have been trained into them. Because they are oversocialized these restraints have been more confining for them than for others; hence their need to break free of them. But they usually justify their rebellion in terms of mainstream values. If they engage in violence they claim to be fighting against racism or the like.",TK,794,"['30', 'certainly', 'claim', 'leftist', 'even', 'oversocialized', 'type', 'never', 'rebel', 'fundamental', 'value', 'society', 'clearly', 'sometimes', 'oversocialized', 'leftist', 'gone', 'far', 'rebel', 'one', 'modern', 'society', 'important', 'principle', 'engaging', 'physical', 'violence', 'account', 'violence', 'form', 'liberation', 'word', 'committing', 'violence', 'break', 'psychological', 'restraint', 'trained', 'oversocialized', 'restraint', 'confining', 'others', 'hence', 'need', 'break', 'free', 'usually', 'justify', 'rebellion', 'term', 'mainstream', 'value', 'engage', 'violence', 'claim', 'fighting', 'racism', 'like']"
1799,"154. Suppose a biological trait is discovered that increases the likelihood that a child will grow up to be a criminal and suppose some sort of gene therapy can remove this trait. [29] Of course most parents whose children possess the trait will have them undergo the therapy. It would be inhumane to do otherwise, since the child would probably have a miserable life if he grew up to be a criminal. But many or most primitive societies have a low crime rate in comparison with that of our society, even though they have neither high-tech methods of child-rearing nor harsh systems of punishment. Since there is no reason to suppose that more modern men than primitive men have innate predatory tendencies, the high crime rate of our society must be due to the pressures that modern conditions put on people, to which many cannot or will not adjust. Thus a treatment designed to remove potential criminal tendencies is at least in part a way of re-engineering people so that they suit the requirements of the system.",TK,1016,"['154', 'suppose', 'biological', 'trait', 'discovered', 'increase', 'likelihood', 'child', 'grow', 'criminal', 'suppose', 'sort', 'gene', 'therapy', 'remove', 'trait', '29', 'course', 'parent', 'whose', 'child', 'posse', 'trait', 'undergo', 'therapy', 'would', 'inhumane', 'otherwise', 'since', 'child', 'would', 'probably', 'miserable', 'life', 'grew', 'criminal', 'many', 'primitive', 'society', 'low', 'crime', 'rate', 'comparison', 'society', 'even', 'though', 'neither', 'hightech', 'method', 'childrearing', 'harsh', 'system', 'punishment', 'since', 'reason', 'suppose', 'modern', 'men', 'primitive', 'men', 'innate', 'predatory', 'tendency', 'high', 'crime', 'rate', 'society', 'must', 'due', 'pressure', 'modern', 'condition', 'put', 'people', 'many', 'cannot', 'adjust', 'thus', 'treatment', 'designed', 'remove', 'potential', 'criminal', 'tendency', 'least', 'part', 'way', 'reengineering', 'people', 'suit', 'requirement', 'system']"
1800,"94. By ""freedom"" we mean the opportunity to go through the power process, with real goals not the artificial goals of surrogate activities, and without interference, manipulation or supervision from anyone, especially from any large organization. Freedom means being in control (either as an individual or as a member of a SMALL group) of the life-and-death issues of one's existence; food, clothing, shelter and defense against whatever threats there may be in one's environment. Freedom means having power; not the power to control other people but the power to control the circumstances of one's own life. One does not have freedom if anyone else (especially a large organization) has power over one, no matter how benevolently, tolerantly and permissively that power may be exercised. It is important not to confuse freedom with mere permissiveness (see paragraph 72).",TK,872,"['94', 'freedom', 'mean', 'opportunity', 'go', 'power', 'process', 'real', 'goal', 'artificial', 'goal', 'surrogate', 'activity', 'without', 'interference', 'manipulation', 'supervision', 'anyone', 'especially', 'large', 'organization', 'freedom', 'mean', 'control', 'either', 'individual', 'member', 'small', 'group', 'lifeanddeath', 'issue', 'one', 'existence', 'food', 'clothing', 'shelter', 'defense', 'whatever', 'threat', 'may', 'one', 'environment', 'freedom', 'mean', 'power', 'power', 'control', 'people', 'power', 'control', 'circumstance', 'one', 'life', 'one', 'doe', 'freedom', 'anyone', 'else', 'especially', 'large', 'organization', 'ha', 'power', 'one', 'matter', 'benevolently', 'tolerantly', 'permissively', 'power', 'may', 'exercised', 'important', 'confuse', 'freedom', 'mere', 'permissiveness', 'see', 'paragraph', '72']"
1801,"80. People vary in their susceptibility to advertising and marketing techniques. Some people are so susceptible that, even if they make a great deal of money, they cannot satisfy their constant craving for the shiny new toys that the marketing industry dangles before their eyes. So they always feel hard-pressed financially even if their income is large, and their cravings are frustrated.",TK,390,"['80', 'people', 'vary', 'susceptibility', 'advertising', 'marketing', 'technique', 'people', 'susceptible', 'even', 'make', 'great', 'deal', 'money', 'cannot', 'satisfy', 'constant', 'craving', 'shiny', 'new', 'toy', 'marketing', 'industry', 'dangles', 'eye', 'always', 'feel', 'hardpressed', 'financially', 'even', 'income', 'large', 'craving', 'frustrated']"
1802,"67. Thus the power process is disrupted in our society through a deficiency of real goals and a deficiency of autonomy in pursuit of goals. But it is also disrupted because of those human drives that fall into group 3: the drives that one cannot adequately satisfy no matter how much effort one makes. One of these drives is the need for security. Our lives depend on decisions made by other people; we have no control over these decisions and usually we do not even know the people who make them. (""We live in a world in which relatively few people - maybe 500 or 1,00 - make the important decisions"" - Philip B. Heymann of Harvard Law School, quoted by Anthony Lewis, New York Times, April 21, 1995.) Our lives depend on whether safety standards at a nuclear power plant are properly maintained; on how much pesticide is allowed to get into our food or how much pollution into our air; on how skillful (or incompetent) our doctor is; whether we lose or get a job may depend on decisions made by government economists or corporation executives; and so forth. Most individuals are not in a position to secure themselves against these threats to more [than] a very limited extent. The individual's search for security is therefore frustrated, which leads to a sense of powerlessness.",TK,1282,"['67', 'thus', 'power', 'process', 'disrupted', 'society', 'deficiency', 'real', 'goal', 'deficiency', 'autonomy', 'pursuit', 'goal', 'also', 'disrupted', 'human', 'drive', 'fall', 'group', '3', 'drive', 'one', 'cannot', 'adequately', 'satisfy', 'matter', 'much', 'effort', 'one', 'make', 'one', 'drive', 'need', 'security', 'life', 'depend', 'decision', 'made', 'people', 'control', 'decision', 'usually', 'even', 'know', 'people', 'make', 'live', 'world', 'relatively', 'people', '', 'maybe', '500', '100', '', 'make', 'important', 'decision', '', 'philip', 'b', 'heymann', 'harvard', 'law', 'school', 'quoted', 'anthony', 'lewis', 'new', 'york', 'time', 'april', '21', '1995', 'life', 'depend', 'whether', 'safety', 'standard', 'nuclear', 'power', 'plant', 'properly', 'maintained', 'much', 'pesticide', 'allowed', 'get', 'food', 'much', 'pollution', 'air', 'skillful', 'incompetent', 'doctor', 'whether', 'lose', 'get', 'job', 'may', 'depend', 'decision', 'made', 'government', 'economist', 'corporation', 'executive', 'forth', 'individual', 'position', 'secure', 'threat', 'limited', 'extent', 'individual', 'search', 'security', 'therefore', 'frustrated', 'lead', 'sense', 'powerlessness']"
1803,"53. Crowding, rapid change and the breakdown of communities have been widely recognized as sources of social problems. but we do not believe they are enough to account for the extent of the problems that are seen today.",TK,219,"['53', 'crowding', 'rapid', 'change', 'breakdown', 'community', 'widely', 'recognized', 'source', 'social', 'problem', 'believe', 'enough', 'account', 'extent', 'problem', 'seen', 'today']"
1804,"89. The same is true of scientists generally. With possible rare exceptions, their motive is neither curiosity nor a desire to benefit humanity but the need to go through the power process: to have a goal (a scientific problem to solve), to make an effort (research) and to attain the goal (solution of the problem.) Science is a surrogate activity because scientists work mainly for the fulfillment they get out of the work itself.",TK,432,"['89', 'true', 'scientist', 'generally', 'possible', 'rare', 'exception', 'motive', 'neither', 'curiosity', 'desire', 'benefit', 'humanity', 'need', 'go', 'power', 'process', 'goal', 'scientific', 'problem', 'solve', 'make', 'effort', 'research', 'attain', 'goal', 'solution', 'problem', 'science', 'surrogate', 'activity', 'scientist', 'work', 'mainly', 'fulfillment', 'get', 'work']"
1805,"208. We distinguish between two kinds of technology, which we will call small-scale technology and organization-dependent technology. Small-scale technology is technology that can be used by small-scale communities without outside assistance. Organization-dependent technology is technology that depends on large-scale social organization. We are aware of no significant cases of regression in small-scale technology. But organization-dependent technology DOES regress when the social organization on which it depends breaks down. Example: When the Roman Empire fell apart the Romans' small-scale technology survived because any clever village craftsman could build, for instance, a water wheel, any skilled smith could make steel by Roman methods, and so forth. But the Romans' organization-dependent technology DID regress. Their aqueducts fell into disrepair and were never rebuilt. Their techniques of road construction were lost. The Roman system of urban sanitation was forgotten, so that until rather recent times did the sanitation of European cities that of Ancient Rome.",TK,1080,"['208', 'distinguish', 'two', 'kind', 'technology', 'call', 'smallscale', 'technology', 'organizationdependent', 'technology', 'smallscale', 'technology', 'technology', 'used', 'smallscale', 'community', 'without', 'outside', 'assistance', 'organizationdependent', 'technology', 'technology', 'depends', 'largescale', 'social', 'organization', 'aware', 'significant', 'case', 'regression', 'smallscale', 'technology', 'organizationdependent', 'technology', 'doe', 'regress', 'social', 'organization', 'depends', 'break', 'example', 'roman', 'empire', 'fell', 'apart', 'roman', 'smallscale', 'technology', 'survived', 'clever', 'village', 'craftsman', 'could', 'build', 'instance', 'water', 'wheel', 'skilled', 'smith', 'could', 'make', 'steel', 'roman', 'method', 'forth', 'roman', 'organizationdependent', 'technology', 'regress', 'aqueduct', 'fell', 'disrepair', 'never', 'rebuilt', 'technique', 'road', 'construction', 'lost', 'roman', 'system', 'urban', 'sanitation', 'wa', 'forgotten', 'rather', 'recent', 'time', 'sanitation', 'european', 'city', 'ancient', 'rome']"
1806,"24. Psychologists use the term ""socialization"" to designate the process by which children are trained to think and act as society demands. A person is said to be well socialized if he believes in and obeys the moral code of his society and fits in well as a functioning part of that society. It may seem senseless to say that many leftists are over-socialized, since the leftist is perceived as a rebel. Nevertheless, the position can be defended. Many leftists are not such rebels as they seem.",TK,495,"['24', 'psychologist', 'use', 'term', 'socialization', 'designate', 'process', 'child', 'trained', 'think', 'act', 'society', 'demand', 'person', 'said', 'well', 'socialized', 'belief', 'obeys', 'moral', 'code', 'society', 'fit', 'well', 'functioning', 'part', 'society', 'may', 'seem', 'senseless', 'say', 'many', 'leftist', 'oversocialized', 'since', 'leftist', 'perceived', 'rebel', 'nevertheless', 'position', 'defended', 'many', 'leftist', 'rebel', 'seem']"
1807,"45. Any of the foregoing symptoms can occur in any society, but in modern industrial society they are present on a massive scale. We aren't the first to mention that the world today seems to be going crazy. This sort of thing is not normal for human societies. There is good reason to believe that primitive man suffered from less stress and frustration and was better satisfied with his way of life than modern man is. It is true that not all was sweetness and light in primitive societies. Abuse of women and common among the Australian aborigines, transexuality was fairly common among some of the American Indian tribes. But is does appear that GENERALLY SPEAKING the kinds of problems that we have listed in the preceding paragraph were far less common among primitive peoples than they are in modern society.",TK,814,"['45', 'foregoing', 'symptom', 'occur', 'society', 'modern', 'industrial', 'society', 'present', 'massive', 'scale', 'arent', 'first', 'mention', 'world', 'today', 'seems', 'going', 'crazy', 'sort', 'thing', 'normal', 'human', 'society', 'good', 'reason', 'believe', 'primitive', 'man', 'suffered', 'le', 'stress', 'frustration', 'wa', 'better', 'satisfied', 'way', 'life', 'modern', 'man', 'true', 'wa', 'sweetness', 'light', 'primitive', 'society', 'abuse', 'woman', 'common', 'among', 'australian', 'aborigine', 'transexuality', 'wa', 'fairly', 'common', 'among', 'american', 'indian', 'tribe', 'doe', 'appear', 'generally', 'speaking', 'kind', 'problem', 'listed', 'preceding', 'paragraph', 'far', 'le', 'common', 'among', 'primitive', 'people', 'modern', 'society']"
1808,"85. In this section we have explained how many people in modern society do satisfy their need for the power process to a greater or lesser extent. But we think that for the majority of people the need for the power process is not fully satisfied. In the first place, those who have an insatiable drive for status, or who get firmly ""hooked"" or a surrogate activity, or who identify strongly enough with a movement or organization to satisfy their need for power in that way, are exceptional personalities. Others are not fully satisfied with surrogate activities or by identification with an organization (see paragraphs 41, 64). In the second place, too much control is imposed by the system through explicit regulation or through socialization, which results in a deficiency of autonomy, and in frustration due to the impossibility of attaining certain goals and the necessity of restraining too many impulses.",TK,912,"['85', 'section', 'explained', 'many', 'people', 'modern', 'society', 'satisfy', 'need', 'power', 'process', 'greater', 'lesser', 'extent', 'think', 'majority', 'people', 'need', 'power', 'process', 'fully', 'satisfied', 'first', 'place', 'insatiable', 'drive', 'status', 'get', 'firmly', 'hooked', 'surrogate', 'activity', 'identify', 'strongly', 'enough', 'movement', 'organization', 'satisfy', 'need', 'power', 'way', 'exceptional', 'personality', 'others', 'fully', 'satisfied', 'surrogate', 'activity', 'identification', 'organization', 'see', 'paragraph', '41', '64', 'second', 'place', 'much', 'control', 'imposed', 'system', 'explicit', 'regulation', 'socialization', 'result', 'deficiency', 'autonomy', 'frustration', 'due', 'impossibility', 'attaining', 'certain', 'goal', 'necessity', 'restraining', 'many', 'impulse']"
1809,"88. The ""benefit of humanity"" explanation doesn't work any better. Some scientific work has no conceivable relation to the welfare of the human race - most of archaeology or comparative linguistics for example. Some other areas of science present obviously dangerous possibilities. Yet scientists in these areas are just as enthusiastic about their work as those who develop vaccines or study air pollution. Consider the case of Dr. Edward Teller, who had an obvious emotional involvement in promoting nuclear power plants. Did this involvement stem from a desire to benefit humanity? If so, then why didn't Dr. Teller get emotional about other ""humanitarian"" causes? If he was such a humanitarian then why did he help to develop the H-bomb? As with many other scientific achievements, it is very much open to question whether nuclear power plants actually do benefit humanity. Does the cheap electricity outweigh the accumulating waste and risk of accidents? Dr. Teller saw only one side of the question. Clearly his emotional involvement with nuclear power arose not from a desire to ""benefit humanity"" but from a personal fulfillment he got from his work and from seeing it put to practical use.",TK,1198,"['88', 'benefit', 'humanity', 'explanation', 'doesnt', 'work', 'better', 'scientific', 'work', 'ha', 'conceivable', 'relation', 'welfare', 'human', 'race', '', 'archaeology', 'comparative', 'linguistics', 'example', 'area', 'science', 'present', 'obviously', 'dangerous', 'possibility', 'yet', 'scientist', 'area', 'enthusiastic', 'work', 'develop', 'vaccine', 'study', 'air', 'pollution', 'consider', 'case', 'dr', 'edward', 'teller', 'obvious', 'emotional', 'involvement', 'promoting', 'nuclear', 'power', 'plant', 'involvement', 'stem', 'desire', 'benefit', 'humanity', 'didnt', 'dr', 'teller', 'get', 'emotional', 'humanitarian', 'cause', 'wa', 'humanitarian', 'help', 'develop', 'hbomb', 'many', 'scientific', 'achievement', 'much', 'open', 'question', 'whether', 'nuclear', 'power', 'plant', 'actually', 'benefit', 'humanity', 'doe', 'cheap', 'electricity', 'outweigh', 'accumulating', 'waste', 'risk', 'accident', 'dr', 'teller', 'saw', 'one', 'side', 'question', 'clearly', 'emotional', 'involvement', 'nuclear', 'power', 'arose', 'desire', 'benefit', 'humanity', 'personal', 'fulfillment', 'got', 'work', 'seeing', 'put', 'practical', 'use']"
1810,"176. Once can envision scenarios that incorporate aspects of more than one of the possibilities that we have just discussed. For instance, it may be that machines will take over most of the work that is of real, practical importance, but that human beings will be kept busy by being given relatively unimportant work. It has been suggested, for example, that a great development of the service of industries might provide work for human beings. Thus people will would spend their time shinning each others shoes, driving each other around inn taxicab, making handicrafts for one another, waiting on each other's tables, etc. This seems to us a thoroughly contemptible way for the human race to end up, and we doubt that many people would find fulfilling lives in such pointless busy-work. They would seek other, dangerous outlets (drugs, , crime, ""cults,"" hate groups) unless they were biological or psychologically engineered to adapt them to such a way of life.",TK,963,"['176', 'envision', 'scenario', 'incorporate', 'aspect', 'one', 'possibility', 'discussed', 'instance', 'may', 'machine', 'take', 'work', 'real', 'practical', 'importance', 'human', 'kept', 'busy', 'given', 'relatively', 'unimportant', 'work', 'ha', 'suggested', 'example', 'great', 'development', 'service', 'industry', 'might', 'provide', 'work', 'human', 'thus', 'people', 'would', 'spend', 'time', 'shinning', 'others', 'shoe', 'driving', 'around', 'inn', 'taxicab', 'making', 'handicraft', 'one', 'another', 'waiting', 'others', 'table', 'etc', 'seems', 'u', 'thoroughly', 'contemptible', 'way', 'human', 'race', 'end', 'doubt', 'many', 'people', 'would', 'find', 'fulfilling', 'life', 'pointless', 'busywork', 'would', 'seek', 'dangerous', 'outlet', 'drug', '', 'crime', 'cult', 'hate', 'group', 'unless', 'biological', 'psychologically', 'engineered', 'adapt', 'way', 'life']"
1811,"69. It is true that primitive man is powerless against some of the things that threaten him; disease for example. But he can accept the risk of disease stoically. It is part of the nature of things, it is no one's fault, unless is the fault of some imaginary, impersonal demon. But threats to the modern individual tend to be MAN-MADE. They are not the results of chance but are IMPOSED on him by other persons whose decisions he, as an individual, is unable to influence. Consequently he feels frustrated, humiliated and angry.",TK,528,"['69', 'true', 'primitive', 'man', 'powerless', 'thing', 'threaten', 'disease', 'example', 'accept', 'risk', 'disease', 'stoically', 'part', 'nature', 'thing', 'one', 'fault', 'unless', 'fault', 'imaginary', 'impersonal', 'demon', 'threat', 'modern', 'individual', 'tend', 'manmade', 'result', 'chance', 'imposed', 'person', 'whose', 'decision', 'individual', 'unable', 'influence', 'consequently', 'feel', 'frustrated', 'humiliated', 'angry']"
1812,"93. We are going to argue that industrial-technological society cannot be reformed in such a way as to prevent it from progressively narrowing the sphere of human freedom. But because ""freedom"" is a word that can be interpreted in many ways, we must first make clear what kind of freedom we are concerned with.",TK,310,"['93', 'going', 'argue', 'industrialtechnological', 'society', 'cannot', 'reformed', 'way', 'prevent', 'progressively', 'narrowing', 'sphere', 'human', 'freedom', 'freedom', 'word', 'interpreted', 'many', 'way', 'must', 'first', 'make', 'clear', 'kind', 'freedom', 'concerned']"
1813,"193. The kind of revolution we have in mind will not necessarily involve an armed uprising against any government. It may or may not involve physical violence, but it will not be a POLITICAL revolution. Its focus will be on technology and economics, not politics. [32]",TK,268,"['193', 'kind', 'revolution', 'mind', 'necessarily', 'involve', 'armed', 'uprising', 'government', 'may', 'may', 'involve', 'physical', 'violence', 'political', 'revolution', 'focus', 'technology', 'economics', 'politics', '32']"
1814,"42. Autonomy as a part of the power process may not be necessary for every individual. But most people need a greater or lesser degree of autonomy in working toward their goals. Their efforts must be undertaken on their own initiative and must be under their own direction and control. Yet most people do not have to exert this initiative, direction and control as single individuals. It is usually enough to act as a member of a SMALL group. Thus if half a dozen people discuss a goal among themselves and make a successful joint effort to attain that goal, their need for the power process will be served. But if they work under rigid orders handed down from above that leave them no room for autonomous decision and initiative, then their need for the power process will not be served. The same is true when decisions are made on a collective bases if the group making the collective decision is so large that the role of each individual is insignificant [5]",TK,961,"['42', 'autonomy', 'part', 'power', 'process', 'may', 'necessary', 'every', 'individual', 'people', 'need', 'greater', 'lesser', 'degree', 'autonomy', 'working', 'toward', 'goal', 'effort', 'must', 'undertaken', 'initiative', 'must', 'direction', 'control', 'yet', 'people', 'exert', 'initiative', 'direction', 'control', 'single', 'individual', 'usually', 'enough', 'act', 'member', 'small', 'group', 'thus', 'half', 'dozen', 'people', 'discus', 'goal', 'among', 'make', 'successful', 'joint', 'effort', 'attain', 'goal', 'need', 'power', 'process', 'served', 'work', 'rigid', 'order', 'handed', 'leave', 'room', 'autonomous', 'decision', 'initiative', 'need', 'power', 'process', 'served', 'true', 'decision', 'made', 'collective', 'base', 'group', 'making', 'collective', 'decision', 'large', 'role', 'individual', 'insignificant', '5']"
1815,"216. Some leftists may seem to oppose technology, but they will oppose it only so long as they are outsiders and the technological system is controlled by non-leftists. If leftism ever becomes dominant in society, so that the technological system becomes a tool in the hands of leftists, they will enthusiastically use it and promote its growth. In doing this they will be repeating a pattern that leftism has shown again and again in the past. When the Bolsheviks in Russia were outsiders, they vigorously opposed censorship and the secret police, they advocated self-determination for ethnic minorities, and so forth; but as soon as they came into power themselves, they imposed a tighter censorship and created a more ruthless secret police than any that had existed under the tsars, and they oppressed ethnic minorities at least as much as the tsars had done. In the United States, a couple of decades ago when leftists were a minority in our universities, leftist professors were vigorous proponents of academic freedom, but today, in those universities where leftists have become dominant, they have shown themselves ready to take away from everyone else's academic freedom. (This is ""political correctness."") The same will happen with leftists and technology: They will use it to oppress everyone else if they ever get it under their own control.",TK,1353,"['216', 'leftist', 'may', 'seem', 'oppose', 'technology', 'oppose', 'long', 'outsider', 'technological', 'system', 'controlled', 'nonleftists', 'leftism', 'ever', 'becomes', 'dominant', 'society', 'technological', 'system', 'becomes', 'tool', 'hand', 'leftist', 'enthusiastically', 'use', 'promote', 'growth', 'repeating', 'pattern', 'leftism', 'ha', 'shown', 'past', 'bolshevik', 'russia', 'outsider', 'vigorously', 'opposed', 'censorship', 'secret', 'police', 'advocated', 'selfdetermination', 'ethnic', 'minority', 'forth', 'soon', 'came', 'power', 'imposed', 'tighter', 'censorship', 'created', 'ruthless', 'secret', 'police', 'existed', 'tsar', 'oppressed', 'ethnic', 'minority', 'least', 'much', 'tsar', 'done', 'united', 'state', 'couple', 'decade', 'ago', 'leftist', 'minority', 'university', 'leftist', 'professor', 'vigorous', 'proponent', 'academic', 'freedom', 'today', 'university', 'leftist', 'become', 'dominant', 'shown', 'ready', 'take', 'away', 'everyone', 'el', 'academic', 'freedom', 'political', 'correctness', 'happen', 'leftist', 'technology', 'use', 'oppress', 'everyone', 'else', 'ever', 'get', 'control']"
1816,"72. Modern society is in certain respects extremely permissive. In matters that are irrelevant to the functioning of the system we can generally do what we please. We can believe in any religion we like (as long as it does not encourage behavior that is dangerous to the system). We can go to bed with anyone we like (as long as we practice ""safe sex""). We can do anything we like as long as it is UNIMPORTANT. But in all IMPORTANT matters the system tends increasingly to regulate our behavior.",TK,495,"['72', 'modern', 'society', 'certain', 'respect', 'extremely', 'permissive', 'matter', 'irrelevant', 'functioning', 'system', 'generally', 'please', 'believe', 'religion', 'like', 'long', 'doe', 'encourage', 'behavior', 'dangerous', 'system', 'go', 'bed', 'anyone', 'like', 'long', 'practice', 'safe', 'sex', 'anything', 'like', 'long', 'unimportant', 'important', 'matter', 'system', 'tends', 'increasingly', 'regulate', 'behavior']"
1817,77. Not everyone in industrial-technological society suffers from psychological problems. Some people even profess to be quite satisfied with society as it is. We now discuss some of the reasons why people differ so greatly in their response to modern society.,TK,260,"['77', 'everyone', 'industrialtechnological', 'society', 'suffers', 'psychological', 'problem', 'people', 'even', 'profess', 'quite', 'satisfied', 'society', 'discus', 'reason', 'people', 'differ', 'greatly', 'response', 'modern', 'society']"
1818,"218. Various thinkers have pointed out that leftism is a kind of religion. Leftism is not a religion in the strict sense because leftist doctrine does not postulate the existence of any supernatural being. But for the leftist, leftism plays a psychological role much like that which religion plays for some people. The leftist NEEDS to believe in leftism; it plays a vital role in his psychological economy. His beliefs are not easily modified by logic or facts. He has a deep conviction that leftism is morally Right with a capital R, and that he has not only a right but a duty to impose leftist morality on everyone. (However, many of the people we are referring to as ""leftists"" do not think of themselves as leftists and would not describe their system of beliefs as leftism. We use the term ""leftism"" because we don't know of any better words to designate the spectrum of related creeds that includes the feminist, gay rights, political correctness, etc., movements, and because these movements have a strong affinity with the old left. See paragraphs 227-230.)",TK,1067,"['218', 'various', 'thinker', 'pointed', 'leftism', 'kind', 'religion', 'leftism', 'religion', 'strict', 'sense', 'leftist', 'doctrine', 'doe', 'postulate', 'existence', 'supernatural', 'leftist', 'leftism', 'play', 'psychological', 'role', 'much', 'like', 'religion', 'play', 'people', 'leftist', 'need', 'believe', 'leftism', 'play', 'vital', 'role', 'psychological', 'economy', 'belief', 'easily', 'modified', 'logic', 'fact', 'ha', 'deep', 'conviction', 'leftism', 'morally', 'right', 'capital', 'r', 'ha', 'right', 'duty', 'impose', 'leftist', 'morality', 'everyone', 'however', 'many', 'people', 'referring', 'leftist', 'think', 'leftist', 'would', 'describe', 'system', 'belief', 'leftism', 'use', 'term', 'leftism', 'dont', 'know', 'better', 'word', 'designate', 'spectrum', 'related', 'creed', 'includes', 'feminist', 'gay', 'right', 'political', 'correctness', 'etc', 'movement', 'movement', 'strong', 'affinity', 'old', 'left', 'see', 'paragraph', '227230']"
1819,"3. If the system breaks down the consequences will still be very painful. But the bigger the system grows the more disastrous the results of its breakdown will be, so if it is to break down it had best break down sooner rather than later.",TK,238,"['3', 'system', 'break', 'consequence', 'still', 'painful', 'bigger', 'system', 'grows', 'disastrous', 'result', 'breakdown', 'break', 'best', 'break', 'sooner', 'rather', 'later']"
1820,"52. Suppose that a public official or a corporation executive appoints his cousin, his friend or his co-religionist to a position rather than appointing the person best qualified for the job. He has permitted personal loyalty to supersede his loyalty to the system, and that is ""nepotism"" or ""discrimination,"" both of which are terrible sins in modern society. Would-be industrial societies that have done a poor job of subordinating personal or local loyalties to loyalty to the system are usually very inefficient. (Look at Latin America.) Thus an advanced industrial society can tolerate only those small-scale communities that are emasculated, tamed and made into tools of the system. [7]",TK,692,"['52', 'suppose', 'public', 'official', 'corporation', 'executive', 'appoints', 'cousin', 'friend', 'coreligionist', 'position', 'rather', 'appointing', 'person', 'best', 'qualified', 'job', 'ha', 'permitted', 'personal', 'loyalty', 'supersede', 'loyalty', 'system', 'nepotism', 'discrimination', 'terrible', 'sin', 'modern', 'society', 'wouldbe', 'industrial', 'society', 'done', 'poor', 'job', 'subordinating', 'personal', 'local', 'loyalty', 'loyalty', 'system', 'usually', 'inefficient', 'look', 'latin', 'america', 'thus', 'advanced', 'industrial', 'society', 'tolerate', 'smallscale', 'community', 'emasculated', 'tamed', 'made', 'tool', 'system', '7']"
1821,"172. First let us postulate that the computer scientists succeed in developing intelligent machines that can do all things better that human beings can do them. In that case presumably all work will be done by vast, highly organized systems of machines and no human effort will be necessary. Either of two cases might occur. The machines might be permitted to make all of their own decisions without human oversight, or else human control over the machines might be retained.",TK,475,"['172', 'first', 'let', 'u', 'postulate', 'computer', 'scientist', 'succeed', 'developing', 'intelligent', 'machine', 'thing', 'better', 'human', 'case', 'presumably', 'work', 'done', 'vast', 'highly', 'organized', 'system', 'machine', 'human', 'effort', 'necessary', 'either', 'two', 'case', 'might', 'occur', 'machine', 'might', 'permitted', 'make', 'decision', 'without', 'human', 'oversight', 'else', 'human', 'control', 'machine', 'might', 'retained']"
1822,"138. Thus it is clear that the human race has at best a very limited capacity for solving even relatively straightforward social problems. How then is it going to solve the far more difficult and subtle problem of reconciling freedom with technology? Technology presents clear-cut material advantages, whereas freedom is an abstraction that means different things to different people, and its loss is easily obscured by propaganda and fancy talk.",TK,446,"['138', 'thus', 'clear', 'human', 'race', 'ha', 'best', 'limited', 'capacity', 'solving', 'even', 'relatively', 'straightforward', 'social', 'problem', 'going', 'solve', 'far', 'difficult', 'subtle', 'problem', 'reconciling', 'freedom', 'technology', 'technology', 'present', 'clearcut', 'material', 'advantage', 'whereas', 'freedom', 'abstraction', 'mean', 'different', 'thing', 'different', 'people', 'loss', 'easily', 'obscured', 'propaganda', 'fancy', 'talk']"
1823,"230. The more dangerous leftists, that is, those who are most power-hungry, are often characterized by arrogance or by a dogmatic approach to ideology. However, the most dangerous leftists of all may be certain oversocialized types who avoid irritating displays of aggressiveness and refrain from advertising their leftism, but work quietly and unobtrusively to promote collectivist values, ""enlightened"" psychological techniques for socializing children, dependence of the individual on the system, and so forth. These crypto-leftists (as we may call them) approximate certain bourgeois types as far as practical action is concerned, but differ from them in psychology, ideology and motivation. The ordinary bourgeois tries to bring people under control of the system in order to protect his way of life, or he does so simply because his attitudes are conventional. The crypto-leftist tries to bring people under control of the system because he is a True Believer in a collectivistic ideology. The crypto-leftist is differentiated from the average leftist of the oversocialized type by the fact that his rebellious impulse is weaker and he is more securely socialized. He is differentiated from the ordinary well-socialized bourgeois by the fact that there is some deep lack within him that makes it necessary for him to devote himself to a cause and immerse himself in a collectivity. And maybe his (well-sublimated) drive for power is stronger than that of the average bourgeois.",TK,1483,"['230', 'dangerous', 'leftist', 'powerhungry', 'often', 'characterized', 'arrogance', 'dogmatic', 'approach', 'ideology', 'however', 'dangerous', 'leftist', 'may', 'certain', 'oversocialized', 'type', 'avoid', 'irritating', 'display', 'aggressiveness', 'refrain', 'advertising', 'leftism', 'work', 'quietly', 'unobtrusively', 'promote', 'collectivist', 'value', 'enlightened', 'psychological', 'technique', 'socializing', 'child', 'dependence', 'individual', 'system', 'forth', 'cryptoleftists', 'may', 'call', 'approximate', 'certain', 'bourgeois', 'type', 'far', 'practical', 'action', 'concerned', 'differ', 'psychology', 'ideology', 'motivation', 'ordinary', 'bourgeois', 'try', 'bring', 'people', 'control', 'system', 'order', 'protect', 'way', 'life', 'doe', 'simply', 'attitude', 'conventional', 'cryptoleftist', 'try', 'bring', 'people', 'control', 'system', 'true', 'believer', 'collectivistic', 'ideology', 'cryptoleftist', 'differentiated', 'average', 'leftist', 'oversocialized', 'type', 'fact', 'rebellious', 'impulse', 'weaker', 'securely', 'socialized', 'differentiated', 'ordinary', 'wellsocialized', 'bourgeois', 'fact', 'deep', 'lack', 'within', 'make', 'necessary', 'devote', 'cause', 'immerse', 'collectivity', 'maybe', 'wellsublimated', 'drive', 'power', 'stronger', 'average', 'bourgeois']"
1824,"87. Science and technology provide the most important examples of surrogate activities. Some scientists claim that they are motivated by ""curiosity,"" that notion is simply absurd. Most scientists work on highly specialized problem that are not the object of any normal curiosity. For example, is an astronomer, a mathematician or an entomologist curious about the properties of isopropyltrimethylmethane? Of course not. Only a chemist is curious about such a thing, and he is curious about it only because chemistry is his surrogate activity. Is the chemist curious about the appropriate classification of a new species of beetle? No. That question is of interest only to the entomologist, and he is interested in it only because entomology is his surrogate activity. If the chemist and the entomologist had to exert themselves seriously to obtain the physical necessities, and if that effort exercised their abilities in an interesting way but in some nonscientific pursuit, then they couldn't giver a damn about isopropyltrimethylmethane or the classification of beetles. Suppose that lack of funds for postgraduate education had led the chemist to become an insurance broker instead of a chemist. In that case he would have been very interested in insurance matters but would have cared nothing about isopropyltrimethylmethane. In any case it is not normal to put into the satisfaction of mere curiosity the amount of time and effort that scientists put into their work. The ""curiosity"" explanation for the scientists' motive just doesn't stand up.",TK,1551,"['87', 'science', 'technology', 'provide', 'important', 'example', 'surrogate', 'activity', 'scientist', 'claim', 'motivated', 'curiosity', 'notion', 'simply', 'absurd', 'scientist', 'work', 'highly', 'specialized', 'problem', 'object', 'normal', 'curiosity', 'example', 'astronomer', 'mathematician', 'entomologist', 'curious', 'property', 'isopropyltrimethylmethane', 'course', 'chemist', 'curious', 'thing', 'curious', 'chemistry', 'surrogate', 'activity', 'chemist', 'curious', 'appropriate', 'classification', 'new', 'specie', 'beetle', 'question', 'interest', 'entomologist', 'interested', 'entomology', 'surrogate', 'activity', 'chemist', 'entomologist', 'exert', 'seriously', 'obtain', 'physical', 'necessity', 'effort', 'exercised', 'ability', 'interesting', 'way', 'nonscientific', 'pursuit', 'couldnt', 'giver', 'damn', 'isopropyltrimethylmethane', 'classification', 'beetle', 'suppose', 'lack', 'fund', 'postgraduate', 'education', 'led', 'chemist', 'become', 'insurance', 'broker', 'instead', 'chemist', 'case', 'would', 'interested', 'insurance', 'matter', 'would', 'cared', 'nothing', 'isopropyltrimethylmethane', 'case', 'normal', 'put', 'satisfaction', 'mere', 'curiosity', 'amount', 'time', 'effort', 'scientist', 'put', 'work', 'curiosity', 'explanation', 'scientist', 'motive', 'doesnt', 'stand']"
1825,"55. On the growing edge of the American frontier during the 19th century, the mobility of the population probably broke down extended families and small-scale social groups to at least the same extent as these are broken down today. In fact, many nuclear families lived by choice in such isolation, having no neighbors within several miles, that they belonged to no community at all, yet they do not seem to have developed problems as a result.",TK,444,"['55', 'growing', 'edge', 'american', 'frontier', '19th', 'century', 'mobility', 'population', 'probably', 'broke', 'extended', 'family', 'smallscale', 'social', 'group', 'least', 'extent', 'broken', 'today', 'fact', 'many', 'nuclear', 'family', 'lived', 'choice', 'isolation', 'neighbor', 'within', 'several', 'mile', 'belonged', 'community', 'yet', 'seem', 'developed', 'problem', 'result']"
1826,"43. It is true that some individuals seem to have little need for autonomy. Either their drive for power is weak or they satisfy it by identifying themselves with some powerful organization to which they belong. And then there are unthinking, animal types who seem to be satisfied with a purely physical sense of power(the good combat soldier, who gets his sense of power by developing fighting skills that he is quite content to use in blind obedience to his superiors).",TK,471,"['43', 'true', 'individual', 'seem', 'little', 'need', 'autonomy', 'either', 'drive', 'power', 'weak', 'satisfy', 'identifying', 'powerful', 'organization', 'belong', 'unthinking', 'animal', 'type', 'seem', 'satisfied', 'purely', 'physical', 'sense', 'powerthe', 'good', 'combat', 'soldier', 'get', 'sense', 'power', 'developing', 'fighting', 'skill', 'quite', 'content', 'use', 'blind', 'obedience', 'superior']"
1827,"173. If the machines are permitted to make all their own decisions, we can't make any conjectures as to the results, because it is impossible to guess how such machines might behave. We only point out that the fate of the human race would be at the mercy of the machines. It might be argued that the human race would never be foolish enough to hand over all the power to the machines. But we are suggesting neither that the human race would voluntarily turn power over to the machines nor that the machines would willfully seize power. What we do suggest is that the human race might easily permit itself to drift into a position of such dependence on the machines that it would have no practical choice but to accept all of the machines decisions. As society and the problems that face it become more and more complex and machines become more and more intelligent, people will let machines make more of their decision for them, simply because machine-made decisions will bring better result than man-made ones. Eventually a stage may be reached at which the decisions necessary to keep the system running will be so complex that human beings will be incapable of making them intelligently. At that stage the machines will be in effective control. People won't be able to just turn the machines off, because they will be so dependent on them that turning them off would amount to suicide.",TK,1388,"['173', 'machine', 'permitted', 'make', 'decision', 'cant', 'make', 'conjecture', 'result', 'impossible', 'guess', 'machine', 'might', 'behave', 'point', 'fate', 'human', 'race', 'would', 'mercy', 'machine', 'might', 'argued', 'human', 'race', 'would', 'never', 'foolish', 'enough', 'hand', 'power', 'machine', 'suggesting', 'neither', 'human', 'race', 'would', 'voluntarily', 'turn', 'power', 'machine', 'machine', 'would', 'willfully', 'seize', 'power', 'suggest', 'human', 'race', 'might', 'easily', 'permit', 'drift', 'position', 'dependence', 'machine', 'would', 'practical', 'choice', 'accept', 'machine', 'decision', 'society', 'problem', 'face', 'become', 'complex', 'machine', 'become', 'intelligent', 'people', 'let', 'machine', 'make', 'decision', 'simply', 'machinemade', 'decision', 'bring', 'better', 'result', 'manmade', 'one', 'eventually', 'stage', 'may', 'reached', 'decision', 'necessary', 'keep', 'system', 'running', 'complex', 'human', 'incapable', 'making', 'intelligently', 'stage', 'machine', 'effective', 'control', 'people', 'wont', 'able', 'turn', 'machine', 'dependent', 'turning', 'would', 'amount', 'suicide']"
1828,"228. But it will be helpful to list some criteria for diagnosing leftism. These criteria cannot be applied in a cut and dried manner. Some individuals may meet some of the criteria without being leftists, some leftists may not meet any of the criteria. Again, you just have to use your judgment.",TK,295,"['228', 'helpful', 'list', 'criterion', 'diagnosing', 'leftism', 'criterion', 'cannot', 'applied', 'cut', 'dried', 'manner', 'individual', 'may', 'meet', 'criterion', 'without', 'leftist', 'leftist', 'may', 'meet', 'criterion', 'use', 'judgment']"
1829,"51.The breakdown of traditional values to some extent implies the breakdown of the bonds that hold together traditional small-scale social groups. The disintegration of small-scale social groups is also promoted by the fact that modern conditions often require or tempt individuals to move to new locations, separating themselves from their communities. Beyond that, a technological society HAS TO weaken family ties and local communities if it is to function efficiently. In modern society an individual's loyalty must be first to the system and only secondarily to a small-scale community, because if the internal loyalties of small-scale small-scale communities were stronger than loyalty to the system, such communities would pursue their own advantage at the expense of the system.",TK,786,"['51the', 'breakdown', 'traditional', 'value', 'extent', 'implies', 'breakdown', 'bond', 'hold', 'together', 'traditional', 'smallscale', 'social', 'group', 'disintegration', 'smallscale', 'social', 'group', 'also', 'promoted', 'fact', 'modern', 'condition', 'often', 'require', 'tempt', 'individual', 'move', 'new', 'location', 'separating', 'community', 'beyond', 'technological', 'society', 'ha', 'weaken', 'family', 'tie', 'local', 'community', 'function', 'efficiently', 'modern', 'society', 'individual', 'loyalty', 'must', 'first', 'system', 'secondarily', 'smallscale', 'community', 'internal', 'loyalty', 'smallscale', 'smallscale', 'community', 'stronger', 'loyalty', 'system', 'community', 'would', 'pursue', 'advantage', 'expense', 'system']"
1830,"95. It is said that we live in a free society because we have a certain number of constitutionally guaranteed rights. But these are not as important as they seem. The degree of personal freedom that exists in a society is determined more by the economic and technological structure of the society than by its laws or its form of government. [16] Most of the Indian nations of New England were monarchies, and many of the cities of the Italian Renaissance were controlled by dictators. But in reading about these societies one gets the impression that they allowed far more personal freedom than out society does. In part this was because they lacked efficient mechanisms for enforcing the ruler's will: There were no modern, well-organized police forces, no rapid long-distance communications, no surveillance cameras, no dossiers of information about the lives of average citizens. Hence it was relatively easy to evade control.",TK,929,"['95', 'said', 'live', 'free', 'society', 'certain', 'number', 'constitutionally', 'guaranteed', 'right', 'important', 'seem', 'degree', 'personal', 'freedom', 'exists', 'society', 'determined', 'economic', 'technological', 'structure', 'society', 'law', 'form', 'government', '16', 'indian', 'nation', 'new', 'england', 'monarchy', 'many', 'city', 'italian', 'renaissance', 'controlled', 'dictator', 'reading', 'society', 'one', 'get', 'impression', 'allowed', 'far', 'personal', 'freedom', 'society', 'doe', 'part', 'wa', 'lacked', 'efficient', 'mechanism', 'enforcing', 'ruler', 'modern', 'wellorganized', 'police', 'force', 'rapid', 'longdistance', 'communication', 'surveillance', 'camera', 'dossier', 'information', 'life', 'average', 'citizen', 'hence', 'wa', 'relatively', 'easy', 'evade', 'control']"
1831,"13. Many leftists have an intense identification with the problems of groups that have an image of being weak (women), defeated (American Indians), repellent (homosexuals), or otherwise inferior. The leftists themselves feel that these groups are inferior. They would never admit it to themselves that they have such feelings, but it is precisely because they do see these groups as inferior that they identify with their problems. (We do not suggest that women, Indians, etc., ARE inferior; we are only making a point about leftist psychology).",TK,545,"['13', 'many', 'leftist', 'intense', 'identification', 'problem', 'group', 'image', 'weak', 'woman', 'defeated', 'american', 'indian', 'repellent', 'homosexual', 'otherwise', 'inferior', 'leftist', 'feel', 'group', 'inferior', 'would', 'never', 'admit', 'feeling', 'precisely', 'see', 'group', 'inferior', 'identify', 'problem', 'suggest', 'woman', 'indian', 'etc', 'inferior', 'making', 'point', 'leftist', 'psychology']"
1832,"194. Probably the revolutionaries should even AVOID assuming political power, whether by legal or illegal means, until the industrial system is stressed to the danger point and has proved itself to be a failure in the eyes of most people. Suppose for example that some ""green"" party should win control of the United States Congress in an election. In order to avoid betraying or watering down their own ideology they would have to take vigorous measures to turn economic growth into economic shrinkage. To the average man the results would appear disastrous: There would be massive unemployment, shortages of commodities, etc. Even if the grosser ill effects could be avoided through superhumanly skillful management, still people would have to begin giving up the luxuries to which they have become addicted. Dissatisfaction would grow, the ""green"" party would be voted out of of fice and the revolutionaries would have suffered a severe setback. For this reason the revolutionaries should not try to acquire political power until the system has gotten itself into such a mess that any hardships will be seen as resulting from the failures of the industrial system itself and not from the policies of the revolutionaries. The revolution against technology will probably have to be a revolution by outsiders, a revolution from below and not from above.",TK,1352,"['194', 'probably', 'revolutionary', 'even', 'avoid', 'assuming', 'political', 'power', 'whether', 'legal', 'illegal', 'mean', 'industrial', 'system', 'stressed', 'danger', 'point', 'ha', 'proved', 'failure', 'eye', 'people', 'suppose', 'example', 'green', 'party', 'win', 'control', 'united', 'state', 'congress', 'election', 'order', 'avoid', 'betraying', 'watering', 'ideology', 'would', 'take', 'vigorous', 'measure', 'turn', 'economic', 'growth', 'economic', 'shrinkage', 'average', 'man', 'result', 'would', 'appear', 'disastrous', 'would', 'massive', 'unemployment', 'shortage', 'commodity', 'etc', 'even', 'grosser', 'ill', 'effect', 'could', 'avoided', 'superhumanly', 'skillful', 'management', 'still', 'people', 'would', 'begin', 'giving', 'luxury', 'become', 'addicted', 'dissatisfaction', 'would', 'grow', 'green', 'party', 'would', 'voted', 'fice', 'revolutionary', 'would', 'suffered', 'severe', 'setback', 'reason', 'revolutionary', 'try', 'acquire', 'political', 'power', 'system', 'ha', 'gotten', 'mess', 'hardship', 'seen', 'resulting', 'failure', 'industrial', 'system', 'policy', 'revolutionary', 'revolution', 'technology', 'probably', 'revolution', 'outsider', 'revolution']"
1833,"145. Imagine a society that subjects people to conditions that amke them terribley unhappy, then gives them the drugs to take away their unhappiness. Science fiction? It is already happening to some extent in our own society. It is well known that the rate of clinical depression had been greatly increasing in recent decades. We believe that this is due to disruption fo the power process, as explained in paragraphs 59-76. But even if we are wrong, the increasing rate of depression is certainly the result of SOME conditions that exist in today's society. Instead of removing the conditions that make people depressed, modern society gives them antidepressant drugs. In effect, antidepressants area a means of modifying an individual's internal state in such a way as to enable him to toelrate social conditions that he would otherwise find intolerable. (Yes, we know that depression is often of purely genetic origin. We are referring here to those cases in which environment plays the predominant role.)",TK,1008,"['145', 'imagine', 'society', 'subject', 'people', 'condition', 'amke', 'terribley', 'unhappy', 'give', 'drug', 'take', 'away', 'unhappiness', 'science', 'fiction', 'already', 'happening', 'extent', 'society', 'well', 'known', 'rate', 'clinical', 'depression', 'greatly', 'increasing', 'recent', 'decade', 'believe', 'due', 'disruption', 'fo', 'power', 'process', 'explained', 'paragraph', '5976', 'even', 'wrong', 'increasing', 'rate', 'depression', 'certainly', 'result', 'condition', 'exist', 'today', 'society', 'instead', 'removing', 'condition', 'make', 'people', 'depressed', 'modern', 'society', 'give', 'antidepressant', 'drug', 'effect', 'antidepressant', 'area', 'mean', 'modifying', 'individual', 'internal', 'state', 'way', 'enable', 'toelrate', 'social', 'condition', 'would', 'otherwise', 'find', 'intolerable', 'yes', 'know', 'depression', 'often', 'purely', 'genetic', 'origin', 'referring', 'case', 'environment', 'play', 'predominant', 'role']"
1834,"40. In modern industrial society only minimal effort is necessary to satisfy one's physical needs. It is enough to go through a training program to acquire some petty technical skill, then come to work on time and exert very modest effort needed to hold a job. The only requirements are a moderate amount of intelligence, and most of all, simple OBEDIENCE. If one has those, society takes care of one from cradle to grave. (Yes, there is an underclass that cannot take physical necessities for granted, but we are speaking here of mainstream society.) Thus it is not surprising that modern society is full of surrogate activities. These include scientific work, athletic achievement, humanitarian work, artistic and literary creation, climbing the corporate ladder, acquisition of money and material goods far beyond the point at which they cease to give any additional physical satisfaction, and social activism when it addresses issues that are not important for the activist personally, as in the case of white activists who work for the rights of nonwhite minorities. These are not always pure surrogate activities, since for many people they may be motivated in part by needs other than the need to have some goal to pursue. Scientific work may be motivated in part by a drive for prestige, artistic creation by a need to express feelings, militant social activism by hostility. But for most people who pursue them, these activities are in large part surrogate activities. For example, the majority of scientists will probably agree that the ""fulfillment"" they get from their work is more important than the money and prestige they earn.",TK,1642,"['40', 'modern', 'industrial', 'society', 'minimal', 'effort', 'necessary', 'satisfy', 'one', 'physical', 'need', 'enough', 'go', 'training', 'program', 'acquire', 'petty', 'technical', 'skill', 'come', 'work', 'time', 'exert', 'modest', 'effort', 'needed', 'hold', 'job', 'requirement', 'moderate', 'amount', 'intelligence', 'simple', 'obedience', 'one', 'ha', 'society', 'take', 'care', 'one', 'cradle', 'grave', 'yes', 'underclass', 'cannot', 'take', 'physical', 'necessity', 'granted', 'speaking', 'mainstream', 'society', 'thus', 'surprising', 'modern', 'society', 'full', 'surrogate', 'activity', 'include', 'scientific', 'work', 'athletic', 'achievement', 'humanitarian', 'work', 'artistic', 'literary', 'creation', 'climbing', 'corporate', 'ladder', 'acquisition', 'money', 'material', 'good', 'far', 'beyond', 'point', 'cease', 'give', 'additional', 'physical', 'satisfaction', 'social', 'activism', 'address', 'issue', 'important', 'activist', 'personally', 'case', 'white', 'activist', 'work', 'right', 'nonwhite', 'minority', 'always', 'pure', 'surrogate', 'activity', 'since', 'many', 'people', 'may', 'motivated', 'part', 'need', 'need', 'goal', 'pursue', 'scientific', 'work', 'may', 'motivated', 'part', 'drive', 'prestige', 'artistic', 'creation', 'need', 'express', 'feeling', 'militant', 'social', 'activism', 'hostility', 'people', 'pursue', 'activity', 'large', 'part', 'surrogate', 'activity', 'example', 'majority', 'scientist', 'probably', 'agree', 'fulfillment', 'get', 'work', 'important', 'money', 'prestige', 'earn']"
1835,"142. Reform is always restrainde by the fear of painful consequences if changes go too far. But once a revolutionary fever has taken hold of a society, people are willing to undergo unlimited hardships for the sake of their revolution. This was clearly shown in the French and Russian Revolutions. It may be that in such cases only a minority of the population is really committed to the revolution, but this minority is sufficiently large and active so that it becomes the dominant force in society. We will have more to say about revolution in paragraphs 180-205.",TK,565,"['142', 'reform', 'always', 'restrainde', 'fear', 'painful', 'consequence', 'change', 'go', 'far', 'revolutionary', 'fever', 'ha', 'taken', 'hold', 'society', 'people', 'willing', 'undergo', 'unlimited', 'hardship', 'sake', 'revolution', 'wa', 'clearly', 'shown', 'french', 'russian', 'revolution', 'may', 'case', 'minority', 'population', 'really', 'committed', 'revolution', 'minority', 'sufficiently', 'large', 'active', 'becomes', 'dominant', 'force', 'society', 'say', 'revolution', 'paragraph', '180205']"
1836,"191. One should think twice before encouraging any other social conflict than that between the power-holding elite (which wields technology) and the general public (over which technology exerts its power). For one thing, other conflicts tend to distract attention from the important conflicts (between power-elite and ordinary people, between technology and nature); for another thing, other conflicts may actually tend to encourage technologization, because each side in such a conflict wants to use technological power to gain advantages over its adversary. This is clearly seen in rivalries between nations. It also appears in ethnic conflicts within nations. For example, in America many black leaders are anxious to gain power for African Americans by placing back individuals in the technological power-elite. They want there to be many black government officials, scientists, corporation executives and so forth. In this way they are helping to absorb the African American subculture into the technological system. Generally speaking, one should encourage only those social conflicts that can be fitted into the framework of the conflicts of power--elite vs. ordinary people, technology vs nature.",TK,1204,"['191', 'one', 'think', 'twice', 'encouraging', 'social', 'conflict', 'powerholding', 'elite', 'wields', 'technology', 'general', 'public', 'technology', 'exerts', 'power', 'one', 'thing', 'conflict', 'tend', 'distract', 'attention', 'important', 'conflict', 'powerelite', 'ordinary', 'people', 'technology', 'nature', 'another', 'thing', 'conflict', 'may', 'actually', 'tend', 'encourage', 'technologization', 'side', 'conflict', 'want', 'use', 'technological', 'power', 'gain', 'advantage', 'adversary', 'clearly', 'seen', 'rivalry', 'nation', 'also', 'appears', 'ethnic', 'conflict', 'within', 'nation', 'example', 'america', 'many', 'black', 'leader', 'anxious', 'gain', 'power', 'african', 'american', 'placing', 'back', 'individual', 'technological', 'powerelite', 'want', 'many', 'black', 'government', 'official', 'scientist', 'corporation', 'executive', 'forth', 'way', 'helping', 'absorb', 'african', 'american', 'subculture', 'technological', 'system', 'generally', 'speaking', 'one', 'encourage', 'social', 'conflict', 'fitted', 'framework', 'conflict', 'powerelite', 'v', 'ordinary', 'people', 'technology', 'v', 'nature']"
1837,"137. Take our environmental problems, for example. Here the conflict of values is straightforward: economic expedience now versus saving some of our natural resources for our grandchildren [22] But on this subject we get only a lot of blather and obfuscation from the people who have power, and nothing like a clear, consistent line of action, and we keep on piling up environmental problems that our grandchildren will have to live with. Attempts to resolve the environmental issue consist of struggles and compromises between different factions, some of which are ascendant at one moment, others at another moment. The line of struggle changes with the shifting currents of public opinion. This is not a rational process, or is it one that is likely to lead to a timely and successful solution to the problem. Major social problems, if they get ""solved"" at all, are rarely or never solved through any rational, comprehensive plan. They just work themselves out through a process in which various competing groups pursing their own usually short-term) self-interest [23] arrive (mainly by luck) at some more or less stable modus vivendi. In fact, the principles we formulated in paragraphs 100-106 make it seem doubtful that rational, long-term social planning can EVER be successful.",TK,1285,"['137', 'take', 'environmental', 'problem', 'example', 'conflict', 'value', 'straightforward', 'economic', 'expedience', 'versus', 'saving', 'natural', 'resource', 'grandchild', '22', 'subject', 'get', 'lot', 'blather', 'obfuscation', 'people', 'power', 'nothing', 'like', 'clear', 'consistent', 'line', 'action', 'keep', 'piling', 'environmental', 'problem', 'grandchild', 'live', 'attempt', 'resolve', 'environmental', 'issue', 'consist', 'struggle', 'compromise', 'different', 'faction', 'ascendant', 'one', 'moment', 'others', 'another', 'moment', 'line', 'struggle', 'change', 'shifting', 'current', 'public', 'opinion', 'rational', 'process', 'one', 'likely', 'lead', 'timely', 'successful', 'solution', 'problem', 'major', 'social', 'problem', 'get', 'solved', 'rarely', 'never', 'solved', 'rational', 'comprehensive', 'plan', 'work', 'process', 'various', 'competing', 'group', 'pursing', 'usually', 'shortterm', 'selfinterest', '23', 'arrive', 'mainly', 'luck', 'le', 'stable', 'modus', 'vivendi', 'fact', 'principle', 'formulated', 'paragraph', '100106', 'make', 'seem', 'doubtful', 'rational', 'longterm', 'social', 'planning', 'ever', 'successful']"
1838,"180. The technophiles are taking us all on an utterly reckless ride into the unknown. Many people understand something of what technological progress is doing to us yet take a passive attitude toward it because they think it is inevitable. But we (FC) don't think it is inevitable. We think it can be stopped, and we will give here some indications of how to go about stopping it.",TK,380,"['180', 'technophile', 'taking', 'u', 'utterly', 'reckless', 'ride', 'unknown', 'many', 'people', 'understand', 'something', 'technological', 'progress', 'u', 'yet', 'take', 'passive', 'attitude', 'toward', 'think', 'inevitable', 'fc', 'dont', 'think', 'inevitable', 'think', 'stopped', 'give', 'indication', 'go', 'stopping']"
1839,"212. Would society EVENTUALLY develop again toward an industrial-technological form? Maybe, but there is no use in worrying about it, since we can't predict or control events 500 or 1,000 years in the future. Those problems must be dealt with by the people who will live at that time.",TK,284,"['212', 'would', 'society', 'eventually', 'develop', 'toward', 'industrialtechnological', 'form', 'maybe', 'use', 'worrying', 'since', 'cant', 'predict', 'control', 'event', '500', '1000', 'year', 'future', 'problem', 'must', 'dealt', 'people', 'live', 'time']"
1840,"109. The American Revolution does not provide a counterexample. The American ""Revolution"" was not a revolution in our sense of the word, but a war of independence followed by a rather far-reaching political reform. The Founding Fathers did not change the direction of development of American society, nor did they aspire to do so. They only freed the development of American society from the retarding effect of British rule. Their political reform did not change any basic trend, but only pushed American political culture along its natural direction of development. British society, of which American society was an off-shoot, had been moving for a long time in the direction of representative democracy. And prior to the War of Independence the Americans were already practicing a significant degree of representative democracy in the colonial assemblies. The political system established by the Constitution was modeled on the British system and on the colonial assemblies. With major alteration, to be sure - there is no doubt that the Founding Fathers took a very important step. But it was a step along the road the English-speaking world was already traveling. The proof is that Britain and all of its colonies that were populated predominantly by people of British descent ended up with systems of representative democracy essentially similar to that of the United States. If the Founding Fathers had lost their nerve and declined to sign the Declaration of Independence, our way of life today would not have been significantly different. Maybe we would have had somewhat closer ties to Britain, and would have had a Parliament and Prime Minister instead of a Congress and President. No big deal. Thus the American Revolution provides not a counterexample to our principles but a good illustration of them.",TK,1815,"['109', 'american', 'revolution', 'doe', 'provide', 'counterexample', 'american', 'revolution', 'wa', 'revolution', 'sense', 'word', 'war', 'independence', 'followed', 'rather', 'farreaching', 'political', 'reform', 'founding', 'father', 'change', 'direction', 'development', 'american', 'society', 'aspire', 'freed', 'development', 'american', 'society', 'retarding', 'effect', 'british', 'rule', 'political', 'reform', 'change', 'basic', 'trend', 'pushed', 'american', 'political', 'culture', 'along', 'natural', 'direction', 'development', 'british', 'society', 'american', 'society', 'wa', 'offshoot', 'moving', 'long', 'time', 'direction', 'representative', 'democracy', 'prior', 'war', 'independence', 'american', 'already', 'practicing', 'significant', 'degree', 'representative', 'democracy', 'colonial', 'assembly', 'political', 'system', 'established', 'constitution', 'wa', 'modeled', 'british', 'system', 'colonial', 'assembly', 'major', 'alteration', 'sure', '', 'doubt', 'founding', 'father', 'took', 'important', 'step', 'wa', 'step', 'along', 'road', 'englishspeaking', 'world', 'wa', 'already', 'traveling', 'proof', 'britain', 'colony', 'populated', 'predominantly', 'people', 'british', 'descent', 'ended', 'system', 'representative', 'democracy', 'essentially', 'similar', 'united', 'state', 'founding', 'father', 'lost', 'nerve', 'declined', 'sign', 'declaration', 'independence', 'way', 'life', 'today', 'would', 'significantly', 'different', 'maybe', 'would', 'somewhat', 'closer', 'tie', 'britain', 'would', 'parliament', 'prime', 'minister', 'instead', 'congress', 'president', 'big', 'deal', 'thus', 'american', 'revolution', 'provides', 'counterexample', 'principle', 'good', 'illustration']"
1841,"108. To illustrate: By the first principle, generally speaking an attempt at social reform either acts in the direction in which the society is developing anyway (so that it merely accelerates a change that would have occurred in any case) or else it only has a transitory effect, so that the society soon slips back into its old groove. To make a lasting change in the direction of development of any important aspect of a society, reform is insufficient and revolution is required. (A revolution does not necessarily involve an armed uprising or the overthrow of a government.) By the second principle, a revolution never changes only one aspect of a society; and by the third principle changes occur that were never expected or desired by the revolutionaries. By the fourth principle, when revolutionaries or utopians set up a new kind of society, it never works out as planned.",TK,881,"['108', 'illustrate', 'first', 'principle', 'generally', 'speaking', 'attempt', 'social', 'reform', 'either', 'act', 'direction', 'society', 'developing', 'anyway', 'merely', 'accelerates', 'change', 'would', 'occurred', 'case', 'else', 'ha', 'transitory', 'effect', 'society', 'soon', 'slip', 'back', 'old', 'groove', 'make', 'lasting', 'change', 'direction', 'development', 'important', 'aspect', 'society', 'reform', 'insufficient', 'revolution', 'required', 'revolution', 'doe', 'necessarily', 'involve', 'armed', 'uprising', 'overthrow', 'government', 'second', 'principle', 'revolution', 'never', 'change', 'one', 'aspect', 'society', 'third', 'principle', 'change', 'occur', 'never', 'expected', 'desired', 'revolutionary', 'fourth', 'principle', 'revolutionary', 'utopian', 'set', 'new', 'kind', 'society', 'never', 'work', 'planned']"
1842,"174. On the other hand it is possible that human control over the machines may be retained. In that case the average man may have control over certain private machines of his own, such as his car of his personal computer, but control over large systems of machines will be in the hands of a tiny elite -- just as it is today, but with two difference. Due to improved techniques the elite will have greater control over the masses; and because human work will no longer be necessary the masses will be superfluous, a useless burden on the system. If the elite is ruthless the may simply decide to exterminate the mass of humanity. If they are humane they may use propaganda or other psychological or biological techniques to reduce the birth rate until the mass of humanity becomes extinct, leaving the world to the elite. Or, if the elite consist of soft-hearted liberals, they may decide to play the role of good shepherds to the rest of the human race. They will see to it that everyone's physical needs are satisfied, that all children are raised under psychologically hygienic conditions, that everyone has a wholesome hobby to keep him busy, and that anyone who may become dissatisfied undergoes ""treatment"" to cure his ""problem."" Of course, life will be so purposeless that people will have to be biologically or psychologically engineered either to remove their need for the power process or to make them ""sublimate"" their drive for power into some harmless hobby. These engineered human beings may be happy in such a society, but they most certainly will not be free. They will have been reduced to the status of domestic animals.",TK,1638,"['174', 'hand', 'possible', 'human', 'control', 'machine', 'may', 'retained', 'case', 'average', 'man', 'may', 'control', 'certain', 'private', 'machine', 'car', 'personal', 'computer', 'control', 'large', 'system', 'machine', 'hand', 'tiny', 'elite', '', 'today', 'two', 'difference', 'due', 'improved', 'technique', 'elite', 'greater', 'control', 'mass', 'human', 'work', 'longer', 'necessary', 'mass', 'superfluous', 'useless', 'burden', 'system', 'elite', 'ruthless', 'may', 'simply', 'decide', 'exterminate', 'mass', 'humanity', 'humane', 'may', 'use', 'propaganda', 'psychological', 'biological', 'technique', 'reduce', 'birth', 'rate', 'mass', 'humanity', 'becomes', 'extinct', 'leaving', 'world', 'elite', 'elite', 'consist', 'softhearted', 'liberal', 'may', 'decide', 'play', 'role', 'good', 'shepherd', 'rest', 'human', 'race', 'see', 'everyones', 'physical', 'need', 'satisfied', 'child', 'raised', 'psychologically', 'hygienic', 'condition', 'everyone', 'ha', 'wholesome', 'hobby', 'keep', 'busy', 'anyone', 'may', 'become', 'dissatisfied', 'undergoes', 'treatment', 'cure', 'problem', 'course', 'life', 'purposeless', 'people', 'biologically', 'psychologically', 'engineered', 'either', 'remove', 'need', 'power', 'process', 'make', 'sublimate', 'drive', 'power', 'harmless', 'hobby', 'engineered', 'human', 'may', 'happy', 'society', 'certainly', 'free', 'reduced', 'status', 'domestic', 'animal']"
1843,"97. Constitutional rights are useful up to a point, but they do not serve to guarantee much more than what could be called the bourgeois conception of freedom. According to the bourgeois conception, a ""free"" man is essentially an element of a social machine and has only a certain set of prescribed and delimited freedoms; freedoms that are designed to serve the needs of the social machine more than those of the individual. Thus the bourgeois's ""free"" man has economic freedom because that promotes growth and progress; he has freedom of the press because public criticism restrains misbehavior by political leaders; he has a rights to a fair trial because imprisonment at the whim of the powerful would be bad for the system. This was clearly the attitude of Simon Bolivar. To him, people deserved liberty only if they used it to promote progress (progress as conceived by the bourgeois). Other bourgeois thinkers have taken a similar view of freedom as a mere means to collective ends. Chester C. Tan, ""Chinese Political Thought in the Twentieth Century,"" page 202, explains the philosophy of the Kuomintang leader Hu Han-min: ""An individual is granted rights because he is a member of society and his community life requires such rights. By community Hu meant the whole society of the nation."" And on page 259 Tan states that according to Carsum Chang (Chang Chun-mai, head of the State Socialist Party in China) freedom had to be used in the interest of the state and of the people as a whole. But what kind of freedom does one have if one can use it only as someone else prescribes? FC's conception of freedom is not that of Bolivar, Hu, Chang or other bourgeois theorists. The trouble with such theorists is that they have made the development and application of social theories their surrogate activity. Consequently the theories are designed to serve the needs of the theorists more than the needs of any people who may be unlucky enough to live in a society on which the theories are imposed.",TK,2003,"['97', 'constitutional', 'right', 'useful', 'point', 'serve', 'guarantee', 'much', 'could', 'called', 'bourgeois', 'conception', 'freedom', 'according', 'bourgeois', 'conception', 'free', 'man', 'essentially', 'element', 'social', 'machine', 'ha', 'certain', 'set', 'prescribed', 'delimited', 'freedom', 'freedom', 'designed', 'serve', 'need', 'social', 'machine', 'individual', 'thus', 'bourgeois', 'free', 'man', 'ha', 'economic', 'freedom', 'promotes', 'growth', 'progress', 'ha', 'freedom', 'press', 'public', 'criticism', 'restrains', 'misbehavior', 'political', 'leader', 'ha', 'right', 'fair', 'trial', 'imprisonment', 'whim', 'powerful', 'would', 'bad', 'system', 'wa', 'clearly', 'attitude', 'simon', 'bolivar', 'people', 'deserved', 'liberty', 'used', 'promote', 'progress', 'progress', 'conceived', 'bourgeois', 'bourgeois', 'thinker', 'taken', 'similar', 'view', 'freedom', 'mere', 'mean', 'collective', 'end', 'chester', 'c', 'tan', 'chinese', 'political', 'thought', 'twentieth', 'century', 'page', '202', 'explains', 'philosophy', 'kuomintang', 'leader', 'hu', 'hanmin', 'individual', 'granted', 'right', 'member', 'society', 'community', 'life', 'requires', 'right', 'community', 'hu', 'meant', 'whole', 'society', 'nation', 'page', '259', 'tan', 'state', 'according', 'carsum', 'chang', 'chang', 'chunmai', 'head', 'state', 'socialist', 'party', 'china', 'freedom', 'used', 'interest', 'state', 'people', 'whole', 'kind', 'freedom', 'doe', 'one', 'one', 'use', 'someone', 'else', 'prescribes', 'fcs', 'conception', 'freedom', 'bolivar', 'hu', 'chang', 'bourgeois', 'theorist', 'trouble', 'theorist', 'made', 'development', 'application', 'social', 'theory', 'surrogate', 'activity', 'consequently', 'theory', 'designed', 'serve', 'need', 'theorist', 'need', 'people', 'may', 'unlucky', 'enough', 'live', 'society', 'theory', 'imposed']"
1844,"54. A few pre-industrial cities were very large and crowded, yet their inhabitants do not seem to have suffered from psychological problems to the same extent as modern man. In America today there still are uncrowded rural areas, and we find there the same problems as in urban areas, though the problems tend to be less acute in the rural areas. Thus crowding does not seem to be the decisive factor.",TK,401,"['54', 'preindustrial', 'city', 'large', 'crowded', 'yet', 'inhabitant', 'seem', 'suffered', 'psychological', 'problem', 'extent', 'modern', 'man', 'america', 'today', 'still', 'uncrowded', 'rural', 'area', 'find', 'problem', 'urban', 'area', 'though', 'problem', 'tend', 'le', 'acute', 'rural', 'area', 'thus', 'crowding', 'doe', 'seem', 'decisive', 'factor']"
1845,"209. The reason why technology has seemed always to progress is that, until perhaps a century or two before the Industrial Revolution, most technology was small-scale technology. But most of the technology developed since the Industrial Revolution is organization-dependent technology. Take the refrigerator for example. Without factory-made parts or the facilities of a post-industrial machine shop it would be virtually impossible for a handful of local craftsmen to build a refrigerator. If by some miracle they did succeed in building one it would be useless to them without a reliable source of electric power. So they would have to dam a stream and build a generator. Generators require large amounts of copper wire. Imagine trying to make that wire without modern machinery. And where would they get a gas suitable for refrigeration? It would be much easier to build an icehouse or preserve food by drying or picking, as was done before the invention of the refrigerator.",TK,978,"['209', 'reason', 'technology', 'ha', 'seemed', 'always', 'progress', 'perhaps', 'century', 'two', 'industrial', 'revolution', 'technology', 'wa', 'smallscale', 'technology', 'technology', 'developed', 'since', 'industrial', 'revolution', 'organizationdependent', 'technology', 'take', 'refrigerator', 'example', 'without', 'factorymade', 'part', 'facility', 'postindustrial', 'machine', 'shop', 'would', 'virtually', 'impossible', 'handful', 'local', 'craftsman', 'build', 'refrigerator', 'miracle', 'succeed', 'building', 'one', 'would', 'useless', 'without', 'reliable', 'source', 'electric', 'power', 'would', 'dam', 'stream', 'build', 'generator', 'generator', 'require', 'large', 'amount', 'copper', 'wire', 'imagine', 'trying', 'make', 'wire', 'without', 'modern', 'machinery', 'would', 'get', 'gas', 'suitable', 'refrigeration', 'would', 'much', 'easier', 'build', 'icehouse', 'preserve', 'food', 'drying', 'picking', 'wa', 'done', 'invention', 'refrigerator']"
1846,"210. So it is clear that if the industrial system were once thoroughly broken down, refrigeration technology would quickly be lost. The same is true of other organization-dependent technology. And once this technology had been lost for a generation or so it would take centuries to rebuild it, just as it took centuries to build it the first time around. Surviving technical books would be few and scattered. An industrial society, if built from scratch without outside help, can only be built in a series of stages: You need tools to make tools to make tools to make tools ... . A long process of economic development and progress in social organization is required. And, even in the absence of an ideology opposed to technology, there is no reason to believe that anyone would be interested in rebuilding industrial society. The enthusiasm for ""progress"" is a phenomenon particular to the modern form of society, and it seems not to have existed prior to the 17th century or thereabouts.",TK,989,"['210', 'clear', 'industrial', 'system', 'thoroughly', 'broken', 'refrigeration', 'technology', 'would', 'quickly', 'lost', 'true', 'organizationdependent', 'technology', 'technology', 'lost', 'generation', 'would', 'take', 'century', 'rebuild', 'took', 'century', 'build', 'first', 'time', 'around', 'surviving', 'technical', 'book', 'would', 'scattered', 'industrial', 'society', 'built', 'scratch', 'without', 'outside', 'help', 'built', 'series', 'stage', 'need', 'tool', 'make', 'tool', 'make', 'tool', 'make', 'tool', '', '', 'long', 'process', 'economic', 'development', 'progress', 'social', 'organization', 'required', 'even', 'absence', 'ideology', 'opposed', 'technology', 'reason', 'believe', 'anyone', 'would', 'interested', 'rebuilding', 'industrial', 'society', 'enthusiasm', 'progress', 'phenomenon', 'particular', 'modern', 'form', 'society', 'seems', 'existed', 'prior', '17th', 'century', 'thereabouts']"
1847,"21. Leftists may claim that their activism is motivated by compassion or by moral principle, and moral principle does play a role for the leftist of the oversocialized type. But compassion and moral principle cannot be the main motives for leftist activism. Hostility is too prominent a component of leftist behavior; so is the drive for power. Moreover, much leftist behavior is not rationally calculated to be of benefit to the people whom the leftists claim to be trying to help. For example, if one believes that affirmative action is good for black people, does it make sense to demand affirmative action in hostile or dogmatic terms? Obviously it would be more productive to take a diplomatic and conciliatory approach that would make at least verbal and symbolic concessions to white people who think that affirmative action discriminates against them. But leftist activists do not take such an approach because it would not satisfy their emotional needs. Helping black people is not their real goal. Instead, race problems serve as an excuse for them to express their own hostility and frustrated need for power. In doing so they actually harm black people, because the activists' hostile attitude toward the white majority tends to intensify race hatred.",TK,1263,"['21', 'leftist', 'may', 'claim', 'activism', 'motivated', 'compassion', 'moral', 'principle', 'moral', 'principle', 'doe', 'play', 'role', 'leftist', 'oversocialized', 'type', 'compassion', 'moral', 'principle', 'cannot', 'main', 'motif', 'leftist', 'activism', 'hostility', 'prominent', 'component', 'leftist', 'behavior', 'drive', 'power', 'moreover', 'much', 'leftist', 'behavior', 'rationally', 'calculated', 'benefit', 'people', 'leftist', 'claim', 'trying', 'help', 'example', 'one', 'belief', 'affirmative', 'action', 'good', 'black', 'people', 'doe', 'make', 'sense', 'demand', 'affirmative', 'action', 'hostile', 'dogmatic', 'term', 'obviously', 'would', 'productive', 'take', 'diplomatic', 'conciliatory', 'approach', 'would', 'make', 'least', 'verbal', 'symbolic', 'concession', 'white', 'people', 'think', 'affirmative', 'action', 'discriminates', 'leftist', 'activist', 'take', 'approach', 'would', 'satisfy', 'emotional', 'need', 'helping', 'black', 'people', 'real', 'goal', 'instead', 'race', 'problem', 'serve', 'excuse', 'express', 'hostility', 'frustrated', 'need', 'power', 'actually', 'harm', 'black', 'people', 'activist', 'hostile', 'attitude', 'toward', 'white', 'majority', 'tends', 'intensify', 'race', 'hatred']"
1848,"171. But suppose now that industrial society does survive the next several decade and that the bugs do eventually get worked out of the system, so that it functions smoothly. What kind of system will it be? We will consider several possibilities.",TK,246,"['171', 'suppose', 'industrial', 'society', 'doe', 'survive', 'next', 'several', 'decade', 'bug', 'eventually', 'get', 'worked', 'system', 'function', 'smoothly', 'kind', 'system', 'consider', 'several', 'possibility']"
1849,"151. The social disruption that we see today is certainly not the result of mere chance. It can only be a result fo the conditions of life that the system imposes on people. (We have argued that the most important of these conditions is disruption of the power process.) If the systems succeeds in imposing sufficient control over human behavior to assure itw own survival, a new watershed in human history will have passed. Whereas formerly the limits of human endurance have imposed limits on the development of societies (as we explained in paragraphs 143, 144), industrial-technological society will be able to pass those limits by modifying human beings, whether by psychological methods or biological methods or both. In the future, social systems will not be adjusted to suit the needs of human beings. Instead, human being will be adjusted to suit the needs of the system. [27]",TK,885,"['151', 'social', 'disruption', 'see', 'today', 'certainly', 'result', 'mere', 'chance', 'result', 'fo', 'condition', 'life', 'system', 'imposes', 'people', 'argued', 'important', 'condition', 'disruption', 'power', 'process', 'system', 'succeeds', 'imposing', 'sufficient', 'control', 'human', 'behavior', 'assure', 'itw', 'survival', 'new', 'watershed', 'human', 'history', 'passed', 'whereas', 'formerly', 'limit', 'human', 'endurance', 'imposed', 'limit', 'development', 'society', 'explained', 'paragraph', '143', '144', 'industrialtechnological', 'society', 'able', 'pas', 'limit', 'modifying', 'human', 'whether', 'psychological', 'method', 'biological', 'method', 'future', 'social', 'system', 'adjusted', 'suit', 'need', 'human', 'instead', 'human', 'adjusted', 'suit', 'need', 'system', '27']"
1850,"96. As for our constitutional rights, consider for example that of freedom of the press. We certainly don't mean to knock that right: it is very important tool for limiting concentration of political power and for keeping those who do have political power in line by publicly exposing any misbehavior on their part. But freedom of the press is of very little use to the average citizen as an individual. The mass media are mostly under the control of large organizations that are integrated into the system. Anyone who has a little money can have something printed, or can distribute it on the Internet or in some such way, but what he has to say will be swamped by the vast volume of material put out by the media, hence it will have no practical effect. To make an impression on society with words is therefore almost impossible for most individuals and small groups. Take us (FC) for example. If we had never done anything violent and had submitted the present writings to a publisher, they probably would not have been accepted. If they had been accepted and published, they probably would not have attracted many readers, because it's more fun to watch the entertainment put out by the media than to read a sober essay. Even if these writings had had many readers, most of these readers would soon have forgotten what they had read as their minds were flooded by the mass of material to which the media expose them. In order to get our message before the public with some chance of making a lasting impression, we've had to kill people.",TK,1541,"['96', 'constitutional', 'right', 'consider', 'example', 'freedom', 'press', 'certainly', 'dont', 'mean', 'knock', 'right', 'important', 'tool', 'limiting', 'concentration', 'political', 'power', 'keeping', 'political', 'power', 'line', 'publicly', 'exposing', 'misbehavior', 'part', 'freedom', 'press', 'little', 'use', 'average', 'citizen', 'individual', 'mass', 'medium', 'mostly', 'control', 'large', 'organization', 'integrated', 'system', 'anyone', 'ha', 'little', 'money', 'something', 'printed', 'distribute', 'internet', 'way', 'ha', 'say', 'swamped', 'vast', 'volume', 'material', 'put', 'medium', 'hence', 'practical', 'effect', 'make', 'impression', 'society', 'word', 'therefore', 'almost', 'impossible', 'individual', 'small', 'group', 'take', 'u', 'fc', 'example', 'never', 'done', 'anything', 'violent', 'submitted', 'present', 'writing', 'publisher', 'probably', 'would', 'accepted', 'accepted', 'published', 'probably', 'would', 'attracted', 'many', 'reader', 'fun', 'watch', 'entertainment', 'put', 'medium', 'read', 'sober', 'essay', 'even', 'writing', 'many', 'reader', 'reader', 'would', 'soon', 'forgotten', 'read', 'mind', 'flooded', 'mass', 'material', 'medium', 'expose', 'order', 'get', 'message', 'public', 'chance', 'making', 'lasting', 'impression', 'weve', 'kill', 'people']"
1851,"2. The industrial-technological system may survive or it may break down. If it survives, it MAY eventually achieve a low level of physical and psychological suffering, but only after passing through a long and very painful period of adjustment and only at the cost of permanently reducing human beings and many other living organisms to engineered products and mere cogs in the social machine. Furthermore, if the system survives, the consequences will be inevitable: There is no way of reforming or modifying the system so as to prevent it from depriving people of dignity and autonomy.",TK,587,"['2', 'industrialtechnological', 'system', 'may', 'survive', 'may', 'break', 'survives', 'may', 'eventually', 'achieve', 'low', 'level', 'physical', 'psychological', 'suffering', 'passing', 'long', 'painful', 'period', 'adjustment', 'cost', 'permanently', 'reducing', 'human', 'many', 'living', 'organism', 'engineered', 'product', 'mere', 'cog', 'social', 'machine', 'furthermore', 'system', 'survives', 'consequence', 'inevitable', 'way', 'reforming', 'modifying', 'system', 'prevent', 'depriving', 'people', 'dignity', 'autonomy']"
1852,"223. Some readers may say, ""This stuff about leftism is a lot of crap. I know John and Jane who are leftish types and they don't have all these totalitarian tendencies."" It's quite true that many leftists, possibly even a numerical majority, are decent people who sincerely believe in tolerating others' values (up to a point) and wouldn't want to use high-handed methods to reach their social goals. Our remarks about leftism are not meant to apply to every individual leftist but to describe the general character of leftism as a movement. And the general character of a movement is not necessarily determined by the numerical proportions of the various kinds of people involved in the movement.",TK,697,"['223', 'reader', 'may', 'say', 'stuff', 'leftism', 'lot', 'crap', 'know', 'john', 'jane', 'leftish', 'type', 'dont', 'totalitarian', 'tendency', 'quite', 'true', 'many', 'leftist', 'possibly', 'even', 'numerical', 'majority', 'decent', 'people', 'sincerely', 'believe', 'tolerating', 'others', 'value', 'point', 'wouldnt', 'want', 'use', 'highhanded', 'method', 'reach', 'social', 'goal', 'remark', 'leftism', 'meant', 'apply', 'every', 'individual', 'leftist', 'describe', 'general', 'character', 'leftism', 'movement', 'general', 'character', 'movement', 'necessarily', 'determined', 'numerical', 'proportion', 'various', 'kind', 'people', 'involved', 'movement']"
1853,"147. To start with, there are the techniques of surveillance. Hidden video cameras are now used in most stores and in many other places, computers are used to collect and process vast amounts of information about individuals. Information so obtained greatly increases the effectiveness of physical coercion (i.e., law enforcement).[26] Then there are the methods of propaganda, for which the mass communication media provide effective vehicles. Efficient techniques have been developed for winning elections, selling products, influencing public opinion. The entertainment industry serves as an important psychological tool of the system, possibly even when it is dishing out large amounts of sex and violence. Entertainment provides modern man with an essential means of escape. While absorbed in television, videos, etc., he can forget stress, anxiety, frustration, dissatisfaction. Many primitive peoples, when they don't have work to do, are quite content to sit for hours at a time doing nothing at all, because they are at peace with themselves and their world. But most modern people must be contantly occupied or entertained, otherwise the get ""bored,"" i.e., they get fidgety, uneasy, irritable.",TK,1203,"['147', 'start', 'technique', 'surveillance', 'hidden', 'video', 'camera', 'used', 'store', 'many', 'place', 'computer', 'used', 'collect', 'process', 'vast', 'amount', 'information', 'individual', 'information', 'obtained', 'greatly', 'increase', 'effectiveness', 'physical', 'coercion', 'ie', 'law', 'enforcement26', 'method', 'propaganda', 'mass', 'communication', 'medium', 'provide', 'effective', 'vehicle', 'efficient', 'technique', 'developed', 'winning', 'election', 'selling', 'product', 'influencing', 'public', 'opinion', 'entertainment', 'industry', 'serf', 'important', 'psychological', 'tool', 'system', 'possibly', 'even', 'dishing', 'large', 'amount', 'sex', 'violence', 'entertainment', 'provides', 'modern', 'man', 'essential', 'mean', 'escape', 'absorbed', 'television', 'video', 'etc', 'forget', 'stress', 'anxiety', 'frustration', 'dissatisfaction', 'many', 'primitive', 'people', 'dont', 'work', 'quite', 'content', 'sit', 'hour', 'time', 'nothing', 'peace', 'world', 'modern', 'people', 'must', 'contantly', 'occupied', 'entertained', 'otherwise', 'get', 'bored', 'ie', 'get', 'fidgety', 'uneasy', 'irritable']"
1854,"7. But what is leftism? During the first half of the 20th century leftism could have been practically identified with socialism. Today the movement is fragmented and it is not clear who can properly be called a leftist. When we speak of leftists in this article we have in mind mainly socialists, collectivists, ""politically correct"" types, feminists, gay and disability activists, animal rights activists and the like. But not everyone who is associated with one of these movements is a leftist. What we are trying to get at in discussing leftism is not so much a movement or an ideology as a psychological type, or rather a collection of related types. Thus, what we mean by ""leftism"" will emerge more clearly in the course of our discussion of leftist psychology (Also, see paragraphs 227-230.)",TK,797,"['7', 'leftism', 'first', 'half', '20th', 'century', 'leftism', 'could', 'practically', 'identified', 'socialism', 'today', 'movement', 'fragmented', 'clear', 'properly', 'called', 'leftist', 'speak', 'leftist', 'article', 'mind', 'mainly', 'socialist', 'collectivist', 'politically', 'correct', 'type', 'feminist', 'gay', 'disability', 'activist', 'animal', 'right', 'activist', 'like', 'everyone', 'associated', 'one', 'movement', 'leftist', 'trying', 'get', 'discussing', 'leftism', 'much', 'movement', 'ideology', 'psychological', 'type', 'rather', 'collection', 'related', 'type', 'thus', 'mean', 'leftism', 'emerge', 'clearly', 'course', 'discussion', 'leftist', 'psychology', 'also', 'see', 'paragraph', '227230']"
1855,"104. FOURTH PRINCIPLE. A new kind of society cannot be designed on paper. That is, you cannot plan out a new form of society in advance, then set it up and expect it to function as it was designed to.",TK,200,"['104', 'fourth', 'principle', 'new', 'kind', 'society', 'cannot', 'designed', 'paper', 'cannot', 'plan', 'new', 'form', 'society', 'advance', 'set', 'expect', 'function', 'wa', 'designed']"
1856,"166. Therefore two tasks confront those who hate the servitude to which the industrial system is reducing the human race. First, we must work to heighten the social stresses within the system so as to increase the likelihood that it will break down or be weakened sufficiently so that a revolution against it becomes possible. Second, it is necessary to develop and propagate an ideology that opposes technology and the industrial society if and when the system becomes sufficiently weakened. And such an ideology will help to assure that, if and when industrial society breaks down, its remnants will be smashed beyond repair, so that the system cannot be reconstituted. The factories should be destroyed, technical books burned, etc.",TK,735,"['166', 'therefore', 'two', 'task', 'confront', 'hate', 'servitude', 'industrial', 'system', 'reducing', 'human', 'race', 'first', 'must', 'work', 'heighten', 'social', 'stress', 'within', 'system', 'increase', 'likelihood', 'break', 'weakened', 'sufficiently', 'revolution', 'becomes', 'possible', 'second', 'necessary', 'develop', 'propagate', 'ideology', 'opposes', 'technology', 'industrial', 'society', 'system', 'becomes', 'sufficiently', 'weakened', 'ideology', 'help', 'assure', 'industrial', 'society', 'break', 'remnant', 'smashed', 'beyond', 'repair', 'system', 'cannot', 'reconstituted', 'factory', 'destroyed', 'technical', 'book', 'burned', 'etc']"
1857,"99. Think of history as being the sum of two components: an erratic component that consists of unpredictable events that follow no discernible pattern, and a regular component that consists of long-term historical trends. Here we are concerned with the long-term trends.",TK,270,"['99', 'think', 'history', 'sum', 'two', 'component', 'erratic', 'component', 'consists', 'unpredictable', 'event', 'follow', 'discernible', 'pattern', 'regular', 'component', 'consists', 'longterm', 'historical', 'trend', 'concerned', 'longterm', 'trend']"
1858,23. We emphasize that the foregoing does not pretend to be an accurate description of everyone who might be considered a leftist. It is only a rough indication of a general tendency of leftism.,TK,193,"['23', 'emphasize', 'foregoing', 'doe', 'pretend', 'accurate', 'description', 'everyone', 'might', 'considered', 'leftist', 'rough', 'indication', 'general', 'tendency', 'leftism']"
1859,"22. If our society had no social problems at all, the leftists would have to INVENT problems in order to provide themselves with an excuse for making a fuss.",TK,157,"['22', 'society', 'social', 'problem', 'leftist', 'would', 'invent', 'problem', 'order', 'provide', 'excuse', 'making', 'fuss']"
1860,"66. Today people live more by virtue of what the system does FOR them or TO them than by virtue of what they do for themselves. And what they do for themselves is done more and more along channels laid down by the system. Opportunities tend to be those that the system provides, the opportunities must be exploited in accord with the rules and regulations [13], and techniques prescribed by experts must be followed if there is to be a chance of success.",TK,454,"['66', 'today', 'people', 'live', 'virtue', 'system', 'doe', 'virtue', 'done', 'along', 'channel', 'laid', 'system', 'opportunity', 'tend', 'system', 'provides', 'opportunity', 'must', 'exploited', 'accord', 'rule', 'regulation', '13', 'technique', 'prescribed', 'expert', 'must', 'followed', 'chance', 'success']"
1861,"49. For primitive societies the natural world (which usually changes only slowly) provided a stable framework and therefore a sense of security. In the modern world it is human society that dominates nature rather than the other way around, and modern society changes very rapidly owing to technological change. Thus there is no stable framework.",TK,346,"['49', 'primitive', 'society', 'natural', 'world', 'usually', 'change', 'slowly', 'provided', 'stable', 'framework', 'therefore', 'sense', 'security', 'modern', 'world', 'human', 'society', 'dominates', 'nature', 'rather', 'way', 'around', 'modern', 'society', 'change', 'rapidly', 'owing', 'technological', 'change', 'thus', 'stable', 'framework']"
1862,"177. Needless to day, the scenarios outlined above do not exhaust all the possibilities. They only indicate the kinds of outcomes that seem to us mots likely. But wee can envision no plausible scenarios that are any more palatable that the ones we've just described. It is overwhelmingly probable that if the industrial-technological system survives the next 40 to 100 years, it will by that time have developed certain general characteristics: Individuals (at least those of the ""bourgeois"" type, who are integrated into the system and make it run, and who therefore have all the power) will be more dependent than ever on large organizations; they will be more ""socialized"" that ever and their physical and mental qualities to a significant extent (possibly to a very great extent ) will be those that are engineered into them rather than being the results of chance (or of God's will, or whatever); and whatever may be left of wild nature will be reduced to remnants preserved for scientific study and kept under the supervision and management of scientists (hence it will no longer be truly wild). In the long run (say a few centuries from now) it is it is likely that neither the human race nor any other important organisms will exist as we know them today, because once you start modifying organisms through genetic engineering there is no reason to stop at any particular point, so that the modifications will probably continue until man and other organisms have been utterly transformed.",TK,1496,"['177', 'needle', 'day', 'scenario', 'outlined', 'exhaust', 'possibility', 'indicate', 'kind', 'outcome', 'seem', 'u', 'mot', 'likely', 'wee', 'envision', 'plausible', 'scenario', 'palatable', 'one', 'weve', 'described', 'overwhelmingly', 'probable', 'industrialtechnological', 'system', 'survives', 'next', '40', '100', 'year', 'time', 'developed', 'certain', 'general', 'characteristic', 'individual', 'least', 'bourgeois', 'type', 'integrated', 'system', 'make', 'run', 'therefore', 'power', 'dependent', 'ever', 'large', 'organization', 'socialized', 'ever', 'physical', 'mental', 'quality', 'significant', 'extent', 'possibly', 'great', 'extent', '', 'engineered', 'rather', 'result', 'chance', 'god', 'whatever', 'whatever', 'may', 'left', 'wild', 'nature', 'reduced', 'remnant', 'preserved', 'scientific', 'study', 'kept', 'supervision', 'management', 'scientist', 'hence', 'longer', 'truly', 'wild', 'long', 'run', 'say', 'century', 'likely', 'neither', 'human', 'race', 'important', 'organism', 'exist', 'know', 'today', 'start', 'modifying', 'organism', 'genetic', 'engineering', 'reason', 'stop', 'particular', 'point', 'modification', 'probably', 'continue', 'man', 'organism', 'utterly', 'transformed']"
1863,"155. Our society tends to regard as a ""sickness"" any mode of thought or behavior that is inconvenient for the system, and this is plausible because when an individual doesn't fit into the system it causes pain to the individual as well as problems for the system. Thus the manipulation of an individual to adjust him to the system is seen as a ""cure"" for a ""sickness"" and therefore as good.",TK,390,"['155', 'society', 'tends', 'regard', 'sickness', 'mode', 'thought', 'behavior', 'inconvenient', 'system', 'plausible', 'individual', 'doesnt', 'fit', 'system', 'cause', 'pain', 'individual', 'well', 'problem', 'system', 'thus', 'manipulation', 'individual', 'adjust', 'system', 'seen', 'cure', 'sickness', 'therefore', 'good']"
1864,"16. Words like ""self-confidence,"" ""self-reliance,"" ""initiative"", ""enterprise,"" ""optimism,"" etc. play little role in the liberal and leftist vocabulary. The leftist is anti-individualistic, pro-collectivist. He wants society to solve everyone's needs for them, take care of them. He is not the sort of person who has an inner sense of confidence in his own ability to solve his own problems and satisfy his own needs. The leftist is antagonistic to the concept of competition because, deep inside, he feels like a loser.",TK,519,"['16', 'word', 'like', 'selfconfidence', 'selfreliance', 'initiative', 'enterprise', 'optimism', 'etc', 'play', 'little', 'role', 'liberal', 'leftist', 'vocabulary', 'leftist', 'antiindividualistic', 'procollectivist', 'want', 'society', 'solve', 'everyones', 'need', 'take', 'care', 'sort', 'person', 'ha', 'inner', 'sense', 'confidence', 'ability', 'solve', 'problem', 'satisfy', 'need', 'leftist', 'antagonistic', 'concept', 'competition', 'deep', 'inside', 'feel', 'like', 'loser']"
1865,"70. Thus primitive man for the most part has his security in his own hands (either as an individual or as a member of a SMALL group) whereas the security of modern man is in the hands of persons or organizations that are too remote or too large for him to be able personally to influence them. So modern man's drive for security tends to fall into groups 1 and 3; in some areas (food, shelter, etc.) his security is assured at the cost of only trivial effort, whereas in other areas he CANNOT attain security. (The foregoing greatly simplifies the real situation, but it does indicate in a rough, general way how the condition of modern man differs from that of primitive man.)",TK,677,"['70', 'thus', 'primitive', 'man', 'part', 'ha', 'security', 'hand', 'either', 'individual', 'member', 'small', 'group', 'whereas', 'security', 'modern', 'man', 'hand', 'person', 'organization', 'remote', 'large', 'able', 'personally', 'influence', 'modern', 'man', 'drive', 'security', 'tends', 'fall', 'group', '1', '3', 'area', 'food', 'shelter', 'etc', 'security', 'assured', 'cost', 'trivial', 'effort', 'whereas', 'area', 'cannot', 'attain', 'security', 'foregoing', 'greatly', 'simplifies', 'real', 'situation', 'doe', 'indicate', 'rough', 'general', 'way', 'condition', 'modern', 'man', 'differs', 'primitive', 'man']"
1866,"141. People tend to assume that because a revolution involves a much greater change than reform does, it is more difficult to bring about than reform is. Actually, under certain circumstances revolution is much easier than reform. The reason is that a revolutionary movement can inspire an intensity of commitment that a reform movement cannot inspire. A reform movement merely offers to solve a particular social problem A revolutionary movement offers to solve all problems at one stroke and create a whole new world; it provides the kind of ideal for which people will take great risks and make great sacrifices. For this reasons it would be much easier to overthrow the whole technological system than to put effective, permanent restraints on the development of application of any one segment of technology, such as genetic engineering, but under suitable conditions large numbers of people may devote themselves passionately to a revolution against the industrial-technological system. As we noted in paragraph 132, reformers seeking to limite certain aspects of technology would be working to avoid a negative outcome. But revolutionaries work to gain a powerful reward -- fulfillment of their revolutionary vision -- and therefore work harder and more persistently than reformers do.",TK,1291,"['141', 'people', 'tend', 'assume', 'revolution', 'involves', 'much', 'greater', 'change', 'reform', 'doe', 'difficult', 'bring', 'reform', 'actually', 'certain', 'circumstance', 'revolution', 'much', 'easier', 'reform', 'reason', 'revolutionary', 'movement', 'inspire', 'intensity', 'commitment', 'reform', 'movement', 'cannot', 'inspire', 'reform', 'movement', 'merely', 'offer', 'solve', 'particular', 'social', 'problem', 'revolutionary', 'movement', 'offer', 'solve', 'problem', 'one', 'stroke', 'create', 'whole', 'new', 'world', 'provides', 'kind', 'ideal', 'people', 'take', 'great', 'risk', 'make', 'great', 'sacrifice', 'reason', 'would', 'much', 'easier', 'overthrow', 'whole', 'technological', 'system', 'put', 'effective', 'permanent', 'restraint', 'development', 'application', 'one', 'segment', 'technology', 'genetic', 'engineering', 'suitable', 'condition', 'large', 'number', 'people', 'may', 'devote', 'passionately', 'revolution', 'industrialtechnological', 'system', 'noted', 'paragraph', '132', 'reformer', 'seeking', 'limite', 'certain', 'aspect', 'technology', 'would', 'working', 'avoid', 'negative', 'outcome', 'revolutionary', 'work', 'gain', 'powerful', 'reward', '', 'fulfillment', 'revolutionary', 'vision', '', 'therefore', 'work', 'harder', 'persistently', 'reformer']"
1867,"31. We realize that many objections could be raised to the foregoing thumb-nail sketch of leftist psychology. The real situation is complex, and anything like a complete description of it would take several volumes even if the necessary data were available. We claim only to have indicated very roughly the two most important tendencies in the psychology of modern leftism.",TK,373,"['31', 'realize', 'many', 'objection', 'could', 'raised', 'foregoing', 'thumbnail', 'sketch', 'leftist', 'psychology', 'real', 'situation', 'complex', 'anything', 'like', 'complete', 'description', 'would', 'take', 'several', 'volume', 'even', 'necessary', 'data', 'available', 'claim', 'indicated', 'roughly', 'two', 'important', 'tendency', 'psychology', 'modern', 'leftism']"
1868,"222. Leftists, especially those of the oversocialized type, are True Believers in the sense of Eric Hoffer's book, ""The True Believer."" But not all True Believers are of the same psychological type as leftists. Presumably a truebelieving nazi, for instance is very different psychologically from a truebelieving leftist. Because of their capacity for single-minded devotion to a cause, True Believers are a useful, perhaps a necessary, ingredient of any revolutionary movement. This presents a problem with which we must admit we don't know how to deal. We aren't sure how to harness the energies of the True Believer to a revolution against technology. At present all we can say is that no True Believer will make a safe recruit to the revolution unless his commitment is exclusively to the destruction of technology. If he is committed also to another ideal, he may want to use technology as a tool for pursuing that other ideal (see paragraphs 220, 221).",TK,957,"['222', 'leftist', 'especially', 'oversocialized', 'type', 'true', 'believer', 'sense', 'eric', 'hoffers', 'book', 'true', 'believer', 'true', 'believer', 'psychological', 'type', 'leftist', 'presumably', 'truebelieving', 'nazi', 'instance', 'different', 'psychologically', 'truebelieving', 'leftist', 'capacity', 'singleminded', 'devotion', 'cause', 'true', 'believer', 'useful', 'perhaps', 'necessary', 'ingredient', 'revolutionary', 'movement', 'present', 'problem', 'must', 'admit', 'dont', 'know', 'deal', 'arent', 'sure', 'harness', 'energy', 'true', 'believer', 'revolution', 'technology', 'present', 'say', 'true', 'believer', 'make', 'safe', 'recruit', 'revolution', 'unless', 'commitment', 'exclusively', 'destruction', 'technology', 'committed', 'also', 'another', 'ideal', 'may', 'want', 'use', 'technology', 'tool', 'pursuing', 'ideal', 'see', 'paragraph', '220', '221']"
1869,"217. In earlier revolutions, leftists of the most power-hungry type, repeatedly, have first cooperated with non-leftist revolutionaries, as well as with leftists of a more libertarian inclination, and later have double-crossed them to seize power for themselves. Robespierre did this in the French Revolution, the Bolsheviks did it in the Russian Revolution, the communists did it in Spain in 1938 and Castro and his followers did it in Cuba. Given the past history of leftism, it would be utterly foolish for non-leftist revolutionaries today to collaborate with leftists.",TK,573,"['217', 'earlier', 'revolution', 'leftist', 'powerhungry', 'type', 'repeatedly', 'first', 'cooperated', 'nonleftist', 'revolutionary', 'well', 'leftist', 'libertarian', 'inclination', 'later', 'doublecrossed', 'seize', 'power', 'robespierre', 'french', 'revolution', 'bolshevik', 'russian', 'revolution', 'communist', 'spain', '1938', 'castro', 'follower', 'cuba', 'given', 'past', 'history', 'leftism', 'would', 'utterly', 'foolish', 'nonleftist', 'revolutionary', 'today', 'collaborate', 'leftist']"
1870,"44. But for most people it is through the power process-having a goal, making an AUTONOMOUS effort and attaining t the goal-that self-esteem, self-confidence and a sense of power are acquired. When one does not have adequate opportunity to go throughout the power process the consequences are (depending on the individual and on the way the power process is disrupted) boredom, demoralization, low self-esteem, inferiority feelings, defeatism, depression, anxiety, guilt, frustration, hostility, spouse or child abuse, insatiable hedonism, abnormal sexual behavior, sleep disorders, eating disorders, etc. [6]",TK,609,"['44', 'people', 'power', 'processhaving', 'goal', 'making', 'autonomous', 'effort', 'attaining', 'goalthat', 'selfesteem', 'selfconfidence', 'sense', 'power', 'acquired', 'one', 'doe', 'adequate', 'opportunity', 'go', 'throughout', 'power', 'process', 'consequence', 'depending', 'individual', 'way', 'power', 'process', 'disrupted', 'boredom', 'demoralization', 'low', 'selfesteem', 'inferiority', 'feeling', 'defeatism', 'depression', 'anxiety', 'guilt', 'frustration', 'hostility', 'spouse', 'child', 'abuse', 'insatiable', 'hedonism', 'abnormal', 'sexual', 'behavior', 'sleep', 'disorder', 'eating', 'disorder', 'etc', '6']"
1871,"163. Suppose the system survives the crisis of the next several decades. By that time it will have to have solved, or at least brought under control, the principal problems that confront it, in particular that of ""socializing"" human beings; that is, making people sufficiently docile so that their behavior no longer threatens the system. That being accomplished, it does not appear that there would be any further obstacle to the development of technology, and it would presumably advance toward its logical conclusion, which is complete control over everything on Earth, including human beings and all other important organisms. The system may become a unitary, monolithic organization, or it may be more or less fragmented and consist of a number of organizations coexisting in a relationship that includes elements of both cooperation and competition, just as today the government, the corporations and other large organizations both cooperate and compete with one another. Human freedom mostly will have vanished, because individuals and small groups will be impotent vis-a-vis large organizations armed with supertechnology and an arsenal of advanced psychological and biological tools for manipulating human beings, besides instruments of surveillance and physical coercion. Only a small number of people will have any real power, and even these probably will have only very limited freedom, because their behavior too will be regulated; just as today our politicians and corporation executives can retain their positions of power only as long as their behavior remains within certain fairly narrow limits.",TK,1613,"['163', 'suppose', 'system', 'survives', 'crisis', 'next', 'several', 'decade', 'time', 'solved', 'least', 'brought', 'control', 'principal', 'problem', 'confront', 'particular', 'socializing', 'human', 'making', 'people', 'sufficiently', 'docile', 'behavior', 'longer', 'threatens', 'system', 'accomplished', 'doe', 'appear', 'would', 'obstacle', 'development', 'technology', 'would', 'presumably', 'advance', 'toward', 'logical', 'conclusion', 'complete', 'control', 'everything', 'earth', 'including', 'human', 'important', 'organism', 'system', 'may', 'become', 'unitary', 'monolithic', 'organization', 'may', 'le', 'fragmented', 'consist', 'number', 'organization', 'coexisting', 'relationship', 'includes', 'element', 'cooperation', 'competition', 'today', 'government', 'corporation', 'large', 'organization', 'cooperate', 'compete', 'one', 'another', 'human', 'freedom', 'mostly', 'vanished', 'individual', 'small', 'group', 'impotent', 'visavis', 'large', 'organization', 'armed', 'supertechnology', 'arsenal', 'advanced', 'psychological', 'biological', 'tool', 'manipulating', 'human', 'besides', 'instrument', 'surveillance', 'physical', 'coercion', 'small', 'number', 'people', 'real', 'power', 'even', 'probably', 'limited', 'freedom', 'behavior', 'regulated', 'today', 'politician', 'corporation', 'executive', 'retain', 'position', 'power', 'long', 'behavior', 'remains', 'within', 'certain', 'fairly', 'narrow', 'limit']"
1872,"215. The anarchist [34] too seeks power, but he seeks it on an individual or small-group basis; he wants individuals and small groups to be able to control the circumstances of their own lives. He opposes technology because it makes small groups dependent on large organizations.",TK,279,"['215', 'anarchist', '34', 'seek', 'power', 'seek', 'individual', 'smallgroup', 'basis', 'want', 'individual', 'small', 'group', 'able', 'control', 'circumstance', 'life', 'opposes', 'technology', 'make', 'small', 'group', 'dependent', 'large', 'organization']"
1873,"110. Still, one has to use common sense in applying the principles. They are expressed in imprecise language that allows latitude for interpretation, and exceptions to them can be found. So we present these principles not as inviolable laws but as rules of thumb, or guides to thinking, that may provide a partial antidote to naive ideas about the future of society. The principles should be borne constantly in mind, and whenever one reaches a conclusion that conflicts with them one should carefully reexamine one's thinking and retain the conclusion only if one has good, solid reasons for doing so.",TK,602,"['110', 'still', 'one', 'ha', 'use', 'common', 'sense', 'applying', 'principle', 'expressed', 'imprecise', 'language', 'allows', 'latitude', 'interpretation', 'exception', 'found', 'present', 'principle', 'inviolable', 'law', 'rule', 'thumb', 'guide', 'thinking', 'may', 'provide', 'partial', 'antidote', 'naive', 'idea', 'future', 'society', 'principle', 'borne', 'constantly', 'mind', 'whenever', 'one', 'reach', 'conclusion', 'conflict', 'one', 'carefully', 'reexamine', 'one', 'thinking', 'retain', 'conclusion', 'one', 'ha', 'good', 'solid', 'reason']"
1874,"76. In response to the arguments of this section someone will say, ""Society must find a way to give people the opportunity to go through the power process."" For such people the value of the opportunity is destroyed by the very fact that society gives it to them. What they need is to find or make their own opportunities. As long as the system GIVES them their opportunities it still has them on a leash. To attain autonomy they must get off that leash.",TK,453,"['76', 'response', 'argument', 'section', 'someone', 'say', 'society', 'must', 'find', 'way', 'give', 'people', 'opportunity', 'go', 'power', 'process', 'people', 'value', 'opportunity', 'destroyed', 'fact', 'society', 'give', 'need', 'find', 'make', 'opportunity', 'long', 'system', 'give', 'opportunity', 'still', 'ha', 'leash', 'attain', 'autonomy', 'must', 'get', 'leash']"
1875,"186. Most people hate psychological conflict. For this reason they avoid doing any serious thinking about difficult social issues, and they like to have such issues presented to them in simple, black-and-white terms: THIS is all good and THAT is all bad. The revolutionary ideology should therefore be developed on two levels.",TK,326,"['186', 'people', 'hate', 'psychological', 'conflict', 'reason', 'avoid', 'serious', 'thinking', 'difficult', 'social', 'issue', 'like', 'issue', 'presented', 'simple', 'blackandwhite', 'term', 'good', 'bad', 'revolutionary', 'ideology', 'therefore', 'developed', 'two', 'level']"
1876,"156. In paragraph 127 we pointed out that if the use of a new item of technology is INITIALLY optional, it does not necessarily REMAIN optional, because the new technology tends to change society in such a way that it becomes difficult or impossible for an individual to function without using that technology. This applies also to the technology of human behavior. In a world in which most children are put through a program to make them enthusiastic about studying, a parent will almost be forced to put his kid through such a program, because if he does not, then the kid will grow up to be, comparatively speaking, an ignoramus and therefore unemployable. Or suppose a biological treatment is discovered that, without undesirable side-effects, will greatly reduce the psychological stress from which so many people suffer in our society. If large numbers of people choose to undergo the treatment, then the general level of stress in society will be reduced, so that it will be possible for the system to increase the stress-producing pressures. In fact, something like this seems to have happened already with one of our society's most important psychological tools for enabling people to reduce (or at least temporarily escape from) stress, namely, mass entertainment (see paragraph 147). Our use of mass entertainment is ""optional"": No law requires us to watch television, listen to the radio, read magazines. Yet mass entertainment is a means of escape and stress-reduction on which most of us have become dependent. Everyone complains about the trashiness of television, but almost everyone watches it. A few have kicked the TV habit, but it would be a rare person who could get along today without using ANY form of mass entertainment. (Yet until quite recently in human history most people got along very nicely with no other entertainment than that which each local community created for itself.) Without the entertainment industry the system probably would not have been able to get away with putting as much stress-producing pressure on us as it does.",TK,2065,"['156', 'paragraph', '127', 'pointed', 'use', 'new', 'item', 'technology', 'initially', 'optional', 'doe', 'necessarily', 'remain', 'optional', 'new', 'technology', 'tends', 'change', 'society', 'way', 'becomes', 'difficult', 'impossible', 'individual', 'function', 'without', 'using', 'technology', 'applies', 'also', 'technology', 'human', 'behavior', 'world', 'child', 'put', 'program', 'make', 'enthusiastic', 'studying', 'parent', 'almost', 'forced', 'put', 'kid', 'program', 'doe', 'kid', 'grow', 'comparatively', 'speaking', 'ignoramus', 'therefore', 'unemployable', 'suppose', 'biological', 'treatment', 'discovered', 'without', 'undesirable', 'sideeffects', 'greatly', 'reduce', 'psychological', 'stress', 'many', 'people', 'suffer', 'society', 'large', 'number', 'people', 'choose', 'undergo', 'treatment', 'general', 'level', 'stress', 'society', 'reduced', 'possible', 'system', 'increase', 'stressproducing', 'pressure', 'fact', 'something', 'like', 'seems', 'happened', 'already', 'one', 'society', 'important', 'psychological', 'tool', 'enabling', 'people', 'reduce', 'least', 'temporarily', 'escape', 'stress', 'namely', 'mass', 'entertainment', 'see', 'paragraph', '147', 'use', 'mass', 'entertainment', 'optional', 'law', 'requires', 'u', 'watch', 'television', 'listen', 'radio', 'read', 'magazine', 'yet', 'mass', 'entertainment', 'mean', 'escape', 'stressreduction', 'u', 'become', 'dependent', 'everyone', 'complains', 'trashiness', 'television', 'almost', 'everyone', 'watch', 'kicked', 'tv', 'habit', 'would', 'rare', 'person', 'could', 'get', 'along', 'today', 'without', 'using', 'form', 'mass', 'entertainment', 'yet', 'quite', 'recently', 'human', 'history', 'people', 'got', 'along', 'nicely', 'entertainment', 'local', 'community', 'created', 'without', 'entertainment', 'industry', 'system', 'probably', 'would', 'able', 'get', 'away', 'putting', 'much', 'stressproducing', 'pressure', 'u', 'doe']"
1877,"143. Since the beginning of civilization, organized societies have had to put pressures on human beings of the sake of the functioning of the social organism. The kinds of pressures vary greatly from one society to another. Some of the pressures are physical (poor diet, excessive labor, environmental pollution), some are psychological (noise, crowding, forcing humans behavior into the mold that society requires). In the past, human nature has been approximately constant, or at any rate has varied only within certain bounds. Consequently, societies have been able to push people only up to certain limits. When the limit of human endurance has been passed, things start going rong: rebellion, or crime, or corruption, or evasion of work, or depression and other mental problems, or an elevated death rate, or a declining birth rate or something else, so that either the society breaks down, or its functioning becomes too inefficient and it is (quickly or gradually, through conquest, attrition or evolution) replaces by some more efficient form of society. [25]",TK,1067,"['143', 'since', 'beginning', 'civilization', 'organized', 'society', 'put', 'pressure', 'human', 'sake', 'functioning', 'social', 'organism', 'kind', 'pressure', 'vary', 'greatly', 'one', 'society', 'another', 'pressure', 'physical', 'poor', 'diet', 'excessive', 'labor', 'environmental', 'pollution', 'psychological', 'noise', 'crowding', 'forcing', 'human', 'behavior', 'mold', 'society', 'requires', 'past', 'human', 'nature', 'ha', 'approximately', 'constant', 'rate', 'ha', 'varied', 'within', 'certain', 'bound', 'consequently', 'society', 'able', 'push', 'people', 'certain', 'limit', 'limit', 'human', 'endurance', 'ha', 'passed', 'thing', 'start', 'going', 'rong', 'rebellion', 'crime', 'corruption', 'evasion', 'work', 'depression', 'mental', 'problem', 'elevated', 'death', 'rate', 'declining', 'birth', 'rate', 'something', 'else', 'either', 'society', 'break', 'functioning', 'becomes', 'inefficient', 'quickly', 'gradually', 'conquest', 'attrition', 'evolution', 'replaces', 'efficient', 'form', 'society', '25']"
1878,106. FIFTH PRINCIPLE. People do not consciously and rationally choose the form of their society. Societies develop through processes of social evolution that are not under rational human control.,TK,195,"['106', 'fifth', 'principle', 'people', 'consciously', 'rationally', 'choose', 'form', 'society', 'society', 'develop', 'process', 'social', 'evolution', 'rational', 'human', 'control']"
1879,"9. The two psychological tendencies that underlie modern leftism we call ""feelings of inferiority"" and ""oversocialization."" Feelings of inferiority are characteristic of modern leftism as a whole, while oversocialization is characteristic only of a certain segment of modern leftism; but this segment is highly influential.",TK,323,"['9', 'two', 'psychological', 'tendency', 'underlie', 'modern', 'leftism', 'call', 'feeling', 'inferiority', 'oversocialization', 'feeling', 'inferiority', 'characteristic', 'modern', 'leftism', 'whole', 'oversocialization', 'characteristic', 'certain', 'segment', 'modern', 'leftism', 'segment', 'highly', 'influential']"
1880,"165. But suppose on the other hand that the stresses of the coming decades prove to be too much for the system. If the system breaks down there may be a period of chaos, a ""time of troubles"" such as those that history has recorded: at various epochs in the past. It is impossible to predict what would emerge from such a time of troubles, but at any rate the human race would be given a new chance. The greatest danger is that industrial society may begin to reconstitute itself within the first few years after the breakdown. Certainly there will be many people (power-hungry types especially) who will be anxious to get the factories running again.",TK,650,"['165', 'suppose', 'hand', 'stress', 'coming', 'decade', 'prove', 'much', 'system', 'system', 'break', 'may', 'period', 'chaos', 'time', 'trouble', 'history', 'ha', 'recorded', 'various', 'epoch', 'past', 'impossible', 'predict', 'would', 'emerge', 'time', 'trouble', 'rate', 'human', 'race', 'would', 'given', 'new', 'chance', 'greatest', 'danger', 'industrial', 'society', 'may', 'begin', 'reconstitute', 'within', 'first', 'year', 'breakdown', 'certainly', 'many', 'people', 'powerhungry', 'type', 'especially', 'anxious', 'get', 'factory', 'running']"
1881,"189. Prior to that final struggle, the revolutionaries should not expect to have a majority of people on their side. History is made by active, determined minorities, not by the majority, which seldom has a clear and consistent idea of what it really wants. Until the time comes for the final push toward revolution [31], the task of revolutionaries will be less to win the shallow support of the majority than to build a small core of deeply committed people. As for the majority, it will be enough to make them aware of the existence of the new ideology and remind them of it frequently; though of course it will be desirable to get majority support to the extent that this can be done without weakening the core of seriously committed people.",TK,745,"['189', 'prior', 'final', 'struggle', 'revolutionary', 'expect', 'majority', 'people', 'side', 'history', 'made', 'active', 'determined', 'minority', 'majority', 'seldom', 'ha', 'clear', 'consistent', 'idea', 'really', 'want', 'time', 'come', 'final', 'push', 'toward', 'revolution', '31', 'task', 'revolutionary', 'le', 'win', 'shallow', 'support', 'majority', 'build', 'small', 'core', 'deeply', 'committed', 'people', 'majority', 'enough', 'make', 'aware', 'existence', 'new', 'ideology', 'remind', 'frequently', 'though', 'course', 'desirable', 'get', 'majority', 'support', 'extent', 'done', 'without', 'weakening', 'core', 'seriously', 'committed', 'people']"
1882,"231. Throughout this article we've made imprecise statements and statements that ought to have had all sorts of qualifications and reservations attached to them; and some of our statements may be flatly false. Lack of sufficient information and the need for brevity made it impossible for us to fomulate our assertions more precisely or add all the necessary qualifications. And of course in a discussion of this kind one must rely heavily on intuitive judgment, and that can sometimes be wrong. So we don't claim that this article expresses more than a crude approximation to the truth.",TK,587,"['231', 'throughout', 'article', 'weve', 'made', 'imprecise', 'statement', 'statement', 'ought', 'sort', 'qualification', 'reservation', 'attached', 'statement', 'may', 'flatly', 'false', 'lack', 'sufficient', 'information', 'need', 'brevity', 'made', 'impossible', 'u', 'fomulate', 'assertion', 'precisely', 'add', 'necessary', 'qualification', 'course', 'discussion', 'kind', 'one', 'must', 'rely', 'heavily', 'intuitive', 'judgment', 'sometimes', 'wrong', 'dont', 'claim', 'article', 'express', 'crude', 'approximation', 'truth']"
1883,"56.Furthermore, change in American frontier society was very rapid and deep. A man might be born and raised in a log cabin, outside the reach of law and order and fed largely on wild meat; and by the time he arrived at old age he might be working at a regular job and living in an ordered community with effective law enforcement. This was a deeper change that that which typically occurs in the life of a modern individual, yet it does not seem to have led to psychological problems. In fact, 19th century American society had an optimistic and self-confident tone, quite unlike that of today's society. [8]",TK,608,"['56furthermore', 'change', 'american', 'frontier', 'society', 'wa', 'rapid', 'deep', 'man', 'might', 'born', 'raised', 'log', 'cabin', 'outside', 'reach', 'law', 'order', 'fed', 'largely', 'wild', 'meat', 'time', 'arrived', 'old', 'age', 'might', 'working', 'regular', 'job', 'living', 'ordered', 'community', 'effective', 'law', 'enforcement', 'wa', 'deeper', 'change', 'typically', 'occurs', 'life', 'modern', 'individual', 'yet', 'doe', 'seem', 'led', 'psychological', 'problem', 'fact', '19th', 'century', 'american', 'society', 'optimistic', 'selfconfident', 'tone', 'quite', 'unlike', 'today', 'society', '8']"
1884,"79. Some people may have some exceptional drive, in pursuing which they satisfy their need for the power process. For example, those who have an unusually strong drive for social status may spend their whole lives climbing the status ladder without ever getting bored with that game.",TK,283,"['79', 'people', 'may', 'exceptional', 'drive', 'pursuing', 'satisfy', 'need', 'power', 'process', 'example', 'unusually', 'strong', 'drive', 'social', 'status', 'may', 'spend', 'whole', 'life', 'climbing', 'status', 'ladder', 'without', 'ever', 'getting', 'bored', 'game']"
1885,"75. In primitive societies life is a succession of stages. The needs and purposes of one stage having been fulfilled, there is no particular reluctance about passing on to the next stage. A young man goes through the power process by becoming a hunter, hunting not for sport or for fulfillment but to get meat that is necessary for food. (In young women the process is more complex, with greater emphasis on social power; we won't discuss that here.) This phase having been successfully passed through, the young man has no reluctance about settling down to the responsibilities of raising a family. (In contrast, some modern people indefinitely postpone having children because they are too busy seeking some kind of ""fulfillment."" We suggest that the fulfillment they need is adequate experience of the power process -- with real goals instead of the artificial goals of surrogate activities.) Again, having successfully raised his children, going through the power process by providing them with the physical necessities, the primitive man feels that his work is done and he is prepared to accept old age (if he survives that long) and death. Many modern people, on the other hand, are disturbed by the prospect of death, as is shown by the amount of effort they expend trying to maintain their physical condition, appearance and health. We argue that this is due to unfulfillment resulting from the fact that they have never put their physical powers to any use, have never gone through the power process using their bodies in a serious way. It is not the primitive man, who has used his body daily for practical purposes, who fears the deterioration of age, but the modern man, who has never had a practical use for his body beyond walking from his car to his house. It is the man whose need for the power process has been satisfied during his life who is best prepared to accept the end of that life.",TK,1906,"['75', 'primitive', 'society', 'life', 'succession', 'stage', 'need', 'purpose', 'one', 'stage', 'fulfilled', 'particular', 'reluctance', 'passing', 'next', 'stage', 'young', 'man', 'go', 'power', 'process', 'becoming', 'hunter', 'hunting', 'sport', 'fulfillment', 'get', 'meat', 'necessary', 'food', 'young', 'woman', 'process', 'complex', 'greater', 'emphasis', 'social', 'power', 'wont', 'discus', 'phase', 'successfully', 'passed', 'young', 'man', 'ha', 'reluctance', 'settling', 'responsibility', 'raising', 'family', 'contrast', 'modern', 'people', 'indefinitely', 'postpone', 'child', 'busy', 'seeking', 'kind', 'fulfillment', 'suggest', 'fulfillment', 'need', 'adequate', 'experience', 'power', 'process', '', 'real', 'goal', 'instead', 'artificial', 'goal', 'surrogate', 'activity', 'successfully', 'raised', 'child', 'going', 'power', 'process', 'providing', 'physical', 'necessity', 'primitive', 'man', 'feel', 'work', 'done', 'prepared', 'accept', 'old', 'age', 'survives', 'long', 'death', 'many', 'modern', 'people', 'hand', 'disturbed', 'prospect', 'death', 'shown', 'amount', 'effort', 'expend', 'trying', 'maintain', 'physical', 'condition', 'appearance', 'health', 'argue', 'due', 'unfulfillment', 'resulting', 'fact', 'never', 'put', 'physical', 'power', 'use', 'never', 'gone', 'power', 'process', 'using', 'body', 'serious', 'way', 'primitive', 'man', 'ha', 'used', 'body', 'daily', 'practical', 'purpose', 'fear', 'deterioration', 'age', 'modern', 'man', 'ha', 'never', 'practical', 'use', 'body', 'beyond', 'walking', 'car', 'house', 'man', 'whose', 'need', 'power', 'process', 'ha', 'satisfied', 'life', 'best', 'prepared', 'accept', 'end', 'life']"
1886,"37. Thus, in order to avoid serious psychological problems, a human being needs goals whose attainment requires effort, and he must have a reasonable rate of success in attaining his goals.",TK,189,"['37', 'thus', 'order', 'avoid', 'serious', 'psychological', 'problem', 'human', 'need', 'goal', 'whose', 'attainment', 'requires', 'effort', 'must', 'reasonable', 'rate', 'success', 'attaining', 'goal']"
1887,"92. Thus science marches on blindly, without regard to the real welfare of the human race or to any other standard, obedient only to the psychological needs of the scientists and of the government officials and corporation executives who provide the funds for research.",TK,269,"['92', 'thus', 'science', 'march', 'blindly', 'without', 'regard', 'real', 'welfare', 'human', 'race', 'standard', 'obedient', 'psychological', 'need', 'scientist', 'government', 'official', 'corporation', 'executive', 'provide', 'fund', 'research']"
1888,"152. Generally speaking, technological control over human behavior will probably not be introduced with a totalitarian intention or even through a conscious desire to restrict human freedom. [28] Each new step in the assertion of control over the human mind will be taken as a rational response to a problem that faces society, such as curing alcoholism, reducing the crime rate or inducing young people to study science and engineering. In many cases, there will be humanitarian justification. For example, when a psychiatrist prescribes an anti-depressant for a depressed patient, he is clearly doing that individual a favor. It would be inhumane to withhold the drug from someone who needs it. When parents send their children to Sylvan Learning Centers to have them manipulated into becoming enthusiastic about their studies, they do so from concern for their children's welfare. It may be that some of these parents wish that one didn't have to have specialized training to get a job and that their kid didn't have to be brainwashed into becoming a computer nerd. But what can they do? They can't change society, and their child may be unemployable if he doesn't have certain skills. So they send him to Sylvan.",TK,1216,"['152', 'generally', 'speaking', 'technological', 'control', 'human', 'behavior', 'probably', 'introduced', 'totalitarian', 'intention', 'even', 'conscious', 'desire', 'restrict', 'human', 'freedom', '28', 'new', 'step', 'assertion', 'control', 'human', 'mind', 'taken', 'rational', 'response', 'problem', 'face', 'society', 'curing', 'alcoholism', 'reducing', 'crime', 'rate', 'inducing', 'young', 'people', 'study', 'science', 'engineering', 'many', 'case', 'humanitarian', 'justification', 'example', 'psychiatrist', 'prescribes', 'antidepressant', 'depressed', 'patient', 'clearly', 'individual', 'favor', 'would', 'inhumane', 'withhold', 'drug', 'someone', 'need', 'parent', 'send', 'child', 'sylvan', 'learning', 'center', 'manipulated', 'becoming', 'enthusiastic', 'study', 'concern', 'childrens', 'welfare', 'may', 'parent', 'wish', 'one', 'didnt', 'specialized', 'training', 'get', 'job', 'kid', 'didnt', 'brainwashed', 'becoming', 'computer', 'nerd', 'cant', 'change', 'society', 'child', 'may', 'unemployable', 'doesnt', 'certain', 'skill', 'send', 'sylvan']"
1889,"64. It seems that for many people, maybe the majority, these artificial forms of the power process are insufficient. A theme that appears repeatedly in the writings of the social critics of the second half of the 20th century is the sense of purposelessness that afflicts many people in modern society. (This purposelessness is often called by other names such as ""anomic"" or ""middle-class vacuity."") We suggest that the so-called ""identity crisis"" is actually a search for a sense of purpose, often for commitment to a suitable surrogate activity. It may be that existentialism is in large part a response to the purposelessness of modern life. [12] Very widespread in modern society is the search for ""fulfillment."" But we think that for the majority of people an activity whose main goal is fulfillment (that is, a surrogate activity) does not bring completely satisfactory fulfillment. In other words, it does not fully satisfy the need for the power process. (See paragraph 41.) That need can be fully satisfied only through activities that have some external goal, such as physical necessities, sex, love, status, revenge, etc.",TK,1133,"['64', 'seems', 'many', 'people', 'maybe', 'majority', 'artificial', 'form', 'power', 'process', 'insufficient', 'theme', 'appears', 'repeatedly', 'writing', 'social', 'critic', 'second', 'half', '20th', 'century', 'sense', 'purposelessness', 'afflicts', 'many', 'people', 'modern', 'society', 'purposelessness', 'often', 'called', 'name', 'anomic', 'middleclass', 'vacuity', 'suggest', 'socalled', 'identity', 'crisis', 'actually', 'search', 'sense', 'purpose', 'often', 'commitment', 'suitable', 'surrogate', 'activity', 'may', 'existentialism', 'large', 'part', 'response', 'purposelessness', 'modern', 'life', '12', 'widespread', 'modern', 'society', 'search', 'fulfillment', 'think', 'majority', 'people', 'activity', 'whose', 'main', 'goal', 'fulfillment', 'surrogate', 'activity', 'doe', 'bring', 'completely', 'satisfactory', 'fulfillment', 'word', 'doe', 'fully', 'satisfy', 'need', 'power', 'process', 'see', 'paragraph', '41', 'need', 'fully', 'satisfied', 'activity', 'external', 'goal', 'physical', 'necessity', 'sex', 'love', 'status', 'revenge', 'etc']"
1890,"157. Assuming that industrial society survives, it is likely that technology will eventually acquire something approaching complete control over human behavior. It has been established beyond any rational doubt that human thought and behavior have a largely biological basis. As experimenters have demonstrated, feelings such as hunger, pleasure, anger and fear can be turned on and off by electrical stimulation of appropriate parts of the brain. Memories can be destroyed by damaging parts of the brain or they can be brought to the surface by electrical stimulation. Hallucinations can be induced or moods changed by drugs. There may or may not be an immaterial human soul, but if there is one it clearly is less powerful that the biological mechanisms of human behavior. For if that were not the case then researchers would not be able so easily to manipulate human feelings and behavior with drugs and electrical currents.",TK,927,"['157', 'assuming', 'industrial', 'society', 'survives', 'likely', 'technology', 'eventually', 'acquire', 'something', 'approaching', 'complete', 'control', 'human', 'behavior', 'ha', 'established', 'beyond', 'rational', 'doubt', 'human', 'thought', 'behavior', 'largely', 'biological', 'basis', 'experimenter', 'demonstrated', 'feeling', 'hunger', 'pleasure', 'anger', 'fear', 'turned', 'electrical', 'stimulation', 'appropriate', 'part', 'brain', 'memory', 'destroyed', 'damaging', 'part', 'brain', 'brought', 'surface', 'electrical', 'stimulation', 'hallucination', 'induced', 'mood', 'changed', 'drug', 'may', 'may', 'immaterial', 'human', 'soul', 'one', 'clearly', 'le', 'powerful', 'biological', 'mechanism', 'human', 'behavior', 'case', 'researcher', 'would', 'able', 'easily', 'manipulate', 'human', 'feeling', 'behavior', 'drug', 'electrical', 'current']"
1891, 107. The fifth principle is a consequence of the other four.,TK,61,"['', '107', 'fifth', 'principle', 'consequence', 'four']"
1892,"60. In modern industrial society natural human drives tend to be pushed into the first and third groups, and the second group tends to consist increasingly of artificially created drives.",TK,187,"['60', 'modern', 'industrial', 'society', 'natural', 'human', 'drive', 'tend', 'pushed', 'first', 'third', 'group', 'second', 'group', 'tends', 'consist', 'increasingly', 'artificially', 'created', 'drive']"
1893,"124. The usual response to such concerns is to talk about ""medical ethics."" But a code of ethics would not serve to protect freedom in the face of medical progress; it would only make matters worse. A code of ethics applicable to genetic engineering would be in effect a means of regulating the genetic constitution of human beings. Somebody (probably the upper-middle class, mostly) would decide that such and such applications of genetic engineering were ""ethical"" and others were not, so that in effect they would be imposing their own values on the genetic constitution of the population at large. Even if a code of ethics were chosen on a completely democratic basis, the majority would be imposing their own values on any minorities who might have a different idea of what constituted an ""ethical"" use of genetic engineering. The only code of ethics that would truly protect freedom would be one that prohibited ANY genetic engineering of human beings, and you can be sure that no such code will ever be applied in a technological society. No code that reduced genetic engineering to a minor role could stand up for long, because the temptation presented by the immense power of biotechnology would be irresistible, especially since to the majority of people many of its applications will seem obviously and unequivocally good (eliminating physical and mental diseases, giving people the abilities they need to get along in today's world). Inevitably, genetic engineering will be used extensively, but only in ways consistent with the needs of the industrial-technological system. [20]",TK,1591,"['124', 'usual', 'response', 'concern', 'talk', 'medical', 'ethic', 'code', 'ethic', 'would', 'serve', 'protect', 'freedom', 'face', 'medical', 'progress', 'would', 'make', 'matter', 'worse', 'code', 'ethic', 'applicable', 'genetic', 'engineering', 'would', 'effect', 'mean', 'regulating', 'genetic', 'constitution', 'human', 'somebody', 'probably', 'uppermiddle', 'class', 'mostly', 'would', 'decide', 'application', 'genetic', 'engineering', 'ethical', 'others', 'effect', 'would', 'imposing', 'value', 'genetic', 'constitution', 'population', 'large', 'even', 'code', 'ethic', 'chosen', 'completely', 'democratic', 'basis', 'majority', 'would', 'imposing', 'value', 'minority', 'might', 'different', 'idea', 'constituted', 'ethical', 'use', 'genetic', 'engineering', 'code', 'ethic', 'would', 'truly', 'protect', 'freedom', 'would', 'one', 'prohibited', 'genetic', 'engineering', 'human', 'sure', 'code', 'ever', 'applied', 'technological', 'society', 'code', 'reduced', 'genetic', 'engineering', 'minor', 'role', 'could', 'stand', 'long', 'temptation', 'presented', 'immense', 'power', 'biotechnology', 'would', 'irresistible', 'especially', 'since', 'majority', 'people', 'many', 'application', 'seem', 'obviously', 'unequivocally', 'good', 'eliminating', 'physical', 'mental', 'disease', 'giving', 'people', 'ability', 'need', 'get', 'along', 'today', 'world', 'inevitably', 'genetic', 'engineering', 'used', 'extensively', 'way', 'consistent', 'need', 'industrialtechnological', 'system', '20']"
1894,"11. When someone interprets as derogatory almost anything that is said about him (or about groups with whom he identifies) we conclude that he has inferiority feelings or low self-esteem. This tendency is pronounced among minority rights advocates, whether or not they belong to the minority groups whose rights they defend. They are hypersensitive about the words used to designate minorities. The terms ""negro,"" ""oriental,"" ""handicapped"" or ""chick"" for an African, an Asian, a disabled person or a woman originally had no derogatory connotation. ""Broad"" and ""chick"" were merely the feminine equivalents of ""guy,"" ""dude"" or ""fellow."" The negative connotations have been attached to these terms by the activists themselves. Some animal rights advocates have gone so far as to reject the word ""pet"" and insist on its replacement by ""animal companion."" Leftist anthropologists go to great lengths to avoid saying anything about primitive peoples that could conceivably be interpreted as negative. They want to replace the word ""primitive"" by ""nonliterate."" They seem almost paranoid about anything that might suggest that any primitive culture is inferior to our own. (We do not mean to imply that primitive cultures ARE inferior to ours. We merely point out the hypersensitivity of leftish anthropologists.)",TK,1306,"['11', 'someone', 'interprets', 'derogatory', 'almost', 'anything', 'said', 'group', 'identifies', 'conclude', 'ha', 'inferiority', 'feeling', 'low', 'selfesteem', 'tendency', 'pronounced', 'among', 'minority', 'right', 'advocate', 'whether', 'belong', 'minority', 'group', 'whose', 'right', 'defend', 'hypersensitive', 'word', 'used', 'designate', 'minority', 'term', 'negro', 'oriental', 'handicapped', 'chick', 'african', 'asian', 'disabled', 'person', 'woman', 'originally', 'derogatory', 'connotation', 'broad', 'chick', 'merely', 'feminine', 'equivalent', 'guy', 'dude', 'fellow', 'negative', 'connotation', 'attached', 'term', 'activist', 'animal', 'right', 'advocate', 'gone', 'far', 'reject', 'word', 'pet', 'insist', 'replacement', 'animal', 'companion', 'leftist', 'anthropologist', 'go', 'great', 'length', 'avoid', 'saying', 'anything', 'primitive', 'people', 'could', 'conceivably', 'interpreted', 'negative', 'want', 'replace', 'word', 'primitive', 'nonliterate', 'seem', 'almost', 'paranoid', 'anything', 'might', 'suggest', 'primitive', 'culture', 'inferior', 'mean', 'imply', 'primitive', 'culture', 'inferior', 'merely', 'point', 'hypersensitivity', 'leftish', 'anthropologist']"
1895,113. So even on very general grounds it seems highly improbably that any way of changing society could be found that would reconcile freedom with modern technology. In the next few sections we will give more specific reasons for concluding that freedom and technological progress are incompatible.,TK,297,"['113', 'even', 'general', 'ground', 'seems', 'highly', 'improbably', 'way', 'changing', 'society', 'could', 'found', 'would', 'reconcile', 'freedom', 'modern', 'technology', 'next', 'section', 'give', 'specific', 'reason', 'concluding', 'freedom', 'technological', 'progress', 'incompatible']"
1896,"127. A technological advance that appears not to threaten freedom often turns out to threaten freedom often turns out to threaten it very seriously later on. For example, consider motorized transport. A walking man formerly could go where he pleased, go at his own pace without observing any traffic regulations, and was independent of technological support-systems. When motor vehicles were introduced they appeared to increase man's freedom. They took no freedom away from the walking man, no one had to have an automobile if he didn't want one, and anyone who did choose to buy an automobile could travel much faster than the walking man. But the introduction of motorized transport soon changed society in such a way as to restrict greatly man's freedom of locomotion. When automobiles became numerous, it became necessary to regulate their use extensively. In a car, especially in densely populated areas, one cannot just go where one likes at one's own pace one's movement is governed by the flow of traffic and by various traffic laws. One is tied down by various obligations: license requirements, driver test, renewing registration, insurance, maintenance required for safety, monthly payments on purchase price. Moreover, the use of motorized transport is no longer optional. Since the introduction of motorized transport the arrangement of our cities has changed in such a way that the majority of people no longer live within walking distance of their place of employment, shopping areas and recreational opportunities, so that they HAVE TO depend on the automobile for transportation. Or else they must use public transportation, in which case they have even less control over their own movement than when driving a car. Even the walker's freedom is now greatly restricted. In the city he continually has to stop and wait for traffic lights that are designed mainly to serve auto traffic. In the country, motor traffic makes it dangerous and unpleasant to walk along the highway. (Note the important point we have illustrated with the case of motorized transport: When a new item of technology is introduced as an option that an individual can accept or not as he chooses, it does not necessarily REMAIN optional. In many cases the new technology changes society in such a way that people eventually find themselves FORCED to use it.)",TK,2347,"['127', 'technological', 'advance', 'appears', 'threaten', 'freedom', 'often', 'turn', 'threaten', 'freedom', 'often', 'turn', 'threaten', 'seriously', 'later', 'example', 'consider', 'motorized', 'transport', 'walking', 'man', 'formerly', 'could', 'go', 'pleased', 'go', 'pace', 'without', 'observing', 'traffic', 'regulation', 'wa', 'independent', 'technological', 'supportsystems', 'motor', 'vehicle', 'introduced', 'appeared', 'increase', 'man', 'freedom', 'took', 'freedom', 'away', 'walking', 'man', 'one', 'automobile', 'didnt', 'want', 'one', 'anyone', 'choose', 'buy', 'automobile', 'could', 'travel', 'much', 'faster', 'walking', 'man', 'introduction', 'motorized', 'transport', 'soon', 'changed', 'society', 'way', 'restrict', 'greatly', 'man', 'freedom', 'locomotion', 'automobile', 'became', 'numerous', 'became', 'necessary', 'regulate', 'use', 'extensively', 'car', 'especially', 'densely', 'populated', 'area', 'one', 'cannot', 'go', 'one', 'like', 'one', 'pace', 'one', 'movement', 'governed', 'flow', 'traffic', 'various', 'traffic', 'law', 'one', 'tied', 'various', 'obligation', 'license', 'requirement', 'driver', 'test', 'renewing', 'registration', 'insurance', 'maintenance', 'required', 'safety', 'monthly', 'payment', 'purchase', 'price', 'moreover', 'use', 'motorized', 'transport', 'longer', 'optional', 'since', 'introduction', 'motorized', 'transport', 'arrangement', 'city', 'ha', 'changed', 'way', 'majority', 'people', 'longer', 'live', 'within', 'walking', 'distance', 'place', 'employment', 'shopping', 'area', 'recreational', 'opportunity', 'depend', 'automobile', 'transportation', 'else', 'must', 'use', 'public', 'transportation', 'case', 'even', 'le', 'control', 'movement', 'driving', 'car', 'even', 'walker', 'freedom', 'greatly', 'restricted', 'city', 'continually', 'ha', 'stop', 'wait', 'traffic', 'light', 'designed', 'mainly', 'serve', 'auto', 'traffic', 'country', 'motor', 'traffic', 'make', 'dangerous', 'unpleasant', 'walk', 'along', 'highway', 'note', 'important', 'point', 'illustrated', 'case', 'motorized', 'transport', 'new', 'item', 'technology', 'introduced', 'option', 'individual', 'accept', 'chooses', 'doe', 'necessarily', 'remain', 'optional', 'many', 'case', 'new', 'technology', 'change', 'society', 'way', 'people', 'eventually', 'find', 'forced', 'use']"
1897,"200. Until the industrial system has been thoroughly wrecked, the destruction of that system must be the revolutionaries' ONLY goal. Other goals would distract attention and energy from the main goal. More importantly, if the revolutionaries permit themselves to have any other goal than the destruction of technology, they will be tempted to use technology as a tool for reaching that other goal. If they give in to that temptation, they will fall right back into the technological trap, because modern technology is a unified, tightly organized system, so that, in order to retain SOME technology, one finds oneself obliged to retain MOST technology, hence one ends up sacrificing only token amounts of technology.",TK,716,"['200', 'industrial', 'system', 'ha', 'thoroughly', 'wrecked', 'destruction', 'system', 'must', 'revolutionary', 'goal', 'goal', 'would', 'distract', 'attention', 'energy', 'main', 'goal', 'importantly', 'revolutionary', 'permit', 'goal', 'destruction', 'technology', 'tempted', 'use', 'technology', 'tool', 'reaching', 'goal', 'give', 'temptation', 'fall', 'right', 'back', 'technological', 'trap', 'modern', 'technology', 'unified', 'tightly', 'organized', 'system', 'order', 'retain', 'technology', 'one', 'find', 'oneself', 'obliged', 'retain', 'technology', 'hence', 'one', 'end', 'sacrificing', 'token', 'amount', 'technology']"
1898,"219. Leftism is totalitarian force. Wherever leftism is in a position of power it tends to invade every private corner and force every thought into a leftist mold. In part this is because of the quasi-religious character of leftism; everything contrary to leftists beliefs represents Sin. More importantly, leftism is a totalitarian force because of the leftists' drive for power. The leftist seeks to satisfy his need for power through identification with a social movement and he tries to go through the power process by helping to pursue and attain the goals of the movement (see paragraph 83). But no matter how far the movement has gone in attaining its goals the leftist is never satisfied, because his activism is a surrogate activity (see paragraph 41). That is, the leftist's real motive is not to attain the ostensible goals of leftism; in reality he is motivated by the sense of power he gets from struggling for and then reaching a social goal.[35]",TK,960,"['219', 'leftism', 'totalitarian', 'force', 'wherever', 'leftism', 'position', 'power', 'tends', 'invade', 'every', 'private', 'corner', 'force', 'every', 'thought', 'leftist', 'mold', 'part', 'quasireligious', 'character', 'leftism', 'everything', 'contrary', 'leftist', 'belief', 'represents', 'sin', 'importantly', 'leftism', 'totalitarian', 'force', 'leftist', 'drive', 'power', 'leftist', 'seek', 'satisfy', 'need', 'power', 'identification', 'social', 'movement', 'try', 'go', 'power', 'process', 'helping', 'pursue', 'attain', 'goal', 'movement', 'see', 'paragraph', '83', 'matter', 'far', 'movement', 'ha', 'gone', 'attaining', 'goal', 'leftist', 'never', 'satisfied', 'activism', 'surrogate', 'activity', 'see', 'paragraph', '41', 'leftist', 'real', 'motive', 'attain', 'ostensible', 'goal', 'leftism', 'reality', 'motivated', 'sense', 'power', 'get', 'struggling', 'reaching', 'social', 'goal35']"
1899,"61. In primitive societies, physical necessities generally fall into group 2: They can be obtained, but only at the cost of serious effort. But modern society tends to guaranty the physical necessities to everyone [9] in exchange for only minimal effort, hence physical needs are pushed into group 1. (There may be disagreement about whether the effort needed to hold a job is ""minimal""; but usually, in lower- to middle-level jobs, whatever effort is required is merely that of obedience. You sit or stand where you are told to sit or stand and do what you are told to do in the way you are told to do it. Seldom do you have to exert yourself seriously, and in any case you have hardly any autonomy in work, so that the need for the power process is not well served.)",TK,768,"['61', 'primitive', 'society', 'physical', 'necessity', 'generally', 'fall', 'group', '2', 'obtained', 'cost', 'serious', 'effort', 'modern', 'society', 'tends', 'guaranty', 'physical', 'necessity', 'everyone', '9', 'exchange', 'minimal', 'effort', 'hence', 'physical', 'need', 'pushed', 'group', '1', 'may', 'disagreement', 'whether', 'effort', 'needed', 'hold', 'job', 'minimal', 'usually', 'lower', 'middlelevel', 'job', 'whatever', 'effort', 'required', 'merely', 'obedience', 'sit', 'stand', 'told', 'sit', 'stand', 'told', 'way', 'told', 'seldom', 'exert', 'seriously', 'case', 'hardly', 'autonomy', 'work', 'need', 'power', 'process', 'well', 'served']"
1900,"181. As we stated in paragraph 166, the two main tasks for the present are to promote social stress and instability in industrial society and to develop and propagate an ideology that opposes technology and the industrial system. When the system becomes sufficiently stressed and unstable, a revolution against technology may be possible. The pattern would be similar to that of the French and Russian Revolutions. French society and Russian society, for several decades prior to their respective revolutions, showed increasing signs of stress and weakness. Meanwhile, ideologies were being developed that offered a new world view that was quite different from the old one. In the Russian case, revolutionaries were actively working to undermine the old order. Then, when the old system was put under sufficient additional stress (by financial crisis in France, by military defeat in Russia) it was swept away by revolution. What we propose in something along the same lines.",TK,975,"['181', 'stated', 'paragraph', '166', 'two', 'main', 'task', 'present', 'promote', 'social', 'stress', 'instability', 'industrial', 'society', 'develop', 'propagate', 'ideology', 'opposes', 'technology', 'industrial', 'system', 'system', 'becomes', 'sufficiently', 'stressed', 'unstable', 'revolution', 'technology', 'may', 'possible', 'pattern', 'would', 'similar', 'french', 'russian', 'revolution', 'french', 'society', 'russian', 'society', 'several', 'decade', 'prior', 'respective', 'revolution', 'showed', 'increasing', 'sign', 'stress', 'weakness', 'meanwhile', 'ideology', 'developed', 'offered', 'new', 'world', 'view', 'wa', 'quite', 'different', 'old', 'one', 'russian', 'case', 'revolutionary', 'actively', 'working', 'undermine', 'old', 'order', 'old', 'system', 'wa', 'put', 'sufficient', 'additional', 'stress', 'financial', 'crisis', 'france', 'military', 'defeat', 'russia', 'wa', 'swept', 'away', 'revolution', 'propose', 'something', 'along', 'line']"
1901,"84. Another way in which people satisfy their need for the power process is through surrogate activities. As we explained in paragraphs 38-40, a surrogate activity that is directed toward an artificial goal that the individual pursues for the sake of the ""fulfillment"" that he gets from pursuing the goal, not because he needs to attain the goal itself. For instance, there is no practical motive for building enormous muscles, hitting a little ball into a hole or acquiring a complete series of postage stamps. Yet many people in our society devote themselves with passion to bodybuilding, golf or stamp collecting. Some people are more ""other-directed"" than others, and therefore will more readily attack importance to a surrogate activity simply because the people around them treat it as important or because society tells them it is important. That is why some people get very serious about essentially trivial activities such as sports, or bridge, or chess, or arcane scholarly pursuits, whereas others who are more clear-sighted never see these things as anything but the surrogate activities that they are, and consequently never attach enough importance to them to satisfy their need for the power process in that way. It only remains to point out that in many cases a person's way of earning a living is also a surrogate activity. Not a PURE surrogate activity, since part of the motive for the activity is to gain the physical necessities and (for some people) social status and the luxuries that advertising makes them want. But many people put into their work far more effort than is necessary to earn whatever money and status they require, and this extra effort constitutes a surrogate activity. This extra effort, together with the emotional investment that accompanies it, is one of the most potent forces acting toward the continual development and perfecting of the system, with negative consequences for individual freedom (see paragraph 131). Especially, for the most creative scientists and engineers, work tends to be largely a surrogate activity. This point is so important that is deserves a separate discussion, which we shall give in a moment (paragraphs 87-92).",TK,2189,"['84', 'another', 'way', 'people', 'satisfy', 'need', 'power', 'process', 'surrogate', 'activity', 'explained', 'paragraph', '3840', 'surrogate', 'activity', 'directed', 'toward', 'artificial', 'goal', 'individual', 'pursues', 'sake', 'fulfillment', 'get', 'pursuing', 'goal', 'need', 'attain', 'goal', 'instance', 'practical', 'motive', 'building', 'enormous', 'muscle', 'hitting', 'little', 'ball', 'hole', 'acquiring', 'complete', 'series', 'postage', 'stamp', 'yet', 'many', 'people', 'society', 'devote', 'passion', 'bodybuilding', 'golf', 'stamp', 'collecting', 'people', 'otherdirected', 'others', 'therefore', 'readily', 'attack', 'importance', 'surrogate', 'activity', 'simply', 'people', 'around', 'treat', 'important', 'society', 'tell', 'important', 'people', 'get', 'serious', 'essentially', 'trivial', 'activity', 'sport', 'bridge', 'chess', 'arcane', 'scholarly', 'pursuit', 'whereas', 'others', 'clearsighted', 'never', 'see', 'thing', 'anything', 'surrogate', 'activity', 'consequently', 'never', 'attach', 'enough', 'importance', 'satisfy', 'need', 'power', 'process', 'way', 'remains', 'point', 'many', 'case', 'person', 'way', 'earning', 'living', 'also', 'surrogate', 'activity', 'pure', 'surrogate', 'activity', 'since', 'part', 'motive', 'activity', 'gain', 'physical', 'necessity', 'people', 'social', 'status', 'luxury', 'advertising', 'make', 'want', 'many', 'people', 'put', 'work', 'far', 'effort', 'necessary', 'earn', 'whatever', 'money', 'status', 'require', 'extra', 'effort', 'constitutes', 'surrogate', 'activity', 'extra', 'effort', 'together', 'emotional', 'investment', 'accompanies', 'one', 'potent', 'force', 'acting', 'toward', 'continual', 'development', 'perfecting', 'system', 'negative', 'consequence', 'individual', 'freedom', 'see', 'paragraph', '131', 'especially', 'creative', 'scientist', 'engineer', 'work', 'tends', 'largely', 'surrogate', 'activity', 'point', 'important', 'deserves', 'separate', 'discussion', 'shall', 'give', 'moment', 'paragraph', '8792']"
1902,"206. With regard to revolutionary strategy, the only points on which we absolutely insist are that the single overriding goal must be the elimination of modern technology, and that no other goal can be allowed to compete with this one. For the rest, revolutionaries should take an empirical approach. If experience indicates that some of the recommendations made in the foregoing paragraphs are not going to give good results, then those recommendations should be discarded.",TK,474,"['206', 'regard', 'revolutionary', 'strategy', 'point', 'absolutely', 'insist', 'single', 'overriding', 'goal', 'must', 'elimination', 'modern', 'technology', 'goal', 'allowed', 'compete', 'one', 'rest', 'revolutionary', 'take', 'empirical', 'approach', 'experience', 'indicates', 'recommendation', 'made', 'foregoing', 'paragraph', 'going', 'give', 'good', 'result', 'recommendation', 'discarded']"
1903,"50. The conservatives are fools: They whine about the decay of traditional values, yet they enthusiastically support technological progress and economic growth. Apparently it never occurs to them that you can't make rapid, drastic changes in the technology and the economy of a society with out causing rapid changes in all other aspects of the society as well, and that such rapid changes inevitably break down traditional values.",TK,431,"['50', 'conservative', 'fool', 'whine', 'decay', 'traditional', 'value', 'yet', 'enthusiastically', 'support', 'technological', 'progress', 'economic', 'growth', 'apparently', 'never', 'occurs', 'cant', 'make', 'rapid', 'drastic', 'change', 'technology', 'economy', 'society', 'causing', 'rapid', 'change', 'aspect', 'society', 'well', 'rapid', 'change', 'inevitably', 'break', 'traditional', 'value']"
1904,"203. Imagine an alcoholic sitting with a barrel of wine in front of him. Suppose he starts saying to himself, ""Wine isn't bad for you if used in moderation. Why, they say small amounts of wine are even good for you! It won't do me any harm if I take just one little drink..."" Well you know what is going to happen. Never forget that the human race with technology is just like an alcoholic with a barrel of wine.",TK,412,"['203', 'imagine', 'alcoholic', 'sitting', 'barrel', 'wine', 'front', 'suppose', 'start', 'saying', 'wine', 'isnt', 'bad', 'used', 'moderation', 'say', 'small', 'amount', 'wine', 'even', 'good', 'wont', 'harm', 'take', 'one', 'little', 'drink', 'well', 'know', 'going', 'happen', 'never', 'forget', 'human', 'race', 'technology', 'like', 'alcoholic', 'barrel', 'wine']"
1905,"131. Technicians (we use this term in its broad sense to describe all those who perform a specialized task that requires training) tend to be so involved in their work (their surrogate activity) that when a conflict arises between their technical work and freedom, they almost always decide in favor of their technical work. This is obvious in the case of scientists, but it also appears elsewhere: Educators, humanitarian groups, conservation organizations do not hesitate to use propaganda or other psychological techniques to help them achieve their laudable ends. Corporations and government agencies, when they find it useful, do not hesitate to collect information about individuals without regard to their privacy. Law enforcement agencies are frequently inconvenienced by the constitutional rights of suspects and often of completely innocent persons, and they do whatever they can do legally (or sometimes illegally) to restrict or circumvent those rights. Most of these educators, government officials and law officers believe in freedom, privacy and constitutional rights, but when these conflict with their work, they usually feel that their work is more important.",TK,1177,"['131', 'technician', 'use', 'term', 'broad', 'sense', 'describe', 'perform', 'specialized', 'task', 'requires', 'training', 'tend', 'involved', 'work', 'surrogate', 'activity', 'conflict', 'arises', 'technical', 'work', 'freedom', 'almost', 'always', 'decide', 'favor', 'technical', 'work', 'obvious', 'case', 'scientist', 'also', 'appears', 'elsewhere', 'educator', 'humanitarian', 'group', 'conservation', 'organization', 'hesitate', 'use', 'propaganda', 'psychological', 'technique', 'help', 'achieve', 'laudable', 'end', 'corporation', 'government', 'agency', 'find', 'useful', 'hesitate', 'collect', 'information', 'individual', 'without', 'regard', 'privacy', 'law', 'enforcement', 'agency', 'frequently', 'inconvenienced', 'constitutional', 'right', 'suspect', 'often', 'completely', 'innocent', 'person', 'whatever', 'legally', 'sometimes', 'illegally', 'restrict', 'circumvent', 'right', 'educator', 'government', 'official', 'law', 'officer', 'believe', 'freedom', 'privacy', 'constitutional', 'right', 'conflict', 'work', 'usually', 'feel', 'work', 'important']"
1906,81. Some people have low susceptibility to advertising and marketing techniques. These are the people who aren't interested in money. Material acquisition does not serve their need for the power process.,TK,203,"['81', 'people', 'low', 'susceptibility', 'advertising', 'marketing', 'technique', 'people', 'arent', 'interested', 'money', 'material', 'acquisition', 'doe', 'serve', 'need', 'power', 'process']"
1907,"102. SECOND PRINCIPLE. If a change is made that is sufficiently large to alter permanently a long-term historical trend, than it will alter the society as a whole. In other words, a society is a system in which all parts are interrelated, and you can't permanently change any important part without change all the other parts as well.",TK,334,"['102', 'second', 'principle', 'change', 'made', 'sufficiently', 'large', 'alter', 'permanently', 'longterm', 'historical', 'trend', 'alter', 'society', 'whole', 'word', 'society', 'system', 'part', 'interrelated', 'cant', 'permanently', 'change', 'important', 'part', 'without', 'change', 'part', 'well']"
1908,"133. No social arrangements, whether laws, institutions, customs or ethical codes, can provide permanent protection against technology. History shows that all social arrangements are transitory; they all change or break down eventually. But technological advances are permanent within the context of a given civilization. Suppose for example that it were possible to arrive at some social arrangements that would prevent genetic engineering from being applied to human beings, or prevent it from being applied in such a ways as to threaten freedom and dignity. Still, the technology would remain waiting. Sooner or later the social arrangement would break down. Probably sooner, given that pace of change in our society. Then genetic engineering would begin to invade our sphere of freedom, and this invasion would be irreversible (short of a breakdown of technological civilization itself). Any illusions about achieving anything permanent through social arrangements should be dispelled by what is currently happening with environmental legislation. A few years ago it seemed that there were secure legal barriers preventing at least SOME of the worst forms of environmental degradation. A change in the political wind, and those barriers begin to crumble.",TK,1258,"['133', 'social', 'arrangement', 'whether', 'law', 'institution', 'custom', 'ethical', 'code', 'provide', 'permanent', 'protection', 'technology', 'history', 'show', 'social', 'arrangement', 'transitory', 'change', 'break', 'eventually', 'technological', 'advance', 'permanent', 'within', 'context', 'given', 'civilization', 'suppose', 'example', 'possible', 'arrive', 'social', 'arrangement', 'would', 'prevent', 'genetic', 'engineering', 'applied', 'human', 'prevent', 'applied', 'way', 'threaten', 'freedom', 'dignity', 'still', 'technology', 'would', 'remain', 'waiting', 'sooner', 'later', 'social', 'arrangement', 'would', 'break', 'probably', 'sooner', 'given', 'pace', 'change', 'society', 'genetic', 'engineering', 'would', 'begin', 'invade', 'sphere', 'freedom', 'invasion', 'would', 'irreversible', 'short', 'breakdown', 'technological', 'civilization', 'illusion', 'achieving', 'anything', 'permanent', 'social', 'arrangement', 'dispelled', 'currently', 'happening', 'environmental', 'legislation', 'year', 'ago', 'seemed', 'secure', 'legal', 'barrier', 'preventing', 'least', 'worst', 'form', 'environmental', 'degradation', 'change', 'political', 'wind', 'barrier', 'begin', 'crumble']"
1909,"41. For many if not most people, surrogate activities are less satisfying than the pursuit of real goals ( that is, goals that people would want to attain even if their need for the power process were already fulfilled). One indication of this is the fact that, in many or most cases, people who are deeply involved in surrogate activities are never satisfied, never at rest. Thus the money-maker constantly strives for more and more wealth. The scientist no sooner solves one problem than he moves on to the next. The long-distance runner drives himself to run always farther and faster. Many people who pursue surrogate activities will say that they get far more fulfillment from these activities than they do from the ""mundane"" business of satisfying their biological needs, but that it is because in our society the effort needed to satisfy the biological needs has been reduced to triviality. More importantly, in our society people do not satisfy their biological needs AUTONOMOUSLY but by functioning as parts of an immense social machine. In contrast, people generally have a great deal of autonomy in pursuing their surrogate activities. have a great deal of autonomy in pursuing their surrogate activities.",TK,1216,"['41', 'many', 'people', 'surrogate', 'activity', 'le', 'satisfying', 'pursuit', 'real', 'goal', '', 'goal', 'people', 'would', 'want', 'attain', 'even', 'need', 'power', 'process', 'already', 'fulfilled', 'one', 'indication', 'fact', 'many', 'case', 'people', 'deeply', 'involved', 'surrogate', 'activity', 'never', 'satisfied', 'never', 'rest', 'thus', 'moneymaker', 'constantly', 'strives', 'wealth', 'scientist', 'sooner', 'solves', 'one', 'problem', 'move', 'next', 'longdistance', 'runner', 'drive', 'run', 'always', 'farther', 'faster', 'many', 'people', 'pursue', 'surrogate', 'activity', 'say', 'get', 'far', 'fulfillment', 'activity', 'mundane', 'business', 'satisfying', 'biological', 'need', 'society', 'effort', 'needed', 'satisfy', 'biological', 'need', 'ha', 'reduced', 'triviality', 'importantly', 'society', 'people', 'satisfy', 'biological', 'need', 'autonomously', 'functioning', 'part', 'immense', 'social', 'machine', 'contrast', 'people', 'generally', 'great', 'deal', 'autonomy', 'pursuing', 'surrogate', 'activity', 'great', 'deal', 'autonomy', 'pursuing', 'surrogate', 'activity']"
1910,"183. But an ideology, in order to gain enthusiastic support, must have a positive ideals well as a negative one; it must be FOR something as well as AGAINST something. The positive ideal that we propose is Nature. That is , WILD nature; those aspects of the functioning of the Earth and its living things that are independent of human management and free of human interference and control. And with wild nature we include human nature, by which we mean those aspects of the functioning of the human individual that are not subject to regulation by organized society but are products of chance, or free will, or God (depending on your religious or philosophical opinions).",TK,671,"['183', 'ideology', 'order', 'gain', 'enthusiastic', 'support', 'must', 'positive', 'ideal', 'well', 'negative', 'one', 'must', 'something', 'well', 'something', 'positive', 'ideal', 'propose', 'nature', '', 'wild', 'nature', 'aspect', 'functioning', 'earth', 'living', 'thing', 'independent', 'human', 'management', 'free', 'human', 'interference', 'control', 'wild', 'nature', 'include', 'human', 'nature', 'mean', 'aspect', 'functioning', 'human', 'individual', 'subject', 'regulation', 'organized', 'society', 'product', 'chance', 'free', 'god', 'depending', 'religious', 'philosophical', 'opinion']"
1911,"198. Primitive INDIVIDUALS and SMALL GROUPS actually had considerable power over nature; or maybe it would be better to say power WITHIN nature. When primitive man needed food he knew how to find and prepare edible roots, how to track game and take it with homemade weapons. He knew how to protect himself from heat, cold, rain, dangerous animals, etc. But primitive man did relatively little damage to nature because the COLLECTIVE power of primitive society was negligible compared to the COLLECTIVE power of industrial society.",TK,530,"['198', 'primitive', 'individual', 'small', 'group', 'actually', 'considerable', 'power', 'nature', 'maybe', 'would', 'better', 'say', 'power', 'within', 'nature', 'primitive', 'man', 'needed', 'food', 'knew', 'find', 'prepare', 'edible', 'root', 'track', 'game', 'take', 'homemade', 'weapon', 'knew', 'protect', 'heat', 'cold', 'rain', 'dangerous', 'animal', 'etc', 'primitive', 'man', 'relatively', 'little', 'damage', 'nature', 'collective', 'power', 'primitive', 'society', 'wa', 'negligible', 'compared', 'collective', 'power', 'industrial', 'society']"
1912,"103. THIRD PRINCIPLE. If a change is made that is large enough to alter permanently a long-term trend, then the consequences for the society as a whole cannot be predicted in advance. (Unless various other societies have passed through the same change and have all experienced the same consequences, in which case one can predict on empirical grounds that another society that passes through the same change will be like to experience similar consequences.)",TK,457,"['103', 'third', 'principle', 'change', 'made', 'large', 'enough', 'alter', 'permanently', 'longterm', 'trend', 'consequence', 'society', 'whole', 'cannot', 'predicted', 'advance', 'unless', 'various', 'society', 'passed', 'change', 'experienced', 'consequence', 'case', 'one', 'predict', 'empirical', 'ground', 'another', 'society', 'pass', 'change', 'like', 'experience', 'similar', 'consequence']"
1913,"86. But even if most people in industrial-technological society were well satisfied, we (FC) would still be opposed to that form of society, because (among other reasons) we consider it demeaning to fulfill one's need for the power process through surrogate activities or through identification with an organization, rather then through pursuit of real goals.",TK,359,"['86', 'even', 'people', 'industrialtechnological', 'society', 'well', 'satisfied', 'fc', 'would', 'still', 'opposed', 'form', 'society', 'among', 'reason', 'consider', 'demeaning', 'fulfill', 'one', 'need', 'power', 'process', 'surrogate', 'activity', 'identification', 'organization', 'rather', 'pursuit', 'real', 'goal']"
1914,"120. Efforts to make room for a sense of purpose and for autonomy within the system are no better than a joke. For example, one company, instead of having each of its employees assemble only one section of a catalogue, had each assemble a whole catalogue, and this was supposed to give them a sense of purpose and achievement. Some companies have tried to give their employees more autonomy in their work, but for practical reasons this usually can be done only to a very limited extent, and in any case employees are never given autonomy as to ultimate goals -- their ""autonomous"" efforts can never be directed toward goals that they select personally, but only toward their employer's goals, such as the survival and growth of the company. Any company would soon go out of business if it permitted its employees to act otherwise. Similarly, in any enterprise within a socialist system, workers must direct their efforts toward the goals of the enterprise, otherwise the enterprise will not serve its purpose as part of the system. Once again, for purely technical reasons it is not possible for most individuals or small groups to have much autonomy in industrial society. Even the small-business owner commonly has only limited autonomy. Apart from the necessity of government regulation, he is restricted by the fact that he must fit into the economic system and conform to its requirements. For instance, when someone develops a new technology, the small-business person often has to use that technology whether he wants to or not, in order to remain competitive.",TK,1568,"['120', 'effort', 'make', 'room', 'sense', 'purpose', 'autonomy', 'within', 'system', 'better', 'joke', 'example', 'one', 'company', 'instead', 'employee', 'assemble', 'one', 'section', 'catalogue', 'assemble', 'whole', 'catalogue', 'wa', 'supposed', 'give', 'sense', 'purpose', 'achievement', 'company', 'tried', 'give', 'employee', 'autonomy', 'work', 'practical', 'reason', 'usually', 'done', 'limited', 'extent', 'case', 'employee', 'never', 'given', 'autonomy', 'ultimate', 'goal', '', 'autonomous', 'effort', 'never', 'directed', 'toward', 'goal', 'select', 'personally', 'toward', 'employer', 'goal', 'survival', 'growth', 'company', 'company', 'would', 'soon', 'go', 'business', 'permitted', 'employee', 'act', 'otherwise', 'similarly', 'enterprise', 'within', 'socialist', 'system', 'worker', 'must', 'direct', 'effort', 'toward', 'goal', 'enterprise', 'otherwise', 'enterprise', 'serve', 'purpose', 'part', 'system', 'purely', 'technical', 'reason', 'possible', 'individual', 'small', 'group', 'much', 'autonomy', 'industrial', 'society', 'even', 'smallbusiness', 'owner', 'commonly', 'ha', 'limited', 'autonomy', 'apart', 'necessity', 'government', 'regulation', 'restricted', 'fact', 'must', 'fit', 'economic', 'system', 'conform', 'requirement', 'instance', 'someone', 'develops', 'new', 'technology', 'smallbusiness', 'person', 'often', 'ha', 'use', 'technology', 'whether', 'want', 'order', 'remain', 'competitive']"
1915,"178. Whatever else may be the case, it is certain that technology is creating for human begins a new physical and social environment radically different from the spectrum of environments to which natural selection has adapted the human race physically and psychological. If man is not adjust to this new environment by being artificially re-engineered, then he will be adapted to it through a long an painful process of natural selection. The former is far more likely that the latter.",TK,485,"['178', 'whatever', 'else', 'may', 'case', 'certain', 'technology', 'creating', 'human', 'begin', 'new', 'physical', 'social', 'environment', 'radically', 'different', 'spectrum', 'environment', 'natural', 'selection', 'ha', 'adapted', 'human', 'race', 'physically', 'psychological', 'man', 'adjust', 'new', 'environment', 'artificially', 'reengineered', 'adapted', 'long', 'painful', 'process', 'natural', 'selection', 'former', 'far', 'likely', 'latter']"
1916,"47. Among the abnormal conditions present in modern industrial society are excessive density of population, isolation of man from nature, excessive rapidity of social change and the break-down of natural small-scale communities such as the extended family, the village or the tribe.",TK,282,"['47', 'among', 'abnormal', 'condition', 'present', 'modern', 'industrial', 'society', 'excessive', 'density', 'population', 'isolation', 'man', 'nature', 'excessive', 'rapidity', 'social', 'change', 'breakdown', 'natural', 'smallscale', 'community', 'extended', 'family', 'village', 'tribe']"
1917,"6. Almost everyone will agree that we live in a deeply troubled society. One of the most widespread manifestations of the craziness of our world is leftism, so a discussion of the psychology of leftism can serve as an introduction to the discussion of the problems of modern society in general.",TK,294,"['6', 'almost', 'everyone', 'agree', 'live', 'deeply', 'troubled', 'society', 'one', 'widespread', 'manifestation', 'craziness', 'world', 'leftism', 'discussion', 'psychology', 'leftism', 'serve', 'introduction', 'discussion', 'problem', 'modern', 'society', 'general']"
1918,"17. Art forms that appeal to modern leftist intellectuals tend to focus on sordidness, defeat and despair, or else they take an orgiastic tone, throwing off rational control as if there were no hope of accomplishing anything through rational calculation and all that was left was to immerse oneself in the sensations of the moment.",TK,331,"['17', 'art', 'form', 'appeal', 'modern', 'leftist', 'intellectual', 'tend', 'focus', 'sordidness', 'defeat', 'despair', 'else', 'take', 'orgiastic', 'tone', 'throwing', 'rational', 'control', 'hope', 'accomplishing', 'anything', 'rational', 'calculation', 'wa', 'left', 'wa', 'immerse', 'oneself', 'sensation', 'moment']"
1919,"201. Suppose for example that the revolutionaries took ""social justice"" as a goal. Human nature being what it is, social justice would not come about spontaneously; it would have to be enforced. In order to enforce it the revolutionaries would have to retain central organization and control. For that they would need rapid long-distance transportation and communication, and therefore all the technology needed to support the transportation and communication systems. To feed and clothe poor people they would have to use agricultural and manufacturing technology. And so forth. So that the attempt to insure social justice would force them to retain most parts of the technological system. Not that we have anything against social justice, but it must not be allowed to interfere with the effort to get rid of the technological system.",TK,837,"['201', 'suppose', 'example', 'revolutionary', 'took', 'social', 'justice', 'goal', 'human', 'nature', 'social', 'justice', 'would', 'come', 'spontaneously', 'would', 'enforced', 'order', 'enforce', 'revolutionary', 'would', 'retain', 'central', 'organization', 'control', 'would', 'need', 'rapid', 'longdistance', 'transportation', 'communication', 'therefore', 'technology', 'needed', 'support', 'transportation', 'communication', 'system', 'feed', 'clothe', 'poor', 'people', 'would', 'use', 'agricultural', 'manufacturing', 'technology', 'forth', 'attempt', 'insure', 'social', 'justice', 'would', 'force', 'retain', 'part', 'technological', 'system', 'anything', 'social', 'justice', 'must', 'allowed', 'interfere', 'effort', 'get', 'rid', 'technological', 'system']"
1920,"71. People have many transitory drives or impulses that are necessary frustrated in modern life, hence fall into group 3. One may become angry, but modern society cannot permit fighting. In many situations it does not even permit verbal aggression. When going somewhere one may be in a hurry, or one may be in a mood to travel slowly, but one generally has no choice but to move with the flow of traffic and obey the traffic signals. One may want to do one's work in a different way, but usually one can work only according to the rules laid down by one's employer. In many other ways as well, modern man is strapped down by a network of rules and regulations (explicit or implicit) that frustrate many of his impulses and thus interfere with the power process. Most of these regulations cannot be disposed with, because the are necessary for the functioning of industrial society.",TK,881,"['71', 'people', 'many', 'transitory', 'drive', 'impulse', 'necessary', 'frustrated', 'modern', 'life', 'hence', 'fall', 'group', '3', 'one', 'may', 'become', 'angry', 'modern', 'society', 'cannot', 'permit', 'fighting', 'many', 'situation', 'doe', 'even', 'permit', 'verbal', 'aggression', 'going', 'somewhere', 'one', 'may', 'hurry', 'one', 'may', 'mood', 'travel', 'slowly', 'one', 'generally', 'ha', 'choice', 'move', 'flow', 'traffic', 'obey', 'traffic', 'signal', 'one', 'may', 'want', 'one', 'work', 'different', 'way', 'usually', 'one', 'work', 'according', 'rule', 'laid', 'one', 'employer', 'many', 'way', 'well', 'modern', 'man', 'strapped', 'network', 'rule', 'regulation', 'explicit', 'implicit', 'frustrate', 'many', 'impulse', 'thus', 'interfere', 'power', 'process', 'regulation', 'cannot', 'disposed', 'necessary', 'functioning', 'industrial', 'society']"
1921,"153. Thus control over human behavior will be introduced not by a calculated decision of the authorities but through a process of social evolution (RAPID evolution, however). The process will be impossible to resist, because each advance, considered by itself, will appear to be beneficial, or at least the evil involved in making the advance will appear to be beneficial, or at least the evil involved in making the advance will seem to be less than that which would result from not making it (see paragraph 127). Propaganda for example is used for many good purposes, such as discouraging child abuse or race hatred. [14] Sex education is obviously useful, yet the effect of sex education (to the extent that it is successful) is to take the shaping of sexual attitudes away from the family and put it into the hands of the state as represented by the public school system.",TK,875,"['153', 'thus', 'control', 'human', 'behavior', 'introduced', 'calculated', 'decision', 'authority', 'process', 'social', 'evolution', 'rapid', 'evolution', 'however', 'process', 'impossible', 'resist', 'advance', 'considered', 'appear', 'beneficial', 'least', 'evil', 'involved', 'making', 'advance', 'appear', 'beneficial', 'least', 'evil', 'involved', 'making', 'advance', 'seem', 'le', 'would', 'result', 'making', 'see', 'paragraph', '127', 'propaganda', 'example', 'used', 'many', 'good', 'purpose', 'discouraging', 'child', 'abuse', 'race', 'hatred', '14', 'sex', 'education', 'obviously', 'useful', 'yet', 'effect', 'sex', 'education', 'extent', 'successful', 'take', 'shaping', 'sexual', 'attitude', 'away', 'family', 'put', 'hand', 'state', 'represented', 'public', 'school', 'system']"
