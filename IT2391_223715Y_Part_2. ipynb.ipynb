{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb1eccf-2792-4d62-ac30-6782446f66db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "# warnings.resetwarnings() to reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b02a4-a2af-4582-8146-93c00cb1f16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VECTORIZATION\n",
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07e5bad-b198-43ef-b007-b01a8d2b5649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Author</th>\n",
       "      <th>length</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scoring in PROC DISCRIM is as easy as validati...</td>\n",
       "      <td>AM</td>\n",
       "      <td>215</td>\n",
       "      <td>['scoring', 'proc', 'discrim', 'easy', 'valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the GLM procedure, you may have used LSMEAN...</td>\n",
       "      <td>AM</td>\n",
       "      <td>782</td>\n",
       "      <td>['glm', 'procedure', 'may', 'used', 'lsmeans',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first problem, accuracy of the data file, ...</td>\n",
       "      <td>AM</td>\n",
       "      <td>990</td>\n",
       "      <td>['first', 'problem', 'accuracy', 'data', 'file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If the homogeneity of covariance matrices assu...</td>\n",
       "      <td>AM</td>\n",
       "      <td>934</td>\n",
       "      <td>['homogeneity', 'covariance', 'matrix', 'assum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With a CONTRAST statement, you specify L, in t...</td>\n",
       "      <td>AM</td>\n",
       "      <td>1490</td>\n",
       "      <td>['contrast', 'statement', 'specify', 'l', 'cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Author  length  \\\n",
       "0  Scoring in PROC DISCRIM is as easy as validati...     AM     215   \n",
       "1  In the GLM procedure, you may have used LSMEAN...     AM     782   \n",
       "2  The first problem, accuracy of the data file, ...     AM     990   \n",
       "3  If the homogeneity of covariance matrices assu...     AM     934   \n",
       "4  With a CONTRAST statement, you specify L, in t...     AM    1490   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  ['scoring', 'proc', 'discrim', 'easy', 'valida...  \n",
       "1  ['glm', 'procedure', 'may', 'used', 'lsmeans',...  \n",
       "2  ['first', 'problem', 'accuracy', 'data', 'file...  \n",
       "3  ['homogeneity', 'covariance', 'matrix', 'assum...  \n",
       "4  ['contrast', 'statement', 'specify', 'l', 'cas...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"cleaned_data.csv\", index_col=0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb358af-b319-4e16-983c-fb33a6812ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73052e29-93b2-44cf-9606-c99b705b1a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_train[[\"length\", \"preprocessed_text\"]]\n",
    "y = df_train[[\"Author\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48990a94-6163-43d1-89eb-78e048b839d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train test split on dataset\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=1, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd500e19-d2b5-4849-b843-4a1e255e5d88",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "Creating a validation set from the training data helps ensure that the final test set remains completely unseen, avoiding any data leakage and giving a true measure of the model's performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbb713c1-91fe-48c9-bf08-d7df6068c198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0average', '10th', '10unit', ..., 'zero', 'zip', 'zscores'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['preprocessed_text'])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e77316-0690-4261-a526-97bfa5378d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    The reason TFIDF was used over bag of words is because bag of words just creates a set of embeddings which show the word occurrences whereas TF-IDF shows the relative importance of a term to a document in a collection of documents. While bag of words is easy to interpret, majority of the time TF-IDF performs better in machine learning models\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "array(['0average', '0no', '10th', ..., 'zip', 'zscores', 'zt'],\n",
    "      dtype=object)\n",
    "YOU DIDNT CLEAN PROPERLY \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c60acdf2-599a-4dc8-8610-2491a225b3af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48717892],\n",
       "       [ 1.11741945],\n",
       "       [ 0.73314064],\n",
       "       [ 1.78475241],\n",
       "       [-0.89957569]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_length_scaled = scaler.fit_transform(X_train[['length']])\n",
    "X_train_length_scaled[:5] # printing first 5 responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c40a14d-ebca-4ef0-816b-c3f0b05d416f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "TF-IDF gives out normalized values, this means the other features used should also be scaled to ensure that they are contributing appropriately. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4357ec55-b6d2-4cfc-a2ea-a806b288d08d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<612x5690 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 26959 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine TF-IDF feature with 'length' feature\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_length_scaled])\n",
    "X_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "215f9bc4-d10a-4024-a902-fed3bc117ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doing the same for validation set\n",
    "X_val_tfidf = vectorizer.transform(X_val['preprocessed_text'])\n",
    "X_val_length_scaled = scaler.transform(X_val[['length']])\n",
    "\n",
    "X_val_combined = hstack([X_val_tfidf, X_val_length_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6e0577b-d6c6-4d13-a7eb-20d1c86c8849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<204x5690 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8125 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6355c-de44-41a7-bc26-c3d01baa02e5",
   "metadata": {},
   "source": [
    "## IMPLEMENTING LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ffc6621-3e48-427e-94ab-16abfbcbf6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23ad175e-d338-4c0a-93c7-cd352abaf361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AM       1.00      0.62      0.77        16\n",
      "          CD       0.84      0.93      0.88        44\n",
      "          DM       0.92      0.94      0.93        36\n",
      "          DO       0.92      0.75      0.83        16\n",
      "          FE       0.94      0.97      0.96        35\n",
      "          TK       0.97      1.00      0.98        57\n",
      "\n",
      "    accuracy                           0.92       204\n",
      "   macro avg       0.93      0.87      0.89       204\n",
      "weighted avg       0.93      0.92      0.92       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = logreg.predict(X_val_combined)\n",
    "\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
